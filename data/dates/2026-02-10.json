{
  "date": "2026-02-10",
  "count": 58,
  "papers": [
    {
      "date": "2026-02-10",
      "paper_id": "2602.08222",
      "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
      "authors": [
        "Zehao Chen",
        "Gongxun Li",
        "Tianxiang Ai",
        "Yifei Li",
        "Zixuan Huang",
        "Wang Zhou",
        "Fuzhen Zhuang",
        "Xianglong Liu",
        "Jianxin Li",
        "Deqing Wang",
        "Yikun Ban"
      ],
      "abstract": "WMSS is a post-training paradigm that uses weak model checkpoints to identify and fill learning gaps, enabling continued improvement beyond conventional saturation points in large language models. As post-training optimization becomes central to improving large language models , we observe a persistent saturation bottleneck : once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning , WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.",
      "summary_en": "WMSS is a post-training paradigm that uses weak model checkpoints to identify and fill learning gaps, enabling continued improvement beyond conventional saturation points in large language models.",
      "summary_zh": "WMSS是一种后训练范式，利用弱模型检查点识别并填补学习缺口，使大语言模型能够在超越传统饱和点后仍持续改进。",
      "hf_url": "https://huggingface.co/papers/2602.08222",
      "arxiv_url": "https://arxiv.org/abs/2602.08222",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08222",
      "github_url": "https://github.com/chenzehao82/Weak-Driven-Learning",
      "upvotes": 256,
      "fetched_at": "2026-02-19T06:03:14.229880+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07274",
      "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
      "authors": [
        "Kaijie Zhu",
        "Yuzhou Nie",
        "Yijiang Li",
        "Yiming Huang",
        "Jialian Wu",
        "Jiang Liu",
        "Ximeng Sun",
        "Zhenfei Yin",
        "Lun Wang",
        "Zicheng Liu",
        "Emad Barsoum",
        "William Yang Wang",
        "Wenbo Guo"
      ],
      "abstract": "TermiGen introduces a pipeline for generating verifiable terminal environments and resilient trajectories to improve open-weight LLMs' ability to execute complex tasks and recover from runtime errors. Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch , leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories . Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop . Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles . Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench . This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.",
      "summary_en": "TermiGen introduces a pipeline for generating verifiable terminal environments and resilient trajectories to improve open-weight LLMs' ability to execute complex tasks and recover from runtime errors.",
      "summary_zh": "TermiGen提出了一种生成可验证终端环境与弹性轨迹的流程，旨在提升开放权重LLM执行复杂任务及从运行时错误中恢复的能力。",
      "hf_url": "https://huggingface.co/papers/2602.07274",
      "arxiv_url": "https://arxiv.org/abs/2602.07274",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07274",
      "github_url": "https://github.com/ucsb-mlsec/terminal-bench-env",
      "upvotes": 197,
      "fetched_at": "2026-02-19T06:02:47.360137+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07085",
      "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
      "authors": [
        "Jun Han",
        "Shuo Zhang",
        "Wei Li",
        "Zhi Yang",
        "Yifan Dong",
        "Tu Hu",
        "Jialuo Yuan",
        "Xiaomin Yu",
        "Yumo Zhu",
        "Fangqi Lou",
        "Xin Guo",
        "Zhaowei Liu",
        "Tianyi Jiang",
        "Ruichuan An",
        "Jingping Liu",
        "Biao Wu",
        "Rongze Chen",
        "Kunyi Wang",
        "Yifan Wang",
        "Sen Hu",
        "Xinbing Kong",
        "Liwen Zhang"
      ],
      "abstract": "Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajectory and improves factors through trajectory-level mutation and crossover operations. QuantaAlpha localizes suboptimal steps in each trajectory for targeted revision and recombines complementary high-reward segments to reuse effective patterns, enabling structured exploration and refinement across mining iterations. During factor generation, QuantaAlpha enforces semantic consistency across the hypothesis, factor expression, and executable code, while constraining the complexity and redundancy of the generated factor to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains over strong baseline models and prior agentic systems. When utilizing GPT-5.2, QuantaAlpha achieves an Information Coefficient (IC) of 0.1501, with an Annualized Rate of Return (ARR) of 27.75% and a Maximum Drawdown (MDD) of 7.98%. Moreover, factors mined on CSI 300 transfer effectively to the China Securities Index 500 (CSI 500) and the Standard & Poor's 500 Index (S&P 500), delivering 160% and 137% cumulative excess return over four years, respectively, which indicates strong robustness of QuantaAlpha under market distribution shifts.",
      "summary_en": "Financial markets are noisy and non-stationary, making alpha mining sensitive to backtesting noise and regime shifts, while existing agentic frameworks lack controllable multi-round search and reliable reuse of validated experience. QuantaAlpha addresses these challenges through an evolutionary framework that treats each mining run as a trajectory, improving factors via trajectory-level mutation and crossover operations that localize suboptimal steps for targeted revision and recombine complementary high-reward segments to reuse effective patterns. The framework enforces semantic consistency across hypothesis, factor expression, and executable code while constraining complexity and redundancy to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains, with GPT-5.2 achieving an Information Coefficient (IC) of 0.1501, Annualized Rate of Return (ARR) of 27.75%, and Maximum Drawdown (MDD) of 7.98%, and factors transferring effectively to the China Securities Index 500 (CSI 500) and Standard & Poor's 500 Index (S&P 500) to deliver 160% and 137% cumulative excess return over four years, respectively.",
      "summary_zh": "金融市场具有嘈杂且非平稳的特性，使得阿尔法挖掘对回测噪声和机制转换敏感，而现有的智能体框架缺乏可控的多轮搜索和已验证经验的可靠复用。QuantaAlpha通过进化框架应对这些挑战，将每次挖掘运行视为一条轨迹，通过轨迹级变异和交叉操作来改进因子：前者定位次优步骤以进行针对性修正，后者重组互补的高收益片段以复用有效模式。该框架在假设、因子表达式和可执行代码之间强制保持语义一致性，同时约束复杂度和冗余以缓解拥挤。在沪深300指数（CSI 300）上的大量实验表明性能持续提升，其中GPT-5.2实现了0.1501的信息系数（IC）、27.75%的年化收益率（ARR）和7.98%的最大回撤（MDD）；因子有效迁移至中证500指数（CSI 500）和标普500指数（S&P 500），四年内分别实现160%和137%的累计超额收益。",
      "hf_url": "https://huggingface.co/papers/2602.07085",
      "arxiv_url": "https://arxiv.org/abs/2602.07085",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07085",
      "github_url": "https://github.com/QuantaAlpha/QuantaAlpha",
      "upvotes": 181,
      "fetched_at": "2026-02-19T06:02:36.702701+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08794",
      "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
      "authors": [
        "SII-OpenMOSS Team",
        "Donghua Yu",
        "Mingshu Chen",
        "Qi Chen",
        "Qi Luo",
        "Qianyi Wu",
        "Qinyuan Cheng",
        "Ruixiao Li",
        "Tianyi Liang",
        "Wenbo Zhang",
        "Wenming Tu",
        "Xiangyu Peng",
        "Yang Gao",
        "Yanru Huo",
        "Ying Zhu",
        "Yinze Luo",
        "Yiyang Zhang",
        "Yuerong Song",
        "Zhe Xu",
        "Zhiyu Zhang",
        "Chenchen Yang",
        "Cheng Chang"
      ],
      "abstract": "MOVA is an open-source model that generates synchronized audio-visual content using a Mixture-of-Experts architecture with 32 billion parameters, supporting image-text to video-audio generation tasks. Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content , including realistic lip-synced speech , environment-aware sound effects , and content-aligned music . MOVA employs a Mixture-of-Experts ( MoE ) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference , LoRA fine-tuning , and prompt enhancement .",
      "summary_en": "MOVA is an open-source model that generates synchronized audio-visual content using a Mixture-of-Experts architecture with 32 billion parameters, supporting image-text to video-audio generation tasks.",
      "summary_zh": "MOVA是一款采用混合专家（Mixture-of-Experts）架构、拥有320亿参数的开源模型，可生成同步的音视频内容，支持图文到音视频生成任务。",
      "hf_url": "https://huggingface.co/papers/2602.08794",
      "arxiv_url": "https://arxiv.org/abs/2602.08794",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08794",
      "github_url": "https://github.com/OpenMOSS/MOVA",
      "upvotes": 151,
      "fetched_at": "2026-02-19T06:03:32.240922+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07026",
      "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "authors": [
        "Xiaomin Yu",
        "Yi Xin",
        "Wenjie Zhang",
        "Chonghan Liu",
        "Hanzhen Zhao",
        "Xiaoxing Hu",
        "Xinlei Yu",
        "Ziyue Qiao",
        "Hao Tang",
        "Xue Yang",
        "Xiaobin Hu",
        "Chengwei Qin",
        "Hui Xiong",
        "Yu Qiao",
        "Shuicheng Yan"
      ],
      "abstract": "Researchers address the modality gap in multimodal learning by proposing a fixed-frame theory and a training-free alignment method that enables efficient scaling of multimodal models using unpaired data. Despite the success of multimodal contrastive learning in aligning visual and linguistic representations, a persistent geometric anomaly , the Modality Gap , remains: embeddings of distinct modalities expressing identical semantics occupy systematically offset regions. Prior approaches to bridge this gap are largely limited by oversimplified isotropic assumptions , hindering their application in large-scale scenarios. In this paper, we address these limitations by precisely characterizing the geometric shape of the modality gap and leveraging it for efficient model scaling. First, we propose the Fixed-frame Modality Gap Theory , which decomposes the modality gap within a frozen reference frame into stable biases and anisotropic residuals. Guided by this precise modeling, we introduce ReAlign , a training-free modality alignment strategy. Utilizing statistics from massive unpaired data , ReAlign aligns text representation into the image representation distribution via a three-step process comprising Anchor, Trace, and Centroid Alignment , thereby explicitly rectifying geometric misalignment. Building on ReAlign , we propose ReVision , a scalable training paradigm for Multimodal Large Language Models (MLLMs). ReVision integrates ReAlign into the pretraining stage , enabling the model to learn the distribution of visual representations from unpaired text before visual instruction tuning , without the need for large-scale, high-quality image-text pairs. Our framework demonstrates that statistically aligned unpaired data can effectively substitute for expensive image-text pairs, offering a robust path for the efficient scaling of MLLMs.",
      "summary_en": "Researchers address the modality gap in multimodal learning by proposing a fixed-frame theory and a training-free alignment method that enables efficient scaling of multimodal models using unpaired data.",
      "summary_zh": "研究人员提出了固定帧理论和免训练对齐方法，以解决多模态学习中的模态差距，实现了利用非配对数据高效扩展多模态模型。",
      "hf_url": "https://huggingface.co/papers/2602.07026",
      "arxiv_url": "https://arxiv.org/abs/2602.07026",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07026",
      "github_url": "https://github.com/Yu-xm/ReVision",
      "upvotes": 133,
      "fetched_at": "2026-02-19T06:02:23.335532+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06855",
      "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
      "authors": [
        "Alisia Lupidi",
        "Bhavul Gauri",
        "Thomas Simon Foster",
        "Bassel Al Omari",
        "Despoina Magka",
        "Alberto Pepe",
        "Alexis Audran-Reiss",
        "Muna Aghamelu",
        "Nicolas Baldwin",
        "Lucia Cipolina-Kun",
        "Jean-Christophe Gagnon-Audet",
        "Chee Hau Leow",
        "Sandra Lefdal",
        "Hossam Mossalam",
        "Abhinav Moudgil",
        "Saba Nazir",
        "Emanuel Tewolde",
        "Isabel Urrego",
        "Jordi Armengol Estape",
        "Amar Budhiraja",
        "Gaurav Chaurasia",
        "Abhishek Charnalia"
      ],
      "abstract": "AIRS-Bench presents a comprehensive benchmark suite for evaluating LLM agents across diverse scientific domains, demonstrating current limitations while providing open-source resources for advancement. LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark ), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including idea generation, experiment analysis and iterative refinement -- without providing baseline code. The AIRS-Bench task format is versatile, enabling easy integration of new tasks and rigorous comparison across different agentic frameworks. We establish baselines using frontier models paired with both sequential and parallel scaffolds . Our results show that agents exceed human SOTA in four tasks but fail to match it in sixteen others. Even when agents surpass human benchmarks, they do not reach the theoretical performance ceiling for the underlying tasks. These findings indicate that AIRS-Bench is far from saturated and offers substantial room for improvement. We open-source the AIRS-Bench task definitions and evaluation code to catalyze further development in autonomous scientific research.",
      "summary_en": "AIRS-Bench presents a comprehensive benchmark suite for evaluating LLM agents across diverse scientific domains, demonstrating current limitations while providing open-source resources for advancement.",
      "summary_zh": "AIRS-Bench提出了一个全面的基准测试套件，用于评估跨多个科学领域的LLM智能体，揭示当前局限性并提供开源资源以推动发展。",
      "hf_url": "https://huggingface.co/papers/2602.06855",
      "arxiv_url": "https://arxiv.org/abs/2602.06855",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06855",
      "github_url": "https://github.com/facebookresearch/airs-bench",
      "upvotes": 70,
      "fetched_at": "2026-02-19T06:02:18.646878+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08990",
      "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
      "authors": [
        "Shiyang Feng",
        "Runmin Ma",
        "Xiangchao Yan",
        "Yue Fan",
        "Yusong Hu",
        "Songtao Huang",
        "Shuaiyu Zhang",
        "Zongsheng Cao",
        "Tianshuo Peng",
        "Jiakang Yuan",
        "Zijie Guo",
        "Zhijie Zhong",
        "Shangheng Du",
        "Weida Wang",
        "Jinxin Shi",
        "Yuhao Zhou",
        "Xiaohan He",
        "Zhiyin Yu",
        "Fangchen Yu",
        "Qihao Zheng",
        "Jiamin Wu",
        "Mianxin Liu"
      ],
      "abstract": "InternAgent-1.5 is a unified system for autonomous scientific discovery that integrates computational modeling and experimental research through coordinated subsystems for generation, verification, and evolution. We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research , solution optimization , and long horizon memory . The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system . We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery .",
      "summary_en": "InternAgent-1.5 is a unified system for autonomous scientific discovery that integrates computational modeling and experimental research through coordinated subsystems for generation, verification, and evolution.",
      "summary_zh": "InternAgent-1.5是一个统一的自主科学发现系统，通过协调的生成、验证与演化子系统集成计算建模与实验研究。",
      "hf_url": "https://huggingface.co/papers/2602.08990",
      "arxiv_url": "https://arxiv.org/abs/2602.08990",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08990",
      "github_url": "https://github.com/InternScience/InternAgent",
      "upvotes": 69,
      "fetched_at": "2026-02-19T06:03:43.577684+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07845",
      "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning",
      "authors": [
        "Yalcin Tur",
        "Jalal Naghiyev",
        "Haoquan Fang",
        "Wei-Chuan Tsai",
        "Jiafei Duan",
        "Dieter Fox",
        "Ranjay Krishna"
      ],
      "abstract": "RD-VLA introduces a recurrent architecture for vision-language-action models that adapts computational depth through latent iterative refinement, achieving constant memory usage and improved task success rates. Current Vision-Language-Action (VLA) models rely on fixed computational depth, expending the same amount of compute on simple adjustments and complex multi-step manipulation. While Chain-of-Thought (CoT) prompting enables variable computation, it scales memory linearly and is ill-suited for continuous action spaces. We introduce Recurrent-Depth VLA (RD-VLA), an architecture that achieves computational adaptivity via latent iterative refinement rather than explicit token generation. RD-VLA employs a recurrent, weight-tied action head that supports arbitrary inference depth with a constant memory footprint. The model is trained using truncated backpropagation through time (TBPTT) to efficiently supervise the refinement process. At inference, RD-VLA dynamically allocates compute using an adaptive stopping criterion based on latent convergence . Experiments on challenging manipulation tasks show that recurrent depth is critical: tasks that fail entirely (0 percent success) with single-iteration inference exceed 90 percent success with four iterations, while simpler tasks saturate rapidly. RD-VLA provides a scalable path to test-time compute in robotics, replacing token-based reasoning with latent reasoning to achieve constant memory usage and up to 80x inference speedup over prior reasoning-based VLA models. Project page: https://rd-vla.github.io/",
      "summary_en": "RD-VLA introduces a recurrent architecture for vision-language-action models that adapts computational depth through latent iterative refinement, achieving constant memory usage and improved task success rates.",
      "summary_zh": "RD-VLA 为视觉-语言-动作模型引入了一种循环架构，通过潜在迭代细化自适应调整计算深度，实现了恒定内存占用并提升了任务成功率。",
      "hf_url": "https://huggingface.co/papers/2602.07845",
      "arxiv_url": "https://arxiv.org/abs/2602.07845",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07845",
      "github_url": "https://github.com/rd-vla/rd-vla",
      "upvotes": 68,
      "fetched_at": "2026-02-19T06:03:00.977675+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08676",
      "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
      "authors": [
        "Tiwei Bie",
        "Maosong Cao",
        "Xiang Cao",
        "Bingsen Chen",
        "Fuyuan Chen",
        "Kun Chen",
        "Lun Du",
        "Daozhuo Feng",
        "Haibo Feng",
        "Mingliang Gong",
        "Zhuocheng Gong",
        "Yanmei Gu",
        "Jian Guan",
        "Kaiyuan Guan",
        "Hongliang He",
        "Zenan Huang",
        "Juyong Jiang",
        "Zhonghui Jiang",
        "Zhenzhong Lan",
        "Chengxi Li",
        "Jianguo Li",
        "Zehuan Li"
      ],
      "abstract": "LLaDA2.1 introduces a novel token-to-token editing approach with speed and quality modes, enhanced through reinforcement learning for improved reasoning and instruction following in large language diffusion models. While LLaDA2.0 showcased the scaling potential of 100B-level block-diffusion models and their inherent parallelization, the delicate equilibrium between decoding speed and generation quality has remained an elusive frontier. Today, we unveil LLaDA2.1, a paradigm shift designed to transcend this trade-off. By seamlessly weaving Token-to-Token (T2T) editing into the conventional Mask-to-Token (M2T) scheme, we introduce a joint, configurable threshold-decoding scheme . This structural innovation gives rise to two distinct personas: the Speedy Mode (S Mode), which audaciously lowers the M2T threshold to bypass traditional constraints while relying on T2T to refine the output; and the Quality Mode (Q Mode), which leans into conservative thresholds to secure superior benchmark performances with manageable efficiency degrade. Furthering this evolution, underpinned by an expansive context window, we implement the first large-scale Reinforcement Learning (RL) framework specifically tailored for dLLMs, anchored by specialized techniques for stable gradient estimation . This alignment not only sharpens reasoning precision but also elevates instruction-following fidelity, bridging the chasm between diffusion dynamics and complex human intent. We culminate this work by releasing LLaDA2.1-Mini (16B) and LLaDA2.1-Flash (100B). Across 33 rigorous benchmarks, LLaDA2.1 delivers strong task performance and lightning-fast decoding speed . Despite its 100B volume, on coding tasks it attains an astounding 892 TPS on HumanEval+ , 801 TPS on BigCodeBench , and 663 TPS on LiveCodeBench .",
      "summary_en": "LLaDA2.1 introduces a novel token-to-token editing approach with speed and quality modes, enhanced through reinforcement learning for improved reasoning and instruction following in large language diffusion models.",
      "summary_zh": "LLaDA2.1提出了一种新颖的token-to-token编辑方法，具备速度和质量模式，并通过强化学习增强，以提升大型语言扩散模型的推理与指令遵循能力。",
      "hf_url": "https://huggingface.co/papers/2602.08676",
      "arxiv_url": "https://arxiv.org/abs/2602.08676",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08676",
      "github_url": "https://github.com/inclusionAI/LLaDA2.X",
      "upvotes": 66,
      "fetched_at": "2026-02-19T06:03:30.274297+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07837",
      "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI",
      "authors": [
        "Hongzhi Zang",
        "Shu'ang Yu",
        "Hao Lin",
        "Tianxing Zhou",
        "Zefang Huang",
        "Zhen Guo",
        "Xin Xu",
        "Jiakai Zhou",
        "Yuze Sheng",
        "Shizhe Zhang",
        "Feng Gao",
        "Wenhao Tang",
        "Yufeng Yue",
        "Quanlu Zhang",
        "Xinlei Chen",
        "Chao Yu",
        "Yu Wang"
      ],
      "abstract": "USER is a unified systems framework that enables scalable, asynchronous online policy learning in physical robots by treating them as first-class hardware resources and supporting diverse learning paradigms including VLA models. Online policy learning directly in the physical world is a promising yet challenging direction for embodied intelligence . Unlike simulation, real-world systems cannot be arbitrarily accelerated, cheaply reset, or massively replicated, which makes scalable data collection, heterogeneous deployment, and long-horizon effective training difficult. These challenges suggest that real-world policy learning is not only an algorithmic issue but fundamentally a systems problem. We present USER, a Unified and extensible SystEm for Real-world online policy learning . USER treats physical robots as first-class hardware resources alongside GPUs through a unified hardware abstraction layer , enabling automatic discovery, management, and scheduling of heterogeneous robots . To address cloud-edge communication, USER introduces an adaptive communication plane with tunneling-based networking , distributed data channels for traffic localization, and streaming-multiprocessor-aware weight synchronization to regulate GPU-side overhead. On top of this infrastructure, USER organizes learning as a fully asynchronous framework with a persistent, cache-aware buffer , enabling efficient long-horizon experiments with robust crash recovery and reuse of historical data. In addition, USER provides extensible abstractions for rewards, algorithms, and policies, supporting online imitation or reinforcement learning of CNN/MLP, generative policies, and large vision-language-action (VLA) models within a unified pipeline. Results in both simulation and the real world show that USER enables multi-robot coordination , heterogeneous manipulators, edge-cloud collaboration with large models, and long-running asynchronous training, offering a unified and extensible systems foundation for real-world online policy learning .",
      "summary_en": "USER is a unified systems framework that enables scalable, asynchronous online policy learning in physical robots by treating them as first-class hardware resources and supporting diverse learning paradigms including VLA models.",
      "summary_zh": "USER是一个统一的系统框架，通过将物理机器人视为一等硬件资源并支持包括VLA模型在内的多种学习范式，实现可扩展的异步在线策略学习。",
      "hf_url": "https://huggingface.co/papers/2602.07837",
      "arxiv_url": "https://arxiv.org/abs/2602.07837",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07837",
      "github_url": "",
      "upvotes": 53,
      "fetched_at": "2026-02-19T06:02:58.626380+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.00169",
      "title": "Towards Agentic Intelligence for Materials Science",
      "authors": [
        "Huan Zhang",
        "Yizhan Li",
        "Wenhao Huang",
        "Ziyu Hou",
        "Yu Song",
        "Xuye Liu",
        "Farshid Effaty",
        "Jinya Jiang",
        "Sifan Wu",
        "Qianggang Ding",
        "Izumi Takahara",
        "Leonard R. MacGillivray",
        "Teruyasu Mizoguchi",
        "Tianshu Yu",
        "Lizi Liao",
        "Yuyu Luo",
        "Yu Rong",
        "Jia Li",
        "Ying Diao",
        "Heng Ji",
        "Bang Liu"
      ],
      "abstract": "AI-driven materials science integrates large language models across discovery pipelines from data curation to agent-based experimentation, emphasizing system-level optimization and autonomous goal pursuit. The convergence of artificial intelligence and materials science presents a transformative opportunity, but achieving true acceleration in discovery requires moving beyond task-isolated, fine-tuned models toward agentic systems that plan, act, and learn across the full discovery loop. This survey advances a unique pipeline-centric view that spans from corpus curation and pretraining, through domain adaptation and instruction tuning , to goal-conditioned agents interfacing with simulation and experimental platforms . Unlike prior reviews, we treat the entire process as an end-to-end system to be optimized for tangible discovery outcomes rather than proxy benchmarks. This perspective allows us to trace how upstream design choices-such as data curation and training objectives-can be aligned with downstream experimental success through effective credit assignment . To bridge communities and establish a shared frame of reference, we first present an integrated lens that aligns terminology, evaluation, and workflow stages across AI and materials science . We then analyze the field through two focused lenses: From the AI perspective, the survey details LLM strengths in pattern recognition , predictive analytics , and natural language processing for literature mining , materials characterization , and property prediction ; from the materials science perspective, it highlights applications in materials design , process optimization , and the acceleration of computational workflows via integration with external tools (e.g., DFT , robotic labs ). Finally, we contrast passive, reactive approaches with agentic design, cataloging current contributions while motivating systems that pursue long-horizon goals with autonomy, memory, and tool use. This survey charts a practical roadmap towards autonomous, safety-aware LLM agents aimed at discovering novel and useful materials.",
      "summary_en": "AI-driven materials science integrates large language models across discovery pipelines from data curation to agent-based experimentation, emphasizing system-level optimization and autonomous goal pursuit.",
      "summary_zh": "AI驱动的材料科学将大语言模型整合到从数据整理到基于智能体的实验的发现流程中，强调系统级优化和自主目标追求。",
      "hf_url": "https://huggingface.co/papers/2602.00169",
      "arxiv_url": "https://arxiv.org/abs/2602.00169",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.00169",
      "github_url": "",
      "upvotes": 46,
      "fetched_at": "2026-02-19T06:01:47.182578+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06422",
      "title": "Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO",
      "authors": [
        "Yunze Tong",
        "Mushui Liu",
        "Canyu Zhao",
        "Wanggui He",
        "Shiyi Zhang",
        "Hongwei Zhang",
        "Peng Zhang",
        "Jinlong Liu",
        "Ju Huang",
        "Jiamang Wang",
        "Hao Jiang",
        "Pipei Huang"
      ],
      "abstract": "TP-GRPO addresses reward sparsity in flow matching models by introducing step-level incremental rewards and identifying turning points to capture long-term effects in denoising trajectories. Deploying GRPO on Flow Matching models has proven effective for text-to-image generation . However, existing paradigms typically propagate an outcome-based reward to all preceding denoising steps without distinguishing the local effect of each step. Moreover, current group-wise ranking mainly compares trajectories at matched timesteps and ignores within-trajectory dependencies, where certain early denoising actions can affect later states via delayed, implicit interactions. We propose TurningPoint- GRPO (TP- GRPO ), a GRPO framework that alleviates step-wise reward sparsity and explicitly models long-term effects within the denoising trajectory . TP- GRPO makes two key innovations: (i) it replaces outcome-based rewards with step-level incremental rewards , providing a dense, step-aware learning signal that better isolates each denoising action's \"pure\" effect, and (ii) it identifies turning points -steps that flip the local reward trend and make subsequent reward evolution consistent with the overall trajectory trend-and assigns these actions an aggregated long-term reward to capture their delayed impact . Turning points are detected solely via sign changes in incremental rewards , making TP- GRPO efficient and hyperparameter-free. Extensive experiments also demonstrate that TP- GRPO exploits reward signals more effectively and consistently improves generation. Demo code is available at https://github.com/YunzeTong/TurningPoint- GRPO .",
      "summary_en": "TP-GRPO addresses reward sparsity in flow matching models by introducing step-level incremental rewards and identifying turning points to capture long-term effects in denoising trajectories.",
      "summary_zh": "TP-GRPO通过引入步骤级增量奖励并识别转折点，解决流匹配模型中的奖励稀疏性问题，从而捕捉去噪轨迹中的长期效应。",
      "hf_url": "https://huggingface.co/papers/2602.06422",
      "arxiv_url": "https://arxiv.org/abs/2602.06422",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06422",
      "github_url": "https://github.com/YunzeTong/TurningPoint-GRPO",
      "upvotes": 42,
      "fetched_at": "2026-02-19T06:02:05.419662+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08321",
      "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
      "authors": [
        "Zijie Chen",
        "Zhenghao Lin",
        "Xiao Liu",
        "Zhenzhong Lan",
        "Yeyun Gong",
        "Peng Cheng"
      ],
      "abstract": "A large-scale scientific question dataset and post-training pipeline are developed to improve open-ended science question answering through enhanced data processing and reinforcement learning with rubric-guided evaluation. Solving open-ended science questions remains challenging for large language models , particula rl y due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset , which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT , which broadens the model's reasoning pattern coverage prior to RL ; (ii) Dynamic Difficulty Curriculum , which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL , which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr. SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general , consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning , especially in open-ended settings.",
      "summary_en": "A large-scale scientific question dataset and post-training pipeline are developed to improve open-ended science question answering through enhanced data processing and reinforcement learning with rubric-guided evaluation.",
      "summary_zh": "开发了大规模科学问答数据集与后训练流程，通过增强的数据处理及基于评分标准评估的强化学习，改进开放式科学问答。",
      "hf_url": "https://huggingface.co/papers/2602.08321",
      "arxiv_url": "https://arxiv.org/abs/2602.08321",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08321",
      "github_url": "",
      "upvotes": 40,
      "fetched_at": "2026-02-19T06:03:18.766224+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.09007",
      "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
      "authors": [
        "Haodong Li",
        "Jingwei Wu",
        "Quan Sun",
        "Guopeng Li",
        "Juanxi Tian",
        "Huanyu Zhang",
        "Yanlin Lai",
        "Ruichuan An",
        "Hongbo Peng",
        "Yuhong Dai",
        "Chenxi Li",
        "Chunmei Qing",
        "Jia Wang",
        "Ziyang Meng",
        "Zheng Ge",
        "Xiangyu Zhang",
        "Daxin Jiang"
      ],
      "abstract": "A new benchmark and evaluation metric are introduced for assessing temporal coherence and dynamic interaction in GUI generation models, revealing significant challenges in maintaining consistency over extended interaction sequences. Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity , leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench , a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation . GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score , a novel five-dimensional metric that assesses Goal Achievement , Interaction Logic , Content Consistency , UI Plausibility , and Visual Quality . Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/ GEBench .",
      "summary_en": "A new benchmark and evaluation metric are introduced for assessing temporal coherence and dynamic interaction in GUI generation models, revealing significant challenges in maintaining consistency over extended interaction sequences.",
      "summary_zh": "研究者引入了新的基准测试与评估指标，用于评估GUI生成模型的时间连贯性与动态交互，揭示了在扩展交互序列中保持一致性方面存在重大挑战。",
      "hf_url": "https://huggingface.co/papers/2602.09007",
      "arxiv_url": "https://arxiv.org/abs/2602.09007",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.09007",
      "github_url": "https://github.com/stepfun-ai/GEBench",
      "upvotes": 38,
      "fetched_at": "2026-02-19T06:03:47.845871+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08439",
      "title": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
      "authors": [
        "Yuhao Dong",
        "Shulin Tian",
        "Shuai Liu",
        "Shuangrui Ding",
        "Yuhang Zang",
        "Xiaoyi Dong",
        "Yuhang Cao",
        "Jiaqi Wang",
        "Ziwei Liu"
      ],
      "abstract": "Researchers introduce a new video understanding task and benchmark that evaluates models' ability to learn from few-shot demonstrations, along with a specialized MLLM architecture trained using a two-stage approach combining video supervision and preference optimization. Despite the growing video understanding capabilities of recent Multimodal Large Language Models (MLLMs), existing video benchmarks primarily assess understanding based on models' static, internal knowledge, rather than their ability to learn and adapt from dynamic, novel contexts from few examples. To bridge this gap, we present Demo-driven Video In-Context Learning , a novel task focused on learning from in-context demonstrations to answer questions about the target videos. Alongside this, we propose Demo-ICL-Bench , a challenging benchmark designed to evaluate demo-driven video in-context learning capabilities. Demo-ICL-Bench is constructed from 1200 instructional YouTube videos with associated questions, from which two types of demonstrations are derived: (i) summarizing video subtitles for text demonstration; and (ii) corresponding instructional videos as video demonstrations. To effectively tackle this new challenge, we develop Demo-ICL, an MLLM with a two-stage training strategy: video-supervised fine-tuning and information-assisted direct preference optimization , jointly enhancing the model's ability to learn from in-context examples. Extensive experiments with state-of-the-art MLLMs confirm the difficulty of Demo-ICL-Bench , demonstrate the effectiveness of Demo-ICL, and thereby unveil future research directions.",
      "summary_en": "Researchers introduce a new video understanding task and benchmark that evaluates models' ability to learn from few-shot demonstrations, along with a specialized MLLM architecture trained using a two-stage approach combining video supervision and preference optimization.",
      "summary_zh": "研究人员提出了一项用于评估模型从少样本示例中学习能力的视频理解任务与基准，以及一种采用视频监督与偏好优化两阶段训练方法的专用MLLM架构。",
      "hf_url": "https://huggingface.co/papers/2602.08439",
      "arxiv_url": "https://arxiv.org/abs/2602.08439",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08439",
      "github_url": "https://github.com/dongyh20/Demo-ICL",
      "upvotes": 28,
      "fetched_at": "2026-02-19T06:03:20.893592+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06025",
      "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
      "authors": [
        "Haozhen Zhang",
        "Haodong Yue",
        "Tao Feng",
        "Quanyu Long",
        "Jianzhu Bao",
        "Bowen Jin",
        "Weizhi Zhang",
        "Xiao Li",
        "Jiaxuan You",
        "Chengwei Qin",
        "Wenya Wang"
      ],
      "abstract": "BudgetMem is a runtime memory framework for LLM agents that uses modular components with three budget tiers and a neural policy router to optimize performance-cost trade-offs in memory usage. Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present BudgetMem, a runtime agent memory framework for explicit, query-aware performance-cost control . BudgetMem structures memory processing as a set of memory modules , each offered in three budget tiers (i.e., Low/Mid/High). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning . Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers : implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo , LongMemEval , and HotpotQA , BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.",
      "summary_en": "BudgetMem is a runtime memory framework for LLM agents that uses modular components with three budget tiers and a neural policy router to optimize performance-cost trade-offs in memory usage.",
      "summary_zh": "BudgetMem是一种面向LLM智能体的运行时内存框架，采用包含三级预算层级的模块化组件和神经策略路由器，以优化内存使用中的性能与成本权衡。",
      "hf_url": "https://huggingface.co/papers/2602.06025",
      "arxiv_url": "https://arxiv.org/abs/2602.06025",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06025",
      "github_url": "https://github.com/ViktorAxelsen/BudgetMem",
      "upvotes": 27,
      "fetched_at": "2026-02-19T06:02:03.049606+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08543",
      "title": "GISA: A Benchmark for General Information-Seeking Assistant",
      "authors": [
        "Yutao Zhu",
        "Xingshuo Zhang",
        "Maosen Zhang",
        "Jiajie Jin",
        "Liancheng Zhang",
        "Xiaoshuai Song",
        "Kangzhi Zhao",
        "Wencong Zeng",
        "Ruiming Tang",
        "Han Li",
        "Ji-Rong Wen",
        "Zhicheng Dou"
      ],
      "abstract": "A new benchmark called GISA is introduced for evaluating information-seeking assistants, featuring human-crafted queries with structured answer formats and live updates to prevent memorization. The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\\% exact match score , with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.",
      "summary_en": "A new benchmark called GISA is introduced for evaluating information-seeking assistants, featuring human-crafted queries with structured answer formats and live updates to prevent memorization.",
      "summary_zh": "新基准 GISA 用于评估信息检索助手，具有人工编写的查询、结构化答案格式和实时更新机制，以防止记忆。",
      "hf_url": "https://huggingface.co/papers/2602.08543",
      "arxiv_url": "https://arxiv.org/abs/2602.08543",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08543",
      "github_url": "https://github.com/RUC-NLPIR/GISA",
      "upvotes": 26,
      "fetched_at": "2026-02-19T06:03:22.996714+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07962",
      "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
      "authors": [
        "Weihao Zeng",
        "Yuzhen Huang",
        "Junxian He"
      ],
      "abstract": "LOCA-bench is introduced as a benchmark for evaluating language agents in long-context, agentic scenarios with controlled environment state management. Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \" context rot \". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies . While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: https://github.com/hkust-nlp/ LOCA-bench",
      "summary_en": "LOCA-bench is introduced as a benchmark for evaluating language agents in long-context, agentic scenarios with controlled environment state management.",
      "summary_zh": "LOCA-bench 被提出作为评估语言智能体的基准，针对具备受控环境状态管理的长上下文智能体场景。",
      "hf_url": "https://huggingface.co/papers/2602.07962",
      "arxiv_url": "https://arxiv.org/abs/2602.07962",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07962",
      "github_url": "https://github.com/hkust-nlp/LOCA-bench",
      "upvotes": 24,
      "fetched_at": "2026-02-19T06:03:05.810265+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07055",
      "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
      "authors": [
        "Pingyue Zhang",
        "Zihan Huang",
        "Yue Wang",
        "Jieyu Zhang",
        "Letian Xue",
        "Zihan Wang",
        "Qineng Wang",
        "Keshigeyan Chandrasegaran",
        "Ruohan Zhang",
        "Yejin Choi",
        "Ranjay Krishna",
        "Jiajun Wu",
        "Li Fei-Fei",
        "Manling Li"
      ],
      "abstract": "Current multimodal foundation models show limitations in maintaining coherent spatial beliefs during active exploration, exhibiting gaps between active and passive performance, inefficient exploration strategies, and difficulties in updating outdated spatial knowledge. Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing , which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap , where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia , where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models . Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial belief s during active exploration .",
      "summary_en": "Current multimodal foundation models show limitations in maintaining coherent spatial beliefs during active exploration, exhibiting gaps between active and passive performance, inefficient exploration strategies, and difficulties in updating outdated spatial knowledge.",
      "summary_zh": "当前多模态基础模型在主动探索过程中维持连贯空间信念方面存在局限性，表现出主动与被动性能差距、探索策略低效以及更新过时空间知识困难等问题。",
      "hf_url": "https://huggingface.co/papers/2602.07055",
      "arxiv_url": "https://arxiv.org/abs/2602.07055",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07055",
      "github_url": "https://github.com/mll-lab-nu/Theory-of-Space",
      "upvotes": 22,
      "fetched_at": "2026-02-19T06:02:29.766955+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06540",
      "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research",
      "authors": [
        "Yishan Li",
        "Wentong Chen",
        "Yukun Yan",
        "Mingwei Li",
        "Sen Mei",
        "Xiaorong Wang",
        "Kunpeng Liu",
        "Xin Cong",
        "Shuo Wang",
        "Zhong Zhang",
        "Yaxi Lu",
        "Zhenghao Liu",
        "Yankai Lin",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "",
      "summary_en": "AgentCPM-Report是由 THUNLP 、中国人民大学 RUCBM 和 ModelBest 联合开发的开源大语言模型智能体。它基于 MiniCPM4.1 80亿参数基座模型，接受用户指令作为输入，自主生成长篇报告。其有以下亮点：",
      "summary_zh": "AgentCPM-Report是由THUNLP、中国人民大学RUCBM和ModelBest联合开发的开源大语言模型智能体。它基于MiniCPM4.1 80亿参数基座模型，接受用户指令作为输入，自主生成长篇报告。其有以下亮点：",
      "hf_url": "https://huggingface.co/papers/2602.06540",
      "arxiv_url": "https://arxiv.org/abs/2602.06540",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06540",
      "github_url": "https://github.com/OpenBMB/AgentCPM",
      "upvotes": 21,
      "fetched_at": "2026-02-19T06:02:12.686518+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.09022",
      "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "authors": [
        "Zehan Wang",
        "Tengfei Wang",
        "Haiyu Zhang",
        "Xuhui Zuo",
        "Junta Wu",
        "Haoyuan Wang",
        "Wenqiang Sun",
        "Zhenwei Wang",
        "Chenjie Cao",
        "Hengshuang Zhao",
        "Chunchao Guo",
        "Zhou Zhao"
      ],
      "abstract": "WorldCompass enhances long-horizon video-based world models through reinforcement learning post-training with clip-level rollouts, complementary rewards, and efficient RL algorithms. This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models , enabling them to explore the world more accurately and consistently based on interaction signals. To effectively \"steer\" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy : We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions : We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.",
      "summary_en": "WorldCompass enhances long-horizon video-based world models through reinforcement learning post-training with clip-level rollouts, complementary rewards, and efficient RL algorithms.",
      "summary_zh": "WorldCompass 通过采用片段级 rollout、互补奖励和高效 RL 算法的强化学习后训练，增强基于视频的长程世界模型。",
      "hf_url": "https://huggingface.co/papers/2602.09022",
      "arxiv_url": "https://arxiv.org/abs/2602.09022",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.09022",
      "github_url": "",
      "upvotes": 20,
      "fetched_at": "2026-02-19T06:03:50.195696+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07075",
      "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
      "authors": [
        "Xinwu Ye",
        "Yicheng Mao",
        "Jia Zhang",
        "Yimeng Liu",
        "Li Hao",
        "Fang Wu",
        "Zhiwei Li",
        "Yuxuan Liao",
        "Zehong Wang",
        "Zhiyuan Liu",
        "Zhenfei Yin",
        "Li Yuan",
        "Philip Torr",
        "Huan Sun",
        "Xiangxiang Zeng",
        "Mengdi Wang",
        "Le Cong",
        "Shenghua Gao",
        "Xiangru Tang"
      ],
      "abstract": "LatentChem enables chemical reasoning through continuous latent space computations instead of discrete textual tokens, achieving superior performance and efficiency compared to traditional chain-of-thought approaches. Chemical large language models (LLMs) predominantly rely on explicit Chain-of-Thought (CoT) in natural language to perform complex reasoning. However, chemical reasoning is inherently continuous and structural, and forcing it into discrete linguistic tokens introduces a fundamental representation mismatch that constrains both efficiency and performance. We introduce LatentChem, a latent reasoning interface that decouples chemical computation from textual generation , enabling models to perform multi-step reasoning directly in continuous latent space while emitting language only for final outputs. Remarkably, we observe a consistent emergent behavior: when optimized solely for task success, models spontaneously internalize reasoning, progressively abandoning verbose textual derivations in favor of implicit latent computation. This shift is not merely stylistic but computationally advantageous. Across diverse chemical reasoning benchmarks, LatentChem achieves a 59.88\\% non-tie win rate over strong CoT-based baselines on ChemCoTBench , while delivering a 10.84times average inference speedup . Our results provide empirical evidence that chemical reasoning is more naturally and effectively realized as continuous latent dynamics rather than discretized linguistic trajectories.",
      "summary_en": "LatentChem enables chemical reasoning through continuous latent space computations instead of discrete textual tokens, achieving superior performance and efficiency compared to traditional chain-of-thought approaches.",
      "summary_zh": "LatentChem通过连续潜在空间计算而非离散文本token实现化学推理，相较于传统思维链方法取得了更优的性能与效率。",
      "hf_url": "https://huggingface.co/papers/2602.07075",
      "arxiv_url": "https://arxiv.org/abs/2602.07075",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07075",
      "github_url": "https://github.com/xinwuye/LatentChem",
      "upvotes": 18,
      "fetched_at": "2026-02-19T06:02:32.477251+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06694",
      "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
      "authors": [
        "Hyochan Chong",
        "Dongkyu Kim",
        "Changdong Kim",
        "Minseop Choi"
      ],
      "abstract": "NanoQuant enables efficient post-training quantization of large language models to binary and sub-1-bit levels using low-rank binary factorization and ADMM optimization, achieving state-of-the-art accuracy while reducing memory requirements for consumer hardware deployment. Weight-only quantization has become a standard approach for efficiently serving large language models (LLMs). However, existing methods fail to efficiently compress models to binary (1-bit) levels, as they either require large amounts of data and compute or incur additional storage. In this work, we propose NanoQuant, the first post-training quantization (PTQ) method to compress LLMs to both binary and sub-1-bit levels. NanoQuant formulates quantization as a low-rank binary factorization problem, and compresses full-precision weights to low-rank binary matrices and scales. Specifically, it utilizes an efficient alternating direction method of multipliers (ADMM) method to precisely initialize latent binary matrices and scales, and then tune the initialized parameters through a block and model reconstruction process. Consequently, NanoQuant establishes a new Pareto frontier in low-memory post-training quantization , achieving state-of-the-art accuracy even at sub-1-bit compression rates. NanoQuant makes large-scale deployment feasible on consumer hardware. For example, it compresses Llama2-70B by 25.8times in just 13 hours on a single H100, enabling a 70B model to operate on a consumer 8 GB GPU.",
      "summary_en": "NanoQuant enables efficient post-training quantization of large language models to binary and sub-1-bit levels using low-rank binary factorization and ADMM optimization, achieving state-of-the-art accuracy while reducing memory requirements for consumer hardware deployment.",
      "summary_zh": "NanoQuant通过低秩二值分解和ADMM优化，实现大语言模型的高效后训练量化至二值及亚1比特级别，在达到最先进精度的同时降低消费级硬件部署的内存需求。",
      "hf_url": "https://huggingface.co/papers/2602.06694",
      "arxiv_url": "https://arxiv.org/abs/2602.06694",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06694",
      "github_url": "",
      "upvotes": 15,
      "fetched_at": "2026-02-19T06:02:16.508724+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.03784",
      "title": "Context Compression via Explicit Information Transmission",
      "authors": [
        "Jiangnan Ye",
        "Hanqi Yan",
        "Zhenyi Shen",
        "Heng Chang",
        "Ye Mao",
        "Yulan He"
      ],
      "abstract": "ComprExIT introduces a novel approach to long-context inference in LLMs by using explicit information transmission over frozen hidden states, improving compression efficiency through depth-wise and width-wise transmission mechanisms. Long-context inference with Large Language Models ( LLMs ) is costly due to quadratic attention and growing key-value caches , motivating context compression. In this work, we study soft context compression , where a long context is condensed into a small set of continuous representations. Existing methods typically re-purpose the LLM itself as a trainable compressor, relying on layer-by-layer self-attention to iteratively aggregate information. We argue that this paradigm suffers from two structural limitations: (i) progressive representation overwriting across layers (ii) uncoordinated allocation of compression capacity across tokens. We propose ComprExIT (Context Compression via Explicit Information Transmission ), a lightweight framework that formulates soft compression into a new paradigm: explicit information transmission over frozen LLM hidden states . This decouples compression from the model's internal self-attention dynamics. ComprExIT performs (i) depth-wise transmission to selectively transmit multi-layer information into token anchors , mitigating progressive overwriting, and (ii) width-wise transmission to aggregate anchors into a small number of slots via a globally optimized transmission plan, ensuring coordinated allocation of information. Across six question-answering benchmarks, ComprExIT consistently outperforms state-of-the-art context compression methods while introducing only ~1% additional parameters, demonstrating that explicit and coordinated information transmission enables more effective and robust long-context compression.",
      "summary_en": "ComprExIT introduces a novel approach to long-context inference in LLMs by using explicit information transmission over frozen hidden states, improving compression efficiency through depth-wise and width-wise transmission mechanisms.",
      "summary_zh": "ComprExIT 提出了一种用于大语言模型长上下文推理的新方法，该方法通过冻结隐状态上的显式信息传输，并借助深度与宽度方向的传输机制来提升压缩效率。",
      "hf_url": "https://huggingface.co/papers/2602.03784",
      "arxiv_url": "https://arxiv.org/abs/2602.03784",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03784",
      "github_url": "",
      "upvotes": 14,
      "fetched_at": "2026-02-19T06:01:53.843519+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08658",
      "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
      "authors": [
        "Mingzi Cao",
        "Xingwei Tan",
        "Mahmud Akhter",
        "Marco Valentino",
        "Maria Liakata",
        "Xi Wang",
        "Nikolaos Aletras"
      ],
      "abstract": "Research investigates how fundamental reasoning paradigms influence large language model generalization through targeted training approaches and evaluation on real-world tasks. Deduction, induction, and abduction are fundamental reasoning paradigms , core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning , and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts . We comprehensively evaluate induced models on realistic out-of-domain tasks , that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to 14.60) across realistic tasks.",
      "summary_en": "Research investigates how fundamental reasoning paradigms influence large language model generalization through targeted training approaches and evaluation on real-world tasks.",
      "summary_zh": "研究通过针对性训练方法和对真实世界任务的评估，探讨基础推理范式如何影响大语言模型的泛化能力。",
      "hf_url": "https://huggingface.co/papers/2602.08658",
      "arxiv_url": "https://arxiv.org/abs/2602.08658",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08658",
      "github_url": "https://github.com/voalmciaf/FR-OOD",
      "upvotes": 13,
      "fetched_at": "2026-02-19T06:03:27.640100+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06454",
      "title": "RelayGen: Intra-Generation Model Switching for Efficient Reasoning",
      "authors": [
        "Jiwon Song",
        "Yoongon Kim",
        "Jae-Joon Kim"
      ],
      "abstract": "RelayGen is a training-free framework that dynamically switches between large and small reasoning models during inference based on segment-level difficulty estimation, achieving faster execution with minimal accuracy loss. Large reasoning models (LRMs) achieve strong performance on complex reasoning tasks by generating long, multi-step reasoning trajectories , but inference-time scaling incurs substantial deployment cost. A key challenge is that generation difficulty varies within a single output, whereas existing efficiency-oriented approaches either ignore this intra-generation variation or rely on supervised token-level routing with high system complexity. We present RelayGen, a training-free, segment-level runtime model switching framework that exploits difficulty variation in long-form reasoning. Through offline analysis of generation uncertainty using token probability margins , we show that coarse-grained segment-level control is sufficient to capture difficulty transitions within a reasoning trajectory. RelayGen identifies model-specific switch cues that signal transitions to lower-difficulty segments and dynamically delegates their continuation to a smaller model, while preserving high-difficulty reasoning on the large model. Across multiple reasoning benchmarks, RelayGen substantially reduces inference latency while preserving most of the accuracy of large models. When combined with speculative decoding , RelayGen achieves up to 2.2times end-to-end speedup with less than 2\\% accuracy degradation, without requiring additional training or learned routing components.",
      "summary_en": "RelayGen is a training-free framework that dynamically switches between large and small reasoning models during inference based on segment-level difficulty estimation, achieving faster execution with minimal accuracy loss.",
      "summary_zh": "RelayGen是一种免训练框架，它基于片段级难度估计在推理过程中动态切换大型与小型推理模型，以极小的精度损失实现更快的执行速度。",
      "hf_url": "https://huggingface.co/papers/2602.06454",
      "arxiv_url": "https://arxiv.org/abs/2602.06454",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06454",
      "github_url": "https://github.com/jiwonsong-dev/RelayGen",
      "upvotes": 11,
      "fetched_at": "2026-02-19T06:02:10.509721+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08236",
      "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
      "authors": [
        "Shoubin Yu",
        "Yue Zhang",
        "Zun Wang",
        "Jaehong Yoon",
        "Huaxiu Yao",
        "Mingyu Ding",
        "Mohit Bansal"
      ],
      "abstract": "Adaptive test-time framework with world models enables selective visual imagination for spatial reasoning, improving efficiency and reliability by determining when imagination is necessary. Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination , but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. In practice, indiscriminate imagination can increase computation and even degrade performance by introducing misleading evidence. In this work, we present an in-depth analysis of test-time visual imagination as a controllable resource for spatial reasoning. We study when static visual evidence is sufficient, when imagination improves reasoning, and how excessive or unnecessary imagination affects accuracy and efficiency. To support this analysis, we introduce AVIC, an adaptive test-time framework with world models that explicitly reasons about the sufficiency of current visual evidence before selectively invoking and scaling visual imagination . Across spatial reasoning benchmarks ( SAT , MMSI ) and an embodied navigation benchmark ( R2R ), our results reveal clear scenarios where imagination is critical, marginal, or detrimental, and show that selective control can match or outperform fixed imagination strategies with substantially fewer world-model calls and language tokens. Overall, our findings highlight the importance of analyzing and controlling test-time imagination for efficient and reliable spatial reasoning.",
      "summary_en": "Adaptive test-time framework with world models enables selective visual imagination for spatial reasoning, improving efficiency and reliability by determining when imagination is necessary.",
      "summary_zh": "结合世界模型的自适应测试时框架支持选择性视觉想象以进行空间推理，通过判断何时需要想象来提高效率与可靠性。",
      "hf_url": "https://huggingface.co/papers/2602.08236",
      "arxiv_url": "https://arxiv.org/abs/2602.08236",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08236",
      "github_url": "https://github.com/Yui010206/Adaptive-Visual-Imagination-Control",
      "upvotes": 9,
      "fetched_at": "2026-02-19T06:03:16.329480+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08808",
      "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
      "authors": [
        "Yapei Chang",
        "Kyle Lo",
        "Mohit Iyyer",
        "Luca Soldaini"
      ],
      "abstract": "A scalable framework for evaluating and improving goal-conditioned procedure generation using large-scale web mining, automated scoring, and reinforcement learning to enhance step-by-step instruction quality. Generating step-by-step \"how-to\" procedures is a key LLM capability: how-to advice is commonly requested in chatbots, and step-by-step planning is critical for reasoning over complex tasks. Yet, measuring and improving procedural validity at scale on real-world tasks remains challenging and understudied. To address this, we introduce How2Everything, a scalable framework to evaluate and improve goal-conditioned procedure generation . Our framework includes How2Mine , which mines 351K procedures from 980K web pages across 14 topics and readily scales to larger corpora. From this pool we build How2Bench , a 7K-example evaluation set balanced across topics. To reliably score model outputs, we develop How2Score , an evaluation protocol that uses an LLM judge to detect whether a generation contains any critical failure that would prevent achieving the goal. For low-cost, reproducible evaluation, we distill a frontier model into an open 8B model, achieving 80.5% agreement with human annotators. How2Bench reveals clear scaling trends across model sizes and training stages, providing signal early in pretraining . Finally, RL using How2Score as a reward improves performance on How2Bench by >10 points across three models without systematic regressions on standard benchmarks, with gains robust to superficial source-document memorization or format compliance. Taken together, How2Everything shows how pretraining web data can support a closed loop of capability evaluation and improvement at scale.",
      "summary_en": "A scalable framework for evaluating and improving goal-conditioned procedure generation using large-scale web mining, automated scoring, and reinforcement learning to enhance step-by-step instruction quality.",
      "summary_zh": "一种可扩展框架，通过大规模网络挖掘、自动评分和强化学习来评估与改进目标条件化程序生成，以提升分步指令质量。",
      "hf_url": "https://huggingface.co/papers/2602.08808",
      "arxiv_url": "https://arxiv.org/abs/2602.08808",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08808",
      "github_url": "https://github.com/lilakk/how2everything",
      "upvotes": 8,
      "fetched_at": "2026-02-19T06:03:34.360855+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08145",
      "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey",
      "authors": [
        "Xinyu Yang",
        "Junlin Han",
        "Rishi Bommasani",
        "Jinqi Luo",
        "Wenjie Qu",
        "Wangchunshu Zhou",
        "Adel Bibi",
        "Xiyao Wang",
        "Jaehong Yoon",
        "Elias Stengel-Eskin",
        "Shengbang Tong",
        "Lingfeng Shen",
        "Rafael Rafailov",
        "Runjia Li",
        "Zhaoyang Wang",
        "Yiyang Zhou",
        "Chenhang Cui",
        "Yu Wang",
        "Wenhao Zheng",
        "Huichi Zhou",
        "Jindong Gu",
        "Zhaorun Chen"
      ],
      "abstract": "Foundation models including LLMs, MLLMs, and generative models require reliable and responsible development addressing bias, security, explainability, and other critical issues for trustworthy deployment across multiple domains.",
      "summary_en": "Foundation models including LLMs, MLLMs, and generative models require reliable and responsible development addressing bias, security, explainability, and other critical issues for trustworthy deployment across multiple domains.",
      "summary_zh": "包括LLMs、MLLMs和生成模型在内的基础模型需要可靠且负责任的开发，解决偏见、安全性、可解释性及其他关键问题，以实现跨多个领域的可信部署。",
      "hf_url": "https://huggingface.co/papers/2602.08145",
      "arxiv_url": "https://arxiv.org/abs/2602.08145",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08145",
      "github_url": "",
      "upvotes": 8,
      "fetched_at": "2026-02-19T06:03:11.757019+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07796",
      "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents",
      "authors": [
        "Jiatong Li",
        "Changdae Oh",
        "Hyeong Kyu Choi",
        "Jindong Wang",
        "Sharon Li"
      ],
      "abstract": "Explicit reasoning in LLM agents can degrade performance in user-engaged scenarios by reducing information disclosure and weakening agent-user communication, with transparency-aware prompting showing better results. Eliciting reasoning has emerged as a powerful technique for improving the performance of large language models (LLMs) on complex tasks by inducing thinking. However, their effectiveness in realistic user-engaged agent scenarios remains unclear. In this paper, we conduct a comprehensive study on the effect of explicit thinking in user-engaged LLM agents. Our experiments span across seven models, three benchmarks, and two thinking instantiations, and we evaluate them through both a quantitative response taxonomy analysis and qualitative failure propagation case studies. Contrary to expectations, we find that mandatory thinking often backfires on agents in user-engaged settings, causing anomalous performance degradation across various LLMs. Our key finding reveals that thinking makes agents more ``introverted'' by shortening responses and reducing information disclosure to users, which weakens agent-user information exchange and leads to downstream task failures. Furthermore, we demonstrate that explicitly prompting for information disclosure reliably improves performance across diverse model families, suggesting that proactive transparency is a vital lever for agent optimization. Overall, our study suggests that information transparency awareness is a crucial yet underexplored perspective for the future design of reasoning agents in real-world scenarios. Our code is available at https://github.com/deeplearning-wisc/Thinking-Agent.",
      "summary_en": "Explicit reasoning in LLM agents can degrade performance in user-engaged scenarios by reducing information disclosure and weakening agent-user communication, with transparency-aware prompting showing better results.",
      "summary_zh": "在用户参与场景中，LLM智能体的显式推理可能因减少信息披露并削弱智能体与用户的沟通而导致性能下降，而透明性感知提示则能取得更好效果。",
      "hf_url": "https://huggingface.co/papers/2602.07796",
      "arxiv_url": "https://arxiv.org/abs/2602.07796",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07796",
      "github_url": "",
      "upvotes": 7,
      "fetched_at": "2026-02-19T06:02:54.402668+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07775",
      "title": "Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion",
      "authors": [
        "Haodong Li",
        "Shaoteng Liu",
        "Zhe Lin",
        "Manmohan Chandraker"
      ],
      "abstract": "Autoregressive video diffusion models suffer from train-test gaps when generating long videos, but a training-free approach called Rolling Sink addresses this by maintaining AR cache and enabling ultra-long video synthesis. Recently, autoregressive (AR) video diffusion models has achieved remarkable performance. However, due to their limited training durations, a train-test gap emerges when testing at longer horizons, leading to rapid visual degradations. Following Self Forcing , which studies the train-test gap within the training duration, this work studies the train-test gap beyond the training duration, i.e., the gap between the limited horizons during training and open-ended horizons during testing. Since open-ended testing can extend beyond any finite training window, and long-video training is computationally expensive, we pursue a training-free solution to bridge this gap. To explore a training-free solution, we conduct a systematic analysis of AR cache maintenance . These insights lead to Rolling Sink . Built on Self Forcing (trained on only 5s clips), Rolling Sink effectively scales the AR video synthesis to ultra-long durations (e.g., 5-30 minutes at 16 FPS) at test time, with consistent subjects, stable colors, coherent structures, and smooth motions. As demonstrated by extensive experiments, Rolling Sink achieves superior long-horizon visual fidelity and temporal consistency compared to SOTA baselines. Project page: https://rolling-sink.github.io/",
      "summary_en": "Autoregressive video diffusion models suffer from train-test gaps when generating long videos, but a training-free approach called Rolling Sink addresses this by maintaining AR cache and enabling ultra-long video synthesis.",
      "summary_zh": "自回归视频扩散模型在生成长视频时存在训练-测试差距，但一种名为Rolling Sink的免训练方法通过维护AR缓存并支持超长视频合成解决了该问题。",
      "hf_url": "https://huggingface.co/papers/2602.07775",
      "arxiv_url": "https://arxiv.org/abs/2602.07775",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07775",
      "github_url": "",
      "upvotes": 7,
      "fetched_at": "2026-02-19T06:02:52.242091+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07080",
      "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
      "authors": [
        "Yicheng He",
        "Zheng Zhao",
        "Zhou Kaiyu",
        "Bryan Dai",
        "Jie Fu",
        "Yonghui Yang"
      ],
      "abstract": "LLM code verification can be achieved through internal neural dynamics analysis, identifying structural signatures that distinguish correct reasoning from logical failures in computational circuits. Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics encode internally decodable signals that are predictive of logical validity during code generation. Inspired by mechanistic interpretability , we propose to treat code verification as a mechanistic diagnostic task, mapping the model's explicit algorithmic trajectory into line-level attribution graphs . By decomposing complex residual flows , we aim to identify the structural signatures that distinguish sound reasoning from logical failure within the model's internal circuits. Analysis across Python, C++, and Java confirms that intrinsic correctness signals are robust across diverse syntaxes. Topological features from these internal graphs predict correctness more reliably than surface heuristics and enable targeted causal interventions to fix erroneous logic. These findings establish internal introspection as a decodable property for verifying generated code. Our code is at https:// github.com/bruno686/CodeCircuit.",
      "summary_en": "LLM code verification can be achieved through internal neural dynamics analysis, identifying structural signatures that distinguish correct reasoning from logical failures in computational circuits.",
      "summary_zh": "LLM代码验证可通过内部神经动力学分析实现，识别区分计算回路中正确推理与逻辑错误的结构特征。",
      "hf_url": "https://huggingface.co/papers/2602.07080",
      "arxiv_url": "https://arxiv.org/abs/2602.07080",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07080",
      "github_url": "https://github.com/bruno686/CodeCircuit",
      "upvotes": 6,
      "fetched_at": "2026-02-19T06:02:34.578137+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.09003",
      "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
      "authors": [
        "Yudong Wang",
        "Zixuan Fu",
        "Hengyu Zhao",
        "Chen Zhao",
        "Chuyue Zhou",
        "Xinle Lin",
        "Hongya Lyu",
        "Shuaikang Xue",
        "Yi Yi",
        "Yingjiao Wang",
        "Zhi Zheng",
        "Yuzhou Zhang",
        "Jie Zhou",
        "Chaojun Xiao",
        "Xu Han",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Large language models are increasingly guiding data management processes through a tiered framework that optimizes data quality, cost, and training efficiency across different stages of model development. The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency . In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training , mid-training , and alignment . The framework balances data quality , acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management . We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.",
      "summary_en": "Large language models are increasingly guiding data management processes through a tiered framework that optimizes data quality, cost, and training efficiency across different stages of model development.",
      "summary_zh": "大语言模型正日益通过分层框架指导数据管理流程，在模型开发的不同阶段优化数据质量、成本和训练效率。",
      "hf_url": "https://huggingface.co/papers/2602.09003",
      "arxiv_url": "https://arxiv.org/abs/2602.09003",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.09003",
      "github_url": "https://github.com/UltraData-OpenBMB/UltraData-Math",
      "upvotes": 5,
      "fetched_at": "2026-02-19T06:03:45.538931+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07803",
      "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
      "authors": [
        "Jiale Qian",
        "Hao Meng",
        "Tian Zheng",
        "Pengcheng Zhu",
        "Haopeng Lin",
        "Yuhang Dai",
        "Hanke Xie",
        "Wenxiao Cao",
        "Ruixuan Shang",
        "Jun Wu",
        "Hongmei Liu",
        "Hanlin Wen",
        "Jian Zhao",
        "Zhonglin Jiang",
        "Yong Chen",
        "Shunshun Yin",
        "Ming Tao",
        "Jianguo Wei",
        "Lei Xie",
        "Xinsheng Wang"
      ],
      "abstract": "A high-quality open-source singing voice synthesis system is presented with support for multiple languages and controllable generation, along with a dedicated benchmark for evaluating zero-shot performance.",
      "summary_en": "A high-quality open-source singing voice synthesis system is presented with support for multiple languages and controllable generation, along with a dedicated benchmark for evaluating zero-shot performance.",
      "summary_zh": "本文提出了一个高质量的开源歌声合成系统，支持多语言和可控生成，同时提供了一个用于评估零样本性能的专用基准。",
      "hf_url": "https://huggingface.co/papers/2602.07803",
      "arxiv_url": "https://arxiv.org/abs/2602.07803",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07803",
      "github_url": "",
      "upvotes": 4,
      "fetched_at": "2026-02-19T06:02:56.541917+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2601.21363",
      "title": "Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control",
      "authors": [
        "Weidong Huang",
        "Zhehan Li",
        "Hangxin Liu",
        "Biao Hou",
        "Yao Su",
        "Jingwen Zhang"
      ],
      "abstract": "Off-policy Soft Actor-Critic with large-batch updates enables efficient humanoid locomotion policy pretraining, while model-based methods facilitate safe adaptation through deterministic data collection and stochastic exploration within physics-informed world models. Reinforcement learning (RL) is widely used for humanoid control, with on-policy methods such as Proximal Policy Optimization (PPO) enabling robust training via large-scale parallel simulation and, in some cases, zero-shot deployment to real robots. However, the low sample efficiency of on-policy algorithms limits safe adaptation to new environments. Although off-policy RL and model-based RL have shown improved sample efficiency , the gap between large-scale pretraining and efficient finetuning on humanoids still exists. In this paper, we find that off-policy Soft Actor-Critic (SAC), with large-batch update and a high Update-To-Data (UTD) ratio, reliably supports large-scale pretraining of humanoid locomotion policies, achieving zero-shot deployment on real robots. For adaptation, we demonstrate that these SAC-pretrained policies can be finetuned in new environments and out-of-distribution tasks using model-based methods. Data collection in the new environment executes a deterministic policy while stochastic exploration is instead confined to a physics-informed world model . This separation mitigates the risks of random exploration during adaptation while preserving exploratory coverage for improvement. Overall, the approach couples the wall-clock efficiency of large-scale simulation during pretraining with the sample efficiency of model-based learning during fine-tuning.",
      "summary_en": "Off-policy Soft Actor-Critic with large-batch updates enables efficient humanoid locomotion policy pretraining, while model-based methods facilitate safe adaptation through deterministic data collection and stochastic exploration within physics-informed world models.",
      "summary_zh": "离策略Soft Actor-Critic通过大批量更新实现高效的人形机器人运动策略预训练，而基于模型的方法则通过确定性数据收集与物理信息世界模型中的随机探索来促进安全适应。",
      "hf_url": "https://huggingface.co/papers/2601.21363",
      "arxiv_url": "https://arxiv.org/abs/2601.21363",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2601.21363",
      "github_url": "https://github.com/bigai-ai/LIFT-humanoid",
      "upvotes": 4,
      "fetched_at": "2026-02-19T06:01:44.620575+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.09782",
      "title": "Flexible Entropy Control in RLVR with Gradient-Preserving Perspective",
      "authors": [
        "Kun Chen",
        "Peng Shi",
        "Fanfan Liu",
        "Haibo Qiu",
        "Zhixiong Zeng",
        "Siqi Yang",
        "Wenji Mao"
      ],
      "abstract": "Reinforcement learning with verifiable rewards faces entropy collapse issues due to gradient-preserving clipping, which this paper addresses through dynamic entropy control mechanisms. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a critical method for enhancing the reasoning capabilities of Large Language Models (LLMs). However, continuous training often leads to policy entropy collapse , characterized by a rapid decay in entropy that results in premature overconfidence, reduced output diversity, and vanishing gradient norms that inhibit learning. Gradient-Preserving Clipping is a primary factor influencing these dynamics, but existing mitigation strategies are largely static and lack a framework connecting clipping mechanisms to precise entropy control . This paper proposes reshaping entropy control in RL from the perspective of Gradient-Preserving Clipping . We first theoretically and empirically verify the contributions of specific importance sampling ratio regions to entropy growth and reduction. Leveraging these findings, we introduce a novel regulation mechanism using dynamic clipping threshold to precisely manage entropy. Furthermore, we design and evaluate dynamic entropy control strategies , including increase-then-decrease, decrease-increase-decrease, and oscillatory decay. Experimental results demonstrate that these strategies effectively mitigate entropy collapse, and achieve superior performance across multiple benchmarks.",
      "summary_en": "Reinforcement learning with verifiable rewards faces entropy collapse issues due to gradient-preserving clipping, which this paper addresses through dynamic entropy control mechanisms.",
      "summary_zh": "基于可验证奖励的强化学习因梯度保持裁剪而面临熵坍缩问题，本文通过动态熵控制机制解决该问题。",
      "hf_url": "https://huggingface.co/papers/2602.09782",
      "arxiv_url": "https://arxiv.org/abs/2602.09782",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.09782",
      "github_url": "https://github.com/Kwen-Chen/Flexible-Entropy-Control",
      "upvotes": 3,
      "fetched_at": "2026-02-19T06:03:52.308339+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08961",
      "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
      "authors": [
        "Ruijie Zhu",
        "Jiahao Lu",
        "Wenbo Hu",
        "Xiaoguang Han",
        "Jianfei Cai",
        "Ying Shan",
        "Chuanxia Zheng"
      ],
      "abstract": "MotionCrafter is a video diffusion framework that jointly reconstructs 4D geometry and estimates dense motion using a novel joint representation and 4D VAE architecture. We introduce MotionCrafter, a video diffusion -based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system , and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents -despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page",
      "summary_en": "MotionCrafter is a video diffusion framework that jointly reconstructs 4D geometry and estimates dense motion using a novel joint representation and 4D VAE architecture.",
      "summary_zh": "MotionCrafter是一种视频扩散框架，利用新颖的联合表示与4D VAE架构，联合重建4D几何并估计稠密运动。",
      "hf_url": "https://huggingface.co/papers/2602.08961",
      "arxiv_url": "https://arxiv.org/abs/2602.08961",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08961",
      "github_url": "https://github.com/TencentARC/MotionCrafter",
      "upvotes": 3,
      "fetched_at": "2026-02-19T06:03:40.866859+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08829",
      "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
      "authors": [
        "Hao Peng",
        "Yunjia Qi",
        "Xiaozhi Wang",
        "Zijun Yao",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "WildReward demonstrates that reward models can be effectively trained from in-the-wild user interactions using ordinal regression, achieving performance comparable to traditional methods while benefiting from user diversity. Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions ? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models , with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models . Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.",
      "summary_en": "WildReward demonstrates that reward models can be effectively trained from in-the-wild user interactions using ordinal regression, achieving performance comparable to traditional methods while benefiting from user diversity.",
      "summary_zh": "WildReward 表明，利用序数回归基于野外用户交互可有效训练奖励模型，在达到与传统方法相当性能的同时受益于用户多样性。",
      "hf_url": "https://huggingface.co/papers/2602.08829",
      "arxiv_url": "https://arxiv.org/abs/2602.08829",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08829",
      "github_url": "",
      "upvotes": 3,
      "fetched_at": "2026-02-19T06:03:38.633455+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08004",
      "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality",
      "authors": [
        "George Ling",
        "Shanshan Zhong",
        "Richard Huang"
      ],
      "abstract": "",
      "summary_en": "",
      "summary_zh": "",
      "hf_url": "https://huggingface.co/papers/2602.08004",
      "arxiv_url": "https://arxiv.org/abs/2602.08004",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08004",
      "github_url": "",
      "upvotes": 3,
      "fetched_at": "2026-02-19T06:03:09.896374+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06942",
      "title": "Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay",
      "authors": [
        "Duygu Altinok"
      ],
      "abstract": "A comprehensive study of Turkish subword tokenization systematically investigates the relationship between vocabulary size, training corpus, and tokenizer performance across multiple linguistic tasks and diagnostics. Tokenization is a pivotal design choice for neural language modeling in morphologically rich languages (MRLs) such as Turkish, where productive agglutination challenges both vocabulary efficiency and morphological fidelity. Prior studies have explored tokenizer families and vocabulary sizes but typically (i) vary vocabulary without systematically controlling the tokenizer's training corpus, (ii) provide limited intrinsic diagnostics , and (iii) evaluate a narrow slice of downstream tasks. We present the first comprehensive, principled study of Turkish subword tokenization ; a \"subwords manifest\", that jointly varies vocabulary size and tokenizer training corpus size (data and vocabulary coupling), compares multiple tokenizer families under matched parameter budgets ( WordPiece , morphology level , and character baselines), and evaluates across semantic ( NLI , STS , sentiment analysis , NER ), syntactic ( POS , dependency parsing ), and morphology-sensitive probes. To explain why tokenizers succeed or fail, we introduce a morphology-aware diagnostic toolkit that goes beyond coarse aggregates to boundary-level micro/macro F1, decoupled lemma atomicity vs. surface boundary hits, over/under- segmentation indices , character/word edit distances ( CER / WER ), continuation rates , and affix-type coverage and token-level atomicity . Our contributions are fourfold: (i) a systematic investigation of the vocabulary-corpus-success triad; (ii) a unified, morphology-aware evaluation framework linking intrinsic diagnostics to extrinsic outcomes; (iii) controlled comparisons identifying when character-level and morphology-level tokenization pay off; and (iv) an open-source release of evaluation code, tokenizer pipelines, and models. As the first work of its kind, this \"subwords manifest\" delivers actionable guidance for building effective tokenizers in MRLs and establishes a reproducible foundation for future research.",
      "summary_en": "A comprehensive study of Turkish subword tokenization systematically investigates the relationship between vocabulary size, training corpus, and tokenizer performance across multiple linguistic tasks and diagnostics.",
      "summary_zh": "一项针对土耳其语子词分词的全面研究系统性地探究了词汇量、训练语料库与分词器性能之间的关系，涵盖多个语言任务与诊断测试。",
      "hf_url": "https://huggingface.co/papers/2602.06942",
      "arxiv_url": "https://arxiv.org/abs/2602.06942",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06942",
      "github_url": "",
      "upvotes": 3,
      "fetched_at": "2026-02-19T06:02:21.125671+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06445",
      "title": "ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
      "authors": [
        "Weidong Huang",
        "Jingwen Zhang",
        "Jiongye Li",
        "Shibowen Zhang",
        "Jiayang Wu",
        "Jiayi Wang",
        "Hangxin Liu",
        "Yaodong Yang",
        "Yao Su"
      ],
      "abstract": "Energy-constrained optimization framework separates energy metrics from rewards using Lagrangian method to achieve stable, energy-efficient humanoid robot locomotion with reduced hyperparameter tuning. Achieving stable and energy-efficient locomotion is essential for humanoid robots to operate continuously in real-world applications. Existing MPC and RL approaches often rely on energy-related metrics embedded within a multi-objective optimization framework, which require extensive hyperparameter tuning and often result in suboptimal policies. To address these challenges, we propose ECO ( Energy-Constrained Optimization ), a constrained RL framework that separates energy-related metrics from rewards, reformulating them as explicit inequality constraints. This method provides a clear and interpretable physical representation of energy costs, enabling more efficient and intuitive hyperparameter tuning for improved energy efficiency. ECO introduces dedicated constraints for energy consumption and reference motion, enforced by the Lagrangian method , to achieve stable, symmetric, and energy-efficient walking for humanoid robots. We evaluated ECO against MPC, standard RL with reward shaping, and four state-of-the-art constrained RL methods. Experiments, including sim-to-sim and sim-to-real transfer s on the kid-sized humanoid robot BRUCE, demonstrate that ECO significantly reduces energy consumption compared to baselines while maintaining robust walking performance. These results highlight a substantial advancement in energy-efficient humanoid locomotion. All experimental demonstrations can be found on the project website: https://sites.google.com/view/eco-humanoid.",
      "summary_en": "Energy-constrained optimization framework separates energy metrics from rewards using Lagrangian method to achieve stable, energy-efficient humanoid robot locomotion with reduced hyperparameter tuning.",
      "summary_zh": "能量约束优化框架使用拉格朗日方法将能量指标与奖励分离，实现稳定、节能的人形机器人运动，并减少超参数调优。",
      "hf_url": "https://huggingface.co/papers/2602.06445",
      "arxiv_url": "https://arxiv.org/abs/2602.06445",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06445",
      "github_url": "https://github.com/bigai-ai/ECO-humanoid",
      "upvotes": 3,
      "fetched_at": "2026-02-19T06:02:07.963400+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08818",
      "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
      "authors": [
        "Annemette Brok Pirchert",
        "Jacob Nielsen",
        "Mogens Henrik From",
        "Lukas Galke Poech",
        "Peter Schneider-Kamp"
      ],
      "abstract": "FlexMoRE demonstrates that low-rank adapters can replace full-sized experts in mixture-of-experts architectures, achieving better performance with significantly fewer parameters. Recent advances in mixture-of-experts architectures have shown that individual experts models can be trained federatedly, i.e., in isolation from other experts by using a common base model to facilitate coordination. However, we hypothesize that full-sized experts may not be necessary for all domains and that instead low-rank adapters may be sufficient. Here, we introduce FlexMoRE, a Flexible Mixture of Rank-heterogenous Experts , which may be either full-sized experts or adapters of a suitable rank. We systematically investigate the trade-off between expert rank and downstream task performance by evaluating 6 experts with ranks 2^0 to 2^{14} resulting in experiments covering 150 mixtures (96 with 2 experts, 54 with 7 experts) that are evaluated across 120 tasks. For our experiments, we build on FlexOlmo and turn its pre-trained experts into low-rank versions. Our regression analysis from expert rank to downstream task performance reveals that the best-performing rank is substantially higher for reasoning-heavy benchmarks than for knowledge-heavy benchmarks. These findings on rank sensitivity come with direct implications for memory efficiency: Using optimal ranks, FlexMoRE yields improved downstream task performance (average score 47.18) compared to the baseline FlexOlmo-style mixture of full-sized experts (average score 45.46) at less than one third the parameters (10.75B for FlexMoRE vs. 33.27B for FlexOlmo). All code will be made available.",
      "summary_en": "FlexMoRE demonstrates that low-rank adapters can replace full-sized experts in mixture-of-experts architectures, achieving better performance with significantly fewer parameters.",
      "summary_zh": "FlexMoRE 表明，低秩适配器可以替代混合专家架构中的全尺寸专家，以显著更少的参数实现更优性能。",
      "hf_url": "https://huggingface.co/papers/2602.08818",
      "arxiv_url": "https://arxiv.org/abs/2602.08818",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08818",
      "github_url": "",
      "upvotes": 2,
      "fetched_at": "2026-02-19T06:03:36.202095+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07150",
      "title": "On Randomness in Agentic Evals",
      "authors": [
        "Bjarni Haukur Bjarnason",
        "André Silva",
        "Martin Monperrus"
      ],
      "abstract": "Analysis of agentic system evaluation reveals significant variance in single-run performance estimates, necessitating multiple runs and advanced metrics for reliable assessment.",
      "summary_en": "Analysis of agentic system evaluation reveals significant variance in single-run performance estimates, necessitating multiple runs and advanced metrics for reliable assessment.",
      "summary_zh": "对智能体系统评估的分析表明，单次运行的性能估计方差显著，需要进行多次运行并采用高级指标以实现可靠评估。",
      "hf_url": "https://huggingface.co/papers/2602.07150",
      "arxiv_url": "https://arxiv.org/abs/2602.07150",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07150",
      "github_url": "",
      "upvotes": 2,
      "fetched_at": "2026-02-19T06:02:45.134118+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07040",
      "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
      "authors": [
        "Emmett Bicker"
      ],
      "abstract": "Aster is an AI agent that accelerates scientific discovery by iteratively improving programs, achieving state-of-the-art results across multiple domains including mathematics, biology, and machine learning with significantly reduced computational requirements. We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performance s. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to include tasks with long evaluation durations, such as multi-hour machine learning training runs. We applied Aster to problems in mathematics, GPU kernel engineering, biology, neuroscience, and language model training. More specifically: the Erdos minimum overlap problem, optimizing the TriMul kernel, a single-cell analysis denoising problem, training a neural activity prediction model to perform well on ZAPBench, and the NanoGPT Speedrun Competition. Aster attains SOTA results in every task, except for ZAPBench, where it matches the performance of the best human solution with less than 1/190th of the compute. Aster is accessible via a web interface and API at asterlab.ai.",
      "summary_en": "Aster is an AI agent that accelerates scientific discovery by iteratively improving programs, achieving state-of-the-art results across multiple domains including mathematics, biology, and machine learning with significantly reduced computational requirements.",
      "summary_zh": "Aster 是一种 AI 智能体，通过迭代改进程序加速科学发现，在数学、生物学和机器学习等多个领域取得最先进成果，且计算需求大幅降低。",
      "hf_url": "https://huggingface.co/papers/2602.07040",
      "arxiv_url": "https://arxiv.org/abs/2602.07040",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07040",
      "github_url": "",
      "upvotes": 2,
      "fetched_at": "2026-02-19T06:02:25.326140+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.06600",
      "title": "Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning",
      "authors": [
        "Zhuoyuan Hao",
        "Zhuo Li",
        "Wu Li",
        "Fangming Liu",
        "Min Zhang",
        "Jing Li"
      ],
      "abstract": "Large reasoning models exhibit spontaneous question repetition patterns that can be formalized and leveraged to improve computational efficiency and accuracy through echo-aware training and prompting techniques. Test-time compute allocation in large reasoning models (LRMs) is widely used and has applications in mathematical problem solving, code synthesis, and planning. Recent work has addressed this problem by scaling self-consistency and parallel thinking , adding generic `` thinking tokens '' and prompting models to re-read the question before answering. Unfortunately, these approaches either inject task-agnostic tokens or mandate heuristics that do not explain -- and often ignore -- the spontaneous repetition that many LRMs exhibit at the head of their internal chains. In contrast, we analyze and harness the model's tendency to restate the question, which we term the Echo of Prompt (EOP), as a front-loaded, compute-shaping mechanism. We formalize its probabilistic cost by casting echo removal as rejection-based conditioning and defining the Echo Likelihood Gap ΔL as a computable proxy. This provides the missing theoretical link that links early repetition to likelihood gains and downstream accuracy. However, it does not by itself specify how to exploit EOP. Consequently, we develop Echo-Distilled SFT (ED-SFT) to instill an ``echo-then-reason'' pattern through supervised finetuning, and Echoic Prompting (EP) to re-ground the model mid-trace without training. While promising, quantifying benefits beyond verbosity is non-trivial. Therefore, we conduct length and suffix-controlled likelihood analyses together with layer-wise attention studies, showing that EOP increases answer to answer-prefix attention in middle layers, consistent with an attention refocusing mechanism. We evaluate on GSM8K, MathQA, Hendrycks-MATH, AIME24, and MATH-500 under identical decoding settings and budgets, and find consistent gains over baselines. Code is available at https://github.com/hhh2210/echoes-as-anchors.",
      "summary_en": "Large reasoning models exhibit spontaneous question repetition patterns that can be formalized and leveraged to improve computational efficiency and accuracy through echo-aware training and prompting techniques.",
      "summary_zh": "大型推理模型表现出自发的问题重复模式，这些模式可被形式化并加以利用，通过回声感知训练与提示技术提升计算效率与准确性。",
      "hf_url": "https://huggingface.co/papers/2602.06600",
      "arxiv_url": "https://arxiv.org/abs/2602.06600",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06600",
      "github_url": "https://github.com/hhh2210/echoes-as-anchors",
      "upvotes": 2,
      "fetched_at": "2026-02-19T06:02:14.688561+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.05929",
      "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs",
      "authors": [
        "Jian Chen",
        "Zhuoran Wang",
        "Jiayu Qin",
        "Ming Li",
        "Meng Wang",
        "Changyou Chen",
        "Yin Chen",
        "Qizhen Weng",
        "Yirui Liu"
      ],
      "abstract": "KV-CoRE method evaluates kv-cache compressibility through SVD-based low-rank approximation, revealing patterns linking compressibility to model architecture and training data across multiple languages and domains. Large language models rely on kv-cache s to avoid redundant computation during autoregressive decoding , but as context length grows, reading and writing the cache can quickly saturate GPU memory bandwidth . Recent work has explored KV-cache compression , yet most approaches neglect the data-dependent nature of kv-cache s and their variation across layers. We introduce KV-CoRE KV-cache Compressibility by Rank Evaluation), an SVD-based method for quantifying the data-dependent low-rank compressibility of kv-cache s. KV-CoRE computes the optimal low-rank approximation under the Frobenius norm and, being gradient-free and incremental, enables efficient dataset-level, layer-wise evaluation . Using this method, we analyze multiple models and datasets spanning five English domains and sixteen languages, uncovering systematic patterns that link compressibility to model architecture, training data, and language coverage. As part of this analysis, we employ the Normalized Effective Rank as a metric of compressibility and show that it correlates strongly with performance degradation under compression. Our study establishes a principled evaluation framework and the first large-scale benchmark of kv-cache compressibility in LLMs, offering insights for dynamic, data-aware compression and data-centric model development.",
      "summary_en": "KV-CoRE method evaluates kv-cache compressibility through SVD-based low-rank approximation, revealing patterns linking compressibility to model architecture and training data across multiple languages and domains.",
      "summary_zh": "KV-CoRE方法通过基于SVD的低秩近似评估KV缓存可压缩性，揭示其与模型架构及训练数据之间的关联规律，涵盖多种语言和领域。",
      "hf_url": "https://huggingface.co/papers/2602.05929",
      "arxiv_url": "https://arxiv.org/abs/2602.05929",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.05929",
      "github_url": "",
      "upvotes": 2,
      "fetched_at": "2026-02-19T06:01:58.158978+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.02827",
      "title": "Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval",
      "authors": [
        "Roi Pony",
        "Adi Raz",
        "Oshri Naparstek",
        "Idan Friedman",
        "Udi Barzelay"
      ],
      "abstract": "Col-Bandit reduces computational costs in multi-vector late-interaction retrieval by adaptively pruning token-level interactions during query processing while maintaining ranking accuracy. Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-K identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5times, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time.",
      "summary_en": "Col-Bandit reduces computational costs in multi-vector late-interaction retrieval by adaptively pruning token-level interactions during query processing while maintaining ranking accuracy.",
      "summary_zh": "Col-Bandit通过在查询处理过程中自适应地剪枝词元级交互，在多向量后期交互检索中降低计算成本，同时保持排序准确性。",
      "hf_url": "https://huggingface.co/papers/2602.02827",
      "arxiv_url": "https://arxiv.org/abs/2602.02827",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02827",
      "github_url": "",
      "upvotes": 2,
      "fetched_at": "2026-02-19T06:01:51.857309+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.08629",
      "title": "CauScale: Neural Causal Discovery at Scale",
      "authors": [
        "Bo Peng",
        "Sirui Chen",
        "Jiaguo Tian",
        "Yu Qiao",
        "Chaochao Lu"
      ],
      "abstract": "CauScale is a neural architecture that enables efficient causal discovery on large graphs through compressed embeddings and tied attention weights, achieving high accuracy and significant speedups over previous methods. Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention map s. To keep high causal discovery accuracy, CauScale adopts a two-stream design : a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals . CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale.",
      "summary_en": "CauScale is a neural architecture that enables efficient causal discovery on large graphs through compressed embeddings and tied attention weights, achieving high accuracy and significant speedups over previous methods.",
      "summary_zh": "CauScale是一种神经架构，通过压缩嵌入和共享注意力权重，能够在大规模图上高效进行因果发现，实现了高准确率并显著快于先前方法。",
      "hf_url": "https://huggingface.co/papers/2602.08629",
      "arxiv_url": "https://arxiv.org/abs/2602.08629",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.08629",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T06:03:25.391962+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07970",
      "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
      "authors": [
        "Zheyuan Hu",
        "Weitao Chen",
        "Cengiz Öztireli",
        "Chenliang Zhou",
        "Fangcheng Zhong"
      ],
      "abstract": "Research explores PDE solvers including neural frameworks for scientific simulations, examining forward solutions, inverse problems, and equation discovery across multi-variable and non-linear systems. Partial Differential Equations are precise in modelling the physical, biological and graphical phenomena. However, the numerical methods suffer from the curse of dimensionality, high computation costs and domain-specific discretization. We aim to explore pros and cons of different PDE solvers , and apply them to specific scientific simulation problems, including forwarding solution, inverse problems and equations discovery. In particular, we extend the recent CNF (NeurIPS 2023) framework solver to multi-dependent-variable and non-linear settings , together with down-stream applications. The outcomes include implementation of selected methods, self-tuning techniques, evaluation on benchmark problems and a comprehensive survey of neural PDE solvers and scientific simulation applications.",
      "summary_en": "Research explores PDE solvers including neural frameworks for scientific simulations, examining forward solutions, inverse problems, and equation discovery across multi-variable and non-linear systems.",
      "summary_zh": "研究探索了偏微分方程求解器（包括面向科学模拟的神经网络框架），考察了多变量与非线性系统中的正问题、逆问题及方程发现。",
      "hf_url": "https://huggingface.co/papers/2602.07970",
      "arxiv_url": "https://arxiv.org/abs/2602.07970",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07970",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T06:03:07.891150+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07491",
      "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
      "authors": [
        "Isabella A. Stewart",
        "Tarjei Paule Hage",
        "Yu-Chuan Hsu",
        "Markus J. Buehler"
      ],
      "abstract": "A multi-agent framework guided by knowledge graphs addresses materials science challenges by integrating specialized agents for problem decomposition, evidence retrieval, and graph traversal to discover sustainable PFAS alternatives. Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science , where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition , evidence retrieval , design parameter extraction, and graph traversal , uncovering latent connections across distinct knowledge pockets to support hypothesis generation . Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance , thermal stability , chemical resistance , and biocompatibility . This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.",
      "summary_en": "A multi-agent framework guided by knowledge graphs addresses materials science challenges by integrating specialized agents for problem decomposition, evidence retrieval, and graph traversal to discover sustainable PFAS alternatives.",
      "summary_zh": "由知识图谱引导的多智能体框架通过整合专门用于问题分解、证据检索和图遍历的智能体来发现可持续PFAS替代品，从而应对材料科学挑战。",
      "hf_url": "https://huggingface.co/papers/2602.07491",
      "arxiv_url": "https://arxiv.org/abs/2602.07491",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07491",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T06:02:49.748291+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07120",
      "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model",
      "authors": [
        "Jacqueline He",
        "Jonathan Hayase",
        "Wen-tau Yih",
        "Sewoong Oh",
        "Luke Zettlemoyer",
        "Pang Wei Koh"
      ],
      "abstract": "Anchor decoding suppresses verbatim copying in language models while maintaining fluency and factual accuracy through constrained generation that balances risk and utility. Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding , a plug-and-play inference-time method for suppressing verbatim copying : it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM . Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model ( TinyComma 1.8B ), as well as Anchored_{Byte} Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored_{Byte} Decoding define a new Pareto frontier , preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.",
      "summary_en": "Anchor decoding suppresses verbatim copying in language models while maintaining fluency and factual accuracy through constrained generation that balances risk and utility.",
      "summary_zh": "锚点解码通过平衡风险与效用的约束生成，在抑制语言模型逐字复制的同时保持流畅性和事实准确性。",
      "hf_url": "https://huggingface.co/papers/2602.07120",
      "arxiv_url": "https://arxiv.org/abs/2602.07120",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07120",
      "github_url": "https://github.com/jacqueline-he/anchored-decoding",
      "upvotes": 1,
      "fetched_at": "2026-02-19T06:02:41.146969+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07090",
      "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks",
      "authors": [
        "Yu-Che Tsai",
        "Hsiang Hsiao",
        "Kuan-Yu Chen",
        "Shou-De Lin"
      ],
      "abstract": "SPARSE is a user-centric framework that protects text embeddings from privacy leaks by selectively perturbing sensitive dimensions using differentiable masking and Mahalanobis noise calibration. Text embeddings enable numerous NLP applications but face severe privacy risks from embedding inversion attacks , which can expose sensitive attributes or reconstruct raw text. Existing differential privacy defenses assume uniform sensitivity across embedding dimensions, leading to excessive noise and degraded utility. We propose SPARSE, a user-centric framework for concept-specific privacy protection in text embeddings . SPARSE combines (1) differentiable mask learning to identify privacy-sensitive dimensions for user-defined concepts, and (2) the Mahalanobis mechanism that applies elliptical noise calibrated by dimension sensitivity. Unlike traditional spherical noise injection, SPARSE selectively perturbs privacy-sensitive dimensions while preserving non-sensitive semantics. Evaluated across six datasets with three embedding models and attack scenarios, SPARSE consistently reduces privacy leakage while achieving superior downstream performance compared to state-of-the-art DP methods.",
      "summary_en": "SPARSE is a user-centric framework that protects text embeddings from privacy leaks by selectively perturbing sensitive dimensions using differentiable masking and Mahalanobis noise calibration.",
      "summary_zh": "SPARSE是一种以用户为中心的框架，通过可微掩码和马氏距离噪声校准选择性扰动敏感维度，从而保护文本嵌入免受隐私泄露。",
      "hf_url": "https://huggingface.co/papers/2602.07090",
      "arxiv_url": "https://arxiv.org/abs/2602.07090",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07090",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T06:02:39.204499+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07054",
      "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
      "authors": [
        "Ashutosh Chaubey",
        "Jiacheng Pang",
        "Maksim Siniukov",
        "Mohammad Soleymani"
      ],
      "abstract": "A benchmark and optimization technique are presented to improve multimodal large language models' emotion understanding by addressing spurious associations and hallucinations in audiovisual cues. Emotion understanding is essential for building socially intelligent agents. Although recent multimodal large language models have shown strong performance on this task, two key challenges remain - spurious associations between emotions and irrelevant audiovisual cues, and hallucinations of audiovisual cues driven by text priors in the language model backbone. To quantify and understand these issues, we introduce EmoReAlM, a benchmark designed to evaluate MLLMs for cue-emotion associations , hallucinations and modality agreement . We then propose AVEm-DPO , a preference optimization technique that aligns model responses with both audiovisual inputs and emotion-centric queries . Specifically, we construct preferences over responses exhibiting spurious associations or hallucinations , and audiovisual input pairs guided by textual prompts. We also include a regularization term that penalizes reliance on text priors , thereby mitigating modality-specific cue hallucinations . Experimental results on DFEW, RAVDESS and EMER demonstrate that our method significantly improves the performance of the reference baseline models with 6-19% of relative performance gains in zero-shot settings. By providing both a rigorous benchmark and a robust optimization framework, this work enables principled evaluation and improvement of MLLMs for emotion understanding and social AI. Code, models and benchmark will be released at https://avere-iclr.github.io.",
      "summary_en": "A benchmark and optimization technique are presented to improve multimodal large language models' emotion understanding by addressing spurious associations and hallucinations in audiovisual cues.",
      "summary_zh": "提出了一种基准测试与优化技术，通过解决视听线索中的虚假关联和幻觉问题，提升多模态大语言模型的情感理解能力。",
      "hf_url": "https://huggingface.co/papers/2602.07054",
      "arxiv_url": "https://arxiv.org/abs/2602.07054",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07054",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T06:02:27.816090+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.05708",
      "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration",
      "authors": [
        "Chuangtao Ma",
        "Zeyu Zhang",
        "Arijit Khan",
        "Sebastian Schelter",
        "Paul Groth"
      ],
      "abstract": "CE-RAG4EM reduces computational overhead in large-scale entity matching by implementing blocking-based batch retrieval and generation while maintaining competitive matching quality. Retrieval-augmented generation (RAG) enhances LLM reasoning in knowledge-intensive tasks, but existing RAG pipelines incur substantial retrieval and generation overhead when applied to large-scale entity matching . To address this limitation, we introduce CE-RAG4EM, a cost-efficient RAG architecture that reduces computation through blocking-based batch retrieval and generation. We also present a unified framework for analyzing and evaluating RAG systems for entity matching , focusing on blocking-aware optimizations and retrieval granularity. Extensive experiments suggest that CE-RAG4EM can achieve comparable or improved matching quality while substantially reducing end-to-end runtime relative to strong baselines. Our analysis further reveals that key configuration parameters introduce an inherent trade-off between performance and overhead, offering practical guidance for designing efficient and scalable RAG systems for entity matching and data integration .",
      "summary_en": "CE-RAG4EM reduces computational overhead in large-scale entity matching by implementing blocking-based batch retrieval and generation while maintaining competitive matching quality.",
      "summary_zh": "CE-RAG4EM通过实现基于分块的批量检索与生成，在保持有竞争力匹配质量的同时，降低大规模实体匹配的计算开销。",
      "hf_url": "https://huggingface.co/papers/2602.05708",
      "arxiv_url": "https://arxiv.org/abs/2602.05708",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.05708",
      "github_url": "https://github.com/machuangtao/CE-RAG4EM",
      "upvotes": 1,
      "fetched_at": "2026-02-19T06:01:55.820634+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07948",
      "title": "dewi-kadita: A Python Library for Idealized Fish Schooling Simulation with Entropy-Based Diagnostics",
      "authors": [
        "Sandy H. S. Herho",
        "Iwan P. Anwar",
        "Faruq Khadami",
        "Alfita P. Handayani",
        "Karina A. Sujatmiko",
        "Kamaluddin Kasim",
        "Rusmawan Suwarman",
        "Dasapta E. Irawan"
      ],
      "abstract": "Collective motion in fish schools exemplifies emergent self-organization in active matter systems, yet computational tools for simulating and analyzing these dynamics remain fragmented across research groups. We present dewi-kadita, an open-source Python library implementing the three-dimensional Couzin zone-based model with comprehensive entropy diagnostics tailored for marine collective behavior research. The library introduces seven information-theoretic metrics -- school cohesion entropy, polarization entropy, depth stratification entropy, angular momentum entropy, nearest-neighbor entropy, velocity correlation entropy, and school shape entropy -- that characterize distinct organizational features inaccessible to classical order parameters. These metrics combine into an Oceanic Schooling Index (OSI) providing a single scalar measure of collective disorder. Validation across four canonical configurations (swarm, torus, dynamic parallel, highly parallel) confirms correct reproduction of known phase behaviors: the swarm maintains disorder with polarization P < 0.1 and OSI approx 0.71, while the highly parallel state achieves P = 0.998 with OSI = 0.24 and velocity correlation entropy vanishing to zero. The entropy framework successfully discriminates the torus and dynamic parallel configurations that exhibit comparable order parameter magnitudes through different organizational mechanisms. Numba just-in-time (JIT) compilation accelerates pairwise interaction calculations by 10--100times, enabling simulations of 150--250 agents over 1000--2000 time steps within five minutes on standard workstation hardware. NetCDF4 output ensures interoperability with oceanographic analysis tools. The library addresses the need for standardized, reproducible infrastructure in collective behavior modeling analogous to established molecular dynamics codes.",
      "summary_en": "Computational tools for simulating collective motion in fish schools remain fragmented across research groups. We present dewi-kadita, an open-source Python library implementing the three-dimensional Couzin zone-based model with seven information-theoretic metrics -- school cohesion entropy, polarization entropy, depth stratification entropy, angular momentum entropy, nearest-neighbor entropy, velocity correlation entropy, and school shape entropy -- that combine into an Oceanic Schooling Index (OSI). Validation across four canonical configurations (swarm, torus, dynamic parallel, highly parallel) confirms correct reproduction of known phase behaviors, with the swarm maintaining disorder (polarization P < 0.1 and OSI approx 0.71) and the highly parallel state achieving P = 0.998 with OSI = 0.24, while the entropy framework successfully discriminates the torus and dynamic parallel configurations that exhibit comparable order parameter magnitudes. Numba just-in-time (JIT) compilation accelerates pairwise interaction calculations by 10--100times, enabling simulations of 150--250 agents over 1000--2000 time steps within five minutes on standard workstation hardware, and NetCDF4 output ensures interoperability with oceanographic analysis tools.",
      "summary_zh": "用于模拟鱼群集体运动的计算工具目前仍分散于各研究组。我们推出dewi-kadita，这是一个开源Python库，实现了三维Couzin区域模型，并包含七个信息论指标——群体凝聚熵、极化熵、深度分层熵、角动量熵、最近邻熵、速度相关熵和群体形状熵——这些指标组合成海洋集群指数(OSI)。在四种典型构型（群集、环面、动态平行、高度平行）上的验证确认了已知相行为的正确复现，其中群集态保持无序（极化度P < 0.1且OSI约0.71），高度平行态达到P = 0.998且OSI = 0.24，同时熵框架成功区分了环面和动态平行构型，二者具有可比的序参量幅度。Numba即时(JIT)编译将成对相互作用计算加速10-100倍，使得在标准工作站硬件上可在五分钟内完成150-250个个体跨越1000-2000个时间步的模拟，且NetCDF4输出确保了与海洋学分析工具的互操作性。",
      "hf_url": "https://huggingface.co/papers/2602.07948",
      "arxiv_url": "https://arxiv.org/abs/2602.07948",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07948",
      "github_url": "https://github.com/sandyherho/dewi-kadita",
      "upvotes": 0,
      "fetched_at": "2026-02-19T06:03:03.789141+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.07125",
      "title": "Reasoning-Augmented Representations for Multimodal Retrieval",
      "authors": [
        "Jianrui Zhang",
        "Anirudh Sundara Rajan",
        "Brandon Han",
        "Soochahn Lee",
        "Sukanta Ganguly",
        "Yong Jae Lee"
      ],
      "abstract": "UMR systems face challenges with latent reasoning tasks, which the proposed framework addresses by decoupling reasoning from retrieval through enhanced visual and textual representations. Universal Multimodal Retrieval (UMR) seeks any-to-any search across text and vision, yet modern embedding models remain brittle when queries require latent reasoning (e.g., resolving underspecified references or matching compositional constraints ). We argue this brittleness is often data-induced: when images carry \"silent\" evidence and queries leave key semantics implicit, a single embedding pass must both reason and compress, encouraging spurious feature matching. We propose a data-centric framework that decouples these roles by externalizing reasoning before retrieval. Using a strong Vision--Language Model, we make implicit semantics explicit by densely captioning visual evidence in corpus entries, resolving ambiguous multimodal references in queries, and rewriting verbose instructions into concise retrieval constraints . Inference-time enhancement alone is insufficient; the retriever must be trained on these semantically dense representations to avoid distribution shift and fully exploit the added signal. Across M-BEIR, our reasoning-augmented training method yields consistent gains over strong baselines, with ablations showing that corpus enhancement chiefly benefits knowledge-intensive queries while query enhancement is critical for compositional modification requests. We publicly release our code at https://github.com/AugmentedRetrieval/ReasoningAugmentedRetrieval.",
      "summary_en": "UMR systems face challenges with latent reasoning tasks, which the proposed framework addresses by decoupling reasoning from retrieval through enhanced visual and textual representations.",
      "summary_zh": "UMR系统在处理隐式推理任务时面临挑战，所提框架通过增强视觉与文本表征来解耦推理与检索，从而解决该问题。",
      "hf_url": "https://huggingface.co/papers/2602.07125",
      "arxiv_url": "https://arxiv.org/abs/2602.07125",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.07125",
      "github_url": "https://github.com/AugmentedRetrieval/ReasoningAugmentedRetrieval",
      "upvotes": 0,
      "fetched_at": "2026-02-19T06:02:42.950672+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.05946",
      "title": "f-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment",
      "authors": [
        "Rajdeep Haldar",
        "Lantao Mei",
        "Guang Lin",
        "Yue Xing",
        "Qifan Song"
      ],
      "abstract": "Preference alignment objectives are extended to general alignment settings using f-divergence variational representations, introducing novel on-policy and hybrid policy optimization methods for LLM alignment with theoretical and empirical validation. Recent research shows that Preference Alignment (PA) objectives act as divergence estimators between aligned (chosen) and unaligned (rejected) response distributions. In this work, we extend this divergence-based perspective to general alignment settings, such as reinforcement learning with verifiable rewards ( RLVR ), where only environmental rewards are available. Within this unified framework, we propose f-Group Relative Policy Optimization (f-GRPO), a class of on-policy reinforcement learning , and f-Hybrid Alignment Loss (f-HAL), a hybrid on/off policy objectives, for general LLM alignment based on variational representation of f-divergence s. We provide theoretical guarantees that these classes of objectives improve the average reward after alignment. Empirically, we validate our framework on both RLVR ( Math Reasoning ) and PA tasks ( Safety Alignment ), demonstrating superior performance and flexibility compared to current methods.",
      "summary_en": "Preference alignment objectives are extended to general alignment settings using f-divergence variational representations, introducing novel on-policy and hybrid policy optimization methods for LLM alignment with theoretical and empirical validation.",
      "summary_zh": "利用 f-散度变分表示，将偏好对齐目标扩展至通用对齐设置，引入面向 LLM 对齐的新型同策略与混合策略优化方法，并经过理论与实证验证。",
      "hf_url": "https://huggingface.co/papers/2602.05946",
      "arxiv_url": "https://arxiv.org/abs/2602.05946",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.05946",
      "github_url": "",
      "upvotes": 0,
      "fetched_at": "2026-02-19T06:02:00.595569+00:00"
    },
    {
      "date": "2026-02-10",
      "paper_id": "2602.02285",
      "title": "Statistical Learning Theory in Lean 4: Empirical Processes from Scratch",
      "authors": [
        "Yuanhe Zhang",
        "Jason D. Lee",
        "Fanghui Liu"
      ],
      "abstract": "A comprehensive formalization of statistical learning theory in Lean 4 addresses gaps in mathematical libraries and demonstrates human-AI collaboration for verified machine learning theory foundations. We present the first comprehensive Lean 4 formalization of statistical learning theory (SLT) grounded in empirical process theory . Our end-to-end formal infrastructure implement the missing contents in latest Lean 4 Mathlib library , including a complete development of Gaussian Lipschitz concentration , the first formalization of Dudley's entropy integral theorem for sub-Gaussian processes , and an application to least-squares (sparse) regression with a sharp rate. The project was carried out using a human-AI collaborative workflow , in which humans design proof strategies and AI agents execute tactical proof construction , leading to the human-verified Lean 4 toolbox for SLT. Beyond implementation, the formalization process exposes and resolves implicit assumptions and missing details in standard SLT textbooks, enforcing a granular, line-by-line understanding of the theory. This work establishes a reusable formal foundation and opens the door for future developments in machine learning theory. The code is available at https://github.com/YuanheZ/lean-stat-learning-theory",
      "summary_en": "A comprehensive formalization of statistical learning theory in Lean 4 addresses gaps in mathematical libraries and demonstrates human-AI collaboration for verified machine learning theory foundations.",
      "summary_zh": "在 Lean 4 中对统计学习理论的全面形式化填补了数学库的空白，并展示了人机协作在构建经过验证的机器学习理论基础方面的应用。",
      "hf_url": "https://huggingface.co/papers/2602.02285",
      "arxiv_url": "https://arxiv.org/abs/2602.02285",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02285",
      "github_url": "https://github.com/YuanheZ/lean-stat-learning-theory",
      "upvotes": 0,
      "fetched_at": "2026-02-19T06:01:49.429850+00:00"
    }
  ]
}