{
  "date": "2026-02-05",
  "count": 53,
  "papers": [
    {
      "date": "2026-02-05",
      "paper_id": "2602.04705",
      "title": "ERNIE 5.0 Technical Report",
      "authors": [
        "Haifeng Wang",
        "Hua Wu",
        "Tian Wu",
        "Yu Sun",
        "Jing Liu",
        "Dianhai Yu",
        "Yanjun Ma",
        "Jingzhou He",
        "Zhongjun He",
        "Dou Hong",
        "Qiwen Liu",
        "Shuohuan Wang",
        "Junyuan Shang",
        "Zhenyu Zhang",
        "Yuchen Ding",
        "Jinle Zeng",
        "Jiabin Yang",
        "Liang Shen",
        "Ruibiao Chen",
        "Weichong Yin",
        "Siyu Ding",
        "Dai Dai"
      ],
      "abstract": "ERNIE 5.0 is a production-scale trillion-parameter autoregressive model that unifies multimodal understanding and generation through sparse MoE architecture and elastic training.",
      "summary_en": "ERNIE 5.0 is a production-scale trillion-parameter autoregressive model that unifies multimodal understanding and generation through sparse MoE architecture and elastic training.",
      "summary_zh": "ERNIE 5.0是一个生产级规模的万亿参数自回归模型，通过稀疏MoE架构和弹性训练统一了多模态理解与生成。",
      "hf_url": "https://huggingface.co/papers/2602.04705",
      "arxiv_url": "https://arxiv.org/abs/2602.04705",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04705",
      "github_url": "",
      "upvotes": 251,
      "fetched_at": "2026-02-19T05:42:09.686486+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03152",
      "title": "FASA: Frequency-aware Sparse Attention",
      "authors": [
        "Yifei Wang",
        "Yueqi Wang",
        "Zhenrui Yue",
        "Huimin Zeng",
        "Yong Wang",
        "Ismini Lourentzou",
        "Zhengzhong Tu",
        "Xiangxiang Chu",
        "Julian McAuley"
      ],
      "abstract": "FASA is a novel framework that uses query-aware token eviction and functional sparsity in RoPE to reduce KV cache memory usage while maintaining high performance in long-context LLM tasks. The deployment of Large Language Models (LLMs) faces a critical bottleneck when handling lengthy inputs: the prohibitive memory footprint of the Key Value (KV) cache. To address this bottleneck, the token pruning paradigm leverages attention sparsity to selectively retain a small, critical subset of tokens. However, existing approaches fall short, with static methods risking irreversible information loss and dynamic strategies employing heuristics that insufficiently capture the query-dependent nature of token importance. We propose FASA, a novel framework that achieves query-aware token eviction by dynamically predicting token importance. FASA stems from a novel insight into RoPE : the discovery of functional sparsity at the frequency-chunk (FC) level. Our key finding is that a small, identifiable subset of \"dominant\" FCs consistently exhibits high contextual agreement with the full attention head. This provides a robust and computationally free proxy for identifying salient tokens. %making them a powerful and efficient proxy for token importance. Building on this insight, FASA first identifies a critical set of tokens using dominant FCs, and then performs focused attention computation solely on this pruned subset. % Since accessing only a small fraction of the KV cache, FASA drastically lowers memory bandwidth requirements and computational cost . Across a spectrum of long-context tasks , from sequence modeling to complex CoT reasoning , FASA consistently outperforms all token-eviction baselines and achieves near-oracle accuracy, demonstrating remarkable robustness even under constraint budgets. Notably, on LongBench-V1 , FASA reaches nearly 100\\% of full-KV performance when only keeping 256 tokens, and achieves 2.56times speedup using just 18.9\\% of the cache on AIME24 .",
      "summary_en": "FASA is a novel framework that uses query-aware token eviction and functional sparsity in RoPE to reduce KV cache memory usage while maintaining high performance in long-context LLM tasks.",
      "summary_zh": "FASA是一种新颖框架，利用查询感知的token淘汰和RoPE中的功能稀疏性来降低KV缓存内存占用，同时在长上下文LLM任务中保持高性能。",
      "hf_url": "https://huggingface.co/papers/2602.03152",
      "arxiv_url": "https://arxiv.org/abs/2602.03152",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03152",
      "github_url": "",
      "upvotes": 146,
      "fetched_at": "2026-02-19T05:27:28.879926+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04634",
      "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning",
      "authors": [
        "Zelai Xu",
        "Zhexuan Xu",
        "Ruize Zhang",
        "Chunyang Zhu",
        "Shi Yu",
        "Weilin Liu",
        "Quanlu Zhang",
        "Wenbo Ding",
        "Chao Yu",
        "Yu Wang"
      ],
      "abstract": "Multi-agent systems using reinforcement learning enable parallel information seeking with scalable orchestration, achieving performance comparable to larger single agents. Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking . Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution . By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark , which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.",
      "summary_en": "Multi-agent systems using reinforcement learning enable parallel information seeking with scalable orchestration, achieving performance comparable to larger single agents.",
      "summary_zh": "使用强化学习的多智能体系统通过可扩展的编排实现并行信息检索，性能可媲美更大的单智能体。",
      "hf_url": "https://huggingface.co/papers/2602.04634",
      "arxiv_url": "https://arxiv.org/abs/2602.04634",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04634",
      "github_url": "https://github.com/RLinf/RLinf",
      "upvotes": 93,
      "fetched_at": "2026-02-19T05:27:46.485552+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04145",
      "title": "Training Data Efficiency in Multimodal Process Reward Models",
      "authors": [
        "Jinyuan Li",
        "Chengsong Huang",
        "Langlin Huang",
        "Shaoyang Xu",
        "Haolin Liu",
        "Wenxuan Zhang",
        "Jiaxin Huang"
      ],
      "abstract": "Training multimodal process reward models efficiently through balanced-information scoring that prioritizes label mixture and reliability while achieving full-data performance with only 10% of training data. Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench , BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%.",
      "summary_en": "Training multimodal process reward models efficiently through balanced-information scoring that prioritizes label mixture and reliability while achieving full-data performance with only 10% of training data.",
      "summary_zh": "通过平衡信息评分高效训练多模态过程奖励模型，优先关注标签混合与可靠性，仅用10%训练数据即可实现全数据性能。",
      "hf_url": "https://huggingface.co/papers/2602.04145",
      "arxiv_url": "https://arxiv.org/abs/2602.04145",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04145",
      "github_url": "",
      "upvotes": 76,
      "fetched_at": "2026-02-19T05:27:38.392337+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04804",
      "title": "OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models",
      "authors": [
        "Yue Ding",
        "Yiyan Ji",
        "Jungang Li",
        "Xuyang Liu",
        "Xinlong Chen",
        "Junfei Wu",
        "Bozhou Li",
        "Bohan Zeng",
        "Yang Shi",
        "Yushuo Guan",
        "Yuanxing Zhang",
        "Jiaheng Liu",
        "Qiang Liu",
        "Pengfei Wan",
        "Liang Wang"
      ],
      "abstract": "OmniSIFT is a modality-asymmetric token compression framework for Omni-LLMs that reduces computational overhead through spatio-temporal video pruning and vision-guided audio selection while maintaining superior performance. Omni-modal Large Language Models (Omni-LLMs) have demonstrated strong capabilities in audio-video understanding tasks. However, their reliance on long multimodal token sequences leads to substantial computational overhead. Despite this challenge, token compression methods designed for Omni-LLMs remain limited. To bridge this gap, we propose OmniSIFT (Omni-modal Spatio-temporal Informed Fine-grained Token compression ), a modality-asymmetric token compression framework tailored for Omni-LLMs. Specifically, OmniSIFT adopts a two-stage compression strategy: (i) a spatio-temporal video pruning module that removes video redundancy arising from both intra-frame structure and inter-frame overlap, and (ii) a vision-guided audio selection module that filters audio tokens. The entire framework is optimized end-to-end via a differentiable straight-through estimator . Extensive experiments on five representative benchmarks demonstrate the efficacy and robustness of OmniSIFT. Notably, for Qwen2.5-Omni-7B, OmniSIFT introduces only 4.85M parameters while maintaining lower latency than training-free baselines such as OmniZip. With merely 25% of the original token context, OmniSIFT consistently outperforms all compression baselines and even surpasses the performance of the full-token model on several tasks.",
      "summary_en": "OmniSIFT is a modality-asymmetric token compression framework for Omni-LLMs that reduces computational overhead through spatio-temporal video pruning and vision-guided audio selection while maintaining superior performance.",
      "summary_zh": "OmniSIFT是一个面向Omni-LLMs的模态非对称token压缩框架，通过时空视频剪枝和视觉引导的音频选择降低计算开销，同时保持优异性能。",
      "hf_url": "https://huggingface.co/papers/2602.04804",
      "arxiv_url": "https://arxiv.org/abs/2602.04804",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04804",
      "github_url": "",
      "upvotes": 46,
      "fetched_at": "2026-02-19T05:42:12.669331+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03560",
      "title": "HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing",
      "authors": [
        "Yizhao Gao",
        "Jianyu Wei",
        "Qihao Zhang",
        "Yu Cheng",
        "Shimao Chen",
        "Zhengju Tang",
        "Zihan Jiang",
        "Yifan Song",
        "Hailin Zhang",
        "Liang Zhao",
        "Bo Yang",
        "Gang Wang",
        "Shijie Cao",
        "Fuli Luo"
      ],
      "abstract": "Hybrid Sparse Attention architecture interleaves full and sparse attention layers, using full attention output to guide sparse layer token selection and cache reuse for improved efficiency and performance. This work introduces Hybrid Sparse Attention (HySparse), a new architecture that interleaves each full attention layer with several sparse attention layers . While conceptually simple, HySparse strategically derives each sparse layer's token selection and KV caches directly from the preceding full attention layer . This architecture resolves two fundamental limitations of prior sparse attention methods. First, conventional approaches typically rely on additional proxies to predict token importance, introducing extra complexity and potentially suboptimal performance. In contrast, HySparse uses the full attention layer as a precise oracle to identify important tokens. Second, existing sparse attention designs often reduce computation without saving KV cache. HySparse enables sparse attention layers to reuse the full attention KV cache, thereby reducing both computation and memory. We evaluate HySparse on both 7B dense and 80B MoE models . Across all settings, HySparse consistently outperforms both full attention and hybrid SWA baselines. Notably, in the 80B MoE model with 49 total layers, only 5 layers employ full attention, yet HySparse achieves substantial performance gains while reducing KV cache storage by nearly 10x.",
      "summary_en": "Hybrid Sparse Attention architecture interleaves full and sparse attention layers, using full attention output to guide sparse layer token selection and cache reuse for improved efficiency and performance.",
      "summary_zh": "混合稀疏注意力架构将全注意力层与稀疏注意力层交错排列，利用全注意力输出指导稀疏层的令牌选择和缓存复用，以提升效率与性能。",
      "hf_url": "https://huggingface.co/papers/2602.03560",
      "arxiv_url": "https://arxiv.org/abs/2602.03560",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03560",
      "github_url": "",
      "upvotes": 44,
      "fetched_at": "2026-02-19T05:27:31.804292+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04515",
      "title": "EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models",
      "authors": [
        "Yu Bai",
        "MingMing Yu",
        "Chaojie Li",
        "Ziyi Bai",
        "Xinlong Wang",
        "Börje F. Karlsson"
      ],
      "abstract": "EgoActor is a unified vision-language model that translates high-level instructions into precise humanoid robot actions through integrated perception and execution across simulated and real-world environments. Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements , manipulation commands , and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering , and simulated environment demonstrations , enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution , while generalizing across diverse tasks and unseen environments.",
      "summary_en": "EgoActor is a unified vision-language model that translates high-level instructions into precise humanoid robot actions through integrated perception and execution across simulated and real-world environments.",
      "summary_zh": "EgoActor是一个统一的视觉-语言模型，通过集成感知与执行，在模拟与真实环境中将高层指令转化为精确的人形机器人动作。",
      "hf_url": "https://huggingface.co/papers/2602.04515",
      "arxiv_url": "https://arxiv.org/abs/2602.04515",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04515",
      "github_url": "",
      "upvotes": 38,
      "fetched_at": "2026-02-19T05:27:42.747666+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04879",
      "title": "Rethinking the Trust Region in LLM Reinforcement Learning",
      "authors": [
        "Penghui Qi",
        "Xiangxin Zhou",
        "Zichen Liu",
        "Tianyu Pang",
        "Chao Du",
        "Min Lin",
        "Wee Sun Lee"
      ],
      "abstract": "DPPO addresses limitations in PPO for LLM fine-tuning by replacing ratio clipping with direct policy divergence constraints, improving training stability and efficiency. Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence . This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximation s to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.",
      "summary_en": "DPPO addresses limitations in PPO for LLM fine-tuning by replacing ratio clipping with direct policy divergence constraints, improving training stability and efficiency.",
      "summary_zh": "DPPO通过以直接策略散度约束替代比率裁剪，解决了PPO在LLM微调中的局限性，提升了训练稳定性和效率。",
      "hf_url": "https://huggingface.co/papers/2602.04879",
      "arxiv_url": "https://arxiv.org/abs/2602.04879",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04879",
      "github_url": "",
      "upvotes": 33,
      "fetched_at": "2026-02-19T05:42:16.646673+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02958",
      "title": "Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization",
      "authors": [
        "Haocheng Xi",
        "Shuo Yang",
        "Yilong Zhao",
        "Muyang Li",
        "Han Cai",
        "Xingyang Li",
        "Yujun Lin",
        "Zhuoyang Zhang",
        "Jintao Zhang",
        "Xiuyu Li",
        "Zhiying Xu",
        "Jun Wu",
        "Chenfeng Xu",
        "Ion Stoica",
        "Song Han",
        "Kurt Keutzer"
      ],
      "abstract": "Quant VideoGen addresses KV cache memory limitations in autoregressive video diffusion models through semantic-aware smoothing and progressive residual quantization, achieving significant memory reduction with minimal latency impact. Despite rapid progress in autoregressive video diffusion , an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU memory, often exceeding 30 GB, preventing deployment on widely available hardware. More critically, constrained KV cache budgets restrict the effective working memory, directly degrading long horizon consistency in identity, layout, and motion. To address this challenge, we present Quant VideoGen (QVG), a training free KV cache quantization framework for autoregressive video diffusion models. QVG leverages video spatiotemporal redundancy through Semantic Aware Smoothing , producing low magnitude, quantization friendly residuals. It further introduces Progressive Residual Quantization , a coarse to fine multi stage scheme that reduces quantization error while enabling a smooth quality memory trade off. Across LongCat Video, HY WorldPlay, and Self Forcing benchmarks, QVG establishes a new Pareto frontier between quality and memory efficiency , reducing KV cache memory by up to 7.0 times with less than 4% end to end latency overhead while consistently outperforming existing baselines in generation quality.",
      "summary_en": "Quant VideoGen addresses KV cache memory limitations in autoregressive video diffusion models through semantic-aware smoothing and progressive residual quantization, achieving significant memory reduction with minimal latency impact.",
      "summary_zh": "Quant VideoGen 通过语义感知平滑与渐进残差量化解决自回归视频扩散模型中 KV 缓存的内存限制，实现了显著的内存缩减且对延迟影响极小。",
      "hf_url": "https://huggingface.co/papers/2602.02958",
      "arxiv_url": "https://arxiv.org/abs/2602.02958",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02958",
      "github_url": "",
      "upvotes": 33,
      "fetched_at": "2026-02-19T05:27:26.266354+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02196",
      "title": "TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents",
      "authors": [
        "Hang Yan",
        "Xinyu Che",
        "Fangzhi Xu",
        "Qiushi Sun",
        "Zichen Ding",
        "Kanzhi Cheng",
        "Jian Zhang",
        "Tao Qin",
        "Jun Liu",
        "Qika Lin"
      ],
      "abstract": "Test-Time Improvement (TTI) in autonomous LLM agents involves iterative environmental interaction that enhances performance, but current evaluation methods inadequately capture task optimization efficiency and memory utilization. Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency , behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.",
      "summary_en": "Test-Time Improvement (TTI) in autonomous LLM agents involves iterative environmental interaction that enhances performance, but current evaluation methods inadequately capture task optimization efficiency and memory utilization.",
      "summary_zh": "自主LLM智能体中的测试时改进（TTI）通过迭代式环境交互提升性能，但现有评估方法无法充分衡量任务优化效率与记忆利用率。",
      "hf_url": "https://huggingface.co/papers/2602.02196",
      "arxiv_url": "https://arxiv.org/abs/2602.02196",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02196",
      "github_url": "",
      "upvotes": 33,
      "fetched_at": "2026-02-19T05:27:20.819060+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2601.22954",
      "title": "Residual Context Diffusion Language Models",
      "authors": [
        "Yuezhou Hu",
        "Harman Singh",
        "Monishwaran Maheswaran",
        "Haocheng Xi",
        "Coleman Hooper",
        "Jintao Zhang",
        "Aditya Tomar",
        "Michael W. Mahoney",
        "Sewon Min",
        "Mehrdad Farajtabar",
        "Kurt Keutzer",
        "Amir Gholami",
        "Chenfeng Xu"
      ],
      "abstract": "Residual Context Diffusion (RCD) enhances diffusion large language models by recycling discarded token information through contextual residuals, improving accuracy with minimal computational overhead. Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to purely autoregressive language models because they can decode multiple tokens in parallel. However, state-of-the-art block-wise dLLMs rely on a \"remasking\" mechanism that decodes only the most confident tokens and discards the rest, effectively wasting computation. We demonstrate that recycling computation from the discarded tokens is beneficial, as these tokens retain contextual information useful for subsequent decoding iterations. In light of this, we propose Residual Context Diffusion (RCD), a module that converts these discarded token representations into contextual residuals and injects them back for the next denoising step. RCD uses a decoupled two-stage training pipeline to bypass the memory bottlenecks associated with backpropagation . We validate our method on both long CoT reasoning (SDAR) and short CoT instruction following (LLaDA) models. We demonstrate that a standard dLLM can be efficiently converted to the RCD paradigm with merely ~1 billion tokens. RCD consistently improves frontier dLLMs by 5-10 points in accuracy with minimal extra computation overhead across a wide range of benchmarks. Notably, on the most challenging AIME tasks , RCD nearly doubles baseline accuracy and attains up to 4-5x fewer denoising steps at equivalent accuracy levels.",
      "summary_en": "Residual Context Diffusion (RCD) enhances diffusion large language models by recycling discarded token information through contextual residuals, improving accuracy with minimal computational overhead.",
      "summary_zh": "残差上下文扩散（RCD）通过上下文残差回收被丢弃的token信息，以极低的计算开销提升扩散大语言模型的准确性。",
      "hf_url": "https://huggingface.co/papers/2601.22954",
      "arxiv_url": "https://arxiv.org/abs/2601.22954",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2601.22954",
      "github_url": "https://github.com/yuezhouhu/residual-context-diffusion",
      "upvotes": 33,
      "fetched_at": "2026-02-19T05:27:16.528172+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02402",
      "title": "SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation",
      "authors": [
        "Mu Huang",
        "Hui Wang",
        "Kerui Ren",
        "Linning Xu",
        "Yunsong Zhou",
        "Mulin Yu",
        "Bo Dai",
        "Jiangmiao Pang"
      ],
      "abstract": "SoMA is a 3D Gaussian Splat simulator that enables stable, long-horizon manipulation of soft bodies by coupling deformable dynamics, environmental forces, and robot actions in a unified latent neural space. Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation , with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics , environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation . Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding .",
      "summary_en": "SoMA is a 3D Gaussian Splat simulator that enables stable, long-horizon manipulation of soft bodies by coupling deformable dynamics, environmental forces, and robot actions in a unified latent neural space.",
      "summary_zh": "SoMA是一种3D Gaussian Splat模拟器，通过将可变形动力学、环境力和机器人动作耦合在统一的隐式神经空间中，实现了对软体的稳定长程操作。",
      "hf_url": "https://huggingface.co/papers/2602.02402",
      "arxiv_url": "https://arxiv.org/abs/2602.02402",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02402",
      "github_url": "",
      "upvotes": 32,
      "fetched_at": "2026-02-19T05:27:23.301046+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03143",
      "title": "Self-Hinting Language Models Enhance Reinforcement Learning",
      "authors": [
        "Baohao Liao",
        "Hanze Dong",
        "Xinxing Xu",
        "Christof Monz",
        "Jiang Bian"
      ],
      "abstract": "SAGE is an on-policy reinforcement learning framework that enhances GRPO by injecting self-hints during training to increase outcome diversity under sparse rewards, improving alignment of large language models. Group Relative Policy Optimization (GRPO) has recently emerged as a practical recipe for aligning large language models with verifiable objectives. However, under sparse terminal rewards , GRPO often stalls because rollouts within a group frequently receive identical rewards, causing relative advantages to collapse and updates to vanish. We propose self-hint aligned GRPO with privileged supervision (SAGE), an on-policy reinforcement learning framework that injects privileged hints during training to reshape the rollout distribution under the same terminal verifier reward. For each prompt x, the model samples a compact hint h (e.g., a plan or decomposition) and then generates a solution τ conditioned on (x,h). Crucially, the task reward R(x,τ) is unchanged; hints only increase within-group outcome diversity under finite sampling, preventing GRPO advantages from collapsing under sparse rewards . At test time, we set h=varnothing and deploy the no-hint policy without any privileged information. Moreover, sampling diverse self-hint s serves as an adaptive curriculum that tracks the learner's bottlenecks more effectively than fixed hints from an initial policy or a stronger external model. Experiments over 6 benchmarks with 3 LLMs show that SAGE consistently outperforms GRPO, on average +2.0 on Llama-3.2-3B-Instruct, +1.2 on Qwen2.5-7B-Instruct and +1.3 on Qwen3-4B-Instruct. The code is available at https://github.com/BaohaoLiao/SAGE.",
      "summary_en": "SAGE is an on-policy reinforcement learning framework that enhances GRPO by injecting self-hints during training to increase outcome diversity under sparse rewards, improving alignment of large language models.",
      "summary_zh": "SAGE是一种同策略强化学习框架，通过在训练过程中注入自提示来增加稀疏奖励下的结果多样性，从而增强GRPO并提升大语言模型的对齐效果。",
      "hf_url": "https://huggingface.co/papers/2602.03143",
      "arxiv_url": "https://arxiv.org/abs/2602.03143",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03143",
      "github_url": "https://github.com/BaohaoLiao/SAGE",
      "upvotes": 29,
      "fetched_at": "2026-02-19T05:27:27.988537+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03510",
      "title": "Semantic Routing: Exploring Multi-Layer LLM Feature Weighting for Diffusion Transformers",
      "authors": [
        "Bozhou Li",
        "Yushuo Guan",
        "Haolin Li",
        "Bohan Zeng",
        "Yiyan Ji",
        "Yue Ding",
        "Pengfei Wan",
        "Kun Gai",
        "Yuanxing Zhang",
        "Wentao Zhang"
      ],
      "abstract": "Text conditioning in DiT-based models is enhanced through a unified normalized convex fusion framework that optimizes multi-layer LLM hidden states via depth-wise semantic routing, improving text-image alignment and compositional generation. Recent DiT-based text-to-image models increasingly adopt LLMs as text encoders , yet text conditioning remains largely static and often utilizes only a single LLM layer, despite pronounced semantic hierarchy across LLM layers and non-stationary denoising dynamics over both diffusion time and network depth. To better match the dynamic process of DiT generation and thereby enhance the diffusion model's generative capability , we introduce a unified normalized convex fusion framework equipped with lightweight gates to systematically organize multi-layer LLM hidden states via time-wise, depth-wise, and joint fusion . Experiments establish Depth-wise Semantic Routing as the superior conditioning strategy, consistently improving text-image alignment and compositional generation (e.g., +9.97 on the GenAI-Bench Counting task). Conversely, we find that purely time-wise fusion can paradoxically degrade visual generation fidelity. We attribute this to a train-inference trajectory mismatch : under classifier-free guidance , nominal timesteps fail to track the effective SNR , causing semantically mistimed feature injection during inference. Overall, our results position depth-wise routing as a strong and effective baseline and highlight the critical need for trajectory-aware signals to enable robust time-dependent conditioning.",
      "summary_en": "Text conditioning in DiT-based models is enhanced through a unified normalized convex fusion framework that optimizes multi-layer LLM hidden states via depth-wise semantic routing, improving text-image alignment and compositional generation.",
      "summary_zh": "基于DiT的模型的文本条件化通过统一归一化凸融合框架得以增强，该框架利用深度语义路由优化多层LLM隐藏状态，从而提升图文对齐与组合生成能力。",
      "hf_url": "https://huggingface.co/papers/2602.03510",
      "arxiv_url": "https://arxiv.org/abs/2602.03510",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03510",
      "github_url": "",
      "upvotes": 27,
      "fetched_at": "2026-02-19T05:27:31.013762+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02990",
      "title": "Learning to Repair Lean Proofs from Compiler Feedback",
      "authors": [
        "Evan Wang",
        "Simon Chess",
        "Daniel Lee",
        "Siyuan Ge",
        "Ajit Mallavarapu",
        "Vasily Ilin"
      ],
      "abstract": "Neural theorem provers can be improved through supervised learning on proof repair data that includes compiler feedback and diagnostic explanations, enabling better failure interpretation and correction. As neural theorem provers become increasingly agentic, the ability to interpret and act on compiler feedback is critical. However, existing Lean datasets consist almost exclusively of correct proofs, offering little supervision for understanding and repairing failures. We study Lean proof repair as a supervised learning problem: given an erroneous proof and compiler feedback , predict both a corrected proof and a natural-language diagnosis grounded in the same feedback. We introduce APRIL (Automated Proof Repair in Lean ), a dataset of 260,000 supervised tuples pairing systematically generated proof failures with compiler diagnostics and aligned repair and explanation targets. Training language models on APRIL substantially improves repair accuracy and feedback-conditioned reasoning; in our single-shot repair evaluation setting, a finetuned 4B-parameter model outperforms the strongest open-source baseline. We view diagnostic-conditioned supervision as a complementary training signal for feedback-using provers. Our dataset is available at https://huggingface.co/datasets/uw-math-ai/APRIL{this link}.",
      "summary_en": "Neural theorem provers can be improved through supervised learning on proof repair data that includes compiler feedback and diagnostic explanations, enabling better failure interpretation and correction.",
      "summary_zh": "神经定理证明器可通过对包含编译器反馈和诊断解释的证明修复数据进行监督学习来改进，从而实现更好的失败解释与修正。",
      "hf_url": "https://huggingface.co/papers/2602.02990",
      "arxiv_url": "https://arxiv.org/abs/2602.02990",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02990",
      "github_url": "",
      "upvotes": 27,
      "fetched_at": "2026-02-19T05:27:27.151741+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03907",
      "title": "HY3D-Bench: Generation of 3D Assets",
      "authors": [
        "Team Hunyuan3D",
        "Bowen Zhang",
        "Chunchao Guo",
        "Dongyuan Guo",
        "Haolin Liu",
        "Hongyu Yan",
        "Huiwen Shi",
        "Jiaao Yu",
        "Jiachen Xu",
        "Jingwei Huang",
        "Kunhong Li",
        "Lifu Wang",
        "Linus",
        "Penghao Wang",
        "Qingxiang Lin",
        "Ruining Tang",
        "Xianghui Yang",
        "Yang Li",
        "Yirui Guan",
        "Yunfei Zhao",
        "Yunhan Yang",
        "Zeqiang Lai"
      ],
      "abstract": "HY3D-Bench presents an open-source ecosystem for 3D content creation that provides high-fidelity 3D objects and synthetic assets to advance 3D generation capabilities. While recent advances in neural representations and generative models have revolutionized 3D content creation , the field remains constrained by significant data processing bottlenecks. To address this, we introduce HY3D-Bench, an open-source ecosystem designed to establish a unified, high-quality foundation for 3D generation . Our contributions are threefold: (1) We curate a library of 250k high-fidelity 3D objects distilled from large-scale repositories, employing a rigorous pipeline to deliver training-ready artifacts, including watertight meshes and multi-view renderings ; (2) We introduce structured part-level decomposition , providing the granularity essential for fine-grained perception and controllable editing; and (3) We bridge real-world distribution gaps via a scalable AIGC synthesis pipeline , contributing 125k synthetic assets to enhance diversity in long-tail categories. Validated empirically through the training of Hunyuan3D-2.1-Small, HY3D-Bench democratizes access to robust data resources, aiming to catalyze innovation across 3D perception , robotics , and digital content creation .",
      "summary_en": "HY3D-Bench presents an open-source ecosystem for 3D content creation that provides high-fidelity 3D objects and synthetic assets to advance 3D generation capabilities.",
      "summary_zh": "HY3D-Bench 提出了一个用于 3D 内容创作的开源生态系统，提供高保真 3D 物体与合成资产，以推进 3D 生成能力。",
      "hf_url": "https://huggingface.co/papers/2602.03907",
      "arxiv_url": "https://arxiv.org/abs/2602.03907",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03907",
      "github_url": "https://github.com/Tencent-Hunyuan/HY3D-Bench",
      "upvotes": 23,
      "fetched_at": "2026-02-19T05:27:34.290114+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03587",
      "title": "CL-bench: A Benchmark for Context Learning",
      "authors": [
        "Shihan Dou",
        "Ming Zhang",
        "Zhangyue Yin",
        "Chenhao Huang",
        "Yujiong Shen",
        "Junzhe Wang",
        "Jiayi Chen",
        "Yuchen Ni",
        "Junjie Ye",
        "Cheng Zhang",
        "Huaibing Xie",
        "Jianglu Hu",
        "Shaolei Wang",
        "Weichao Wang",
        "Yanling Xiao",
        "Yiting Liu",
        "Zenan Xu",
        "Zhen Guo",
        "Pluto Zhou",
        "Tao Gui",
        "Zuxuan Wu",
        "Xipeng Qiu"
      ],
      "abstract": "Language models struggle with context learning, requiring new knowledge and reasoning beyond pre-training, as demonstrated by a comprehensive benchmark revealing poor performance on real-world tasks. Current language models (LMs) excel at reasoning over prompts using pre-trained knowledge . However, real-world tasks are far more complex and context-dependent: models must learn from task-specific context and leverage new knowledge beyond what is learned during pre-training to reason and resolve tasks. We term this capability context learning , a crucial ability that humans naturally possess but has been largely overlooked. To this end, we introduce CL-bench, a real-world benchmark consisting of 500 complex contexts, 1,899 tasks, and 31,607 verification rubrics, all crafted by experienced domain experts. Each task is designed such that the new content required to resolve it is contained within the corresponding context. Resolving tasks in CL-bench requires models to learn from the context, ranging from new domain-specific knowledge, rule systems, and complex procedures to laws derived from empirical data, all of which are absent from pre-training. This goes far beyond long-context tasks that primarily test retrieval or reading comprehension , and in-context learning tasks, where models learn simple task patterns via instructions and demonstrations. Our evaluations of ten frontier LMs find that models solve only 17.2% of tasks on average. Even the best-performing model, GPT-5.1 , solves only 23.7%, revealing that LMs have yet to achieve effective context learning , which poses a critical bottleneck for tackling real-world, complex context-dependent tasks. CL-bench represents a step towards building LMs with this fundamental capability, making them more intelligent and advancing their deployment in real-world scenarios.",
      "summary_en": "Language models struggle with context learning, requiring new knowledge and reasoning beyond pre-training, as demonstrated by a comprehensive benchmark revealing poor performance on real-world tasks.",
      "summary_zh": "语言模型难以进行上下文学习，需要预训练之外的新知识和推理能力，一项综合基准测试显示其在真实世界任务上表现不佳。",
      "hf_url": "https://huggingface.co/papers/2602.03587",
      "arxiv_url": "https://arxiv.org/abs/2602.03587",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03587",
      "github_url": "https://github.com/Tencent-Hunyuan/CL-bench",
      "upvotes": 23,
      "fetched_at": "2026-02-19T05:27:32.688835+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03973",
      "title": "VLS: Steering Pretrained Robot Policies via Vision-Language Models",
      "authors": [
        "Shuo Liu",
        "Ishneet Sukhvinder Singh",
        "Yiqing Xu",
        "Jiafei Duan",
        "Ranjay Krishna"
      ],
      "abstract": "Pretrained diffusion and flow-matching policies fail under test-time shifts due to tight coupling with training configurations, prompting the development of Vision-Language Steering (VLS) for training-free inference-time adaptation through vision-language model-guided trajectory steering. Why do pretrained diffusion or flow-matching policies fail when the same task is performed near an obstacle, on a shifted support surface, or amid mild clutter? Such failures rarely reflect missing motor skills; instead, they expose a limitation of imitation learning under train-test shifts , where action generation is tightly coupled to training-specific spatial configurations and task specifications. Retraining or fine-tuning to address these failures is costly and conceptually misaligned, as the required behaviors already exist but cannot be selectively adapted at test time. We propose Vision-Language Steering (VLS), a training-free framework for inference-time adaptation of frozen generative robot policies . VLS treats adaptation as an inference-time control problem, steering the sampling process of a pretrained diffusion or flow-matching policy in response to out-of-distribution observation-language inputs without modifying policy parameters. By leveraging vision-language models to synthesize trajectory-differentiable reward functions , VLS guides denoising toward action trajectories that satisfy test-time spatial and task requirements. Across simulation and real-world evaluations, VLS consistently outperforms prior steering methods, achieving a 31% improvement on CALVIN and a 13% gain on LIBERO-PRO. Real-world deployment on a Franka robot further demonstrates robust inference-time adaptation under test-time spatial and semantic shifts. Project page: https://vision-language-steering.github.io/webpage/",
      "summary_en": "Pretrained diffusion and flow-matching policies fail under test-time shifts due to tight coupling with training configurations, prompting the development of Vision-Language Steering (VLS) for training-free inference-time adaptation through vision-language model-guided trajectory steering.",
      "summary_zh": "预训练的扩散和流匹配策略因与训练配置紧密耦合而在测试时偏移下失效，促使了视觉-语言引导（VLS）的提出，其通过视觉-语言模型引导的轨迹引导实现免训练的推理时自适应。",
      "hf_url": "https://huggingface.co/papers/2602.03973",
      "arxiv_url": "https://arxiv.org/abs/2602.03973",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03973",
      "github_url": "https://github.com/Vision-Language-Steering/code",
      "upvotes": 22,
      "fetched_at": "2026-02-19T05:27:36.816781+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03828",
      "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations",
      "authors": [
        "Minjun Zhu",
        "Zhen Lin",
        "Yixuan Weng",
        "Panzhong Lu",
        "Qiujie Xie",
        "Yifan Wei",
        "Sifan Liu",
        "Qiyao Sun",
        "Yue Zhang"
      ],
      "abstract": "FigureBench presents the first large-scale benchmark for generating scientific illustrations from long-form scientific texts, while AutoFigure introduces an agentic framework that produces publication-ready illustrations through extensive thinking, recombination, and validation processes. High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench , the first large-scale benchmark for generating scientific illustrations from long-form scientific text s. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers , surveys , blogs, and textbooks . Moreover, we propose AutoFigure , the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text . Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal . Leveraging the high-quality data from FigureBench , we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations . The code, dataset and huggingface space are released in https://github.com/ResearAI/ AutoFigure .",
      "summary_en": "FigureBench presents the first large-scale benchmark for generating scientific illustrations from long-form scientific texts, while AutoFigure introduces an agentic framework that produces publication-ready illustrations through extensive thinking, recombination, and validation processes.",
      "summary_zh": "FigureBench提出了首个从长篇幅科学文本生成科学插图的大规模基准测试，AutoFigure则引入了一种智能体框架，通过深入思考、重组与验证流程生成可直接发表的插图。",
      "hf_url": "https://huggingface.co/papers/2602.03828",
      "arxiv_url": "https://arxiv.org/abs/2602.03828",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03828",
      "github_url": "https://github.com/ResearAI/AutoFigure-Edit",
      "upvotes": 20,
      "fetched_at": "2026-02-19T05:27:33.433786+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03442",
      "title": "A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces",
      "authors": [
        "Mingxuan Du",
        "Benfeng Xu",
        "Chiwei Zhu",
        "Shaohan Wang",
        "Pengyu Wang",
        "Xiaorui Wang",
        "Zhendong Mao"
      ],
      "abstract": "Agentic RAG framework enables models to dynamically adapt retrieval decisions across multiple granularities, outperforming traditional approaches while scaling efficiently with model improvements. Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search , semantic search , and chunk read , enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute . We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag.",
      "summary_en": "Agentic RAG framework enables models to dynamically adapt retrieval decisions across multiple granularities, outperforming traditional approaches while scaling efficiently with model improvements.",
      "summary_zh": "Agentic RAG框架使模型能够跨多粒度动态调整检索决策，性能优于传统方法，并随模型改进高效扩展。",
      "hf_url": "https://huggingface.co/papers/2602.03442",
      "arxiv_url": "https://arxiv.org/abs/2602.03442",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03442",
      "github_url": "https://github.com/Ayanami0730/arag",
      "upvotes": 19,
      "fetched_at": "2026-02-19T05:27:30.427321+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2601.18207",
      "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
      "authors": [
        "James Burgess",
        "Jan N. Hansen",
        "Duo Peng",
        "Yuhui Zhang",
        "Alejandro Lozano",
        "Min Woo Sun",
        "Emma Lundberg",
        "Serena Yeung-Levy"
      ],
      "abstract": "Search agents trained on scientific paper corpora demonstrate advanced reasoning capabilities for technical question-answering tasks, outperforming traditional retrieval methods through reinforcement learning with verifiable rewards.",
      "summary_en": "Search agents trained on scientific paper corpora demonstrate advanced reasoning capabilities for technical question-answering tasks, outperforming traditional retrieval methods through reinforcement learning with verifiable rewards.",
      "summary_zh": "基于科学论文语料库训练的搜索智能体在技术问答任务中展现出先进的推理能力，通过可验证奖励的强化学习超越传统检索方法。",
      "hf_url": "https://huggingface.co/papers/2601.18207",
      "arxiv_url": "https://arxiv.org/abs/2601.18207",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2601.18207",
      "github_url": "https://github.com/jmhb0/PaperSearchQA",
      "upvotes": 19,
      "fetched_at": "2026-02-19T05:27:13.534884+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04816",
      "title": "Horizon-LM: A RAM-Centric Architecture for LLM Training",
      "authors": [
        "Zhengqing Yuan",
        "Lichao Sun",
        "Yanfang",
        "Ye"
      ],
      "abstract": "Horizon-LM enables large-model training on single GPUs by redefining CPU-GPU roles and eliminating persistent GPU memory usage through explicit recomputation and pipelined execution. The rapid growth of large language models (LLMs) has outpaced the evolution of single-GPU hardware, making model scale increasingly constrained by memory capacity rather than computation. While modern training systems extend GPU memory through distributed parallelism and offloading across CPU and storage tiers, they fundamentally retain a GPU-centric execution paradigm in which GPUs host persistent model replicas and full autograd graphs . As a result, scaling large models remains tightly coupled to multi-GPU clusters, complex distributed runtimes, and unpredictable host memory consumption, creating substantial barriers for node-scale post-training workloads such as instruction tuning, alignment, and domain adaptation. We present Horizon-LM, a memory-centric training system that redefines the roles of CPU and GPU for large-model optimization. Horizon-LM treats host memory as the authoritative parameter store and uses GPUs solely as transient compute engines through a CPU-master , GPU-template execution model. By eliminating persistent GPU-resident modules and autograd graphs , employing explicit recomputation with manual gradient propagation , and introducing a pipelined double-buffered execution engine, Horizon-LM decouples model scale from GPU count and bounds memory usage to the theoretical parameter footprint. On a single H200 GPU with 1.5\\,TB host RAM, Horizon-LM reliably trains models up to 120B parameters. On a standard single A100 machine, Horizon-LM achieves up to 12.2times higher training throughput than DeepSpeed ZeRO-3 with CPU offloading while preserving numerical correctness. Across platforms and scales, Horizon-LM sustains high device utilization and predictable memory growth, demonstrating that host memory, not GPU memory, defines the true feasibility boundary for node-scale large-model training.",
      "summary_en": "Horizon-LM enables large-model training on single GPUs by redefining CPU-GPU roles and eliminating persistent GPU memory usage through explicit recomputation and pipelined execution.",
      "summary_zh": "Horizon-LM 通过重新定义 CPU-GPU 角色，并借助显式重计算和流水线执行消除持久性 GPU 内存占用，从而在单 GPU 上实现大模型训练。",
      "hf_url": "https://huggingface.co/papers/2602.04816",
      "arxiv_url": "https://arxiv.org/abs/2602.04816",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04816",
      "github_url": "https://github.com/DLYuanGod/Horizon-LM",
      "upvotes": 17,
      "fetched_at": "2026-02-19T05:42:15.312300+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04575",
      "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration",
      "authors": [
        "Jiaheng Liu",
        "Yuanxing Zhang",
        "Shihao Li",
        "Xinping Lei"
      ],
      "abstract": "Vibe AIGC introduces a new generative AI paradigm where users provide high-level aesthetic and functional preferences, which are then orchestrated through multi-agent workflows to bridge the gap between human intent and machine execution. For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding , we introduce the Vibe AIGC , a new paradigm for content generation via agentic orchestration , which represents the autonomous synthesis of hierarchical multi-agent workflows . Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration , Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.",
      "summary_en": "Vibe AIGC introduces a new generative AI paradigm where users provide high-level aesthetic and functional preferences, which are then orchestrated through multi-agent workflows to bridge the gap between human intent and machine execution.",
      "summary_zh": "Vibe AIGC提出了一种新的生成式AI范式，用户提供高层次的审美与功能偏好，这些偏好通过多智能体工作流进行编排，从而弥合人类意图与机器执行之间的差距。",
      "hf_url": "https://huggingface.co/papers/2602.04575",
      "arxiv_url": "https://arxiv.org/abs/2602.04575",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04575",
      "github_url": "",
      "upvotes": 17,
      "fetched_at": "2026-02-19T05:27:44.326326+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2601.22859",
      "title": "MEnvAgent: Scalable Polyglot Environment Construction for Verifiable Software Engineering",
      "authors": [
        "Chuanzhe Guo",
        "Jingjing Wu",
        "Sijun He",
        "Yang Chen",
        "Zhaoqi Kuang",
        "Shilong Fan",
        "Bingjin Chen",
        "Siqi Bao",
        "Jing Liu",
        "Hua Wu",
        "Qingfu Zhu",
        "Wanxiang Che",
        "Haifeng Wang"
      ],
      "abstract": "MEnvAgent is a multi-language framework that automates environment construction for software engineering tasks using a planning-execution-verification architecture and environment reuse mechanism, achieving improved performance on a new benchmark and creating the largest open-source polyglot dataset of verifiable Docker environments. The evolution of Large Language Model (LLM) agents for software engineering (SWE) is constrained by the scarcity of verifiable datasets , a bottleneck stemming from the complexity of constructing executable environments across diverse languages. To address this, we introduce MEnvAgent, a Multi-language framework for automated Environment construction that facilitates scalable generation of verifiable task instances. MEnvAgent employs a multi-agent Planning-Execution-Verification architecture to autonomously resolve construction failures and integrates a novel Environment Reuse Mechanism that reduces computational overhead by incrementally patching historical environments. Evaluations on MEnvBench , a new benchmark comprising 1,000 tasks across 10 languages, demonstrate that MEnvAgent outperforms baselines, improving Fail-to-Pass (F2P) rates by 8.6% while reducing time costs by 43%. Additionally, we demonstrate the utility of MEnvAgent by constructing MEnvData-SWE , the largest open-source polyglot dataset of realistic verifiable Docker environments to date, alongside solution trajectories that enable consistent performance gains on SWE tasks across a wide range of models. Our code, benchmark, and dataset are available at https://github.com/ernie-research/MEnvAgent.",
      "summary_en": "MEnvAgent is a multi-language framework that automates environment construction for software engineering tasks using a planning-execution-verification architecture and environment reuse mechanism, achieving improved performance on a new benchmark and creating the largest open-source polyglot dataset of verifiable Docker environments.",
      "summary_zh": "MEnvAgent 是一个多语言框架，采用规划-执行-验证架构和环境复用机制，为软件工程任务自动化构建环境，在新基准上取得性能提升，并创建了最大规模的开源多语言可验证 Docker 环境数据集。",
      "hf_url": "https://huggingface.co/papers/2601.22859",
      "arxiv_url": "https://arxiv.org/abs/2601.22859",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2601.22859",
      "github_url": "https://github.com/ernie-research/MEnvAgent",
      "upvotes": 17,
      "fetched_at": "2026-02-19T05:27:15.874235+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04735",
      "title": "From Data to Behavior: Predicting Unintended Model Behaviors Before Training",
      "authors": [
        "Mengru Wang",
        "Zhenqian Xu",
        "Junfeng Fang",
        "Yunzhi Yao",
        "Shumin Deng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Data2Behavior predicts unintended model behaviors before training using MDF, a lightweight method that analyzes data features to reveal potential biases without parameter updates. Large Language Models (LLMs) can acquire unintended biases from seemingly benign training data even without explicit cues or malicious content. Existing methods struggle to detect such risks before fine-tuning, making post hoc evaluation costly and inefficient. To address this challenge, we introduce Data2Behavior , a new task for predicting unintended model behaviors prior to training. We also propose Manipulating Data Features (MDF), a lightweight approach that summarizes candidate data through their mean representations and injects them into the forward pass of a base model, allowing latent statistical signals in the data to shape model activations and reveal potential biases and safety risks without updating any parameters. MDF achieves reliable prediction while consuming only about 20% of the GPU resources required for fine-tuning. Experiments on Qwen3-14B, Qwen2.5-32B-Instruct, and Gemma-3-12b-it confirm that MDF can anticipate unintended behaviors and provide insight into pre-training vulnerabilities .",
      "summary_en": "Data2Behavior predicts unintended model behaviors before training using MDF, a lightweight method that analyzes data features to reveal potential biases without parameter updates.",
      "summary_zh": "Data2Behavior利用MDF这一轻量级方法，在训练前分析数据特征以预测非预期的模型行为，无需参数更新即可揭示潜在偏差。",
      "hf_url": "https://huggingface.co/papers/2602.04735",
      "arxiv_url": "https://arxiv.org/abs/2602.04735",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04735",
      "github_url": "https://github.com/zjunlp/Data2Behavior",
      "upvotes": 15,
      "fetched_at": "2026-02-19T05:42:11.168927+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02160",
      "title": "D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use",
      "authors": [
        "Bowen Xu",
        "Shaoyu Wu",
        "Hao Jiang",
        "Kai Liu",
        "Xin Chen",
        "Lulu Hu",
        "Bin Yang"
      ],
      "abstract": "A two-stage training framework called D-CORE is proposed to improve large reasoning models' ability to decompose complex tasks and compose reasoning processes, achieving superior performance in tool-use benchmarks. Effective tool use and reasoning are essential capabilities for large reasoning models ~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning . To address this, we propose a two-stage training framework D-CORE~(\\textbf{D}ecomposing tasks and \\textbf{Co}mposing \\textbf{Re}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation , followed by diversity-aware reinforcement learning ~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\\% accuracy, surpassing the best-performing 8B model by 5.7\\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\\%, outperforming 70B models despite being 5times smaller. The source code is available at https://github.com/alibaba/EfficientAI.",
      "summary_en": "A two-stage training framework called D-CORE is proposed to improve large reasoning models' ability to decompose complex tasks and compose reasoning processes, achieving superior performance in tool-use benchmarks.",
      "summary_zh": "提出了一种名为D-CORE的两阶段训练框架，以提升大型推理模型分解复杂任务并组合推理过程的能力，在工具使用基准测试中取得了更优性能。",
      "hf_url": "https://huggingface.co/papers/2602.02160",
      "arxiv_url": "https://arxiv.org/abs/2602.02160",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02160",
      "github_url": "https://github.com/alibaba/EfficientAI",
      "upvotes": 14,
      "fetched_at": "2026-02-19T05:27:20.127432+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04284",
      "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning",
      "authors": [
        "Yansong Ning",
        "Jun Fang",
        "Naiqiang Tan",
        "Hao Liu"
      ],
      "abstract": "Agent-Omit is a training framework that enables LLM agents to adaptively omit redundant thoughts and observations during multi-turn interactions, achieving superior effectiveness-efficiency trade-offs compared to existing methods. Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data , including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence . Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.",
      "summary_en": "Agent-Omit is a training framework that enables LLM agents to adaptively omit redundant thoughts and observations during multi-turn interactions, achieving superior effectiveness-efficiency trade-offs compared to existing methods.",
      "summary_zh": "Agent-Omit是一种训练框架，使LLM智能体能够在多轮交互中自适应地省略冗余的思考和观察，相较于现有方法实现了更优的效果-效率权衡。",
      "hf_url": "https://huggingface.co/papers/2602.04284",
      "arxiv_url": "https://arxiv.org/abs/2602.04284",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04284",
      "github_url": "https://github.com/usail-hkust/Agent-Omit",
      "upvotes": 13,
      "fetched_at": "2026-02-19T05:27:39.936607+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02140",
      "title": "Quantifying the Gap between Understanding and Generation within Unified Multimodal Models",
      "authors": [
        "Chenlong Wang",
        "Yuhang Chen",
        "Zhihan Hu",
        "Dongping Chen",
        "Wenhu Chen",
        "Sarah Wiegreffe",
        "Tianyi Zhou"
      ],
      "abstract": "Unified multimodal models exhibit a persistent gap between understanding and generation capabilities, indicating only surface-level integration rather than deep cognitive convergence. Recent advances in unified multimodal models (UMM) have demonstrated remarkable progress in both understanding and generation tasks. However, whether these two capabilities are genuinely aligned and integrated within a single model remains unclear. To investigate this question, we introduce GapEval, a bidirectional benchmark designed to quantify the gap between understanding and generation capabilities, and quantitatively measure the cognitive coherence of the two \"unified\" directions. Each question can be answered in both modalities (image and text), enabling a symmetric evaluation of a model's bidirectional inference capability and cross-modal consistency . Experiments reveal a persistent gap between the two directions across a wide range of UMMs with different architectures, suggesting that current models achieve only surface-level unification rather than deep cognitive convergence of the two. To further explore the underlying mechanism, we conduct an empirical study from the perspective of knowledge manipulation to illustrate the underlying limitations. Our findings indicate that knowledge within UMMs often remains disjoint. The capability emergence and knowledge across modalities are unsynchronized, paving the way for further exploration.",
      "summary_en": "Unified multimodal models exhibit a persistent gap between understanding and generation capabilities, indicating only surface-level integration rather than deep cognitive convergence.",
      "summary_zh": "统一多模态模型在理解与生成能力之间存在持续差距，表明其仅为表层整合而非深度认知融合。",
      "hf_url": "https://huggingface.co/papers/2602.02140",
      "arxiv_url": "https://arxiv.org/abs/2602.02140",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02140",
      "github_url": "",
      "upvotes": 12,
      "fetched_at": "2026-02-19T05:27:19.394008+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03916",
      "title": "SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?",
      "authors": [
        "Azmine Toushik Wasi",
        "Wahid Faisal",
        "Abdur Rahman",
        "Mahfuz Ahmed Anik",
        "Munem Shahriar",
        "Mohsin Mahmud Topu",
        "Sadia Tasnim Meem",
        "Rahatun Nesa Priti",
        "Sabrina Afroz Mitu",
        "Md. Iqramul Hoque",
        "Shahriyar Zaman Ridoy",
        "Mohammed Eunus Ali",
        "Majd Hawasly",
        "Mohammad Raza",
        "Md Rizwan Parvez"
      ],
      "abstract": "SpatiaLab presents a comprehensive benchmark for evaluating vision-language models' spatial reasoning capabilities across realistic, diverse scenarios, revealing significant gaps compared to human performance.",
      "summary_en": "SpatiaLab presents a comprehensive benchmark for evaluating vision-language models' spatial reasoning capabilities across realistic, diverse scenarios, revealing significant gaps compared to human performance.",
      "summary_zh": "SpatiaLab构建了一个综合性基准，评估视觉-语言模型在真实多样场景中的空间推理能力，揭示了其相较于人类表现的显著差距。",
      "hf_url": "https://huggingface.co/papers/2602.03916",
      "arxiv_url": "https://arxiv.org/abs/2602.03916",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03916",
      "github_url": "https://github.com/SpatiaLab-Reasoning/SpatiaLab",
      "upvotes": 11,
      "fetched_at": "2026-02-19T05:27:35.071403+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03359",
      "title": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling",
      "authors": [
        "Ning Ding",
        "Fangcheng Liu",
        "Kyungrae Kim",
        "Linji Hao",
        "Kyeng-Hun Lee",
        "Hyeonmok Ko",
        "Yehui Tang"
      ],
      "abstract": "MeKi enables efficient large language model deployment on edge devices by injecting pre-stored semantic knowledge through token-level memory experts and re-parameterization techniques. Scaling Large Language Models (LLMs) typically relies on increasing the number of parameters or test-time computations to boost performance. However, these strategies are impractical for edge device deployment due to limited RAM and NPU resources. Despite hardware constraints, deploying performant LLM on edge devices such as smartphone remains crucial for user experience. To address this, we propose MeKi (Memory-based Expert Knowledge Injection), a novel system that scales LLM capacity via storage space rather than FLOPs. MeKi equips each Transformer layer with token-level memory experts that injects pre-stored semantic knowledge into the generation process. To bridge the gap between training capacity and inference efficiency, we employ a re-parameterization strategy to fold parameter matrices used during training into a compact static lookup table . By offloading the knowledge to ROM , MeKi decouples model capacity f rom computational cost, introducing zero inference latency overhead. Extensive experiments demonstrate that MeKi significantly outperforms dense LLM baselines with identical inference speed, validating the effectiveness of memory-based scaling paradigm for on-device LLMs. Project homepage is at https://github.com/ningding-o/MeKi.",
      "summary_en": "MeKi enables efficient large language model deployment on edge devices by injecting pre-stored semantic knowledge through token-level memory experts and re-parameterization techniques.",
      "summary_zh": "MeKi通过token级记忆专家和重参数化技术注入预存储的语义知识，实现了大语言模型在边缘设备上的高效部署。",
      "hf_url": "https://huggingface.co/papers/2602.03359",
      "arxiv_url": "https://arxiv.org/abs/2602.03359",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03359",
      "github_url": "",
      "upvotes": 9,
      "fetched_at": "2026-02-19T05:27:29.680824+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03979",
      "title": "Likelihood-Based Reward Designs for General LLM Reasoning",
      "authors": [
        "Ariel Kwiatkowski",
        "Natasha Butt",
        "Ismail Labiad",
        "Julia Kempe",
        "Yann Ollivier"
      ],
      "abstract": "Log-probability rewards derived from the reference answer's likelihood outperform binary rewards in chain-of-thought fine-tuning across both verifiable and non-verifiable reasoning benchmarks. Fine-tuning large language models (LLMs) on reasoning benchmarks via reinforcement learning requires a specific reward function , often binary, for each benchmark. This comes with two potential limitations: the need to design the reward, and the potentially sparse nature of binary rewards . Here, we systematically investigate rewards derived from the probability or log-probability of emitting the reference answer (or any other prompt continuation present in the data), which have the advantage of not relying on specific verifiers and being available at scale. Several recent works have advocated for the use of similar rewards (e.g., VeriFree, JEPO, RLPR, NOVER). We systematically compare variants of likelihood-based rewards with standard baselines, testing performance both on standard mathematical reasoning benchmarks , and on long-form answers where no external verifier is available. We find that using the log-probability of the reference answer as the reward for chain-of-thought (CoT) learning is the only option that performs well in all setups. This reward is also consistent with the next-token log-likelihood loss used during pretraining . In verifiable settings , log-probability rewards bring comparable or better success rates than reinforcing with standard binary rewards , and yield much better perplexity. In non-verifiable settings , they perform on par with SFT. On the other hand, methods based on probability, such as VeriFree, flatline on non-verifiable settings due to vanishing probabilities of getting the correct answer. Overall, this establishes log-probability rewards as a viable method for CoT fine-tuning , bridging the short, verifiable and long, non-verifiable answer settings.",
      "summary_en": "Log-probability rewards derived from the reference answer's likelihood outperform binary rewards in chain-of-thought fine-tuning across both verifiable and non-verifiable reasoning benchmarks.",
      "summary_zh": "在思维链微调中，基于参考答案似然的对数概率奖励在可验证和不可验证推理基准上均优于二元奖励。",
      "hf_url": "https://huggingface.co/papers/2602.03979",
      "arxiv_url": "https://arxiv.org/abs/2602.03979",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03979",
      "github_url": "",
      "upvotes": 8,
      "fetched_at": "2026-02-19T05:27:37.589545+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.03955",
      "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
      "authors": [
        "Yinyi Luo",
        "Yiqiao Jin",
        "Weichen Yu",
        "Mengqi Zhang",
        "Srijan Kumar",
        "Xiaoxiao Li",
        "Weijie Xu",
        "Xin Chen",
        "Jindong Wang"
      ],
      "abstract": "AgentArk distills multi-agent reasoning dynamics into a single model through hierarchical distillation strategies, enabling efficient yet powerful reasoning capabilities. While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning ; trajectory-based augmentation ; and process-aware distillation . By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.",
      "summary_en": "AgentArk distills multi-agent reasoning dynamics into a single model through hierarchical distillation strategies, enabling efficient yet powerful reasoning capabilities.",
      "summary_zh": "AgentArk 通过分层蒸馏策略将多智能体推理动态蒸馏至单一模型，实现高效且强大的推理能力。",
      "hf_url": "https://huggingface.co/papers/2602.03955",
      "arxiv_url": "https://arxiv.org/abs/2602.03955",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.03955",
      "github_url": "https://github.com/AIFrontierLab/AgentArk",
      "upvotes": 8,
      "fetched_at": "2026-02-19T05:27:35.932498+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02554",
      "title": "BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation",
      "authors": [
        "Jingwen Xu",
        "Yiyang Lu",
        "Zisu Huang",
        "Changze Lv",
        "Xiaohua Wang",
        "Shizheng Li",
        "Zhibo Xu",
        "Zhengkang Guo",
        "Zhengyuan Wang",
        "Muzhao Tian",
        "Xuanjing Huang",
        "Xiaoqing Zheng"
      ],
      "abstract": "BatCoder is a self-supervised reinforcement learning framework that jointly optimizes code and documentation generation through back-translation, achieving superior performance on code-related benchmarks. Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production . BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward , enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1 , outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity .",
      "summary_en": "BatCoder is a self-supervised reinforcement learning framework that jointly optimizes code and documentation generation through back-translation, achieving superior performance on code-related benchmarks.",
      "summary_zh": "BatCoder是一种自监督强化学习框架，通过回译联合优化代码和文档生成，在代码相关基准测试中取得更优性能。",
      "hf_url": "https://huggingface.co/papers/2602.02554",
      "arxiv_url": "https://arxiv.org/abs/2602.02554",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02554",
      "github_url": "",
      "upvotes": 8,
      "fetched_at": "2026-02-19T05:27:24.826432+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.01640",
      "title": "A2Eval: Agentic and Automated Evaluation for Embodied Brain",
      "authors": [
        "Shuai Zhang",
        "Jiayu Hu",
        "Zijie Chen",
        "Zeyuan Ding",
        "Yi Zhang",
        "Yingji Zhang",
        "Ziyi Zhou",
        "Junwei Liao",
        "Shengjie Zhou",
        "Yong Dai",
        "Zhenzhong Lan",
        "Xiaozhu Ju"
      ],
      "abstract": "Agentic automatic evaluation framework automates embodied vision-language model assessment through collaborative agents that reduce evaluation costs and improve ranking accuracy. Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite , while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suite s by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking bias es, improves human alignment to Spearman's rho =0.85, and maintains high ranking fidelity ( Kendall's tau =0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon.",
      "summary_en": "Agentic automatic evaluation framework automates embodied vision-language model assessment through collaborative agents that reduce evaluation costs and improve ranking accuracy.",
      "summary_zh": "智能体自动评估框架通过协作智能体自动化具身视觉-语言模型评估，降低评估成本并提高排序准确性。",
      "hf_url": "https://huggingface.co/papers/2602.01640",
      "arxiv_url": "https://arxiv.org/abs/2602.01640",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.01640",
      "github_url": "",
      "upvotes": 8,
      "fetched_at": "2026-02-19T05:27:17.901089+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2601.20499",
      "title": "Efficient Autoregressive Video Diffusion with Dummy Head",
      "authors": [
        "Hang Guo",
        "Zhaoyang Jia",
        "Jiahao Li",
        "Bin Li",
        "Yuanhao Cai",
        "Jiangshan Wang",
        "Yawei Li",
        "Yan Lu"
      ],
      "abstract": "Autoregressive video diffusion models suffer from inefficient attention mechanisms that underutilize historical frames, but a new method called Dummy Forcing improves efficiency through heterogeneous memory allocation and dynamic head programming while maintaining quality. The autoregressive video diffusion model has recently gained considerable research interest due to its causal modeling and iterative denoising . In this work, we identify that the multi-head self-attention in these models under-utilizes historical frames: approximately 25% heads attend almost exclusively to the current frame, and discarding their KV caches incurs only minor performance degradation. Building upon this, we propose Dummy Forcing, a simple yet effective method to control context accessibility across different heads. Specifically, the proposed heterogeneous memory allocation reduces head-wise context redundancy, accompanied by dynamic head programming to adaptively classify head types. Moreover, we develop a context packing technique to achieve more aggressive cache compression . Without additional training, our Dummy Forcing delivers up to 2.0x speedup over the baseline, supporting video generation at 24.3 FPS with less than 0.5% quality drop. Project page is available at https://csguoh.github.io/project/DummyForcing/.",
      "summary_en": "Autoregressive video diffusion models suffer from inefficient attention mechanisms that underutilize historical frames, but a new method called Dummy Forcing improves efficiency through heterogeneous memory allocation and dynamic head programming while maintaining quality.",
      "summary_zh": "自回归视频扩散模型的注意力机制效率低下，未能充分利用历史帧，而Dummy Forcing这一新方法通过异构内存分配与动态头编程，在保持质量的同时提升了效率。",
      "hf_url": "https://huggingface.co/papers/2601.20499",
      "arxiv_url": "https://arxiv.org/abs/2601.20499",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2601.20499",
      "github_url": "https://github.com/csguoh/DummyForcing",
      "upvotes": 8,
      "fetched_at": "2026-02-19T05:27:14.384525+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04805",
      "title": "Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging",
      "authors": [
        "Jia-peng Zhang",
        "Cheng-Feng Pu",
        "Meng-Hao Guo",
        "Yan-Pei Cao",
        "Shi-Min Hu"
      ],
      "abstract": "Generative 3D models face challenges in animation rigging, which this work addresses by introducing SkinTokens—a learned discrete representation for skinning weights—and TokenRig, a unified autoregressive framework that models skeletons and skin deformations together, improving rigging accuracy through reinforcement learning. The rapid proliferation of generative 3D models has created a critical bottleneck in animation pipelines: rigging. Existing automated methods are fundamentally limited by their approach to skinning, treating it as an ill-posed, high-dimensional regression task that is inefficient to optimize and is typically decoupled from skeleton generation. We posit this is a representation problem and introduce SkinTokens: a learned, compact, and discrete representation for skinning weights . By leveraging an FSQ-CVAE to capture the intrinsic sparsity of skinning, we reframe the task from continuous regression to a more tractable token sequence prediction problem. This representation enables TokenRig, a unified autoregressive framework that models the entire rig as a single sequence of skeletal parameters and SkinTokens, learning the complicated dependencies between skeletons and skin deformations. The unified model is then amenable to a reinforcement learning stage, where tailored geometric and semantic rewards improve generalization to complex, out-of-distribution assets. Quantitatively, the SkinTokens representation leads to a 98%-133% percents improvement in skinning accuracy over state-of-the-art methods, while the full TokenRig framework, refined with RL, enhances bone prediction by 17%-22%. Our work presents a unified, generative approach to rigging that yields higher fidelity and robustness, offering a scalable solution to a long-standing challenge in 3D content creation.",
      "summary_en": "Generative 3D models face challenges in animation rigging, which this work addresses by introducing SkinTokens—a learned discrete representation for skinning weights—and TokenRig, a unified autoregressive framework that models skeletons and skin deformations together, improving rigging accuracy through reinforcement learning.",
      "summary_zh": "生成式3D模型在动画绑定上面临挑战，本工作通过引入SkinTokens（一种针对蒙皮权重的习得离散表示）和TokenRig（一种联合建模骨骼与皮肤形变的统一自回归框架）来解决该问题，并利用强化学习提升绑定精度。",
      "hf_url": "https://huggingface.co/papers/2602.04805",
      "arxiv_url": "https://arxiv.org/abs/2602.04805",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04805",
      "github_url": "",
      "upvotes": 6,
      "fetched_at": "2026-02-19T05:42:13.869434+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04486",
      "title": "Beyond Unimodal Shortcuts: MLLMs as Cross-Modal Reasoners for Grounded Named Entity Recognition",
      "authors": [
        "Jinlong Ma",
        "Yu Zhang",
        "Xuefeng Bai",
        "Kehai Chen",
        "Yuwei Wang",
        "Zeming Liu",
        "Jun Yu",
        "Min Zhang"
      ],
      "abstract": "MLLMs suffer from modality bias in GMNER tasks, which is addressed through a proposed method that enforces cross-modal reasoning via multi-style reasoning schema injection and constraint-guided verifiable optimization. Grounded Multimodal Named Entity Recognition ( GMNER ) aims to extract text-based entities, assign them semantic categories, and ground them to corresponding visual regions. In this work, we explore the potential of Multimodal Large Language Models (MLLMs) to perform GMNER in an end-to-end manner, moving beyond their typical role as auxiliary tools within cascaded pipelines. Crucially, our investigation reveals a fundamental challenge: MLLMs exhibit modality bias , including visual bias and textual bias, which stems from their tendency to take unimodal shortcuts rather than rigorous cross-modal verification. To address this, we propose Modality-aware Consistency Reasoning (MCR), which enforces structured cross-modal reasoning through Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI transforms abstract constraints into executable reasoning chains, while CVO empowers the model to dynamically align its reasoning trajectories with Group Relative Policy Optimization (GRPO). Experiments on GMNER and visual grounding tasks demonstrate that MCR effectively mitigates modality bias and achieves superior performance compared to existing baselines.",
      "summary_en": "MLLMs suffer from modality bias in GMNER tasks, which is addressed through a proposed method that enforces cross-modal reasoning via multi-style reasoning schema injection and constraint-guided verifiable optimization.",
      "summary_zh": "MLLMs在GMNER任务中存在模态偏见，本文提出了一种通过多风格推理模式注入与约束引导的可验证优化来强制跨模态推理的方法来解决该问题。",
      "hf_url": "https://huggingface.co/papers/2602.04486",
      "arxiv_url": "https://arxiv.org/abs/2602.04486",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04486",
      "github_url": "",
      "upvotes": 6,
      "fetched_at": "2026-02-19T05:27:42.029664+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.01849",
      "title": "Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models",
      "authors": [
        "Ziwei Luo",
        "Ziqi Jin",
        "Lei Wang",
        "Lidong Bing",
        "Thomas B. Schön"
      ],
      "abstract": "Self-rewarding sequential Monte Carlo enables effective sampling of masked diffusion language models by using parallel diffusion processes and trajectory-level confidence signals to improve generation quality. This work presents self-rewarding sequential Monte Carlo (SMC), an inference-time scaling algorithm enabling effective sampling of masked diffusion language models (MDLMs). Our algorithm stems from the observation that most existing MDLMs rely on a confidence-based sampling strategy, where only tokens with the highest prediction confidence are preserved at each step. This restricts the generation to a noise-sensitive, greedy decoding paradigm, resulting in an inevitable collapse in the diversity of possible paths. We address this problem by launching multiple interacting diffusion processes in parallel, referred to as particles, for trajectory exploration. Importantly, we introduce the trajectory-level confidence as a self-rewarding signal for assigning particle importance weights. During sampling, particles are iteratively weighted and resampled to systematically steer generation towards globally confident, high-quality samples. Our self-rewarding SMC is verified on various masked diffusion language models and benchmarks, achieving significant improvement without extra training or reward guidance, while effectively converting parallel inference capacity into improved sampling quality. Our code is available at https://github.com/Algolzw/self-rewarding-smc.",
      "summary_en": "Self-rewarding sequential Monte Carlo enables effective sampling of masked diffusion language models by using parallel diffusion processes and trajectory-level confidence signals to improve generation quality.",
      "summary_zh": "自奖励序贯蒙特卡洛利用并行扩散过程和轨迹级置信信号，实现对掩码扩散语言模型的有效采样，从而提升生成质量。",
      "hf_url": "https://huggingface.co/papers/2602.01849",
      "arxiv_url": "https://arxiv.org/abs/2602.01849",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.01849",
      "github_url": "https://github.com/Algolzw/self-rewarding-smc",
      "upvotes": 5,
      "fetched_at": "2026-02-19T05:27:18.680734+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02350",
      "title": "Context Learning for Multi-Agent Discussion",
      "authors": [
        "Xingyuan Hua",
        "Sheng Yue",
        "Xinyi Li",
        "Yizhe Zhao",
        "Jinrui Zhang",
        "Ju Ren"
      ],
      "abstract": "",
      "summary_en": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper.",
      "summary_zh": "这是来自 Librarian Bot 的自动消息。我找到了以下与本文相似的论文。",
      "hf_url": "https://huggingface.co/papers/2602.02350",
      "arxiv_url": "https://arxiv.org/abs/2602.02350",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02350",
      "github_url": "https://github.com/HansenHua/M2CL-ICLR26",
      "upvotes": 4,
      "fetched_at": "2026-02-19T05:27:22.396051+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04883",
      "title": "Protein Autoregressive Modeling via Multiscale Structure Generation",
      "authors": [
        "Yanru Qu",
        "Cheng-Yen Hsieh",
        "Zaixiang Zheng",
        "Ge Liu",
        "Quanquan Gu"
      ],
      "abstract": "PAR is a multi-scale autoregressive framework for protein backbone generation that uses hierarchical structure modeling, autoregressive transformers, and flow-based decoding to produce high-quality protein structures with improved generalization and reduced exposure bias. We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias , caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling , enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization , supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark , PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.",
      "summary_en": "PAR is a multi-scale autoregressive framework for protein backbone generation that uses hierarchical structure modeling, autoregressive transformers, and flow-based decoding to produce high-quality protein structures with improved generalization and reduced exposure bias.",
      "summary_zh": "PAR是一种用于蛋白质骨架生成的多尺度自回归框架，通过层次化结构建模、自回归Transformer和基于流的解码生成高质量蛋白质结构，提升了泛化能力并降低了曝光偏差。",
      "hf_url": "https://huggingface.co/papers/2602.04883",
      "arxiv_url": "https://arxiv.org/abs/2602.04883",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04883",
      "github_url": "",
      "upvotes": 3,
      "fetched_at": "2026-02-19T05:42:18.141226+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04442",
      "title": "No One-Size-Fits-All: Building Systems For Translation to Bashkir, Kazakh, Kyrgyz, Tatar and Chuvash Using Synthetic And Original Data",
      "authors": [
        "Dmitry Karpov"
      ],
      "abstract": "Machine translation experiments for Turkic languages using nllb-200, LoRA fine-tuning, and prompt-based approaches achieved varying chrF++ scores across language pairs. We explore machine translation for five Turkic language pairs: Russian-Bashkir, Russian-Kazakh, Russian-Kyrgyz, English-Tatar, English-Chuvash. Fine-tuning nllb-200 -distilled-600M with LoRA on synthetic data achieved chrF++ 49.71 for Kazakh and 46.94 for Bashkir. Prompting DeepSeek-V3.2 with retrieved similar examples achieved chrF++ 39.47 for Chuvash. For Tatar, zero-shot or retrieval-based approaches achieved chrF++ 41.6, while for Kyrgyz the zero-shot approach reached 45.6. We release the dataset and the obtained weights.",
      "summary_en": "Machine translation experiments for Turkic languages using nllb-200, LoRA fine-tuning, and prompt-based approaches achieved varying chrF++ scores across language pairs.",
      "summary_zh": "使用 nllb-200、LoRA 微调和基于提示的方法开展的突厥语族语言机器翻译实验在不同语言对上取得了不同的 chrF++ 分数。",
      "hf_url": "https://huggingface.co/papers/2602.04442",
      "arxiv_url": "https://arxiv.org/abs/2602.04442",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04442",
      "github_url": "",
      "upvotes": 3,
      "fetched_at": "2026-02-19T05:27:41.313551+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04289",
      "title": "Proxy Compression for Language Modeling",
      "authors": [
        "Lin Zheng",
        "Xinyu Li",
        "Qian Liu",
        "Xiachong Feng",
        "Lingpeng Kong"
      ],
      "abstract": "Proxy compression trains language models on both raw byte sequences and compressed views, enabling efficient training with end-to-end raw-byte inference while maintaining model robustness. Modern language models are trained almost exclusively on token sequences produced by a fixed tokenizer , an external lossless compressor often over UTF-8 byte sequences , thereby coupling the model to that compressor. This work introduces proxy compression , an alternative training scheme that preserves the efficiency benefits of compressed inputs while providing an end-to-end, raw-byte interface at inference time . During training, one language model is jointly trained on raw byte sequences and compressed views generated by external compressors ; through the process, the model learns to internally align compressed sequences and raw bytes. This alignment enables strong transfer between the two formats, even when training predominantly on compressed inputs which are discarded at inference. Extensive experiments on code language modeling demonstrate that proxy compression substantially improves training efficiency and significantly outperforms pure byte-level baselines given fixed compute budgets. As model scale increases, these gains become more pronounced, and proxy-trained models eventually match or rival tokenizer approaches, all while operating solely on raw bytes and retaining the inherent robustness of byte-level modeling .",
      "summary_en": "Proxy compression trains language models on both raw byte sequences and compressed views, enabling efficient training with end-to-end raw-byte inference while maintaining model robustness.",
      "summary_zh": "代理压缩在原始字节序列和压缩视图上训练语言模型，实现高效训练与端到端原始字节推理，同时保持模型鲁棒性。",
      "hf_url": "https://huggingface.co/papers/2602.04289",
      "arxiv_url": "https://arxiv.org/abs/2602.04289",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04289",
      "github_url": "https://github.com/LZhengisme/proxy-compression",
      "upvotes": 3,
      "fetched_at": "2026-02-19T05:27:40.581880+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.01031",
      "title": "HalluHard: A Hard Multi-Turn Hallucination Benchmark",
      "authors": [
        "Dongyang Fan",
        "Sebastien Delsad",
        "Nicolas Flammarion",
        "Maksym Andriushchenko"
      ],
      "abstract": "Large language models continue to generate plausible but ungrounded factual claims in multi-turn dialogue, with hallucinations remaining significant even when utilizing web search for verification across high-stakes domains. Large language models (LLMs) still produce plausible-sounding but ungrounded factual claims, a problem that worsens in multi-turn dialogue as context grows and early errors cascade. We introduce HalluHard, a challenging multi-turn hallucination benchmark with 950 seed questions spanning four high-stakes domains: legal cases, research questions, medical guidelines, and coding. We operationalize groundedness by requiring inline citations for factual assertions . To support reliable evaluation in open-ended settings , we propose a judging pipeline that iteratively retrieves evidence via web search . It can fetch, filter, and parse full-text sources (including PDFs) to assess whether cited material actually supports the generated content. Across a diverse set of frontier proprietary and open-weight models, hallucination s remain substantial even with web search (approx 30% for the strongest configuration, Opus-4.5 with web search ), with content-grounding errors persisting at high rates. Finally, we show that hallucination behavior is shaped by model capacity , turn position , effective reasoning , and the type of knowledge required.",
      "summary_en": "Large language models continue to generate plausible but ungrounded factual claims in multi-turn dialogue, with hallucinations remaining significant even when utilizing web search for verification across high-stakes domains.",
      "summary_zh": "大语言模型在多轮对话中持续生成看似合理但缺乏事实依据的陈述，即使在高风险领域利用网络搜索进行验证，幻觉现象依然显著。",
      "hf_url": "https://huggingface.co/papers/2602.01031",
      "arxiv_url": "https://arxiv.org/abs/2602.01031",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.01031",
      "github_url": "https://github.com/epfml/halluhard",
      "upvotes": 3,
      "fetched_at": "2026-02-19T05:27:17.223875+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02495",
      "title": "Reward-free Alignment for Conflicting Objectives",
      "authors": [
        "Peter Chen",
        "Xiaopeng Li",
        "Xi Chen",
        "Tianyi Lin"
      ],
      "abstract": "A reward-free alignment framework addresses multi-objective conflicts in language models through conflict-averse gradient descent with clipping, improving Pareto trade-offs across diverse model architectures. Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent . We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.",
      "summary_en": "A reward-free alignment framework addresses multi-objective conflicts in language models through conflict-averse gradient descent with clipping, improving Pareto trade-offs across diverse model architectures.",
      "summary_zh": "一种无奖励对齐框架通过带裁剪的冲突规避梯度下降解决语言模型中的多目标冲突，在多种模型架构上改进了帕累托权衡。",
      "hf_url": "https://huggingface.co/papers/2602.02495",
      "arxiv_url": "https://arxiv.org/abs/2602.02495",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02495",
      "github_url": "",
      "upvotes": 2,
      "fetched_at": "2026-02-19T05:27:24.006695+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.05000",
      "title": "EntRGi: Entropy Aware Reward Guidance for Diffusion Language Models",
      "authors": [
        "Atula Tejaswi",
        "Litu Rout",
        "Constantine Caramanis",
        "Sanjay Shakkottai",
        "Sujay Sanghavi"
      ],
      "abstract": "Discrete diffusion language models use entropy-aware reward guidance to improve test-time adaptation by dynamically regulating gradient feedback from reward models.",
      "summary_en": "Discrete diffusion language models use entropy-aware reward guidance to improve test-time adaptation by dynamically regulating gradient feedback from reward models.",
      "summary_zh": "离散扩散语言模型利用熵感知奖励引导，通过动态调节来自奖励模型的梯度反馈来改进测试时自适应。",
      "hf_url": "https://huggingface.co/papers/2602.05000",
      "arxiv_url": "https://arxiv.org/abs/2602.05000",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.05000",
      "github_url": "https://github.com/atutej/entrgi",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:42:19.395334+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04651",
      "title": "SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF",
      "authors": [
        "Dipan Maity"
      ],
      "abstract": "A new reinforcement learning algorithm for language model alignment that improves stability and performance over PPO through enhanced KL divergence control and adaptive reward management. Optimization ( PPO ) has been positioned by recent literature as the canonical method for the RL part of RLHF . PPO performs well empirically but has a heuristic motivation and handles the KL-divergence constraint used in LM- RLHF in an ad-hoc manner and suffers form reward oscillations , entropy collapse , value function drift , and sudden policy divergence that require frequent restarts and extensive hyperparameter tuning. In this paper, we develop a new pure on policy actor-critic RL method for the LM- RLHF setting. We present SAFE (Stable Alignment Finetuning with Entropy-aware control),a novel RLHF algorithm that combines a Double Soft-Min Critic for pessimistic value estimation with a new multi-layer stabilization framework combining entropy-gated KL regulation , and PID-controlled adaptive thresholds . Unlike standard PPO 's symmetric KL penalties, SAFE distinguishes high-entropy exploration from low-entropy mode collapse and adjusts penalties dynamically based on reward velocity. Experiments on a 3B parameter model show SAFE achieves +5.15\\% training-average reward than PPO (0.725 vs 0.689), negligible reward crashes, and superior KL control than ppo . Our method adds minimal computational overhead and provides an interpretable, crash-resistant RLHF framework that maintains aggressive learning speed while ensuring stable long-horizon optimization suitable for production deployment. Code is available at https://github.com/ryyzn9/SAFE",
      "summary_en": "A new reinforcement learning algorithm for language model alignment that improves stability and performance over PPO through enhanced KL divergence control and adaptive reward management.",
      "summary_zh": "一种用于语言模型对齐的新型强化学习算法，通过增强的KL散度控制和自适应奖励管理，在稳定性和性能上优于PPO。",
      "hf_url": "https://huggingface.co/papers/2602.04651",
      "arxiv_url": "https://arxiv.org/abs/2602.04651",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04651",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:42:08.372643+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04605",
      "title": "RexBERT: Context Specialized Bidirectional Encoders for E-commerce",
      "authors": [
        "Rahul Bajaj",
        "Anuj Garg"
      ],
      "abstract": "RexBERT, a family of BERT-style encoders designed for e-commerce semantics, achieves superior performance on domain-specific tasks through specialized pretraining and high-quality in-domain data. Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BERT-style encoders designed specifically for e-commerce semantics . We make three contributions. First, we release Ecom-niverse , a 350 billion token corpus curated from diverse retail and shopping sources. We describe a modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present a reproducible pretraining recipe building on ModernBERT 's architectural advances. The recipe consists of three phases: general pre-training, context extension , and annealed domain specialization . Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification , semantic similarity , and general natural language understanding tasks using e-commerce datasets. Despite having 2-3x fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long-context models on domain-specific benchmarks. Our results demonstrate that high quality in-domain data combined with a principled training approach provides a stronger foundation for e-commerce applications than indiscriminate scaling alone.",
      "summary_en": "RexBERT, a family of BERT-style encoders designed for e-commerce semantics, achieves superior performance on domain-specific tasks through specialized pretraining and high-quality in-domain data.",
      "summary_zh": "RexBERT是一系列专为电商语义设计的BERT风格编码器，通过专门预训练与高质量领域数据，在特定领域任务上取得了优异性能。",
      "hf_url": "https://huggingface.co/papers/2602.04605",
      "arxiv_url": "https://arxiv.org/abs/2602.04605",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04605",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:27:45.769155+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04581",
      "title": "Trust The Typical",
      "authors": [
        "Debargha Ganguly",
        "Sreehari Sankar",
        "Biyao Zhang",
        "Vikash Singh",
        "Kanan Gupta",
        "Harshini Kavuru",
        "Alan Luo",
        "Weicong Chen",
        "Warren Morningstar",
        "Raghu Machiraju",
        "Vipin Chaudhary"
      ],
      "abstract": "A novel framework for LLM safety that treats safety as an out-of-distribution detection problem, achieving state-of-the-art performance without harmful example training through semantic space analysis and efficient GPU implementation. Current approaches to LLM safety fundamentally rely on a brittle cat-and-mouse game of identifying and blocking known threats via guardrails . We argue for a fresh approach: robust safety comes not from enumerating what is harmful, but from deeply understanding what is safe. We introduce Trust The Typical (T3), a framework that operationalizes this principle by treating safety as an out-of-distribution (OOD) detection problem. T3 learns the distribution of acceptable prompts in a semantic space and flags any significant deviation as a potential threat. Unlike prior methods, it requires no training on harmful examples, yet achieves state-of-the-art performance across 18 benchmarks spanning toxicity, hate speech, jailbreaking, multilingual harms , and over-refusal , reducing false positive rates by up to 40x relative to specialized safety models. A single model trained only on safe English text transfers effectively to diverse domains and over 14 languages without retraining. Finally, we demonstrate production readiness by integrating a GPU-optimized version into vLLM , enabling continuous guardrailing during token generation with less than 6% overhead even under dense evaluation intervals on large-scale workloads.",
      "summary_en": "A novel framework for LLM safety that treats safety as an out-of-distribution detection problem, achieving state-of-the-art performance without harmful example training through semantic space analysis and efficient GPU implementation.",
      "summary_zh": "一种针对LLM安全的新框架，将安全性建模为分布外检测问题，借助语义空间分析和高效GPU实现，无需有害样本训练即可达到最优性能。",
      "hf_url": "https://huggingface.co/papers/2602.04581",
      "arxiv_url": "https://arxiv.org/abs/2602.04581",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04581",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:27:45.017131+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04547",
      "title": "OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis",
      "authors": [
        "Luca Zedda",
        "Andrea Loddo",
        "Cecilia Di Ruberto"
      ],
      "abstract": "OmniRad is a self-supervised radiological foundation model pretrained on 1.2 million medical images that demonstrates improved performance in classification and segmentation tasks through representation reuse and cross-task transferability. Radiological analysis increasingly benefits from pretrained visual representations that can support heterogeneous downstream tasks across imaging modalities. In this work, we introduce OmniRad, a self-supervised radiological foundation model pretrained on 1.2 million medical images, designed with radiology-inspired principles emphasizing representation reuse and cross-task transferability . We evaluate the pretrained encoder under multiple downstream adaptation regimes, including lightweight task-specific adapters with a frozen backbone as well as full end-to-end fine-tuning for classification, allowing us to assess both representation quality and task-specific performance. OmniRad is evaluated on a broad suite of public benchmarks spanning classification and segmentation across multiple modalities. On the MedMNISTv2 collection, OmniRad improves classification F1 by up to 2.05% over competing foundation models. For dense prediction, OmniRad attains mean Dice score improvements across six MedSegBench datasets when using frozen representations. Qualitative analyses and latent-space visualization s suggest improved feature clustering and modality-related separation.",
      "summary_en": "OmniRad is a self-supervised radiological foundation model pretrained on 1.2 million medical images that demonstrates improved performance in classification and segmentation tasks through representation reuse and cross-task transferability.",
      "summary_zh": "OmniRad是一种在120万张医学影像上预训练的自监督放射学基础模型，通过表征复用和跨任务可迁移性，在分类和分割任务中展现出更优性能。",
      "hf_url": "https://huggingface.co/papers/2602.04547",
      "arxiv_url": "https://arxiv.org/abs/2602.04547",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04547",
      "github_url": "https://github.com/unica-visual-intelligence-lab/OmniRad",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:27:43.461583+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.04271",
      "title": "SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization",
      "authors": [
        "Lifan Wu",
        "Ruijie Zhu",
        "Yubo Ai",
        "Tianzhu Zhang"
      ],
      "abstract": "SkeletonGaussian enables editable 4D generation by decomposing motion into rigid skeleton-driven and non-rigid fine-grained components using hexplane-based refinement. 4D generation has made remarkable progress in synthesizing dynamic 3D objects from input text, images, or videos. However, existing methods often represent motion as an implicit deformation field, which limits direct control and editability. To address this issue, we propose SkeletonGaussian, a novel framework for generating editable dynamic 3D Gaussians from monocular video input . Our approach introduces a hierarchical articulated representation that decomposes motion into sparse rigid motion explicitly driven by a skeleton and fine-grained non-rigid motion. Concretely, we extract a robust skeleton and drive rigid motion via linear blend skinning , followed by a hexplane-based refinement for non-rigid deformations , enhancing interpretability and editability. Experimental results demonstrate that SkeletonGaussian surpasses existing methods in generation quality while enabling intuitive motion editing , establishing a new paradigm for editable 4D generation . Project page: https://wusar.github.io/projects/skeletongaussian/",
      "summary_en": "SkeletonGaussian enables editable 4D generation by decomposing motion into rigid skeleton-driven and non-rigid fine-grained components using hexplane-based refinement.",
      "summary_zh": "SkeletonGaussian利用基于六平面的细化将运动分解为刚性骨骼驱动和非刚性细粒度组件，实现了可编辑的4D生成。",
      "hf_url": "https://huggingface.co/papers/2602.04271",
      "arxiv_url": "https://arxiv.org/abs/2602.04271",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04271",
      "github_url": "https://github.com/wusar/SkeletonGaussian",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:27:39.125137+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02863",
      "title": "\"I May Not Have Articulated Myself Clearly\": Diagnosing Dynamic Instability in LLM Reasoning at Inference Time",
      "authors": [
        "Jinkun Chen",
        "Fengxiang Cheng",
        "Sijia Han",
        "Vlado Keselj"
      ],
      "abstract": "Analysis of reasoning failures in large language models reveals that instability signals derived from token log probabilities and entropy can predict incorrect answers and distinguish between corrective and destructive instability based on timing of distribution shifts. Reasoning failures in large language models (LLMs) are typically measured only at the end of a generation, yet many failures manifest as a process-level breakdown: the model \"loses the thread\" mid-reasoning. We study whether such breakdowns are detectable from inference-time observables available in standard APIs ( token log probabilities ), without any training or fine-tuning. We define a simple instability signal that combines consecutive-step distributional shift (JSD) and uncertainty ( entropy ), summarize each trace by its peak instability strength, and show that this signal reliably predicts failure. Across GSM8K and HotpotQA , instability strength predicts wrong answers with above-chance AUC and yields monotonic bucket-level accuracy decline at scale across model sizes. Crucially, we show that instability is not uniformly harmful: early instability can reflect subsequent stabilization and a correct final answer ( corrective instability ), whereas late instability is more often followed by failure ( destructive instability ), even at comparable peak magnitudes, indicating that recoverability depends not only on how strongly the distribution changes but also on when such changes occur relative to the remaining decoding horizon. The method is model-agnostic, training-free, and reproducible, and is presented as a diagnostic lens rather than a corrective or control mechanism.",
      "summary_en": "Analysis of reasoning failures in large language models reveals that instability signals derived from token log probabilities and entropy can predict incorrect answers and distinguish between corrective and destructive instability based on timing of distribution shifts.",
      "summary_zh": "针对大语言模型推理失败的分析表明，由 token 对数概率和熵推导出的不稳定信号可预测错误答案，并能根据分布偏移的时机区分修正性不稳定与破坏性不稳定。",
      "hf_url": "https://huggingface.co/papers/2602.02863",
      "arxiv_url": "https://arxiv.org/abs/2602.02863",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02863",
      "github_url": "",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:27:25.585262+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2602.02341",
      "title": "LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization",
      "authors": [
        "Zhenpeng Huang",
        "Jiaqi Li",
        "Zihan Jia",
        "Xinhao Li",
        "Desen Meng",
        "Lingxue Song",
        "Xi Chen",
        "Liang Li",
        "Limin Wang"
      ],
      "abstract": "LongVPO is a two-stage Direct Preference Optimization framework that enables short-context vision-language models to understand ultra-long videos through synthetic preference triples and recursive captioning, achieving state-of-the-art performance with minimal human annotation. We present LongVPO, a novel two-stage Direct Preference Optimization framework that enables short-context vision-language models to robustly understand ultra-long videos without any long-video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual-similarity and question-specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model's scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata , then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, LongVPO outperforms the state-of-the-art open-source models on multiple long-video benchmarks, while maintaining strong short-video performance (e.g., on MVBench), offering a scalable paradigm for efficient long-form video understanding.",
      "summary_en": "LongVPO is a two-stage Direct Preference Optimization framework that enables short-context vision-language models to understand ultra-long videos through synthetic preference triples and recursive captioning, achieving state-of-the-art performance with minimal human annotation.",
      "summary_zh": "LongVPO是一个两阶段直接偏好优化框架，通过合成偏好三元组与递归字幕生成，使短上下文视觉语言模型能够理解超长视频，在极少人工标注下达到当前最优性能。",
      "hf_url": "https://huggingface.co/papers/2602.02341",
      "arxiv_url": "https://arxiv.org/abs/2602.02341",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02341",
      "github_url": "https://github.com/MCG-NJU/LongVPO",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:27:21.519265+00:00"
    },
    {
      "date": "2026-02-05",
      "paper_id": "2601.22596",
      "title": "FOTBCD: A Large-Scale Building Change Detection Benchmark from French Orthophotos and Topographic Data",
      "authors": [
        "Abdelrrahman Moubane"
      ],
      "abstract": "A large-scale building change detection dataset named FOTBCD is introduced, covering 28 French departments with high-resolution imagery and comprehensive annotations for both binary and instance-level change detection tasks. We introduce FOTBCD, a large-scale building change detection dataset derived from authoritative French orthophotos and topographic building data provided by IGN France. Unlike existing benchmarks that are geographically constrained to single cities or limited regions, FOTBCD spans 28 departments across mainland France, with 25 used for training and three geographically disjoint departments held out for evaluation. The dataset covers diverse urban, suburban, and rural environments at 0.2m/pixel resolution. We publicly release FOTBCD-Binary, a dataset comprising approximately 28,000 before/after image pairs with pixel-wise binary building change masks, each associated with patch-level spatial metadata. The dataset is designed for large-scale benchmarking and evaluation under geographic domain shift , with validation and test samples drawn from held-out departments and manually verified to ensure label quality. In addition, we publicly release FOTBCD-Instances, a publicly available instance-level annotated subset comprising several thousand image pairs, which illustrates the complete annotation schema used in the full instance-level version of FOTBCD. Using a fixed reference baseline, we benchmark FOTBCD-Binary against LEVIR-CD+ and WHU-CD, providing strong empirical evidence that geographic diversity at the dataset level is associated with improved cross-domain generalization in building change detection .",
      "summary_en": "A large-scale building change detection dataset named FOTBCD is introduced, covering 28 French departments with high-resolution imagery and comprehensive annotations for both binary and instance-level change detection tasks.",
      "summary_zh": "本文介绍了一个名为FOTBCD的大规模建筑物变化检测数据集，涵盖28个法国省份的高分辨率影像，并为二值与实例级变化检测任务提供了全面的标注。",
      "hf_url": "https://huggingface.co/papers/2601.22596",
      "arxiv_url": "https://arxiv.org/abs/2601.22596",
      "arxiv_pdf_url": "https://arxiv.org/pdf/2601.22596",
      "github_url": "https://github.com/abdelpy/FOTBCD-datasets",
      "upvotes": 1,
      "fetched_at": "2026-02-19T05:27:15.161340+00:00"
    }
  ]
}