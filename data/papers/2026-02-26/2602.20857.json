{
  "date": "2026-02-26",
  "paper_id": "2602.20857",
  "title": "Functional Continuous Decomposition",
  "authors": [
    "Teymur Aghayev"
  ],
  "abstract": "Functional Continuous Decomposition enables parametric, continuous optimization of time-series data with guaranteed continuity for capturing local and global patterns, enhancing machine learning model performance through improved feature extraction. The analysis of non-stationary time-series data requires insight into its local and global patterns with physical interpretability. However, traditional smoothing algorithms, such as B-splines, Savitzky-Golay filtering, and Empirical Mode Decomposition (EMD), lack the ability to perform parametric optimization with guaranteed continuity. In this paper, we propose Functional Continuous Decomposition (FCD), a JAX-accelerated framework that performs parametric, continuous optimization on a wide range of mathematical functions. By using Levenberg-Marquardt optimization to achieve up to C^1 continuous fitting , FCD transforms raw time-series data into M modes that capture different temporal patterns from short-term to long-term trends. Applications of FCD include physics, medicine, financial analysis, and machine learning, where it is commonly used for the analysis of signal temporal patterns, optimized parameters, derivatives, and integrals of decomposition. Furthermore, FCD can be applied for physical analysis and feature extraction with an average SRMSE of 0.735 per segment and a speed of 0.47s on full decomposition of 1,000 points. Finally, we demonstrate that a Convolutional Neural Network (CNN) enhanced with FCD features, such as optimized function values, parameters, and derivatives, achieved 16.8% faster convergence and 2.5% higher accuracy over a standard CNN.",
  "summary_en": "Functional Continuous Decomposition enables parametric, continuous optimization of time-series data with guaranteed continuity for capturing local and global patterns, enhancing machine learning model performance through improved feature extraction.",
  "summary_zh": "函数连续分解支持对时间序列数据进行具有连续性保证的参数化连续优化，以捕获局部与全局模式，并通过改进特征提取提升机器学习模型性能。",
  "hf_url": "https://huggingface.co/papers/2602.20857",
  "arxiv_url": "https://arxiv.org/abs/2602.20857",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.20857",
  "github_url": "https://github.com/Tima-a/fcd",
  "upvotes": 1,
  "fetched_at": "2026-02-27T01:56:13.954533+00:00"
}