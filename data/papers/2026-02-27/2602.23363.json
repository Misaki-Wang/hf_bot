{
  "date": "2026-02-27",
  "paper_id": "2602.23363",
  "title": "MediX-R1: Open Ended Medical Reinforcement Learning",
  "authors": [
    "Sahal Shaji Mullappilly",
    "Mohammed Irfan Kurpath",
    "Omair Mohamed",
    "Mohamed Zidan",
    "Fahad Khan",
    "Salman Khan",
    "Rao Anwer",
    "Hisham Cholakkal"
  ],
  "abstract": "MediX-R1 presents an open-ended reinforcement learning framework for medical multimodal large language models that uses diverse reward signals and LLM-based evaluation to improve clinical reasoning beyond multiple-choice formats. We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning : an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only sim51K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at https://medix.cvmbzuai.com",
  "summary_en": "MediX-R1 presents an open-ended reinforcement learning framework for medical multimodal large language models that uses diverse reward signals and LLM-based evaluation to improve clinical reasoning beyond multiple-choice formats.",
  "summary_zh": "MediX-R1提出了一种面向医疗多模态大语言模型的开放式强化学习框架，该框架利用多样化的奖励信号和基于LLM的评估，以提升超越多选格式的临床推理能力。",
  "hf_url": "https://huggingface.co/papers/2602.23363",
  "arxiv_url": "https://arxiv.org/abs/2602.23363",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.23363",
  "github_url": "https://github.com/mbzuai-oryx/MediX-R1",
  "upvotes": 14,
  "fetched_at": "2026-02-28T01:47:00.984735+00:00"
}