{
  "date": "2026-02-27",
  "paper_id": "2602.20981",
  "title": "Echoes Over Time: Unlocking Length Generalization in Video-to-Audio Generation Models",
  "authors": [
    "Christian Simon",
    "Masato Ishii",
    "Wei-Yao Wang",
    "Koichi Saito",
    "Akio Hayakawa",
    "Dongseok Shim",
    "Zhi Zhong",
    "Shuyang Cui",
    "Shusuke Takahashi",
    "Takashi Shibuya",
    "Yuki Mitsufuji"
  ],
  "abstract": "MMHNet enables long-form audio generation from video by integrating hierarchical methods and non-causal Mamba, achieving superior performance over existing video-to-audio approaches. Scaling multimodal alignment between video and audio is challenging, particularly due to limited data and the mismatch between text descriptions and frame-level video information. In this work, we tackle the scaling challenge in multimodal-to-audio generation, examining whether models trained on short instances can generalize to longer ones during testing. To tackle this challenge, we present multimodal hierarchical networks so-called MMHNet , an enhanced extension of state-of-the-art video-to-audio models. Our approach integrates a hierarchical method and non-causal Mamba to support long-form audio generation . Our proposed method significantly improves long audio generation up to more than 5 minutes. We also prove that training short and testing long is possible in the video-to-audio generation tasks without training on the longer durations. We show in our experiments that our proposed method could achieve remarkable results on long-video to audio benchmarks, beating prior works in video-to-audio tasks. Moreover, we showcase our model capability in generating more than 5 minutes, while prior video-to-audio methods fall short in generating with long durations.",
  "summary_en": "MMHNet enables long-form audio generation from video by integrating hierarchical methods and non-causal Mamba, achieving superior performance over existing video-to-audio approaches.",
  "summary_zh": "MMHNet通过整合分层方法和非因果Mamba实现从视频生成长音频，性能优于现有视频到音频方法。",
  "hf_url": "https://huggingface.co/papers/2602.20981",
  "arxiv_url": "https://arxiv.org/abs/2602.20981",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.20981",
  "github_url": "",
  "upvotes": 0,
  "fetched_at": "2026-02-28T01:46:39.629701+00:00"
}