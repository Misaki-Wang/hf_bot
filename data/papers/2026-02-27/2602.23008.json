{
  "date": "2026-02-27",
  "paper_id": "2602.23008",
  "title": "Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization",
  "authors": [
    "Zeyuan Liu",
    "Jeonghye Kim",
    "Xufang Luo",
    "Dongsheng Li",
    "Yuqing Yang"
  ],
  "abstract": "EMPO² is a hybrid reinforcement learning framework that enhances exploration for large language model agents by integrating memory mechanisms with on- and off-policy updates, demonstrating improved performance and adaptability in complex environments. Exploration remains the key bottleneck for large language model agents trained with reinforcement learning . While prior methods exploit pretrained knowledge, they fail in environments requiring the discovery of novel states. We propose Exploratory Memory-Augmented On- and Off-Policy Optimization (EMPO^2), a hybrid RL framework that leverages memory for exploration and combines on- and off-policy updates to make LLMs perform well with memory while also ensuring robustness without it. On ScienceWorld and WebShop , EMPO^2 achieves 128.6% and 11.3% improvements over GRPO, respectively. Moreover, in out-of-distribution tests, EMPO^2 demonstrates superior adaptability to new tasks, requiring only a few trials with memory and no parameter updates. These results highlight EMPO^2 as a promising framework for building more exploratory and generalizable LLM-based agents.",
  "summary_en": "EMPO² is a hybrid reinforcement learning framework that enhances exploration for large language model agents by integrating memory mechanisms with on- and off-policy updates, demonstrating improved performance and adaptability in complex environments.",
  "summary_zh": "EMPO² 是一种混合强化学习框架，通过整合记忆机制与 on-policy 和 off-policy 更新来增强大语言模型智能体的探索能力，并在复杂环境中展现出改进的性能和适应性。",
  "hf_url": "https://huggingface.co/papers/2602.23008",
  "arxiv_url": "https://arxiv.org/abs/2602.23008",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.23008",
  "github_url": "",
  "upvotes": 26,
  "fetched_at": "2026-02-28T01:46:52.289029+00:00"
}