{
  "date": "2026-02-16",
  "paper_id": "2602.09870",
  "title": "Steer2Edit: From Activation Steering to Component-Level Editing",
  "authors": [
    "Chung-En Sun",
    "Ge Yan",
    "Zimo Wang",
    "Tsui-Wei Weng"
  ],
  "abstract": "Steering methods influence Large Language Model behavior by identifying semantic directions in hidden representations, but are typically realized through inference-time activation interventions that apply a fixed, global modification to the model's internal states. While effective, such interventions often induce unfavorable attribute-utility trade-offs under strong control, as they ignore the fact that many behaviors are governed by a small and heterogeneous subset of model components. We propose Steer2Edit, a theoretically grounded, training-free framework that transforms steering vectors from inference-time control signals into diagnostic signals for component-level rank-1 weight editing. Instead of uniformly injecting a steering direction during generation, Steer2Edit selectively redistributes behavioral influence across individual attention heads and MLP neurons, yielding interpretable edits that preserve the standard forward pass and remain compatible with optimized parallel inference. Across safety alignment, hallucination mitigation, and reasoning efficiency, Steer2Edit consistently achieves more favorable attribute-utility trade-offs: at matched downstream performance, it improves safety by up to 17.2%, increases truthfulness by 9.8%, and reduces reasoning length by 12.2% on average. Overall, Steer2Edit provides a principled bridge between representation steering and weight editing by translating steering signals into interpretable, training-free parameter updates.",
  "summary_en": "Current steering methods apply fixed global modifications during inference, which induces unfavorable attribute-utility trade-offs by ignoring that behaviors are governed by small, heterogeneous subsets of components. Steer2Edit transforms steering vectors into diagnostic signals for component-level rank-1 weight editing, selectively redistributing behavioral influence across individual attention heads and MLP neurons while preserving the standard forward pass. This training-free framework achieves more favorable trade-offs than standard steering, improving safety by up to 17.2%, truthfulness by 9.8%, and reducing reasoning length by 12.2% on average across safety alignment, hallucination mitigation, and reasoning efficiency tasks.",
  "summary_zh": "现有的 steering 方法在 inference 期间施加固定的全局修改，因其忽略了行为受小型、异质的组件子集调控的事实，从而导致不利的 attribute-utility trade-offs。Steer2Edit 将 steering vectors 转化为用于组件级 rank-1 weight editing 的诊断信号，在保持标准 forward pass 的同时，选择性地将行为影响重新分配至各个 attention heads 和 MLP neurons。该 training-free 框架相比标准 steering 实现了更优的 trade-offs，在 safety alignment、hallucination mitigation 和 reasoning efficiency 任务中，平均将 safety 提升最多达 17.2%，truthfulness 提升 9.8%，并将 reasoning length 减少 12.2%。",
  "hf_url": "https://huggingface.co/papers/2602.09870",
  "arxiv_url": "https://arxiv.org/abs/2602.09870",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.09870",
  "github_url": "",
  "upvotes": 1,
  "fetched_at": "2026-02-17T09:52:02.393593+00:00"
}