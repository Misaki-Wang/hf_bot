{
  "date": "2026-02-04",
  "paper_id": "2602.01785",
  "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding",
  "authors": [
    "Yuling Shi",
    "Chaoxiang Xie",
    "Zhensu Sun",
    "Yeheng Chen",
    "Chenxu Zhang",
    "Longfei Yun",
    "Chengcheng Wan",
    "Hongyu Zhang",
    "David Lo",
    "Xiaodong Gu"
  ],
  "abstract": "Multimodal large language models can effectively understand source code when represented as compressed images, achieving significant token reduction while maintaining or improving performance on code comprehension tasks.",
  "summary_en": "Multimodal large language models can effectively understand source code when represented as compressed images, achieving significant token reduction while maintaining or improving performance on code comprehension tasks.",
  "summary_zh": "多模态大语言模型能够有效理解以压缩图像形式表示的源代码，在实现显著 token 缩减的同时，于代码理解任务上保持或提升性能。",
  "hf_url": "https://huggingface.co/papers/2602.01785",
  "arxiv_url": "https://arxiv.org/abs/2602.01785",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.01785",
  "github_url": "",
  "upvotes": 93,
  "fetched_at": "2026-02-19T05:38:57.629302+00:00"
}