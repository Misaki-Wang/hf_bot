{
  "date": "2026-02-04",
  "paper_id": "2602.02419",
  "title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration",
  "authors": [
    "Qingni Wang",
    "Yue Fan",
    "Xin Eric Wang"
  ],
  "abstract": "SafeGround is a uncertainty-aware framework for GUI grounding models that uses distribution-aware uncertainty quantification and calibration to enable risk-aware predictions with controlled false discovery rates. Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibration s before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference.",
  "summary_en": "SafeGround is a uncertainty-aware framework for GUI grounding models that uses distribution-aware uncertainty quantification and calibration to enable risk-aware predictions with controlled false discovery rates.",
  "summary_zh": "SafeGround是一种面向GUI定位模型的不确定性感知框架，利用分布感知的不确定性量化和校准，实现具有受控错误发现率的风险感知预测。",
  "hf_url": "https://huggingface.co/papers/2602.02419",
  "arxiv_url": "https://arxiv.org/abs/2602.02419",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02419",
  "github_url": "https://github.com/Cece1031/SAFEGROUND",
  "upvotes": 4,
  "fetched_at": "2026-02-19T05:39:07.476858+00:00"
}