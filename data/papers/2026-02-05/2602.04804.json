{
  "date": "2026-02-05",
  "paper_id": "2602.04804",
  "title": "OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models",
  "authors": [
    "Yue Ding",
    "Yiyan Ji",
    "Jungang Li",
    "Xuyang Liu",
    "Xinlong Chen",
    "Junfei Wu",
    "Bozhou Li",
    "Bohan Zeng",
    "Yang Shi",
    "Yushuo Guan",
    "Yuanxing Zhang",
    "Jiaheng Liu",
    "Qiang Liu",
    "Pengfei Wan",
    "Liang Wang"
  ],
  "abstract": "OmniSIFT is a modality-asymmetric token compression framework for Omni-LLMs that reduces computational overhead through spatio-temporal video pruning and vision-guided audio selection while maintaining superior performance. Omni-modal Large Language Models (Omni-LLMs) have demonstrated strong capabilities in audio-video understanding tasks. However, their reliance on long multimodal token sequences leads to substantial computational overhead. Despite this challenge, token compression methods designed for Omni-LLMs remain limited. To bridge this gap, we propose OmniSIFT (Omni-modal Spatio-temporal Informed Fine-grained Token compression ), a modality-asymmetric token compression framework tailored for Omni-LLMs. Specifically, OmniSIFT adopts a two-stage compression strategy: (i) a spatio-temporal video pruning module that removes video redundancy arising from both intra-frame structure and inter-frame overlap, and (ii) a vision-guided audio selection module that filters audio tokens. The entire framework is optimized end-to-end via a differentiable straight-through estimator . Extensive experiments on five representative benchmarks demonstrate the efficacy and robustness of OmniSIFT. Notably, for Qwen2.5-Omni-7B, OmniSIFT introduces only 4.85M parameters while maintaining lower latency than training-free baselines such as OmniZip. With merely 25% of the original token context, OmniSIFT consistently outperforms all compression baselines and even surpasses the performance of the full-token model on several tasks.",
  "summary_en": "OmniSIFT is a modality-asymmetric token compression framework for Omni-LLMs that reduces computational overhead through spatio-temporal video pruning and vision-guided audio selection while maintaining superior performance.",
  "summary_zh": "OmniSIFT是一个面向Omni-LLMs的模态非对称token压缩框架，通过时空视频剪枝和视觉引导的音频选择降低计算开销，同时保持优异性能。",
  "hf_url": "https://huggingface.co/papers/2602.04804",
  "arxiv_url": "https://arxiv.org/abs/2602.04804",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04804",
  "github_url": "",
  "upvotes": 46,
  "fetched_at": "2026-02-19T05:42:12.669331+00:00"
}