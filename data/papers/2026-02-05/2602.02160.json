{
  "date": "2026-02-05",
  "paper_id": "2602.02160",
  "title": "D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use",
  "authors": [
    "Bowen Xu",
    "Shaoyu Wu",
    "Hao Jiang",
    "Kai Liu",
    "Xin Chen",
    "Lulu Hu",
    "Bin Yang"
  ],
  "abstract": "A two-stage training framework called D-CORE is proposed to improve large reasoning models' ability to decompose complex tasks and compose reasoning processes, achieving superior performance in tool-use benchmarks. Effective tool use and reasoning are essential capabilities for large reasoning models ~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning . To address this, we propose a two-stage training framework D-CORE~(\\textbf{D}ecomposing tasks and \\textbf{Co}mposing \\textbf{Re}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation , followed by diversity-aware reinforcement learning ~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\\% accuracy, surpassing the best-performing 8B model by 5.7\\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\\%, outperforming 70B models despite being 5times smaller. The source code is available at https://github.com/alibaba/EfficientAI.",
  "summary_en": "A two-stage training framework called D-CORE is proposed to improve large reasoning models' ability to decompose complex tasks and compose reasoning processes, achieving superior performance in tool-use benchmarks.",
  "summary_zh": "提出了一种名为D-CORE的两阶段训练框架，以提升大型推理模型分解复杂任务并组合推理过程的能力，在工具使用基准测试中取得了更优性能。",
  "hf_url": "https://huggingface.co/papers/2602.02160",
  "arxiv_url": "https://arxiv.org/abs/2602.02160",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.02160",
  "github_url": "https://github.com/alibaba/EfficientAI",
  "upvotes": 14,
  "fetched_at": "2026-02-19T05:27:20.127432+00:00"
}