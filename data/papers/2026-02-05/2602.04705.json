{
  "date": "2026-02-05",
  "paper_id": "2602.04705",
  "title": "ERNIE 5.0 Technical Report",
  "authors": [
    "Haifeng Wang",
    "Hua Wu",
    "Tian Wu",
    "Yu Sun",
    "Jing Liu",
    "Dianhai Yu",
    "Yanjun Ma",
    "Jingzhou He",
    "Zhongjun He",
    "Dou Hong",
    "Qiwen Liu",
    "Shuohuan Wang",
    "Junyuan Shang",
    "Zhenyu Zhang",
    "Yuchen Ding",
    "Jinle Zeng",
    "Jiabin Yang",
    "Liang Shen",
    "Ruibiao Chen",
    "Weichong Yin",
    "Siyu Ding",
    "Dai Dai"
  ],
  "abstract": "ERNIE 5.0 is a production-scale trillion-parameter autoregressive model that unifies multimodal understanding and generation through sparse MoE architecture and elastic training.",
  "summary_en": "ERNIE 5.0 is a production-scale trillion-parameter autoregressive model that unifies multimodal understanding and generation through sparse MoE architecture and elastic training.",
  "summary_zh": "ERNIE 5.0是一个生产级规模的万亿参数自回归模型，通过稀疏MoE架构和弹性训练统一了多模态理解与生成。",
  "hf_url": "https://huggingface.co/papers/2602.04705",
  "arxiv_url": "https://arxiv.org/abs/2602.04705",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.04705",
  "github_url": "",
  "upvotes": 251,
  "fetched_at": "2026-02-19T05:42:09.686486+00:00"
}