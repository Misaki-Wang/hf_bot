{
  "date": "2026-02-13",
  "paper_id": "2602.11598",
  "title": "ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation",
  "authors": [
    "Zedong Chu",
    "Shichao Xie",
    "Xiaolong Wu",
    "Yanfen Shen",
    "Minghua Luo",
    "Zhengbo Wang",
    "Fei Liu",
    "Xiaoxu Leng",
    "Junjun Hu",
    "Mingyang Yin",
    "Jia Lu",
    "Yingnan Guo",
    "Kai Yang",
    "Jiawei Han",
    "Xu Chen",
    "Yanqing Zhu",
    "Yuxiang Zhao",
    "Xin Liu",
    "Yirong Yang",
    "Ye He",
    "Jiahang Wang",
    "Yang Cai"
  ],
  "abstract": "A unified Vision-Language-Action model with a hierarchical architecture combining semantic reasoning and continuous trajectory generation achieves state-of-the-art performance across multiple embodied navigation tasks. Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation. To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 km^2). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory , enabling robust, long-horizon missions in dynamic real-world environments.",
  "summary_en": "A unified Vision-Language-Action model with a hierarchical architecture combining semantic reasoning and continuous trajectory generation achieves state-of-the-art performance across multiple embodied navigation tasks.",
  "summary_zh": "一种具有分层架构、结合语义推理与连续轨迹生成的统一视觉-语言-动作模型，在多个具身导航任务中达到了最先进的性能。",
  "hf_url": "https://huggingface.co/papers/2602.11598",
  "arxiv_url": "https://arxiv.org/abs/2602.11598",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.11598",
  "github_url": "https://github.com/amap-cvlab/ABot-Navigation",
  "upvotes": 2,
  "fetched_at": "2026-02-19T06:38:23.036149+00:00"
}