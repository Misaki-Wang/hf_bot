{
  "date": "2026-02-13",
  "paper_id": "2602.10934",
  "title": "MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models",
  "authors": [
    "Yitian Gong",
    "Kuangwei Chen",
    "Zhaoye Fei",
    "Xiaogui Yang",
    "Ke Chen",
    "Yang Wang",
    "Kexin Huang",
    "Mingshu Chen",
    "Ruixiao Li",
    "Qingyuan Cheng",
    "Shimin Li",
    "Xipeng Qiu"
  ],
  "abstract": "A fully end-to-end Transformer-based audio tokenizer architecture achieves high-fidelity reconstruction across diverse audio domains and enables superior text-to-speech and automatic speech recognition performance. Discrete audio tokenizers are fundamental to empowering large language models with native audio processing and generation capabilities. Despite recent progress, existing approaches often rely on pretrained encoder s, semantic distillation , or heterogeneous CNN-based architectures . These designs introduce fixed inductive biases that limit reconstruction fidelity and hinder effective scaling. In this paper, we argue that discrete audio tokenization should be learned fully end-to-end using a homogeneous and scalable architecture. To this end, we first propose CAT ( Causal Audio Tokenizer with Transformer), a purely Transformer-based architecture that jointly optimizes the encoder , quantizer , and decoder from scratch for high-fidelity reconstruction. Building on the CAT architecture, we develop MOSS-Audio-Tokenizer, a large-scale audio tokenizer featuring 1.6 billion parameters, pre-trained on 3 million hours of diverse, general audio data. We show that this simple, fully end-to-end approach built from homogeneous, causal Transformer blocks scales gracefully and supports high-fidelity reconstruction across diverse audio domains. Across speech, sound, and music, MOSS-Audio-Tokenizer consistently outperforms prior codec s over a wide range of bitrates, while exhibiting predictable improvements with increased scale. Notably, leveraging the discrete tokens from our model, we develop the first purely autoregressive TTS model that surpasses prior non-autoregressive and cascaded systems. Furthermore, MOSS-Audio-Tokenizer enables competitive ASR performance without auxiliary encoder s. Our findings position the CAT architecture as a unified, scalable interface for the next generation of native audio foundation models.",
  "summary_en": "A fully end-to-end Transformer-based audio tokenizer architecture achieves high-fidelity reconstruction across diverse audio domains and enables superior text-to-speech and automatic speech recognition performance.",
  "summary_zh": "完全端到端的Transformer音频分词器架构可在多种音频领域实现高保真重建，并带来更优的文本转语音与自动语音识别性能。",
  "hf_url": "https://huggingface.co/papers/2602.10934",
  "arxiv_url": "https://arxiv.org/abs/2602.10934",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.10934",
  "github_url": "https://github.com/OpenMOSS/MOSS-Audio-Tokenizer",
  "upvotes": 49,
  "fetched_at": "2026-02-19T06:38:06.334530+00:00"
}