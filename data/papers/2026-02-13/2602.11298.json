{
  "date": "2026-02-13",
  "paper_id": "2602.11298",
  "title": "Voxtral Realtime",
  "authors": [
    "Alexander H. Liu",
    "Andy Ehrenberg",
    "Andy Lo",
    "Chen-Yo Sun",
    "Guillaume Lample",
    "Jean-Malo Delignon",
    "Khyathi Raghavi Chandu",
    "Patrick von Platen",
    "Pavankumar Reddy Muddireddy",
    "Rohin Arora",
    "Sanchit Gandhi",
    "Sandeep Subramanian",
    "Soham Ghosh",
    "Srijan Mishra",
    "Abhinav Rastogi",
    "Alan Jeffares",
    "Albert Jiang",
    "Alexandre Sablayrolles",
    "Amélie Héliou",
    "Andrew Bai",
    "Angele Lenglemetz",
    "Anmol Agarwal"
  ],
  "abstract": "Voxtral Realtime is a streaming speech recognition model trained end-to-end for sub-second latency with performance matching offline systems. We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency . Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming , with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. We scale pretraining to a large-scale dataset spanning 13 languages. At a delay of 480ms, Voxtral Realtime achieves performance on par with Whisper, the most widely deployed offline transcription system. We release the model weights under the Apache 2.0 license.",
  "summary_en": "Voxtral Realtime is a streaming speech recognition model trained end-to-end for sub-second latency with performance matching offline systems.",
  "summary_zh": "Voxtral Realtime是端到端训练的流式语音识别模型，具有亚秒级延迟，性能与离线系统相当。",
  "hf_url": "https://huggingface.co/papers/2602.11298",
  "arxiv_url": "https://arxiv.org/abs/2602.11298",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.11298",
  "github_url": "",
  "upvotes": 15,
  "fetched_at": "2026-02-19T06:38:11.269412+00:00"
}