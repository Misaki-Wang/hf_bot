{
  "date": "2026-02-18",
  "paper_id": "2602.15322",
  "title": "On Surprising Effectiveness of Masking Updates in Adaptive Optimizers",
  "authors": [
    "Taejong Joo",
    "Wenhan Xia",
    "Cheolmin Kim",
    "Ming Zhang",
    "Eugene Ie"
  ],
  "abstract": "Random parameter update masking achieves superior optimization for large language models by inducing curvature-dependent regularization, with a momentum-aligned variant delivering significant performance improvements over state-of-the-art adaptive optimizers. Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners . We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment . Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\\% and 9\\% compared to Adam and Muon, respectively.",
  "summary_en": "Random parameter update masking achieves superior optimization for large language models by inducing curvature-dependent regularization, with a momentum-aligned variant delivering significant performance improvements over state-of-the-art adaptive optimizers.",
  "summary_zh": "随机参数更新掩码通过诱导曲率相关正则化，在大语言模型上实现了更优的优化，其动量对齐变体相较于当前最先进的自适应优化器带来了显著的性能提升。",
  "hf_url": "https://huggingface.co/papers/2602.15322",
  "arxiv_url": "https://arxiv.org/abs/2602.15322",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.15322",
  "github_url": "",
  "upvotes": 3,
  "fetched_at": "2026-02-18T14:10:31.823721+00:00"
}