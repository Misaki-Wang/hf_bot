{
  "date": "2026-02-16",
  "paper_id": "2602.12684",
  "title": "Xiaomi-Robotics-0: An Open-Sourced Vision-Language-Action Model with Real-Time Execution",
  "authors": [
    "Rui Cai",
    "Jun Guo",
    "Xinze He",
    "Piaopiao Jin",
    "Jie Li",
    "Bingxuan Lin",
    "Futeng Liu",
    "Wei Liu",
    "Fei Ma",
    "Kun Ma",
    "Feng Qiu",
    "Heng Qu",
    "Yifei Su",
    "Qiao Sun",
    "Dong Wang",
    "Donghao Wang",
    "Yunhong Wang",
    "Rujie Wu",
    "Diyun Xiang",
    "Yu Yang",
    "Hangjun Ye",
    "Yuan Zhang"
  ],
  "abstract": "A vision-language-action model for robotics combines large-scale pretraining with specialized training techniques to enable real-time execution and high-performance manipulation tasks.",
  "summary_en": "A vision-language-action model for robotics combines large-scale pretraining with specialized training techniques to enable real-time execution and high-performance manipulation tasks.",
  "summary_zh": "面向机器人领域的视觉-语言-动作模型结合大规模预训练与专门的训练技术，实现实时执行和高性能操作任务。",
  "hf_url": "https://huggingface.co/papers/2602.12684",
  "arxiv_url": "https://arxiv.org/abs/2602.12684",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.12684",
  "github_url": "https://github.com/XiaomiRobotics/Xiaomi-Robotics-0",
  "upvotes": 3,
  "fetched_at": "2026-02-17T08:53:06.787066+00:00"
}