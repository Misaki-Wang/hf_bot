{
  "date": "2026-02-17",
  "paper_id": "2602.13294",
  "title": "VisPhyWorld: Probing Physical Reasoning via Code-Driven Video Reconstruction",
  "authors": [
    "Jiarong Liang",
    "Max Ku",
    "Ka-Hei Hui",
    "Ping Nie",
    "Wenhu Chen"
  ],
  "abstract": "VisPhyWorld framework evaluates physical reasoning in MLLMs by requiring executable simulator code generation from visual observations, separating physical reasoning from rendering and enabling inspectable, falsifiable world representations. Evaluating whether Multimodal Large Language Models (MLLMs) genuinely reason about physical dynamics remains challenging. Most existing benchmarks rely on recognition-style protocols such as Visual Question Answering (VQA) and Violation of Expectation (VoE), which can often be answered without committing to an explicit, testable physical hypothesis. We propose VisPhyWorld, an execution-based framework that evaluates physical reasoning by requiring models to generate executable simulator code from visual observations. By producing runnable code, the inferred world representation is directly inspectable, editable, and falsifiable. This separates physical reasoning from rendering. Building on this framework, we introduce VisPhyBench, comprising 209 evaluation scenes derived from 108 physical templates and a systematic protocol that evaluates how well models reconstruct appearance and reproduce physically plausible motion. Our pipeline produces valid reconstructed videos in 97.7% on the benchmark. Experiments show that while state-of-the-art MLLMs achieve strong semantic scene understanding , they struggle to accurately infer physical parameters and to simulate consistent physical dynamics .",
  "summary_en": "VisPhyWorld framework evaluates physical reasoning in MLLMs by requiring executable simulator code generation from visual observations, separating physical reasoning from rendering and enabling inspectable, falsifiable world representations.",
  "summary_zh": "VisPhyWorld框架通过要求基于视觉观察生成可执行的模拟器代码来评估MLLM的物理推理能力，将物理推理与渲染分离，并实现可检查、可证伪的世界表征。",
  "hf_url": "https://huggingface.co/papers/2602.13294",
  "arxiv_url": "https://arxiv.org/abs/2602.13294",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.13294",
  "github_url": "https://github.com/TIGER-AI-Lab/VisPhyWorld",
  "upvotes": 12,
  "fetched_at": "2026-02-19T06:45:26.467001+00:00"
}