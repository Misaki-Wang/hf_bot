{
  "date": "2026-02-20",
  "paper_id": "2602.17270",
  "title": "Unified Latents (UL): How to train your latents",
  "authors": [
    "Jonathan Heek",
    "Emiel Hoogeboom",
    "Thomas Mensink",
    "Tim Salimans"
  ],
  "abstract": "Unified Latents framework learns joint latent representations using diffusion prior regularization and diffusion model decoding, achieving competitive FID scores with reduced training compute. We present Unified Latents (UL), a framework for learning latent representations that are jointly regularized by a diffusion prior and decoded by a diffusion model . By linking the encoder's output noise to the prior's minimum noise level, we obtain a simple training objective that provides a tight upper bound on the latent bitrate . On ImageNet-512, our approach achieves competitive FID of 1.4, with high reconstruction quality ( PSNR ) while requiring fewer training FLOPs than models trained on Stable Diffusion latents. On Kinetics-600, we set a new state-of-the-art FVD of 1.3.",
  "summary_en": "Unified Latents framework learns joint latent representations using diffusion prior regularization and diffusion model decoding, achieving competitive FID scores with reduced training compute.",
  "summary_zh": "Unified Latents 框架通过扩散先验正则化与扩散模型解码学习联合潜在表示，以更低的训练计算量取得了具有竞争力的 FID 分数。",
  "hf_url": "https://huggingface.co/papers/2602.17270",
  "arxiv_url": "https://arxiv.org/abs/2602.17270",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.17270",
  "github_url": "",
  "upvotes": 21,
  "fetched_at": "2026-02-21T01:53:03.694814+00:00"
}