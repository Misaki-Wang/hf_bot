{
  "date": "2026-02-10",
  "paper_id": "2602.09022",
  "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
  "authors": [
    "Zehan Wang",
    "Tengfei Wang",
    "Haiyu Zhang",
    "Xuhui Zuo",
    "Junta Wu",
    "Haoyuan Wang",
    "Wenqiang Sun",
    "Zhenwei Wang",
    "Chenjie Cao",
    "Hengshuang Zhao",
    "Chunchao Guo",
    "Zhou Zhao"
  ],
  "abstract": "WorldCompass enhances long-horizon video-based world models through reinforcement learning post-training with clip-level rollouts, complementary rewards, and efficient RL algorithms. This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models , enabling them to explore the world more accurately and consistently based on interaction signals. To effectively \"steer\" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy : We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions : We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.",
  "summary_en": "WorldCompass enhances long-horizon video-based world models through reinforcement learning post-training with clip-level rollouts, complementary rewards, and efficient RL algorithms.",
  "summary_zh": "WorldCompass 通过采用片段级 rollout、互补奖励和高效 RL 算法的强化学习后训练，增强基于视频的长程世界模型。",
  "hf_url": "https://huggingface.co/papers/2602.09022",
  "arxiv_url": "https://arxiv.org/abs/2602.09022",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.09022",
  "github_url": "",
  "upvotes": 20,
  "fetched_at": "2026-02-19T06:03:50.195696+00:00"
}