{
  "date": "2026-02-19",
  "paper_id": "2602.14979",
  "title": "RynnBrain: Open Embodied Foundation Models",
  "authors": [
    "Ronghao Dang",
    "Jiayan Guo",
    "Bohan Hou",
    "Sicong Leng",
    "Kehan Li",
    "Xin Li",
    "Jiangpin Liu",
    "Yunxuan Mao",
    "Zhikai Wang",
    "Yuqian Yuan",
    "Minghao Zhu",
    "Xiao Lin",
    "Yang Bai",
    "Qian Jiang",
    "Yaxi Zhao",
    "Minghua Zeng",
    "Junlong Gao",
    "Yuming Jiang",
    "Jun Cen",
    "Siteng Huang",
    "Liuyi Wang",
    "Wenqiao Zhang"
  ],
  "abstract": "RynnBrain is an open-source spatiotemporal foundation model for embodied intelligence that unifies perception, reasoning, and planning capabilities across multiple scales and task-specific variants. Despite rapid progress in multimodal foundation models , embodied intelligence community still lacks a unified, physically grounded foundation model that integrates perception, reasoning, and planning within real-world spatial-temporal dynamics. We introduce RynnBrain, an open-source spatiotemporal foundation model for embodied intelligence . RynnBrain strengthens four core capabilities in a unified framework: comprehensive egocentric understanding , diverse spatiotemporal localization , physically grounded reasoning , and physics-aware planning . The RynnBrain family comprises three foundation model scales (2B, 8B, and 30B-A3B MoE ) and four post-trained variants tailored for downstream embodied tasks (i.e., RynnBrain-Nav, RynnBrain-Plan, and RynnBrain-VLA) or complex spatial reasoning tasks (i.e., RynnBrain-CoP). In terms of extensive evaluations on 20 embodied benchmarks and 8 general vision understanding benchmarks , our RynnBrain foundation models largely outperform existing embodied foundation models by a significant margin. The post-trained model suite further substantiates two key potentials of the RynnBrain foundation model: (i) enabling physically grounded reasoning and planning, and (ii) serving as a strong pretrained backbone that can be efficiently adapted to diverse embodied tasks.",
  "summary_en": "RynnBrain is an open-source spatiotemporal foundation model for embodied intelligence that unifies perception, reasoning, and planning capabilities across multiple scales and task-specific variants.",
  "summary_zh": "RynnBrain是一个面向具身智能的开源时空基础模型，统一了多尺度及任务特定变体下的感知、推理与规划能力。",
  "hf_url": "https://huggingface.co/papers/2602.14979",
  "arxiv_url": "https://arxiv.org/abs/2602.14979",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.14979",
  "github_url": "https://github.com/alibaba-damo-academy/RynnBrain",
  "upvotes": 10,
  "fetched_at": "2026-02-19T06:47:26.457151+00:00"
}