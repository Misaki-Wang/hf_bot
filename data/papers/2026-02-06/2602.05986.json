{
  "date": "2026-02-06",
  "paper_id": "2602.05986",
  "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
  "authors": [
    "Mingxin Liu",
    "Shuran Ma",
    "Shibei Meng",
    "Xiangyu Zhao",
    "Zicheng Zhang",
    "Shaofeng Zhang",
    "Zhihang Zhong",
    "Peixian Chen",
    "Haoyu Cao",
    "Xing Sun",
    "Haodong Duan",
    "Xue Yang"
  ],
  "abstract": "RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation. While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: Reasoning Alignment , Temporal Consistency , Physical Rationality , and Visual Quality . To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models.",
  "summary_en": "RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation.",
  "summary_zh": "[DUMMY-TRANSLATION] 未配置真实翻译服务，以下保留英文原文。\nRISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation.",
  "hf_url": "https://huggingface.co/papers/2602.05986",
  "arxiv_url": "https://arxiv.org/abs/2602.05986",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.05986",
  "github_url": "https://github.com/VisionXLab/Rise-Video",
  "upvotes": 26,
  "fetched_at": "2026-02-19T05:43:24.376799+00:00"
}