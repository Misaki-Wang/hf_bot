{
  "date": "2026-02-06",
  "paper_id": "2602.05216",
  "title": "Semantic Search over 9 Million Mathematical Theorems",
  "authors": [
    "Luke Alexander",
    "Eric Leonen",
    "Sophie Szeto",
    "Artemii Remizov",
    "Ignacio Tejeda",
    "Giovanni Inchiostro",
    "Vasily Ilin"
  ],
  "abstract": "Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies. Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of 9.2 million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice , embedding model , and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at https://huggingface.co/spaces/uw-math-ai/theorem-search{this link}, and the dataset is available at https://huggingface.co/datasets/uw-math-ai/TheoremSearch{this link}.",
  "summary_en": "Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies.",
  "summary_zh": "[DUMMY-TRANSLATION] 未配置真实翻译服务，以下保留英文原文。\nLarge-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies.",
  "hf_url": "https://huggingface.co/papers/2602.05216",
  "arxiv_url": "https://arxiv.org/abs/2602.05216",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.05216",
  "github_url": "",
  "upvotes": 20,
  "fetched_at": "2026-02-19T05:43:00.782393+00:00"
}