{
  "date": "2026-02-02",
  "paper_id": "2601.21716",
  "title": "DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning",
  "authors": [
    "Mingshuang Luo",
    "Shuang Liang",
    "Zhengkun Rong",
    "Yuxuan Luo",
    "Tianshu Hu",
    "Ruibing Hou",
    "Hong Chang",
    "Yong Li",
    "Yuan Zhang",
    "Mingyuan Gao"
  ],
  "abstract": "DreamActor-M2 presents a universal character animation framework that addresses motion injection trade-offs and pose prior limitations through in-context learning and self-bootstrapped data synthesis for improved generalization across diverse characters. Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a \"see-saw\", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space , enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs , facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation . This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization . Project Page: https://grisoon.github.io/DreamActor-M2/",
  "summary_en": "DreamActor-M2 presents a universal character animation framework that addresses motion injection trade-offs and pose prior limitations through in-context learning and self-bootstrapped data synthesis for improved generalization across diverse characters.",
  "summary_zh": "[DUMMY-TRANSLATION] 未配置真实翻译服务，以下保留英文原文。\nDreamActor-M2 presents a universal character animation framework that addresses motion injection trade-offs and pose prior limitations through in-context learning and self-bootstrapped data synthesis for improved generalization across diverse characters.",
  "hf_url": "https://huggingface.co/papers/2601.21716",
  "arxiv_url": "https://arxiv.org/abs/2601.21716",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2601.21716",
  "github_url": "",
  "upvotes": 13,
  "fetched_at": "2026-02-19T05:34:47.043028+00:00"
}