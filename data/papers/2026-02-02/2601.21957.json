{
  "date": "2026-02-02",
  "paper_id": "2601.21957",
  "title": "PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing",
  "authors": [
    "Cheng Cui",
    "Ting Sun",
    "Suyin Liang",
    "Tingquan Gao",
    "Zelun Zhang",
    "Jiaxuan Liu",
    "Xueqing Wang",
    "Changda Zhou",
    "Hongen Liu",
    "Manhui Lin",
    "Yue Zhang",
    "Yubo Zhang",
    "Yi Liu",
    "Dianhai Yu",
    "Yanjun Ma"
  ],
  "abstract": "A compact vision-language model achieves state-of-the-art accuracy on document understanding tasks while maintaining efficiency through specialized benchmarking and extended functionality. We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR",
  "summary_en": "A compact vision-language model achieves state-of-the-art accuracy on document understanding tasks while maintaining efficiency through specialized benchmarking and extended functionality.",
  "summary_zh": "一种紧凑型视觉语言模型通过专门的基准测试和扩展功能，在文档理解任务上实现了最先进的准确率，同时保持效率。",
  "hf_url": "https://huggingface.co/papers/2601.21957",
  "arxiv_url": "https://arxiv.org/abs/2601.21957",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2601.21957",
  "github_url": "",
  "upvotes": 19,
  "fetched_at": "2026-02-19T05:34:48.943153+00:00"
}