{
  "date": "2026-02-02",
  "paper_id": "2601.15625",
  "title": "Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors",
  "authors": [
    "Zhiwei Zhang",
    "Fei Zhao",
    "Rui Wang",
    "Zezhong Wang",
    "Bin Liang",
    "Jiakang Wang",
    "Yao Hu",
    "Shaosheng Cao",
    "Kam-Fai Wong"
  ],
  "abstract": "A framework called Fission-GRPO is introduced to improve multi-turn tool execution in large language models by converting execution errors into corrective supervision during reinforcement learning training. Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution : following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO , a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator , then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.",
  "summary_en": "A framework called Fission-GRPO is introduced to improve multi-turn tool execution in large language models by converting execution errors into corrective supervision during reinforcement learning training.",
  "summary_zh": "[DUMMY-TRANSLATION] 未配置真实翻译服务，以下保留英文原文。\nA framework called Fission-GRPO is introduced to improve multi-turn tool execution in large language models by converting execution errors into corrective supervision during reinforcement learning training.",
  "hf_url": "https://huggingface.co/papers/2601.15625",
  "arxiv_url": "https://arxiv.org/abs/2601.15625",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2601.15625",
  "github_url": "",
  "upvotes": 8,
  "fetched_at": "2026-02-19T05:34:20.795603+00:00"
}