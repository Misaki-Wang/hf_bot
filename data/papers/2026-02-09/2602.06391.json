{
  "date": "2026-02-09",
  "paper_id": "2602.06391",
  "title": "POINTS-GUI-G: GUI-Grounding Journey",
  "authors": [
    "Zhongyin Zhao",
    "Yuan Liu",
    "Yikun Liu",
    "Haicheng Wang",
    "Le Tian",
    "Xiao Zhou",
    "Yangxiu You",
    "Zilin Yu",
    "Yang Yu",
    "Jie Zhou"
  ],
  "abstract": "GUI agents for automated digital tasks rely on vision-language models with enhanced grounding capabilities, achieved through refined data engineering, improved training strategies, and reinforcement learning with verifiable rewards.",
  "summary_en": "GUI agents for automated digital tasks rely on vision-language models with enhanced grounding capabilities, achieved through refined data engineering, improved training strategies, and reinforcement learning with verifiable rewards.",
  "summary_zh": "用于自动化数字任务的GUI智能体依赖具备增强grounding能力的视觉语言模型，这些能力通过精细化的数据工程、改进的训练策略以及可验证奖励的强化学习来实现。",
  "hf_url": "https://huggingface.co/papers/2602.06391",
  "arxiv_url": "https://arxiv.org/abs/2602.06391",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.06391",
  "github_url": "https://github.com/Tencent/POINTS-GUI",
  "upvotes": 16,
  "fetched_at": "2026-02-19T05:44:20.305138+00:00"
}