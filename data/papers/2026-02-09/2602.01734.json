{
  "date": "2026-02-09",
  "paper_id": "2602.01734",
  "title": "MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration",
  "authors": [
    "Lianhai Ren",
    "Yucheng Ding",
    "Xiao Liu",
    "Qianxiao Li",
    "Peng Cheng",
    "Yeyun Gong"
  ],
  "abstract": "Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions. Training instability remains a critical challenge in large language model (LLM) pretraining , often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via μP, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm ), and (2) increasing alignment between adjacent layer Jacobian s. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.",
  "summary_en": "Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions.",
  "summary_zh": "[DUMMY-TRANSLATION] 未配置真实翻译服务，以下保留英文原文。\nTraining instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions.",
  "hf_url": "https://huggingface.co/papers/2602.01734",
  "arxiv_url": "https://arxiv.org/abs/2602.01734",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.01734",
  "github_url": "",
  "upvotes": 32,
  "fetched_at": "2026-02-19T05:43:44.153517+00:00"
}