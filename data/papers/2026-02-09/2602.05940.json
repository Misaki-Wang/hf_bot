{
  "date": "2026-02-09",
  "paper_id": "2602.05940",
  "title": "Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training",
  "authors": [
    "Junxiao Liu",
    "Zhijun Wang",
    "Yixiao Li",
    "Zhejian Lai",
    "Liqian Huang",
    "Xin Huang",
    "Xue Han",
    "Junlan Feng",
    "Shujian Huang"
  ],
  "abstract": "TRIT framework improves multilingual reasoning by jointly training translation and reasoning components, enhancing question understanding and response generation across languages. Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning . To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning . Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH , our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200 .",
  "summary_en": "TRIT framework improves multilingual reasoning by jointly training translation and reasoning components, enhancing question understanding and response generation across languages.",
  "summary_zh": "[DUMMY-TRANSLATION] 未配置真实翻译服务，以下保留英文原文。\nTRIT framework improves multilingual reasoning by jointly training translation and reasoning components, enhancing question understanding and response generation across languages.",
  "hf_url": "https://huggingface.co/papers/2602.05940",
  "arxiv_url": "https://arxiv.org/abs/2602.05940",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.05940",
  "github_url": "",
  "upvotes": 18,
  "fetched_at": "2026-02-19T05:44:07.148907+00:00"
}