{
  "date": "2026-02-03",
  "paper_id": "2602.01983",
  "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning",
  "authors": [
    "Xintian Shen",
    "Jiawei Chen",
    "Lihao Zheng",
    "Hao Ma",
    "Tao Wei",
    "Kun Zhan"
  ],
  "abstract": "A training-free framework enables language model agents to automatically create and optimize tools during inference, improving their reasoning capabilities through self-evolution and memory consolidation. Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%uparrow and +23.04%uparrow on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.",
  "summary_en": "A training-free framework enables language model agents to automatically create and optimize tools during inference, improving their reasoning capabilities through self-evolution and memory consolidation.",
  "summary_zh": "一种无需训练的框架使语言模型智能体能够在推理过程中自动创建和优化工具，通过自我进化和记忆巩固提升其推理能力。",
  "hf_url": "https://huggingface.co/papers/2602.01983",
  "arxiv_url": "https://arxiv.org/abs/2602.01983",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.01983",
  "github_url": "",
  "upvotes": 2,
  "fetched_at": "2026-02-19T05:37:24.084259+00:00"
}