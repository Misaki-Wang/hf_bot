{
  "date": "2026-02-03",
  "paper_id": "2602.01801",
  "title": "Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention",
  "authors": [
    "Dvir Samuel",
    "Issar Tzachor",
    "Matan Levy",
    "Micahel Green",
    "Gal Chechik",
    "Rami Ben-Ari"
  ],
  "abstract": "Autoregressive video diffusion models face efficiency challenges due to growing KV caches and redundant attention computations, which are addressed through TempCache, AnnCA, and AnnSA techniques that reduce computational demands while maintaining visual quality and stable performance. Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; Ann CA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor ( ANN ) matching; and Ann SA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN . Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.",
  "summary_en": "Autoregressive video diffusion models face efficiency challenges due to growing KV caches and redundant attention computations, which are addressed through TempCache, AnnCA, and AnnSA techniques that reduce computational demands while maintaining visual quality and stable performance.",
  "summary_zh": "自回归视频扩散模型因KV缓存增长和注意力计算冗余面临效率挑战，TempCache、AnnCA和AnnSA技术通过降低计算需求并保持视觉质量与稳定性能解决这些问题。",
  "hf_url": "https://huggingface.co/papers/2602.01801",
  "arxiv_url": "https://arxiv.org/abs/2602.01801",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.01801",
  "github_url": "",
  "upvotes": 28,
  "fetched_at": "2026-02-19T05:37:12.726742+00:00"
}