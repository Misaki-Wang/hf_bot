{
  "date": "2026-02-03",
  "paper_id": "2602.01511",
  "title": "Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training",
  "authors": [
    "Ran Xu",
    "Tianci Liu",
    "Zihan Dong",
    "Tony You",
    "Ilgee Hong",
    "Carl Yang",
    "Linjun Zhang",
    "Tao Zhao",
    "Haoyu Wang"
  ],
  "abstract": "Rubric-ARM framework jointly optimizes rubric generation and judging through reinforcement learning to improve response quality assessment in creative and open-ended tasks. Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback . Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.",
  "summary_en": "Rubric-ARM framework jointly optimizes rubric generation and judging through reinforcement learning to improve response quality assessment in creative and open-ended tasks.",
  "summary_zh": "Rubric-ARM框架通过强化学习联合优化评分标准生成与评判，以提升创意性和开放式任务中的回复质量评估。",
  "hf_url": "https://huggingface.co/papers/2602.01511",
  "arxiv_url": "https://arxiv.org/abs/2602.01511",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2602.01511",
  "github_url": "",
  "upvotes": 14,
  "fetched_at": "2026-02-19T05:36:52.236345+00:00"
}