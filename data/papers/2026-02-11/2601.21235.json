{
  "date": "2026-02-11",
  "paper_id": "2601.21235",
  "title": "SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models",
  "authors": [
    "Alok Abhishek",
    "Tushar Bandopadhyay",
    "Lisa Erickson"
  ],
  "abstract": "Large language models exhibit varying levels of social risk across multiple dimensions, with significant differences in worst-case behavior that cannot be captured by traditional scalar evaluation metrics. Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior . This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias , fairness , ethics , and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk . The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility . Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.",
  "summary_en": "Large language models exhibit varying levels of social risk across multiple dimensions, with significant differences in worst-case behavior that cannot be captured by traditional scalar evaluation metrics.",
  "summary_zh": "大语言模型在多个维度上表现出不同程度的社会风险，其最坏情况行为存在显著差异，而传统标量评估指标无法捕捉这些差异。",
  "hf_url": "https://huggingface.co/papers/2601.21235",
  "arxiv_url": "https://arxiv.org/abs/2601.21235",
  "arxiv_pdf_url": "https://arxiv.org/pdf/2601.21235",
  "github_url": "",
  "upvotes": 1,
  "fetched_at": "2026-02-19T06:20:17.074995+00:00"
}