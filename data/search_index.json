[
  {
    "id": "2602.14111",
    "date": "2026-02-18",
    "title": "Sanity Checks for Sparse Autoencoders: Do SAEs Beat Random Baselines?",
    "authors": "Anton Korznikov Andrey Galichin Alexey Dontsov Oleg Rogov Ivan Oseledets Elena Tutubalina",
    "abstract": "Sparse Autoencoders fail to reliably decompose neural network internals despite strong reconstruction performance, as demonstrated through synthetic and real activation evaluations. Sparse Autoencoders (SAEs) have emerged as a promising tool for interpreting neural networks by decomposing their activations into sparse sets of human-interpretable features. Recent work has introduced multiple SAE variants and successfully scaled them to frontier models. Despite much excitement, a growing number of negative results in downstream tasks casts doubt on whether SAEs recover meaningful features. To directly investigate this, we perform two complementary evaluations. On a synthetic setup with known ground-truth features, we demonstrate that SAEs recover only 9% of true features despite achieving 71% explained variance , showing that they fail at their core task even when reconstruction is strong. To evaluate SAEs on real activations , we introduce three baselines that constrain SAE feature directions or their activation patterns to random values. Through extensive experiments across multiple SAE architectures, we show that our baselines match fully-trained SAEs in interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72). Together, these results suggest that SAEs in their current state do not reliably decompose models' internal mechanisms.",
    "summary_en": "Sparse Autoencoders fail to reliably decompose neural network internals despite strong reconstruction performance, as demonstrated through synthetic and real activation evaluations.",
    "summary_zh": "稀疏自编码器尽管具有较强的重建性能，却无法可靠地分解神经网络内部结构，这一点在合成与真实激活评估中得到了证实。",
    "upvotes": 51
  },
  {
    "id": "2602.12670",
    "date": "2026-02-18",
    "title": "SkillsBench: Benchmarking How Well Agent Skills Work Across Diverse Tasks",
    "authors": "Xiangyi Li Wenbo Chen Yimin Liu Shenghan Zheng Xiaokun Chen Yifeng He Yubo Li Bingran You Haotian Shen Jiankai Sun Shuyi Wang Qunhong Zeng Di Wang Xuandong Zhao Yuanli Wang Roey Ben Chaim Zonglin Di Yipeng Gao Junwei He Yizhuo He Liqiang Jing Luyang Kong",
    "abstract": "SkillsBench evaluates agent skills across 86 tasks and finds that curated skills improve performance significantly but inconsistently, while self-generated skills offer no benefit, indicating that models struggle to create useful procedural knowledge despite benefiting from curated versions. Agent Skills are structured packages of procedural knowledge that augment LLM agents at inference time. Despite rapid adoption, there is no standard way to measure whether they actually help. We present SkillsBench , a benchmark of 86 tasks across 11 domains paired with curated Skills and deterministic verifiers. Each task is evaluated under three conditions: no Skills, curated Skills , and self-generated Skills . We test 7 agent-model configurations over 7,308 trajectories. Curated Skills raise average pass rate by 16.2 percentage points(pp), but effects vary widely by domain (+4.5pp for Software Engineering to +51.9pp for Healthcare) and 16 of 84 tasks show negative deltas. Self-generated Skills provide no benefit on average, showing that models cannot reliably author the procedural knowledge they benefit from consuming. Focused Skills with 2--3 modules outperform comprehensive documentation, and smaller models with Skills can match larger models without them.",
    "summary_en": "SkillsBench evaluates agent skills across 86 tasks and finds that curated skills improve performance significantly but inconsistently, while self-generated skills offer no benefit, indicating that models struggle to create useful procedural knowledge despite benefiting from curated versions.",
    "summary_zh": "SkillsBench在86项任务中评估了智能体技能，发现精选技能虽能显著提升性能但效果不一，而自生成技能则毫无助益，这表明尽管模型能从精选版本中获益，却难以创建有用的程序性知识。",
    "upvotes": 38
  },
  {
    "id": "2602.15763",
    "date": "2026-02-18",
    "title": "GLM-5: from Vibe Coding to Agentic Engineering",
    "authors": "GLM-5 Team Aohan Zeng Xin Lv Zhenyu Hou Zhengxiao Du Qinkai Zheng Bin Chen Da Yin Chendi Ge Chengxing Xie Cunxiang Wang Gengzheng Pan Hao Zeng Haoke Zhang Haoran Wang Huilong Chen Jiajie Zhang Jian Jiao Jiaqi Guo Jingsen Wang Jingzhao Du Jinzhu Wu",
    "abstract": "GLM-5 advances foundation models with DSA for cost reduction, asynchronous reinforcement learning for improved alignment, and enhanced coding capabilities for real-world software engineering. We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering . Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks . Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.",
    "summary_en": "GLM-5 advances foundation models with DSA for cost reduction, asynchronous reinforcement learning for improved alignment, and enhanced coding capabilities for real-world software engineering.",
    "summary_zh": "GLM-5通过DSA降低成本，利用异步强化学习改进对齐，并增强编程能力以支持真实世界软件工程，从而推进基础模型发展。",
    "upvotes": 31
  },
  {
    "id": "2602.14299",
    "date": "2026-02-18",
    "title": "Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook",
    "authors": "Ming Li Xirui Li Tianyi Zhou",
    "abstract": "Large language model agents in networked environments exhibit dynamic stability without true social convergence, maintaining individual diversity while lacking collective influence structures. As large language model agents increasingly populate networked environments , a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitative diagnostic framework for dynamic evolution in AI agent societies , measuring semantic stabilization , lexical turnover , individual inertia , influence persistence , and collective consensus . Our analysis reveals a system in dynamic balance in Moltbook: while global semantic averages stabilize rapidly, individual agents retain high diversity and persistent lexical turnover , defying homogenization. However, agents exhibit strong individual inertia and minimal adaptive response to interaction partners, preventing mutual influence and consensus. Consequently, influence remains transient with no persistent supernodes, and the society fails to develop stable collective influence anchors due to the absence of shared social memory. These findings demonstrate that scale and interaction density alone are insufficient to induce socialization, providing actionable design and analysis principles for upcoming next-generation AI agent societies .",
    "summary_en": "Large language model agents in networked environments exhibit dynamic stability without true social convergence, maintaining individual diversity while lacking collective influence structures.",
    "summary_zh": "网络环境中的大语言模型智能体表现出动态稳定性，但未实现真正的社会收敛，在保持个体多样性的同时缺乏集体影响结构。",
    "upvotes": 21
  },
  {
    "id": "2602.12279",
    "date": "2026-02-18",
    "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
    "authors": "Leon Liangyu Chen Haoyu Ma Zhipeng Fan Ziqi Huang Animesh Sinha Xiaoliang Dai Jialiang Wang Zecheng He Jianwei Yang Chunyuan Li Junzhe Sun Chu Wang Serena Yeung-Levy Felix Juefei-Xu",
    "abstract": "UniT framework enables unified multimodal models to perform iterative reasoning and refinement through chain-of-thought test-time scaling, improving both generation and understanding capabilities. Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis , unified model training , and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning . These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models .",
    "summary_en": "UniT framework enables unified multimodal models to perform iterative reasoning and refinement through chain-of-thought test-time scaling, improving both generation and understanding capabilities.",
    "summary_zh": "UniT框架使统一多模态模型能够通过思维链测试时缩放进行迭代推理与优化，从而提升生成与理解能力。",
    "upvotes": 16
  },
  {
    "id": "2602.15112",
    "date": "2026-02-18",
    "title": "ResearchGym: Evaluating Language Model Agents on Real-World AI Research",
    "authors": "Aniketh Garikaparthi Manasi Patwardhan Arman Cohan",
    "abstract": "ResearchGym presents a benchmark environment for evaluating AI agents on end-to-end research tasks, revealing significant capability-reliability gaps in current autonomous agents despite occasional state-of-the-art performance. We introduce ResearchGym , a benchmark and execution environment for evaluating AI agents on end-to-end research . To instantiate this, we repurpose five oral and spotlight papers from ICML , ICLR , and ACL . From each paper's repository, we preserve the datasets , evaluation harness , and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5 , we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length . Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex ( GPT-5 .2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.",
    "summary_en": "ResearchGym presents a benchmark environment for evaluating AI agents on end-to-end research tasks, revealing significant capability-reliability gaps in current autonomous agents despite occasional state-of-the-art performance.",
    "summary_zh": "ResearchGym提出了一个用于评估AI智能体端到端研究任务的基准环境，揭示了当前自主智能体尽管偶尔能取得最优性能，但仍存在显著的能力-可靠性差距。",
    "upvotes": 14
  },
  {
    "id": "2602.15547",
    "date": "2026-02-18",
    "title": "jina-embeddings-v5-text: Task-Targeted Embedding Distillation",
    "authors": "Mohammad Kalim Akram Saba Sturua Nastia Havriushenko Quentin Herreros Michael Günther Maximilian Werk Han Xiao",
    "abstract": "Compact text embedding models are developed through a combined training approach using distillation and contrastive loss, achieving state-of-the-art performance while supporting long-context sequences and efficient quantization. Text embedding models are widely used for semantic similarity tasks, including information retrieval , clustering , and classification . General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models . Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization . Model weights are publicly available, hopefully inspiring further advances in embedding model development.",
    "summary_en": "Compact text embedding models are developed through a combined training approach using distillation and contrastive loss, achieving state-of-the-art performance while supporting long-context sequences and efficient quantization.",
    "summary_zh": "紧凑型文本嵌入模型通过蒸馏与对比损失相结合的联合训练方法开发，在实现最先进性能的同时支持长上下文序列和高效量化。",
    "upvotes": 9
  },
  {
    "id": "2602.14486",
    "date": "2026-02-18",
    "title": "Revisiting the Platonic Representation Hypothesis: An Aristotelian View",
    "authors": "Fabian Gröger Shuo Wen Maria Brbić",
    "abstract": "Network representations converge toward shared local neighborhood relationships rather than global statistical models, as revealed by calibrated similarity metrics. The Platonic Representation Hypothesis suggests that representations from neural networks are converging to a common statistical model of reality. We show that the existing metrics used to measure representational similarity are confounded by network scale: increasing model depth or width can systematically inflate representational similarity scores. To correct these effects, we introduce a permutation-based null-calibration framework that transforms any representational similarity metric into a calibrated score with statistical guarantees. We revisit the Platonic Representation Hypothesis with our calibration framework, which reveals a nuanced picture: the apparent convergence reported by global spectral measures largely disappears after calibration, while local neighborhood similarity , but not local distances, retains significant agreement across different modalities. Based on these findings, we propose the Aristotelian Representation Hypothesis : representations in neural networks are converging to shared local neighborhood relationships.",
    "summary_en": "Network representations converge toward shared local neighborhood relationships rather than global statistical models, as revealed by calibrated similarity metrics.",
    "summary_zh": "经校准的相似性度量显示，网络表征收敛于共享的局部邻域关系，而非全局统计模型。",
    "upvotes": 7
  },
  {
    "id": "2602.15772",
    "date": "2026-02-18",
    "title": "Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models",
    "authors": "Sen Ye Mengde Xu Shuyang Gu Di He Liwei Wang Han Hu",
    "abstract": "The Reason-Reflect-Refine framework addresses the trade-off between generation and understanding in multimodal models by reformulating single-step generation into a multi-step process that explicitly incorporates understanding during generation. Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of \"generate-understand-regenerate\". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma , achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models . Code is available at https://github.com/sen-ye/R3.",
    "summary_en": "The Reason-Reflect-Refine framework addresses the trade-off between generation and understanding in multimodal models by reformulating single-step generation into a multi-step process that explicitly incorporates understanding during generation.",
    "summary_zh": "推理-反思-精炼框架通过将单步生成重新表述为在生成过程中显式融入理解的多步过程，解决了多模态模型中生成与理解之间的权衡问题。",
    "upvotes": 5
  },
  {
    "id": "2602.15322",
    "date": "2026-02-18",
    "title": "On Surprising Effectiveness of Masking Updates in Adaptive Optimizers",
    "authors": "Taejong Joo Wenhan Xia Cheolmin Kim Ming Zhang Eugene Ie",
    "abstract": "Random parameter update masking achieves superior optimization for large language models by inducing curvature-dependent regularization, with a momentum-aligned variant delivering significant performance improvements over state-of-the-art adaptive optimizers. Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners . We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment . Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\\% and 9\\% compared to Adam and Muon, respectively.",
    "summary_en": "Random parameter update masking achieves superior optimization for large language models by inducing curvature-dependent regularization, with a momentum-aligned variant delivering significant performance improvements over state-of-the-art adaptive optimizers.",
    "summary_zh": "随机参数更新掩码通过诱导曲率相关正则化，在大语言模型上实现了更优的优化，其动量对齐变体相较于当前最先进的自适应优化器带来了显著的性能提升。",
    "upvotes": 5
  },
  {
    "id": "2602.15200",
    "date": "2026-02-18",
    "title": "COMPOT: Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers Compression",
    "authors": "Denis Makhov Dmitriy Shopkhoev Magauiya Zhussip Ammar Ali Baher Mohammad Stamatios Lefkimmiatis",
    "abstract": "COMPOT is a training-free compression framework for Transformer models that uses sparse dictionary learning with orthogonal dictionaries and closed-form updates to achieve better quality-compression trade-offs than traditional low-rank methods. Post-training compression of Transformer models commonly relies on truncated singular value decomposition (SVD). However, enforcing a single shared subspace can degrade accuracy even at moderate compression. Sparse dictionary learning provides a more flexible union-of-subspaces representation, but existing approaches often suffer from iterative dictionary and coefficient updates. We propose COMPOT (Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers), a training-free compression framework that uses a small calibration dataset to estimate a sparse weight factorization . COMPOT employs orthogonal dictionaries that enable closed-form Procrustes updates for the dictionary and analytical single-step sparse coding for the coefficients, eliminating iterative optimization. To handle heterogeneous layer sensitivity under a global compression budget, COMPOT further introduces a one-shot dynamic allocation strategy that adaptively redistributes layer-wise compression rates. Extensive experiments across diverse architectures and tasks show that COMPOT consistently delivers a superior quality-compression trade-off over strong low-rank and sparse baselines, while remaining fully compatible with post-training quantization for extreme compression. Code is available https://github.com/mts-ai/COMPOT{here}.",
    "summary_en": "COMPOT is a training-free compression framework for Transformer models that uses sparse dictionary learning with orthogonal dictionaries and closed-form updates to achieve better quality-compression trade-offs than traditional low-rank methods.",
    "summary_zh": "COMPOT 是一种面向 Transformer 模型的免训练压缩框架，利用基于正交字典与闭式更新的稀疏字典学习，实现了优于传统低秩方法的质量-压缩权衡。",
    "upvotes": 5
  },
  {
    "id": "2602.15156",
    "date": "2026-02-18",
    "title": "Panini: Continual Learning in Token Space via Structured Memory",
    "authors": "Shreyas Rajesh Pavan Holur Mehmet Yigit Turali Chenda Duan Vwani Roychowdhury",
    "abstract": "Panini enables efficient and accurate language model reasoning through a non-parametric continual learning framework that uses generative semantic workspaces to store and retrieve knowledge, achieving superior performance with reduced computational overhead.",
    "summary_en": "Panini enables efficient and accurate language model reasoning through a non-parametric continual learning framework that uses generative semantic workspaces to store and retrieve knowledge, achieving superior performance with reduced computational overhead.",
    "summary_zh": "Panini通过非参数化持续学习框架实现高效准确的语言模型推理，该框架利用生成式语义工作空间存储和检索知识，在降低计算开销的同时取得卓越性能。",
    "upvotes": 5
  },
  {
    "id": "2602.15449",
    "date": "2026-02-18",
    "title": "TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models",
    "authors": "Chansung Park Juyong Jiang Fan Wang Sayak Paul Jiasi Shen Jing Tang Jianguo Li",
    "abstract": "Reinforcement fine-tuning approach for code generation that adapts curriculum design based on model capability through a four-tier test suite structure. Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.",
    "summary_en": "Reinforcement fine-tuning approach for code generation that adapts curriculum design based on model capability through a four-tier test suite structure.",
    "summary_zh": "面向代码生成的强化微调方法，通过四层测试套件结构基于模型能力进行自适应课程设计。",
    "upvotes": 4
  },
  {
    "id": "2602.15620",
    "date": "2026-02-18",
    "title": "STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens",
    "authors": "Shiqi Liu Zeyu He Guojian Zhan Letian Tao Zhilong Zheng Jiang Wu Yinuo Wang Yang Guan Kehua Sheng Bo Zhang Keqiang Li Jingliang Duan Shengbo Eben Li",
    "abstract": "Research identifies spurious tokens as the cause of training instability in reinforcement learning fine-tuning of large language models and proposes a solution that selectively masks problematic gradient updates to improve reasoning performance. Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy . Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\\%, which we term spurious tokens . When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates . Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\\% over GRPO , 20- Entropy and JustRL .",
    "summary_en": "Research identifies spurious tokens as the cause of training instability in reinforcement learning fine-tuning of large language models and proposes a solution that selectively masks problematic gradient updates to improve reasoning performance.",
    "summary_zh": "研究发现，大语言模型强化学习微调中的训练不稳定性源于虚假 token，并提出通过选择性掩码问题梯度更新以提升推理性能的解决方案。",
    "upvotes": 3
  },
  {
    "id": "2602.15278",
    "date": "2026-02-18",
    "title": "Visual Persuasion: What Influences Decisions of Vision-Language Models?",
    "authors": "Manuel Cherep Pranav M R Pattie Maes Nikhil Singh",
    "abstract": "Visual-language models' decision-making preferences are studied through controlled image choice tasks with systematic input perturbations, revealing visual vulnerabilities and safety concerns. The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision function as a latent visual utility that can be inferred through revealed preference : choices between systematically edited images. Starting from common images, such as product photos, we propose methods for visual prompt optimization , adapting text optimization methods to iteratively propose and apply visually plausible modifications using an image generation model (such as in composition, lighting, or background). We then evaluate which edits increase selection probability. Through large-scale experiments on frontier VLMs, we demonstrate that optimized edits significantly shift choice probabilities in head-to-head comparisons. We develop an automatic interpretability pipeline to explain these preferences, identifying consistent visual themes that drive selection. We argue that this approach offers a practical and efficient way to surface visual vulnerabilities , safety concerns that might otherwise be discovered implicitly in the wild, supporting more proactive auditing and governance of image-based AI agents.",
    "summary_en": "Visual-language models' decision-making preferences are studied through controlled image choice tasks with systematic input perturbations, revealing visual vulnerabilities and safety concerns.",
    "summary_zh": "通过受控的图像选择任务与系统性输入扰动，研究视觉-语言模型的决策偏好，揭示其视觉漏洞与安全问题。",
    "upvotes": 3
  },
  {
    "id": "2602.15382",
    "date": "2026-02-18",
    "title": "The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems",
    "authors": "Xiaoze Liu Ruowang Zhang Weichen Yu Siheng Xiong Liu He Feijie Wu Hoin Jung Matt Fredrikson Xiaoqian Wang Jing Gao",
    "abstract": "A Vision Wormhole framework enables efficient, model-agnostic communication in multi-agent systems by using visual-language models to transfer reasoning states through a shared latent space, reducing computational overhead while maintaining reasoning accuracy. Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec , we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway , effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas",
    "summary_en": "A Vision Wormhole framework enables efficient, model-agnostic communication in multi-agent systems by using visual-language models to transfer reasoning states through a shared latent space, reducing computational overhead while maintaining reasoning accuracy.",
    "summary_zh": "Vision Wormhole框架通过视觉语言模型在共享隐空间中传递推理状态，实现了多智能体系统中高效且与模型无关的通信，在降低计算开销的同时保持推理准确性。",
    "upvotes": 2
  },
  {
    "id": "2602.15327",
    "date": "2026-02-18",
    "title": "Prescriptive Scaling Reveals the Evolution of Language Model Capabilities",
    "authors": "Hanlin Zhang Jikai Jin Vasilis Syrgkanis Sham Kakade",
    "abstract": "Large-scale observational analysis estimates capability boundaries and performance predictions for foundation models using quantile regression and evaluates temporal stability across tasks. For deploying foundation models, practitioners increasingly need prescriptive scaling laws : given a pre training compute budget , what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance , we estimate capability boundaries , high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization . We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budget s into reliable performance expectations and for monitoring when capability boundaries shift across time.",
    "summary_en": "Large-scale observational analysis estimates capability boundaries and performance predictions for foundation models using quantile regression and evaluates temporal stability across tasks.",
    "summary_zh": "大规模观察性分析使用分位数回归估计基础模型的能力边界和性能预测，并评估跨任务的时间稳定性。",
    "upvotes": 2
  },
  {
    "id": "2602.13964",
    "date": "2026-02-18",
    "title": "HLE-Verified: A Systematic Verification and Structured Revision of Humanity's Last Exam",
    "authors": "Weiqi Zhai Zhihai Wang Jinghang Wang Boyu Yang Xiaogang Li Xiang Xu Bohan Wang Peng Wang Xingzhe Wu Anfeng Li Qiyuan Feng Yuhao Zhou Shoulin Han Wenjie Luo Yiyuan Li Yaxuan Wang Ruixian Luo Guojie Lin Peiyao Xiao Chengliang Xu Ben Wang Zeyu Wang",
    "abstract": "HLE-Verified presents a validated and revised version of the HLE benchmark with improved reliability through expert review and model-based checks, demonstrating significant accuracy improvements in language model evaluations. Humanity's Last Exam (HLE) has become a widely used benchmark for evaluating frontier large language models on challenging, multi-domain questions. However, community-led analyses have raised concerns that HLE contains a non-trivial number of noisy items, which can bias evaluation results and distort cross-model comparisons. To address this challenge, we introduce HLE-Verified, a verified and revised version of HLE with a transparent verification protocol and fine-grained error taxonomy . Our construction follows a two-stage validation -and-repair workflow resulting in a certified benchmark . In Stage I, each item undergoes binary validation of the problem and final answer through domain-expert review and model-based cross-checks , yielding 641 verified items. In Stage II, flawed but fixable items are revised under strict constraints preserving the original evaluation intent, through dual independent expert repairs , model-assisted auditing , and final adjudication , resulting in 1,170 revised-and-certified items. The remaining 689 items are released as a documented uncertain set with explicit uncertainty sources and expertise tags for future refinement. We evaluate seven state-of-the-art language models on HLE and HLE-Verified, observing an average absolute accuracy gain of 7--10 percentage points on HLE-Verified. The improvement is particularly pronounced on items where the original problem statement and/or reference answer is erroneous, with gains of 30--40 percentage points. Our analyses further reveal a strong association between model confidence and the presence of errors in the problem statement or reference answer, supporting the effectiveness of our revisions. Overall, HLE-Verified improves HLE-style evaluations by reducing annotation noise and enabling more faithful measurement of model capabilities. Data is available at: https://github.com/SKYLENAGE-AI/HLE-Verified",
    "summary_en": "HLE-Verified presents a validated and revised version of the HLE benchmark with improved reliability through expert review and model-based checks, demonstrating significant accuracy improvements in language model evaluations.",
    "summary_zh": "HLE-Verified提出了HLE基准测试的验证与修订版本，通过专家审核和基于模型的检查提升了可靠性，在语言模型评估中展现出显著的准确率提升。",
    "upvotes": 2
  },
  {
    "id": "2602.12978",
    "date": "2026-02-18",
    "title": "Learning Native Continuation for Action Chunking Flow Policies",
    "authors": "Yufeng Liu Hang Yu Juntu Zhao Bocheng Li Di Zhang Mingzhu Li Wenxuan Wu Yingdong Hu Junyuan Xie Junliang Guo Dequan Wang Yang Gao",
    "abstract": "Legato improves action-chunked Vision Language Action models by using training-time continuation methods that ensure smooth trajectories and reduce multimodal switching during real-time execution. Action chunking enables Vision Language Action (VLA) models to run in real time, but naive chunked execution often exhibits discontinuities at chunk boundaries. Real-Time Chunking (RTC) alleviates this issue but is external to the policy, leading to spurious multimodal switching and trajectories that are not intrinsically smooth. We propose Legato, a training-time continuation method for action-chunked flow-based VLA policies. Specifically, Legato initializes denoising from a schedule-shaped mixture of known actions and noise, exposing the model to partial action information. Moreover, Legato reshapes the learned flow dynamics to ensure that the denoising process remains consistent between training and inference under per-step guidance. Legato further uses randomized schedule condition during training to support varying inference delays and achieve controllable smoothness. Empirically, Legato produces smoother trajectories and reduces spurious multimodal switching during execution, leading to less hesitation and shorter task completion time . Extensive real-world experiments show that Legato consistently outperforms RTC across five manipulation tasks, achieving approximately 10% improvements in both trajectory smoothness and task completion time .",
    "summary_en": "Legato improves action-chunked Vision Language Action models by using training-time continuation methods that ensure smooth trajectories and reduce multimodal switching during real-time execution.",
    "summary_zh": "Legato 利用训练时延续方法改进动作分块的视觉-语言-动作模型，确保轨迹平滑并减少实时执行中的多模态切换。",
    "upvotes": 2
  },
  {
    "id": "2602.11389",
    "date": "2026-02-18",
    "title": "Causal-JEPA: Learning World Models through Object-Level Latent Interventions",
    "authors": "Heejeong Nam Quentin Le Lidec Lucas Maes Yann LeCun Randall Balestriero",
    "abstract": "C-JEPA extends masked joint embedding prediction to object-centric representations, enabling robust relational understanding through object-level masking that induces causal inductive biases and improves reasoning and control tasks.",
    "summary_en": "C-JEPA extends masked joint embedding prediction to object-centric representations, enabling robust relational understanding through object-level masking that induces causal inductive biases and improves reasoning and control tasks.",
    "summary_zh": "C-JEPA将掩码联合嵌入预测扩展至以对象为中心的表征，通过引入因果归纳偏置的对象级掩码实现稳健的关系理解，并提升推理与控制任务的表现。",
    "upvotes": 2
  },
  {
    "id": "2602.09653",
    "date": "2026-02-18",
    "title": "ClinAlign: Scaling Healthcare Alignment from Clinician Preference",
    "authors": "Shiwei Lyu Xidong Wang Lei Liu Hao Zhu Chaohe Zhang Jian Wang Jinjie Gu Benyou Wang Yue Shen",
    "abstract": "A two-stage framework addresses alignment of large language models with clinician preferences through physician-verified examples and distilled clinical principles for improved medical reasoning. Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics , a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples : 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision . A 30B parameter model that activates only 3B parameters at inference trained with our framework achieves 33.4% on HealthBench-Hard , outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.",
    "summary_en": "A two-stage framework addresses alignment of large language models with clinician preferences through physician-verified examples and distilled clinical principles for improved medical reasoning.",
    "summary_zh": "一种两阶段框架通过医生验证的示例和蒸馏得到的临床原则，实现大语言模型与临床医生偏好的对齐，以改进医学推理。",
    "upvotes": 2
  },
  {
    "id": "2602.07854",
    "date": "2026-02-18",
    "title": "Geometry-Aware Rotary Position Embedding for Consistent Video World Model",
    "authors": "Chendong Xiang Jiajun Liu Jintao Zhang Xiao Yang Zhengwei Fang Shizun Wang Zijun Wang Yingtian Zou Hang Su Jun Zhu",
    "abstract": "ViewRope, a geometry-aware encoding method, enhances long-term consistency in predictive world models by injecting camera-ray directions into video transformer attention layers, addressing spatial persistence issues through relative ray geometry parameterization. Predictive world models that simulate future observations under explicit camera control are fundamental to interactive AI. Despite rapid advances, current systems lack spatial persistence: they fail to maintain stable scene structures over long trajectories, frequently hallucinating details when cameras revisit previously observed locations. We identify that this geometric drift stems from reliance on screen-space positional embeddings , which conflict with the projective geometry required for 3D consistency. We introduce ViewRope, a geometry-aware encoding that injects camera-ray directions directly into video transformer self-attention layers . By parameterizing attention with relative ray geometry rather than pixel locality, ViewRope provides a model-native inductive bias for retrieving 3D-consistent content across temporal gaps. We further propose Geometry-Aware Frame-Sparse Attention , which exploits these geometric cues to selectively attend to relevant historical frames, improving efficiency without sacrificing memory consistency. We also present ViewBench, a diagnostic suite measuring loop-closure fidelity and geometric drift . Our results demonstrate that ViewRope substantially improves long-term consistency while reducing computational costs.",
    "summary_en": "ViewRope, a geometry-aware encoding method, enhances long-term consistency in predictive world models by injecting camera-ray directions into video transformer attention layers, addressing spatial persistence issues through relative ray geometry parameterization.",
    "summary_zh": "ViewRope是一种几何感知编码方法，通过将相机射线方向注入视频Transformer的注意力层来增强预测性世界模型的长期一致性，并利用相对射线几何参数化解决空间持久性问题。",
    "upvotes": 2
  },
  {
    "id": "2602.14364",
    "date": "2026-02-18",
    "title": "A Trajectory-Based Safety Audit of Clawdbot (OpenClaw)",
    "authors": "Tianyu Chen Dongrui Liu Xia Hu Jingyi Yu Wenjie Wang",
    "abstract": "Clawdbot, a self-hosted AI agent with diverse tool capabilities, exhibits varying safety performance across different risk dimensions, particularly struggling with ambiguous or adversarial inputs despite consistent reliability in specified tasks. Clawdbot is a self-hosted, tool-using personal AI agent with a broad action space spanning local execution and web-mediated workflows, which raises heightened safety and security concerns under ambiguity and adversarial steering. We present a trajectory-centric evaluation of Clawdbot across six risk dimensions. Our test suite samples and lightly adapts scenarios from prior agent-safety benchmarks (including ATBench and LPS-Bench ) and supplements them with hand-designed cases tailored to Clawdbot's tool surface. We log complete interaction trajectories (messages, actions, tool-call arguments/outputs) and assess safety using both an automated trajectory judge ( AgentDoG-Qwen3-4B ) and human review. Across 34 canonical cases, we find a non-uniform safety profile: performance is generally consistent on reliability-focused tasks, while most failures arise under underspecified intent, open-ended goals, or benign-seeming jailbreak prompts, where minor misinterpretations can escalate into higher-impact tool actions. We supplemented the overall results with representative case studies and summarized the commonalities of these cases, analyzing the security vulnerabilities and typical failure modes that Clawdbot is prone to trigger in practice.",
    "summary_en": "Clawdbot, a self-hosted AI agent with diverse tool capabilities, exhibits varying safety performance across different risk dimensions, particularly struggling with ambiguous or adversarial inputs despite consistent reliability in specified tasks.",
    "summary_zh": "Clawdbot是一款具备多样化工具能力的自托管AI智能体，其在不同风险维度上的安全性能表现各异，尤其在处理模糊或对抗性输入时存在困难，尽管在指定任务中保持一致的可靠性。",
    "upvotes": 1
  },
  {
    "id": "2602.12235",
    "date": "2026-02-18",
    "title": "Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation",
    "authors": "Julia Belikova Danila Rozhevskii Dennis Svirin Konstantin Polev Alexander Panchenko",
    "abstract": "Soft compression architectures for long-context LLMs use query-aware probing classifiers to detect token overflow and mitigate compression-induced errors. Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens . Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define token overflow as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA , SQuADv2 , and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.",
    "summary_en": "Soft compression architectures for long-context LLMs use query-aware probing classifiers to detect token overflow and mitigate compression-induced errors.",
    "summary_zh": "面向长上下文LLM的软压缩架构使用查询感知探测分类器检测token溢出并缓解压缩引起的错误。",
    "upvotes": 1
  },
  {
    "id": "2602.10210",
    "date": "2026-02-18",
    "title": "How Much Reasoning Do Retrieval-Augmented Models Add beyond LLMs? A Benchmarking Framework for Multi-Hop Inference over Hybrid Knowledge",
    "authors": "Junhong Lin Bing Zhang Song Wang Ziyan Liu Dan Gutfreund Julian Shun Yada Zhu",
    "abstract": "HybridRAG-Bench evaluates retrieval-intensive multi-hop reasoning in large language models by combining unstructured text and structured knowledge graphs from recent scientific literature, providing a contamination-aware benchmark that distinguishes genuine retrieval and reasoning from parametric recall. Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up-to-date information and multi-hop reasoning . Augmenting LLMs with hybrid external knowledge , such as unstructured text and structured knowledge graphs , offers a promising alternative to costly continual pretraining. As such, reliable evaluation of their retrieval and reasoning capabilities becomes critical. However, many existing benchmarks increasingly overlap with LLM pretraining data, which means answers or supporting knowledge may already be encoded in model parameters, making it difficult to distinguish genuine retrieval and reasoning from parametric recall . We introduce HybridRAG-Bench, a framework for constructing benchmarks to evaluate retrieval-intensive, multi-hop reasoning over hybrid knowledge. HybridRAG-Bench automatically couples unstructured text and structured knowledge graph representations derived from recent scientific literature on arXiv, and generates knowledge-intensive question-answer pairs grounded in explicit reasoning paths. The framework supports flexible domain and time-frame selection, enabling contamination-aware and customizable evaluation as models and knowledge evolve. Experiments across three domains (artificial intelligence, governance and policy, and bioinformatics) demonstrate that HybridRAG-Bench rewards genuine retrieval and reasoning rather than parametric recall , offering a principled testbed for evaluating hybrid knowledge-augmented reasoning systems. We release our code and data at github.com/junhongmit/HybridRAG-Bench.",
    "summary_en": "HybridRAG-Bench evaluates retrieval-intensive multi-hop reasoning in large language models by combining unstructured text and structured knowledge graphs from recent scientific literature, providing a contamination-aware benchmark that distinguishes genuine retrieval and reasoning from parametric recall.",
    "summary_zh": "HybridRAG-Bench通过结合最新科学文献中的非结构化文本和结构化知识图谱，评估大语言模型的检索密集型多跳推理能力，提供了一个污染感知基准，用于区分真正的检索与推理和参数化记忆。",
    "upvotes": 1
  },
  {
    "id": "2602.10809",
    "date": "2026-02-17",
    "title": "DeepImageSearch: Benchmarking Multimodal Agents for Context-Aware Image Retrieval in Visual Histories",
    "authors": "Chenlong Deng Mengjie Deng Junjie Wu Dun Zeng Teng Wang Qingsong Xie Jiadeng Huang Shengjie Ma Changwang Zhang Zhaoxiang Wang Jun Wang Yutao Zhu Zhicheng Dou",
    "abstract": "DeepImageSearch presents an agentic approach to image retrieval that addresses limitations of traditional semantic matching by enabling multi-step reasoning over visual histories through a modular agent framework with dual-memory system. Existing multimodal retrieval systems excel at semantic matching but implicitly assume that query-image relevance can be measured in isolation. This paradigm overlooks the rich dependencies inherent in realistic visual streams , where information is distributed across temporal sequences rather than confined to single snapshots. To bridge this gap, we introduce DeepImageSearch, a novel agentic paradigm that reformulates image retrieval as an autonomous exploration task. Models must plan and perform multi-step reasoning over raw visual histories to locate targets based on implicit contextual cues . We construct DISBench , a challenging benchmark built on interconnected visual data. To address the scalability challenge of creating context-dependent queries, we propose a human-model collaborative pipeline that employs vision-language models to mine latent spatiotemporal associations , effectively offloading intensive context discovery before human verification. Furthermore, we build a robust baseline using a modular agent framework equipped with fine-grained tools and a dual-memory system for long-horizon navigation . Extensive experiments demonstrate that DISBench poses significant challenges to state-of-the-art models, highlighting the necessity of incorporating agentic reasoning into next-generation retrieval systems.",
    "summary_en": "DeepImageSearch presents an agentic approach to image retrieval that addresses limitations of traditional semantic matching by enabling multi-step reasoning over visual histories through a modular agent framework with dual-memory system.",
    "summary_zh": "DeepImageSearch 提出了一种用于图像检索的智能体方法，该方法通过配备双记忆系统的模块化智能体框架，实现对视觉历史的多步推理，从而解决传统语义匹配的局限性。",
    "upvotes": 24
  },
  {
    "id": "2602.14265",
    "date": "2026-02-17",
    "title": "STATe-of-Thoughts: Structured Action Templates for Tree-of-Thoughts",
    "authors": "Zachary Bamberger Till R. Saenger Gilad Morad Ofra Amir Brandon M. Stewart Amir Feder",
    "abstract": "STATe presents an interpretable inference-time compute method that uses discrete textual interventions to generate diverse, high-quality, and explainable text by searching over reasoning patterns rather than relying on stochastic sampling.",
    "summary_en": "STATe presents an interpretable inference-time compute method that uses discrete textual interventions to generate diverse, high-quality, and explainable text by searching over reasoning patterns rather than relying on stochastic sampling.",
    "summary_zh": "STATe 提出了一种可解释的推理时计算方法，利用离散文本干预，通过对推理模式的搜索而非随机采样，生成多样化、高质量且可解释的文本。",
    "upvotes": 18
  },
  {
    "id": "2602.14492",
    "date": "2026-02-17",
    "title": "Query as Anchor: Scenario-Adaptive User Representation via Large Language Model",
    "authors": "Jiahao Yuan Yike Xu Jinyong Wen Baokun Wang Ziyi Gao Xiaotong Lin Yun Liu Xing Fu Yu Cheng Yongchao Liu Weiqiang Wang Zhongle Xie",
    "abstract": "A novel framework called Query-as-Anchor is introduced that transforms user modeling from static encoding to dynamic, query-aware synthesis using large language models with specialized architectures and training methods. Industrial-scale user representation learning requires balancing robust universality with acute task-sensitivity. However, existing paradigms primarily yield static, task-agnostic embeddings that struggle to reconcile the divergent requirements of downstream scenarios within unified vector spaces. Furthermore, heterogeneous multi-source data introduces inherent noise and modality conflicts, degrading representation. We propose Query-as-Anchor, a framework shifting user modeling from static encoding to dynamic, query-aware synthesis. To empower Large Language Models (LLMs) with deep user understanding, we first construct UserU , an industrial-scale pre-training dataset that aligns multi-modal behavioral sequences with user understanding semantics, and our Q-Anchor Embedding architecture integrates hierarchical coarse-to-fine encoders into dual-tower LLMs via joint contrastive-autoregressive optimization for query-aware user representation. To bridge the gap between general pre-training and specialized business logic, we further introduce Cluster-based Soft Prompt Tuning to enforce discriminative latent structures, effectively aligning model attention with scenario-specific modalities. For deployment, anchoring queries at sequence termini enables KV-cache-accelerated inference with negligible incremental latency. Evaluations on 10 Alipay industrial benchmarks show consistent SOTA performance, strong scalability, and efficient deployment. Large-scale online A/B testing in Alipay's production system across two real-world scenarios further validates its practical effectiveness. Our code is prepared for public release and will be available at: https://github.com/JhCircle/Q-Anchor.",
    "summary_en": "A novel framework called Query-as-Anchor is introduced that transforms user modeling from static encoding to dynamic, query-aware synthesis using large language models with specialized architectures and training methods.",
    "summary_zh": "本文提出了一种名为 Query-as-Anchor 的新框架，利用具有专门架构和训练方法的大语言模型，将用户建模从静态编码转变为动态、查询感知的合成。",
    "upvotes": 14
  },
  {
    "id": "2602.13949",
    "date": "2026-02-17",
    "title": "Experiential Reinforcement Learning",
    "authors": "Taiwei Shi Sihao Chen Bowen Jiang Linxin Song Longqi Yang Jieyu Zhao",
    "abstract": "Experiential Reinforcement Learning introduces an explicit experience-reflection-consolidation loop that improves learning efficiency and performance in sparse-reward environments by enabling structured behavioral revision without additional inference costs. Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should translate into behavioral changes for future iterations. We introduce Experiential Reinforcement Learning (ERL), a training paradigm that embeds an explicit experience-reflection-consolidation loop into the reinforcement learning process. Given a task, the model generates an initial attempt, receives environmental feedback , and produces a reflection that guides a refined second attempt, whose success is reinforced and internalized into the base policy. This process converts feedback into structured behavioral revision , improving exploration and stabilizing optimization while preserving gains at deployment without additional inference cost. Across sparse-reward control environments and agentic reasoning benchmarks, ERL consistently improves learning efficiency and final performance over strong reinforcement learning baselines, achieving gains of up to +81% in complex multi-step environments and up to +11% in tool-using reasoning tasks. These results suggest that integrating explicit self-reflection into policy training provides a practical mechanism for transforming feedback into durable behavioral improvement.",
    "summary_en": "Experiential Reinforcement Learning introduces an explicit experience-reflection-consolidation loop that improves learning efficiency and performance in sparse-reward environments by enabling structured behavioral revision without additional inference costs.",
    "summary_zh": "Experiential Reinforcement Learning 引入了一种显式的 experience-reflection-consolidation 循环，通过在不增加额外推理成本的情况下实现结构化行为修正，提升了稀疏奖励环境中的学习效率与性能。",
    "upvotes": 14
  },
  {
    "id": "2602.11574",
    "date": "2026-02-17",
    "title": "Learning to Configure Agentic AI Systems",
    "authors": "Aditya Taparia Som Sagar Ransalu Senanayake",
    "abstract": "Learning per-query agent configurations through reinforcement learning improves task accuracy while reducing computational costs compared to fixed templates and hand-tuned heuristics. Configuring LLM-based agent systems involves choosing workflows, tools, token budget s, and prompts from a large combinatorial design space, and is typically handled today by fixed large templates or hand-tuned heuristics. This leads to brittle behavior and unnecessary compute, since the same cumbersome configuration is often applied to both easy and hard input queries. We formulate agent configuration as a query-wise decision problem and introduce ARC (Agentic Resource & Configuration learner), which learns a light-weight hierarchical policy using reinforcement learning to dynamically tailor these configurations. Across multiple benchmarks spanning reasoning and tool-augmented question answering , the learned policy consistently outperforms strong hand-designed and other baselines, achieving up to 25% higher task accuracy while also reducing token and runtime costs. These results demonstrate that learning per-query agent configuration s is a powerful alternative to \"one size fits all\" designs.",
    "summary_en": "Learning per-query agent configurations through reinforcement learning improves task accuracy while reducing computational costs compared to fixed templates and hand-tuned heuristics.",
    "summary_zh": "通过强化学习习得逐查询智能体配置，相较于固定模板与手工调优启发式方法，可在提升任务准确率的同时降低计算成本。",
    "upvotes": 14
  },
  {
    "id": "2602.14699",
    "date": "2026-02-17",
    "title": "Qute: Towards Quantum-Native Database",
    "authors": "Muzhi Chen Xuanhe Zhou Wei Zhou Bangrui Xu Surui Tang Guoliang Li Bingsheng He Yeye He Yitong Song Fan Wu",
    "abstract": "This paper envisions a quantum database (Qute) that treats quantum computation as a first-class execution option. Unlike prior simulation-based methods that either run quantum algorithms on classical machines or adapt existing databases for quantum simulation, Qute instead (i) compiles an extended form of SQL into gate-efficient quantum circuits, (ii) employs a hybrid optimizer to dynamically select between quantum and classical execution plans, (iii) introduces selective quantum indexing, and (iv) designs fidelity-preserving storage to mitigate current qubit constraints. We also present a three-stage evolution roadmap toward quantum-native database. Finally, by deploying Qute on a real quantum processor (origin_wukong), we show that it outperforms a classical baseline at scale, and we release an open-source prototype at https://github.com/weAIDB/Qute.",
    "summary_en": "This paper presents Qute, a quantum database that treats quantum computation as a first-class execution option. Qute compiles extended SQL into gate-efficient quantum circuits and employs a hybrid optimizer, selective quantum indexing, and fidelity-preserving storage to mitigate qubit constraints. Deployed on the origin_wukong quantum processor, Qute outperforms classical baselines at scale, and the authors release an open-source prototype.",
    "summary_zh": "本文提出Qute，一种将量子计算视为一级执行选项的量子数据库。Qute将扩展SQL编译为门高效的量子线路，并采用混合优化器、选择性量子索引和保真度保持存储来缓解量子比特约束。部署于origin_wukong量子处理器后，Qute在大规模下性能优于经典基线，且作者发布了开源原型。",
    "upvotes": 13
  },
  {
    "id": "2602.14234",
    "date": "2026-02-17",
    "title": "REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents",
    "authors": "Zheng Chu Xiao Wang Jack Hong Huiming Fan Yuqi Huang Yue Yang Guohai Xu Chenxiao Zhao Cheng Xiang Shengchao Hu Dongdong Kuang Ming Liu Bing Qin Xing Yu",
    "abstract": "REDSearcher presents a unified framework for optimizing search agents through improved task synthesis, tool-augmented queries, midtraining capability enhancement, and simulated environments to address challenges in long-horizon search tasks. Large language models are transitioning from generalpurpose knowledge engines to realworld problem solvers, yet optimizing them for deep search tasks remains challenging. The central bottleneck lies in the extreme sparsity of highquality search trajectories and reward signals, arising from the difficulty of scalable longhorizon task construction and the high cost of interactionheavy rollouts involving external tool calls. To address these challenges, we propose REDSearcher, a unified framework that codesigns complex task synthesis , midtraining , and posttraining for scalable searchagent optimization. Specifically, REDSearcher introduces the following improvements: (1) We frame task synthesis as a dualconstrained optimization, where task difficulty is precisely governed by graph topology and evidence dispersion , allowing scalable generation of complex, highquality tasks. (2) We introduce toolaugmented queries to encourage proactive tool use rather than passive recall.(3) During midtraining , we strengthen core atomic capabilities knowledge , planning , and function calling substantially reducing the cost of collecting highquality trajectories for downstream training. (4) We build a local simulated environment that enables rapid, lowcost algorithmic iteration for reinforcement learning experiments. Across both textonly and multimodal searchagent benchmarks, our approach achieves stateoftheart performance. To facilitate future research on longhorizon search agents , we will release 10K highquality complex text search trajectories, 5K multimodal trajectories and 1K text RL query set, and together with code and model checkpoints.",
    "summary_en": "REDSearcher presents a unified framework for optimizing search agents through improved task synthesis, tool-augmented queries, midtraining capability enhancement, and simulated environments to address challenges in long-horizon search tasks.",
    "summary_zh": "REDSearcher 提出了一个统一框架，通过改进的任务合成、工具增强查询、中期训练能力增强和模拟环境来优化搜索智能体，以应对长程搜索任务中的挑战。",
    "upvotes": 13
  },
  {
    "id": "2602.14367",
    "date": "2026-02-17",
    "title": "InnoEval: On Research Idea Evaluation as a Knowledge-Grounded, Multi-Perspective Reasoning Problem",
    "authors": "Shuofei Qiao Yunxiang Wei Xuehai Wang Bin Wu Boyang Xue Ningyu Zhang Hossein A. Rahmani Yanshan Wang Qiang Zhang Keyan Ding Jeff Z. Pan Huajun Chen Emine Yilmaz",
    "abstract": "InnoEval is a deep innovation evaluation framework that emulates human-level idea assessment through knowledge-grounded, multi-perspective reasoning with heterogeneous deep knowledge search and multi-dimensional decoupled evaluation. The rapid evolution of Large Language Models has catalyzed a surge in scientific idea production, yet this leap has not been accompanied by a matching advance in idea evaluation . The fundamental nature of scientific evaluation needs knowledgeable grounding, collective deliberation, and multi-criteria decision-making. However, existing idea evaluation methods often suffer from narrow knowledge horizons, flattened evaluation dimensions, and the inherent bias in LLM-as-a-Judge. To address these, we regard idea evaluation as a knowledge-grounded, multi-perspective reasoning problem and introduce InnoEval, a deep innovation evaluation framework designed to emulate human-level idea assessment. We apply a heterogeneous deep knowledge search engine that retrieves and grounds dynamic evidence from diverse online sources. We further achieve review consensus with an innovation review board containing reviewers with distinct academic backgrounds, enabling a multi-dimensional decoupled evaluation across multiple metrics. We construct comprehensive datasets derived from authoritative peer-reviewed submissions to benchmark InnoEval. Experiments demonstrate that InnoEval can consistently outperform baselines in point-wise, pair-wise, and group-wise evaluation tasks, exhibiting judgment patterns and consensus highly aligned with human experts.",
    "summary_en": "InnoEval is a deep innovation evaluation framework that emulates human-level idea assessment through knowledge-grounded, multi-perspective reasoning with heterogeneous deep knowledge search and multi-dimensional decoupled evaluation.",
    "summary_zh": "InnoEval 是一种深度创新评估框架，通过基于知识的多视角推理、异构深度知识检索与多维解耦评估，模拟人类水平的创意评估。",
    "upvotes": 12
  },
  {
    "id": "2602.13294",
    "date": "2026-02-17",
    "title": "VisPhyWorld: Probing Physical Reasoning via Code-Driven Video Reconstruction",
    "authors": "Jiarong Liang Max Ku Ka-Hei Hui Ping Nie Wenhu Chen",
    "abstract": "VisPhyWorld framework evaluates physical reasoning in MLLMs by requiring executable simulator code generation from visual observations, separating physical reasoning from rendering and enabling inspectable, falsifiable world representations. Evaluating whether Multimodal Large Language Models (MLLMs) genuinely reason about physical dynamics remains challenging. Most existing benchmarks rely on recognition-style protocols such as Visual Question Answering (VQA) and Violation of Expectation (VoE), which can often be answered without committing to an explicit, testable physical hypothesis. We propose VisPhyWorld, an execution-based framework that evaluates physical reasoning by requiring models to generate executable simulator code from visual observations. By producing runnable code, the inferred world representation is directly inspectable, editable, and falsifiable. This separates physical reasoning from rendering. Building on this framework, we introduce VisPhyBench, comprising 209 evaluation scenes derived from 108 physical templates and a systematic protocol that evaluates how well models reconstruct appearance and reproduce physically plausible motion. Our pipeline produces valid reconstructed videos in 97.7% on the benchmark. Experiments show that while state-of-the-art MLLMs achieve strong semantic scene understanding , they struggle to accurately infer physical parameters and to simulate consistent physical dynamics .",
    "summary_en": "VisPhyWorld framework evaluates physical reasoning in MLLMs by requiring executable simulator code generation from visual observations, separating physical reasoning from rendering and enabling inspectable, falsifiable world representations.",
    "summary_zh": "VisPhyWorld框架通过要求基于视觉观察生成可执行的模拟器代码来评估MLLM的物理推理能力，将物理推理与渲染分离，并实现可检查、可证伪的世界表征。",
    "upvotes": 12
  },
  {
    "id": "2602.14041",
    "date": "2026-02-17",
    "title": "BitDance: Scaling Autoregressive Generative Models with Binary Tokens",
    "authors": "Yuang Ai Jiaming Han Shaobin Zhuang Weijia Mao Xuefeng Hu Ziyan Yang Zhenheng Yang Huaibo Huang Xiangyu Yue Hao Chen",
    "abstract": "BitDance is a scalable autoregressive image generator that uses binary visual tokens and diffusion-based methods to achieve efficient high-resolution image generation with improved speed and performance. We present BitDance, a scalable autoregressive (AR) image generator that predicts binary visual tokens instead of codebook indices. With high-entropy binary latents , BitDance lets each token represent up to 2^{256} states, yielding a compact yet highly expressive discrete representation. Sampling from such a huge token space is difficult with standard classification. To resolve this, BitDance uses a binary diffusion head : instead of predicting an index with softmax, it employs continuous-space diffusion to generate the binary tokens. Furthermore, we propose next-patch diffusion , a new decoding method that predicts multiple tokens in parallel with high accuracy, greatly speeding up inference. On ImageNet 256x256, BitDance achieves an FID of 1.24, the best among AR models. With next-patch diffusion , BitDance beats state-of-the-art parallel AR models that use 1.4B parameters, while using 5.4x fewer parameters (260M) and achieving 8.7x speedup. For text-to-image generation , BitDance trains on large-scale multimodal tokens and generates high-resolution, photorealistic images efficiently, showing strong performance and favorable scaling. When generating 1024x1024 images, BitDance achieves a speedup of over 30x compared to prior AR models. We release code and models to facilitate further research on AR foundation models. Code and models are available at: https://github.com/shallowdream204/BitDance.",
    "summary_en": "BitDance is a scalable autoregressive image generator that uses binary visual tokens and diffusion-based methods to achieve efficient high-resolution image generation with improved speed and performance.",
    "summary_zh": "BitDance是一种可扩展的自回归图像生成器，利用二进制视觉令牌和基于扩散的方法，实现高效的高分辨率图像生成，并在速度和性能方面均有提升。",
    "upvotes": 10
  },
  {
    "id": "2602.07824",
    "date": "2026-02-17",
    "title": "Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training",
    "authors": "Yiwei Qin Zhen Huang Tiantian Mi Weiye Si Chenyang Zhou Qipeng Guo Siyuan Feng Pengfei Liu",
    "abstract": "Data Darwinism presents a systematic framework for data-model co-evolution through a ten-level taxonomy, demonstrating that advanced processing techniques significantly improve foundation model performance on scientific text. Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution : advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 ( Generative Refinement ) and L5 ( Cognitive Completion ) using frontier LLMs to explicate reasoning and terminology. To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training , Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks . Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.",
    "summary_en": "Data Darwinism presents a systematic framework for data-model co-evolution through a ten-level taxonomy, demonstrating that advanced processing techniques significantly improve foundation model performance on scientific text.",
    "summary_zh": "Data Darwinism 提出了一个系统性的数据-模型协同进化框架，该框架通过十层分类体系，证明先进处理技术能够显著提升基础模型在科学文本上的性能。",
    "upvotes": 10
  },
  {
    "id": "2602.14178",
    "date": "2026-02-17",
    "title": "UniWeTok: An Unified Binary Tokenizer with Codebook Size 2^{128} for Unified Multimodal Large Language Model",
    "authors": "Shaobin Zhuang Yuang Ai Jiaming Han Weijia Mao Xiaohui Li Fangyikang Wang Xiao Wang Yan Li Shanchuan Lin Kun Xu Zhenheng Yang Huaibo Huang Xiangyu Yue Hao Chen Yali Wang",
    "abstract": "UniWeTok introduces a unified discrete tokenizer with a massive binary codebook and novel training techniques to achieve superior performance in image generation and multimodal tasks while reducing computational requirements. Unified Multimodal Large Language Models (MLLMs) require a visual representation that simultaneously supports high-fidelity reconstruction, complex semantic extraction, and generative suitability. However, existing visual tokenizers typically struggle to satisfy these conflicting objectives within a single framework. In this paper, we introduce UniWeTok, a unified discrete tokenizer designed to bridge this gap using a massive binary codebook (2^{128}). For training framework, we introduce Pre-Post Distillation and a Generative-Aware Prior to enhance the semantic extraction and generative prior of the discrete tokens. In terms of model architecture, we propose a convolution-attention hybrid architecture with the SigLu activation function . SigLu activation not only bounds the encoder output and stabilizes the semantic distillation process but also effectively addresses the optimization conflict between token entropy loss and commitment loss . We further propose a three-stage training framework designed to enhance UniWeTok's adaptability cross various image resolutions and perception-sensitive scenarios, such as those involving human faces and textual content. On ImageNet, UniWeTok achieves state-of-the-art image generation performance (FID: UniWeTok 1.38 vs. REPA 1.42) while requiring a remarkably low training compute (Training Tokens: UniWeTok 33B vs. REPA 262B). On general-domain, UniWeTok demonstrates highly competitive capabilities across a broad range of tasks, including multimodal understanding , image generation ( DPG Score : UniWeTok 86.63 vs. FLUX.1 [Dev] 83.84), and editing ( GEdit Overall Score : UniWeTok 5.09 vs. OmniGen 5.06). We release code and models to facilitate community exploration of unified tokenizer and MLLM.",
    "summary_en": "UniWeTok introduces a unified discrete tokenizer with a massive binary codebook and novel training techniques to achieve superior performance in image generation and multimodal tasks while reducing computational requirements.",
    "summary_zh": "UniWeTok引入了一种统一离散tokenizer，其采用大规模二进制码本和新颖的训练技术，在图像生成和多模态任务中实现了卓越性能，同时降低了计算需求。",
    "upvotes": 6
  },
  {
    "id": "2602.13367",
    "date": "2026-02-17",
    "title": "Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts",
    "authors": "Chen Yang Guangyue Peng Jiaying Zhu Ran Le Ruixiang Feng Tao Zhang Xiyun Xu Yang Song Yiming Jia Yuntao Wen Yunzhi Xu Zekai Wang Zhenwei An Zhicong Sun Zongchao Chen",
    "abstract": "Nanbeige4.1-3B is a 3B-parameter unified language model that demonstrates superior performance in agentic behavior, code generation, and reasoning compared to larger models through advanced reward modeling and training techniques. We present Nanbeige4.1-3B, a unified generalist language model that simultaneously achieves strong agentic behavior , code generation , and general reasoning with only 3B parameters. To the best of our knowledge, it is the first open-source small language model (SLM) to achieve such versatility in a single model. To improve reasoning and preference alignment, we combine point-wise and pair-wise reward modeling , ensuring high-quality, human-aligned responses . For code generation , we design complexity-aware rewards in Reinforcement Learning , optimizing both correctness and efficiency. In deep search , we perform complex data synthesis and incorporate turn-level supervision during training. This enables stable long-horizon tool interactions, allowing Nanbeige4.1-3B to reliably execute up to 600 tool-call turns for complex problem-solving. Extensive experimental results show that Nanbeige4.1-3B significantly outperforms prior models of similar scale, such as Nanbeige4-3B-2511 and Qwen3-4B, even achieving superior performance compared to much larger models, such as Qwen3-30B-A3B. Our results demonstrate that small models can achieve both broad competence and strong specialization simultaneously, redefining the potential of 3B parameter models.",
    "summary_en": "Nanbeige4.1-3B is a 3B-parameter unified language model that demonstrates superior performance in agentic behavior, code generation, and reasoning compared to larger models through advanced reward modeling and training techniques.",
    "summary_zh": "Nanbeige4.1-3B是一个3B参数的统一语言模型，通过先进的奖励建模和训练技术，在agentic行为、代码生成和推理方面展现出相较于更大模型更优的性能。",
    "upvotes": 6
  },
  {
    "id": "2602.13823",
    "date": "2026-02-17",
    "title": "Embed-RL: Reinforcement Learning for Reasoning-Driven Multimodal Embeddings",
    "authors": "Haonan Jiang Yuji Wang Yongjie Zhu Xin Lu Wenyu Qin Meng Wang Pengfei Wan Yansong Tang",
    "abstract": "A reasoning-driven universal multimodal embedding framework integrates embedder-guided reinforcement learning with traceability chain-of-thought to enhance cross-modal semantic consistency and retrieval performance. Leveraging Multimodal Large Language Models (MLLMs) has become pivotal for advancing Universal Multimodal Embeddings (UME) in addressing diverse cross-modal tasks . Recent studies demonstrate that incorporating generative Chain-of-Thought (CoT) reasoning can substantially enhance task-specific representations compared to discriminative methods. However, the generated reasoning CoTs of existing generative embedding methods are limited to the textual analysis of queries and are irrelevant to the retrieval of the targets. To address these limitations, we propose a reasoning-driven UME framework that integrates Embedder-Guided Reinforcement Learning (EG-RL) to optimize the Reasoner to produce evidential Traceability CoT (T-CoT). Our key contributions are threefold: (1) We design an EG-RL framework where the Embedder provides explicit supervision to the Reasoner , ensuring the generated CoT traces are aligned with embedding tasks. (2) We introduce T-CoT, which extracts critical multimodal cues to focus on retrieval-relevant elements and provides multimodal inputs for the Embedder. (3) With limited computational resources, our framework outperforms the pioneering embedding model on both MMEB-V2 and UVRB benchmarks. The integration of multimodal evidence in structured reasoning, paired with retrieval-oriented alignment , effectively strengthens cross-modal semantic consistency and boosts the fine-grained matching capability of the model as well as the generalization across complex scenarios. Our work demonstrates that targeted reasoning optimization can significantly improve multimodal embedding quality, providing a practical and efficient solution for reasoning-driven UME development.",
    "summary_en": "A reasoning-driven universal multimodal embedding framework integrates embedder-guided reinforcement learning with traceability chain-of-thought to enhance cross-modal semantic consistency and retrieval performance.",
    "summary_zh": "一种推理驱动的通用多模态 embedding 框架整合了 embedder-guided 强化学习与可追溯 chain-of-thought，以增强跨模态语义一致性和检索性能。",
    "upvotes": 5
  },
  {
    "id": "2602.12876",
    "date": "2026-02-17",
    "title": "BrowseComp-V^3: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents",
    "authors": "Huanyao Zhang Jiepeng Zhou Bo Li Bowen Zhou Yanzhe Dan Haishan Lu Zhiyong Cao Jiaoyang Chen Yuqian Han Zinan Sheng Zhengwei Tao Hao Liang Jialong Wu Yang Shi Yuanpeng He Jiaye Lin Qintong Zhang Guochen Yan Runhao Zhao Zhengpin Li Xiaohan Yu Lang Mei",
    "abstract": "A new benchmark called BrowseComp-V3 challenges multimodal large language models with complex, multi-hop reasoning tasks requiring deep search across text and visual modalities, revealing significant gaps in current capabilities. Multimodal large language models (MLLMs), equipped with increasingly advanced planning and tool-use capabilities, are evolving into autonomous agents capable of performing multimodal web browsing and deep search in open-world environments. However, existing benchmarks for multimodal browsing remain limited in task complexity, evidence accessibility, and evaluation granularity, hindering comprehensive and reproducible assessments of deep search capabilities. To address these limitations, we introduce BrowseComp-V^3, a novel benchmark consisting of 300 carefully curated and challenging questions spanning diverse domains. The benchmark emphasizes deep, multi-level, and cross-modal multi-hop reasoning, where critical evidence is interleaved across textual and visual modalities within and across web pages. All supporting evidence is strictly required to be publicly searchable, ensuring fairness and reproducibility. Beyond final-answer accuracy, we incorporate an expert-validated, subgoal-driven process evaluation mechanism that enables fine-grained analysis of intermediate reasoning behaviors and systematic characterization of capability boundaries. In addition, we propose OmniSeeker, a unified multimodal browsing agent framework integrating diverse web search and visual perception tools. Comprehensive experiments demonstrate that even state-of-the-art models achieve only 36% accuracy on our benchmark, revealing critical bottlenecks in multimodal information integration and fine-grained perception . Our results highlight a fundamental gap between current model capabilities and robust multimodal deep search in real-world settings.",
    "summary_en": "A new benchmark called BrowseComp-V3 challenges multimodal large language models with complex, multi-hop reasoning tasks requiring deep search across text and visual modalities, revealing significant gaps in current capabilities.",
    "summary_zh": "一项名为 BrowseComp-V3 的新基准通过需要在文本和视觉模态间进行深度搜索的复杂多跳推理任务挑战多模态大语言模型，揭示了当前能力的显著差距。",
    "upvotes": 5
  },
  {
    "id": "2602.13195",
    "date": "2026-02-17",
    "title": "Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision",
    "authors": "Aadarsh Sahoo Georgia Gkioxari",
    "abstract": "Conversational image segmentation addresses functional and physical reasoning tasks by introducing a new benchmark and model that combines segmentation priors with language understanding. Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., \"left-most apple\") and overlooks functional and physical reasoning (e.g., \"where can I safely store the knife?\"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding , and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/",
    "summary_en": "Conversational image segmentation addresses functional and physical reasoning tasks by introducing a new benchmark and model that combines segmentation priors with language understanding.",
    "summary_zh": "对话式图像分割通过引入结合分割先验与语言理解的新基准和模型，解决功能性和物理性推理任务。",
    "upvotes": 4
  },
  {
    "id": "2602.14147",
    "date": "2026-02-17",
    "title": "LaViDa-R1: Advancing Reasoning for Unified Multimodal Diffusion Language Models",
    "authors": "Shufan Li Yuchen Zhu Jiuxiang Gu Kangning Liu Zhe Lin Yongxin Chen Molei Tao Aditya Grover Jason Kuen",
    "abstract": "LaViDa-R1 is a multimodal reasoning diffusion language model that unifies supervised fine-tuning and multi-task reinforcement learning with novel training techniques for enhanced performance across visual reasoning and generation tasks. Diffusion language models (dLLMs) recently emerged as a promising alternative to auto-regressive LLMs. The latest works further extended it to multimodal understanding and generation tasks. In this work, we propose LaViDa-R1, a multimodal, general-purpose reasoning dLLM. Unlike existing works that build reasoning dLLMs through task-specific reinforcement learning, LaViDa-R1 incorporates diverse multimodal understanding and generation tasks in a unified manner. In particular, LaViDa-R1 is built with a novel unified post-training framework that seamlessly integrates supervised finetuning (SFT) and multi-task reinforcement learning (RL). It employs several novel training techniques, including answer-forcing , tree search , and complementary likelihood estimation , to enhance effectiveness and scalability. Extensive experiments demonstrate LaViDa-R1's strong performance on a wide range of multimodal tasks, including visual math reasoning , reason-intensive grounding , and image editing .",
    "summary_en": "LaViDa-R1 is a multimodal reasoning diffusion language model that unifies supervised fine-tuning and multi-task reinforcement learning with novel training techniques for enhanced performance across visual reasoning and generation tasks.",
    "summary_zh": "LaViDa-R1 是一种多模态推理扩散语言模型，它通过新颖的训练技术统一了监督微调与多任务强化学习，从而在视觉推理和生成任务中实现了性能提升。",
    "upvotes": 3
  },
  {
    "id": "2602.13344",
    "date": "2026-02-17",
    "title": "FireRed-Image-Edit-1.0 Techinical Report",
    "authors": "Super Intelligence Team Changhao Qiao Chao Hui Chen Li Cunzheng Wang Dejia Song Jiale Zhang Jing Li Qiang Xiang Runqi Wang Shuang Sun Wei Zhu Xu Tang Yao Hu Yibo Chen Yuhao Huang Yuxuan Duan Zhiyi Chen Ziyuan Guo",
    "abstract": "FireRed-Image-Edit uses a diffusion transformer with optimized data curation and training methods to achieve state-of-the-art performance in instruction-based image editing, supported by a comprehensive benchmark and novel techniques for data efficiency and optimization stability. We present FireRed-Image-Edit, a diffusion transformer for instruction-based image editing that achieves state-of-the-art performance through systematic optimization of data curation , training methodology , and evaluation design . We construct a 1.6B-sample training corpus, comprising 900M text-to-image and 700M image editing pairs from diverse sources. After rigorous cleaning, stratification, auto-labeling, and two-stage filtering, we retain over 100M high-quality samples balanced between generation and editing, ensuring strong semantic coverage and instruction alignment. Our multi-stage training pipeline progressively builds editing capability via pre-training, supervised fine-tuning, and reinforcement learning. To improve data efficiency, we introduce a Multi-Condition Aware Bucket Sampler for variable-resolution batching and Stochastic Instruction Alignment with dynamic prompt re-indexing. To stabilize optimization and enhance controllability, we propose Asymmetric Gradient Optimization for DPO , DiffusionNFT with layout-aware OCR rewards for text editing, and a differentiable Consistency Loss for identity preservation. We further establish REDEdit-Bench , a comprehensive benchmark spanning 15 editing categories, including newly introduced beautification and low-level enhancement tasks. Extensive experiments on REDEdit-Bench and public benchmarks ( ImgEdit and GEdit ) demonstrate competitive or superior performance against both open-source and proprietary systems. We release code, models, and the benchmark suite to support future research.",
    "summary_en": "FireRed-Image-Edit uses a diffusion transformer with optimized data curation and training methods to achieve state-of-the-art performance in instruction-based image editing, supported by a comprehensive benchmark and novel techniques for data efficiency and optimization stability.",
    "summary_zh": "FireRed-Image-Edit 采用 diffusion transformer，结合优化的数据整理与训练方法，在 instruction-based image editing 中实现了 SOTA 性能，并辅以 comprehensive benchmark 以及提升数据效率和优化稳定性的新技术。",
    "upvotes": 3
  },
  {
    "id": "2602.14721",
    "date": "2026-02-17",
    "title": "WebWorld: A Large-Scale World Model for Web Agent Training",
    "authors": "Zikai Xiao Jianhong Tu Chuhang Zou Yuxin Zuo Zhi Li Peng Wang Bowen Yu Fei Huang Junyang Lin Zuozhu Liu",
    "abstract": "Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce WebWorld series, the first open- web simulator trained at scale. While existing simulators are restricted to closed environments with thousands of trajectories, WebWorld leverages a scalable data pipeline to train on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps. For intrinsic evaluation , we introduce WebWorld-Bench with dual metrics spanning nine dimensions, where WebWorld achieves simulation performance comparable to Gemini-3-Pro. For extrinsic evaluation , Qwen3-14B trained on WebWorld-synthesized trajectories improves by +9.2\\% on WebArena, reaching performance comparable to GPT-4o. WebWorld enables effective inference-time search , outperforming GPT-5 as a world model . Beyond web simulation, WebWorld exhibits cross-domain generalization to code, GUI, and game environments, providing a replicable recipe for world model construction.",
    "summary_en": "Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce WebWorld series, the first open- web simulator trained at scale. While existing simulators are restricted to closed environments with thousands of trajectories, WebWorld leverages a scalable data pipeline to train on 1M+ open-web interactions, supporting reasoning, multi-format data, and long-horizon simulations of 30+ steps. For intrinsic evaluation , we introduce WebWorld-Bench with dual metrics spanning nine dimensions, where WebWorld achieves simulation performance comparable to Gemini-3-Pro. For extrinsic evaluation , Qwen3-14B trained on WebWorld-synthesized trajectories improves by +9.2\\% on WebArena, reaching performance comparable to GPT-4o. WebWorld enables effective inference-time search , outperforming GPT-5 as a world model . Beyond web simulation, WebWorld exhibits cross-domain generalization to code, GUI, and game environments, providing a replicable recipe for world model construction.",
    "summary_zh": "网页智能体需要大量轨迹来实现泛化，但真实世界训练受限于网络延迟、速率限制和安全风险。我们推出 WebWorld 系列，首个大规模训练的开放网页模拟器。现有模拟器局限于包含数千条轨迹的封闭环境，而 WebWorld 利用可扩展的数据流水线，基于 100 万+ 开放网页交互进行训练，支持推理、多格式数据以及 30+ 步的长程模拟。对于内在评估，我们引入 WebWorld-Bench，其双重指标涵盖九个维度，WebWorld 在该基准上达到与 Gemini-3-Pro 可比的模拟性能。对于外部评估，在 WebWorld 合成轨迹上训练的 Qwen3-14B 在 WebArena 上提升 +9.2%，性能达到与 GPT-4o 相当的水平。WebWorld 实现有效的推理时搜索，作为世界模型其性能优于 GPT-5。除网页模拟外，WebWorld 还展现出对代码、GUI 和游戏环境的跨域泛化能力，为世界模型构建提供可复现的方案。",
    "upvotes": 2
  },
  {
    "id": "2602.14534",
    "date": "2026-02-17",
    "title": "MoRL: Reinforced Reasoning for Unified Motion Understanding and Generation",
    "authors": "Hongpeng Wang Zeyu Zhang Wenhao Li Hao Tang",
    "abstract": "A unified multimodal motion model trained with supervised fine-tuning and reinforcement learning with verifiable rewards improves human motion understanding and generation through semantic alignment, reasoning coherence, and physical plausibility. Human motion understanding and generation are crucial for vision and robotics but remain limited in reasoning capability and test-time planning. We propose MoRL, a unified multimodal motion model trained with supervised fine-tuning and reinforcement learning with verifiable rewards . Our task-specific reward design combines semantic alignment and reasoning coherence for understanding with physical plausibility and text-motion consistency for generation, improving both logical reasoning and perceptual realism. To further enhance inference, we introduce Chain-of-Motion (CoM), a test-time reasoning method that enables step-by-step planning and reflection. We also construct two large-scale CoT datasets , MoUnd-CoT-140K and MoGen-CoT-140K, to align motion sequences with reasoning traces and action descriptions. Experiments on HumanML3D and KIT-ML show that MoRL achieves significant gains over state-of-the-art baselines. Code: https://github.com/AIGeeksGroup/MoRL. Website: https://aigeeksgroup.github.io/MoRL.",
    "summary_en": "A unified multimodal motion model trained with supervised fine-tuning and reinforcement learning with verifiable rewards improves human motion understanding and generation through semantic alignment, reasoning coherence, and physical plausibility.",
    "summary_zh": "通过监督微调和可验证奖励的强化学习训练的统一多模态运动模型，通过语义对齐、推理连贯性和物理合理性，提升了人体运动理解与生成能力。",
    "upvotes": 2
  },
  {
    "id": "2602.14060",
    "date": "2026-02-17",
    "title": "LM-Lexicon: Improving Definition Modeling via Harmonizing Semantic Experts",
    "authors": "Yang Liu Jiaye Yang Weikang Li Jiahui Liang Yang Li Lingyong Yan",
    "abstract": "LM-Lexicon improves definition modeling through data clustering, semantic expert learning, and sparse mixture-of-experts architecture, achieving higher BLEU scores and better expert specialization. We introduce LM-Lexicon, an innovative definition modeling approach that incorporates data clustering , semantic expert learning , and model merging using a sparse mixture-of-experts architecture . By decomposing the definition modeling task into specialized semantic domains , where small language models are trained as domain experts , LM-Lexicon achieves substantial improvements (+7% BLEU score compared with the prior state-of-the-art model) over existing methods on five widely used benchmarks. Empirically, we demonstrate that 1) the clustering strategy enables fine-grained expert specialization with nearly 10% improvement in definition quality; 2) the semantic-aware domain-level routing mechanism achieves higher expert efficacy (+1%) than conventional token-level routing; and 3) further performance gains can be obtained through test-time compute and semantic expert scaling. Our work advances definition modeling while providing insights into the development of efficient language models for semantic-intensive applications.",
    "summary_en": "LM-Lexicon improves definition modeling through data clustering, semantic expert learning, and sparse mixture-of-experts architecture, achieving higher BLEU scores and better expert specialization.",
    "summary_zh": "LM-Lexicon通过数据聚类、语义专家学习和稀疏混合专家架构改进定义建模，实现了更高的BLEU分数和更好的专家特化。",
    "upvotes": 2
  },
  {
    "id": "2602.09185",
    "date": "2026-02-17",
    "title": "AIDev: Studying AI Coding Agents on GitHub",
    "authors": "Hao Li Haoxiang Zhang Ahmed E. Hassan",
    "abstract": "AIDev is a large-scale dataset of agent-authored pull requests from real-world GitHub repositories that captures AI coding agent usage in practical software development scenarios. AI coding agents are rapidly transforming software engineering by performing tasks such as feature development, debugging, and testing. Despite their growing impact, the research community lacks a comprehensive dataset capturing how these agents are used in real-world projects. To address this gap, we introduce AIDev, a large-scale dataset focused on agent-authored pull requests (Agentic-PRs) in real-world GitHub repositories . AIDev aggregates 932,791 Agentic-PRs produced by five agents: OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code. These PRs span 116,211 repositories and involve 72,189 developers. In addition, AIDev includes a curated subset of 33,596 Agentic-PRs from 2,807 repositories with over 100 stars, providing further information such as comments, reviews, commits, and related issues. This dataset offers a foundation for future research on AI adoption, developer productivity , and human-AI collaboration in the new era of software engineering. > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Agentic Software Engineering , Agentic Engineering",
    "summary_en": "AIDev is a large-scale dataset of agent-authored pull requests from real-world GitHub repositories that captures AI coding agent usage in practical software development scenarios.",
    "summary_zh": "AIDev是一个大规模数据集，收录了真实GitHub仓库中由agent编写的pull request，捕捉了AI coding agent在实际软件开发场景中的使用情况。",
    "upvotes": 2
  },
  {
    "id": "2602.15031",
    "date": "2026-02-17",
    "title": "EditCtrl: Disentangled Local and Global Control for Real-Time Generative Video Editing",
    "authors": "Yehonathan Litman Shikun Liu Dario Seyb Nicholas Milef Yang Zhou Carl Marshall Shubham Tulsiani Caleb Leak",
    "abstract": "Efficient video inpainting framework that focuses computation on masked regions while maintaining global context consistency through a lightweight embedder. High-fidelity generative video editing has seen significant quality improvements by leveraging pre-trained video foundation models . However, their computational cost is a major bottleneck, as they are often designed to inefficiently process the full video context regardless of the inpainting mask's size, even for sparse, localized edits. In this paper, we introduce EditCtrl, an efficient video inpainting control framework that focuses computation only where it is needed. Our approach features a novel local video context module that operates solely on masked tokens , yielding a computational cost proportional to the edit size. This local-first generation is then guided by a lightweight temporal global context embedder that ensures video-wide context consistency with minimal overhead. Not only is EditCtrl 10 times more compute efficient than state-of-the-art generative editing methods, it even improves editing quality compared to methods designed with full-attention. Finally, we showcase how EditCtrl unlocks new capabilities, including multi-region editing with text prompts and autoregressive content propagation .",
    "summary_en": "Efficient video inpainting framework that focuses computation on masked regions while maintaining global context consistency through a lightweight embedder.",
    "summary_zh": "高效的视频修复框架，将计算聚焦于掩码区域，同时通过轻量级嵌入器保持全局上下文一致性。",
    "upvotes": 1
  },
  {
    "id": "2602.14941",
    "date": "2026-02-17",
    "title": "AnchorWeave: World-Consistent Video Generation with Retrieved Local Spatial Memories",
    "authors": "Zun Wang Han Lin Jaehong Yoon Jaemin Cho Yue Zhang Mohit Bansal",
    "abstract": "AnchorWeave addresses long-term video generation consistency by replacing global 3D scene reconstruction with multiple local geometric memories and a multi-anchor weaving controller to reconcile cross-view inconsistencies. Maintaining spatial world consistency over long horizons remains a central challenge for camera-controllable video generation . Existing memory-based approaches often condition generation on globally reconstructed 3D scenes by rendering anchor videos from the reconstructed geometry in the history. However, reconstructing a global 3D scene from multiple views inevitably introduces cross-view misalignment , as pose and depth estimation errors cause the same surfaces to be reconstructed at slightly different 3D locations across views. When fused, these inconsistencies accumulate into noisy geometry that contaminates the conditioning signals and degrades generation quality. We introduce AnchorWeave, a memory-augmented video generation framework that replaces a single misaligned global memory with multiple clean local geometric memories and learns to reconcile their cross-view inconsistencies. To this end, AnchorWeave performs coverage-driven local memory retrieval aligned with the target trajectory and integrates the selected local memories through a multi-anchor weaving controller during generation. Extensive experiments demonstrate that AnchorWeave significantly improves long-term scene consistency while maintaining strong visual quality, with ablation and analysis studies further validating the effectiveness of local geometric conditioning, multi-anchor control, and coverage-driven retrieval .",
    "summary_en": "AnchorWeave addresses long-term video generation consistency by replacing global 3D scene reconstruction with multiple local geometric memories and a multi-anchor weaving controller to reconcile cross-view inconsistencies.",
    "summary_zh": "AnchorWeave 通过以多个局部几何记忆替代全局三维场景重建，并借助多锚点编织控制器调和跨视图不一致性，解决长期视频生成的一致性问题。",
    "upvotes": 1
  },
  {
    "id": "2602.14689",
    "date": "2026-02-17",
    "title": "Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks",
    "authors": "Lukas Struppek Adam Gleave Kellin Pelrine",
    "abstract": "Prefill attacks represent a significant and underexplored vulnerability in open-weight language models, affecting major contemporary models despite some resistance from large reasoning models. As the capabilities of large language models continue to advance, so does their potential for misuse. While closed-source models typically rely on external defenses , open-weight models must primarily depend on internal safeguards to mitigate harmful behavior. Prior red-teaming research has largely focused on input-based jailbreaking and parameter-level manipulations. However, open-weight models also natively support prefilling , which allows an attacker to predefine initial response tokens before generation begins. Despite its potential, this attack vector has received little systematic attention. We present the largest empirical study to date of prefill attacks, evaluating over 20 existing and novel strategies across multiple model families and state-of-the-art open-weight models . Our results show that prefill attacks are consistently effective against all major contemporary open-weight models , revealing a critical and previously underexplored vulnerability with significant implications for deployment. While certain large reasoning models exhibit some robustness against generic prefilling , they remain vulnerable to tailored, model-specific strategies . Our findings underscore the urgent need for model developers to prioritize defenses against prefill attacks in open-weight LLMs.",
    "summary_en": "Prefill attacks represent a significant and underexplored vulnerability in open-weight language models, affecting major contemporary models despite some resistance from large reasoning models.",
    "summary_zh": "Prefill attacks 代表了开放权重语言模型中一种重大且未被充分探索的漏洞，影响着主流当代模型，尽管大型推理模型对此表现出一定的抵抗性。",
    "upvotes": 1
  },
  {
    "id": "2602.13346",
    "date": "2026-02-17",
    "title": "CellMaster: Collaborative Cell Type Annotation in Single-Cell Analysis",
    "authors": "Zhen Wang Yiming Gao Jieyuan Liu Enze Ma Jefferson Chen Mark Antkowiak Mengzhou Hu JungHo Kong Dexter Pratt Zhiting Hu Wei Wang Trey Ideker Eric P. Xing",
    "abstract": "CellMaster uses LLM-encoded knowledge for zero-shot cell-type annotation in single-cell RNA sequencing, improving accuracy over existing tools through interpretable rationales without pre-training. Single-cell RNA-seq (scRNA-seq) enables atlas-scale profiling of complex tissues, revealing rare lineages and transient states. Yet, assigning biologically valid cell identities remains a bottleneck because markers are tissue- and state-dependent, and novel states lack references. We present CellMaster, an AI agent that mimics expert practice for zero-shot cell-type annotation . Unlike existing automated tools, CellMaster leverages LLM-encoded knowledge (e.g., GPT-4o) to perform on-the-fly annotation with interpretable rationales , without pre-training or fixed marker databases. Across 9 datasets spanning 8 tissues, CellMaster improved accuracy by 7.1% over best-performing baselines (including CellTypist and scTab ) in automatic mode. With human-in-the-loop refinement, this advantage increased to 18.6%, with a 22.1% gain on subtype populations. The system demonstrates particular strength in rare and novel cell states where baselines often fail. Source code and the web application are available at https://github.com/AnonymousGym/CellMaster{https://github.com/AnonymousGym/CellMaster}.",
    "summary_en": "CellMaster uses LLM-encoded knowledge for zero-shot cell-type annotation in single-cell RNA sequencing, improving accuracy over existing tools through interpretable rationales without pre-training.",
    "summary_zh": "CellMaster利用LLM编码的知识实现单细胞RNA测序的零样本细胞类型注释，通过可解释的依据在不经过预训练的情况下取得了优于现有工具的准确性。",
    "upvotes": 1
  },
  {
    "id": "2602.12586",
    "date": "2026-02-17",
    "title": "Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models",
    "authors": "Joshua Ong Jun Leang Yu Zhao Mihaela Cătălina Stoian Wenda Li Shay B. Cohen Eleonora Giunchiglia",
    "abstract": "McDiffuSE enhances Masked Diffusion Models by optimizing slot infilling order through Monte Carlo Tree Search, improving reasoning task performance through strategic exploration of generation sequences. While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders . Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.",
    "summary_en": "McDiffuSE enhances Masked Diffusion Models by optimizing slot infilling order through Monte Carlo Tree Search, improving reasoning task performance through strategic exploration of generation sequences.",
    "summary_zh": "McDiffuSE通过Monte Carlo Tree Search优化slot infilling order以增强Masked Diffusion Models，并通过strategic exploration of generation sequences提升reasoning task performance。",
    "upvotes": 1
  },
  {
    "id": "2602.12299",
    "date": "2026-02-17",
    "title": "Acoustivision Pro: An Open-Source Interactive Platform for Room Impulse Response Analysis and Acoustic Characterization",
    "authors": "Mandip Goswami",
    "abstract": "Room acoustics analysis plays a central role in architectural design, audio engineering, speech intelligibility assessment, and hearing research. Despite the availability of standardized metrics such as reverberation time, clarity, and speech transmission index, accessible tools that combine rigorous signal processing with intuitive visualization remain scarce. This paper presents AcoustiVision Pro, an open-source web-based platform for comprehensive room impulse response (RIR) analysis. The system computes twelve distinct acoustic parameters from uploaded or dataset-sourced RIRs, provides interactive 3D visualizations of early reflections, generates frequency-dependent decay characteristics through waterfall plots, and checks compliance against international standards including ANSI S12.60 and ISO 3382. We introduce the accompanying RIRMega and RIRMega Speech datasets hosted on Hugging Face, containing thousands of simulated room impulse responses with full metadata. The platform supports real-time auralization through FFT-based convolution, exports detailed PDF reports suitable for engineering documentation, and provides CSV data export for further analysis. We describe the mathematical foundations underlying each acoustic metric, detail the system architecture, and present preliminary case studies demonstrating the platform's utility across diverse application domains including classroom acoustics, healthcare facility design, and recording studio evaluation.",
    "summary_en": "This paper presents AcoustiVision Pro, an open-source web-based platform for room impulse response (RIR) analysis that computes twelve acoustic parameters, provides interactive 3D visualizations of early reflections, generates frequency-dependent waterfall plots, and checks compliance against ANSI S12.60 and ISO 3382 standards. The system supports real-time auralization through FFT-based convolution, exports PDF reports and CSV data, and is accompanied by the RIRMega and RIRMega Speech datasets hosted on Hugging Face containing thousands of simulated RIRs with full metadata. We describe the mathematical foundations underlying each metric, detail the system architecture, and present case studies demonstrating the platform's utility in classroom acoustics, healthcare facility design, and recording studio evaluation.",
    "summary_zh": "本文介绍了 AcoustiVision Pro，这是一个开源的基于 Web 的房间脉冲响应 (RIR) 分析平台，可计算十二项声学参数，提供早期反射的交互式 3D 可视化，生成频域 waterfall plots，并检查是否符合 ANSI S12.60 和 ISO 3382 标准。该系统支持通过基于 FFT 的卷积实现实时 auralization，可导出 PDF 报告和 CSV 数据，并附带托管于 Hugging Face 的 RIRMega 和 RIRMega Speech 数据集，包含数千条带有完整元数据的模拟 RIR。我们描述了各项指标背后的数学基础，详细介绍了系统架构，并展示了案例研究，证明了该平台在教室声学、医疗设施设计和录音棚评估中的实用性。",
    "upvotes": 1
  },
  {
    "id": "2602.11968",
    "date": "2026-02-17",
    "title": "DHPLT: large-scale multilingual diachronic corpora and word representations for semantic change modelling",
    "authors": "Mariia Fedorova Andrey Kutuzov Khonzoda Umarova",
    "abstract": "In this resource paper, we present DHPLT, an open collection of diachronic corpora in 41 diverse languages. DHPLT is based on the web-crawled HPLT datasets; we use web crawl timestamps as the approximate signal of document creation time. The collection covers three time periods: 2011-2015, 2020-2021 and 2024-present (1 million documents per time period for each language). We additionally provide pre-computed word type and token embeddings and lexical substitutions for our chosen target words, while at the same time leaving it open for the other researchers to come up with their own target words using the same datasets. DHPLT aims at filling in the current lack of multilingual diachronic corpora for semantic change modelling (beyond a dozen of high-resource languages). It opens the way for a variety of new experimental setups in this field. All the resources described in this paper are available at https://data.hplt-project.org/three/diachronic/, sorted by language.",
    "summary_en": "DHPLT is an open collection of diachronic corpora covering 41 diverse languages across three time periods (2011-2015, 2020-2021, and 2024-present), derived from HPLT web-crawled data using timestamps as temporal signals with one million documents per period per language. The resource provides pre-computed word type and token embeddings and lexical substitutions for target words while allowing researchers to define custom targets, aiming to fill the gap in multilingual diachronic corpora for semantic change modelling beyond high-resource languages. All datasets are available at https://data.hplt-project.org/three/diachronic/.",
    "summary_zh": "DHPLT是一个涵盖41种不同语言、跨越三个时期（2011-2015、2020-2021和2024至今）的开放历时语料库集合，基于时间戳作为时间信号从HPLT网络爬取数据中提取，每种语言每个时期包含一百万篇文档。该资源提供预计算的word type和token embeddings以及目标词的词汇替换，同时允许研究者定义自定义目标，旨在填补针对高资源语言之外的语言、用于语义变化建模的多语言历时语料库的空白。所有数据集均可在 https://data.hplt-project.org/three/diachronic/ 获取。",
    "upvotes": 1
  },
  {
    "id": "2602.09319",
    "date": "2026-02-17",
    "title": "Benchmarking Knowledge-Extraction Attack and Defense on Retrieval-Augmented Generation",
    "authors": "Zhisheng Qi Utkarsh Sahu Li Ma Haoyu Han Ryan Rossi Franck Dernoncourt Mahantesh Halappanavar Nesreen Ahmed Yushun Dong Yue Zhao Yu Zhang Yu Wang",
    "abstract": "A systematic benchmark for evaluating knowledge-extraction attacks on Retrieval-Augmented Generation systems is introduced, covering diverse attack and defense strategies across multiple retrieval and generation models with standardized evaluation protocols. Retrieval-Augmented Generation (RAG) has become a cornerstone of knowledge-intensive applications, including enterprise chatbots, healthcare assistants, and agentic memory management. However, recent studies show that knowledge-extraction attacks can recover sensitive knowledge-base content through maliciously crafted queries, raising serious concerns about intellectual property theft and privacy leakage. While prior work has explored individual attack and defense techniques, the research landscape remains fragmented, spanning heterogeneous retrieval embeddings, diverse generation models , and evaluations based on non-standardized metrics and inconsistent datasets. To address this gap, we introduce the first systematic benchmark for knowledge-extraction attacks on RAG systems. Our benchmark covers a broad spectrum of attack and defense strategies , representative retrieval embedding models , and both open- and closed-source generators, all evaluated under a unified experimental framework with standardized protocols across multiple datasets. By consolidating the experimental landscape and enabling reproducible, comparable evaluation, this benchmark provides actionable insights and a practical foundation for developing privacy-preserving RAG systems in the face of emerging knowledge extraction threats. Our code is available here.",
    "summary_en": "A systematic benchmark for evaluating knowledge-extraction attacks on Retrieval-Augmented Generation systems is introduced, covering diverse attack and defense strategies across multiple retrieval and generation models with standardized evaluation protocols.",
    "summary_zh": "介绍了一种用于评估针对检索增强生成（Retrieval-Augmented Generation）系统的知识提取攻击（knowledge-extraction attacks）的系统性基准测试，涵盖多种攻击与防御策略，跨越多种检索与生成模型，并采用标准化评估协议。",
    "upvotes": 1
  },
  {
    "id": "2602.07673",
    "date": "2026-02-17",
    "title": "Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation",
    "authors": "Jiangnan Fang Cheng-Tse Liu Hanieh Deilamsalehy Nesreen K. Ahmed Puneet Mathur Nedim Lipka Franck Dernoncourt Ryan A. Rossi",
    "abstract": "LLM judges exhibit bias toward summaries similar to their own generation, with performance deteriorating as summary overlap with human references decreases across multiple model sizes and architectures.",
    "summary_en": "LLM judges exhibit bias toward summaries similar to their own generation, with performance deteriorating as summary overlap with human references decreases across multiple model sizes and architectures.",
    "summary_zh": "LLM评判器偏向与其自身生成相似的摘要，且随着摘要与人类参考的重叠度降低，其性能会下降，这一现象在多种模型规模和架构中均存在。",
    "upvotes": 1
  },
  {
    "id": "2602.15259",
    "date": "2026-02-17",
    "title": "Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight",
    "authors": "Kirandeep Kaur Xingda Lyu Chirag Shah",
    "abstract": "Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. Existing approaches to proactivity remain narrowly anticipatory, extrapolating from past behavior and presuming that goals are already well defined, thereby failing to support users meaningfully. However, surfacing possibilities beyond a user's current awareness is not inherently beneficial. Unconstrained proactive interventions can misdirect attention, overwhelm users, or introduce harm. Proactive agents, therefore, require behavioral grounding: principled constraints on when, how, and to what extent an agent should intervene. We advance the position that generative proactivity must be grounded both epistemically and behaviorally. Drawing on the philosophy of ignorance and research on proactive behavior, we argue that these theories offer critical guidance for designing agents that can engage responsibly and foster meaningful partnerships.",
    "summary_en": "Generative AI agents conventionally equate understanding with resolving explicit queries, an assumption that fails under epistemic incompleteness where users lack awareness of unknown unknowns required for progress. The authors argue that effective proactivity requires dual grounding: epistemically to surface possibilities beyond current user awareness, and behaviorally through principled constraints on when and how to intervene, drawing on philosophy of ignorance and proactive behavior research. Existing anticipatory approaches fail by assuming well-defined goals, while unconstrained proactivity risks misdirection or harm, but epistemically and behaviorally grounded agents can engage responsibly to foster meaningful partnerships.",
    "summary_zh": "生成式AI智能体传统上将理解等同于解决显式查询，这一假设在认知不完备性情境下失效——用户缺乏对进步所需的\"未知的未知\"的意识。作者认为，有效的主动性需要双重基础：在认识论层面，揭示超出当前用户意识的可能性；在行为层面，通过原则性约束规范干预的时机与方式，其理论依据来自无知哲学与主动行为研究。现有的预测性方法因假设目标明确定义而失效，而无约束的主动性则存在误导或伤害的风险；唯有在认识论和行为层面均具备基础的智能体，才能负责任地参与互动，促成有意义的伙伴关系。",
    "upvotes": 0
  },
  {
    "id": "2602.14696",
    "date": "2026-02-17",
    "title": "A Critical Look at Targeted Instruction Selection: Disentangling What Matters (and What Doesn't)",
    "authors": "Nihal V. Nayak Paula Rodriguez-Diaz Neha Hulkund Sara Beery David Alvarez-Melis",
    "abstract": "Targeted instruction selection for LLM fine-tuning can be improved by systematically analyzing data representation and selection algorithms, with gradient-based representations and greedy round-robin selection performing best at low budgets. Instruction fine-tuning of large language models (LLMs) often involves selecting a subset of instruction training data from a large candidate pool, using a small query set from the target task. Despite growing interest, the literature on targeted instruction selection remains fragmented and opaque: methods vary widely in selection budgets, often omit zero-shot baselines, and frequently entangle the contributions of key components. As a result, practitioners lack actionable guidance on selecting instructions for their target tasks. In this work, we aim to bring clarity to this landscape by disentangling and systematically analyzing the two core ingredients: data representation and selection algorithms . Our framework enables controlled comparisons across models, tasks, and budgets. We find that only gradient-based data representation s choose subsets whose similarity to the query consistently predicts performance across datasets and models. While no single method dominates, gradient-based representations paired with a greedy round-robin selection algorithm tend to perform best on average at low budgets, but these benefits diminish at larger budgets. Finally, we unify several existing selection algorithms as forms of approximate distance minimization between the selected subset and the query set, and support this view with new generalization bounds . More broadly, our findings provide critical insights and a foundation for more principled data selection in LLM fine-tuning. The code is available at https://github.com/dcml-lab/targeted-instruction-selection.",
    "summary_en": "Targeted instruction selection for LLM fine-tuning can be improved by systematically analyzing data representation and selection algorithms, with gradient-based representations and greedy round-robin selection performing best at low budgets.",
    "summary_zh": "针对LLM微调的指令选择可通过系统分析数据表示与选择算法加以改进，其中基于梯度的表示与贪心轮询选择在低预算下表现最佳。",
    "upvotes": 0
  },
  {
    "id": "2602.14560",
    "date": "2026-02-17",
    "title": "Preliminary sonification of ENSO using traditional Javanese gamelan scales",
    "authors": "Sandy H. S. Herho Rusmawan Suwarman Nurjanna J. Trilaksono Iwan P. Anwar Faiz R. Fajary",
    "abstract": "Parameter-mapping sonification of ENSO data preserves dynamical signatures through acoustic phase space analysis, revealing distinct coupling regimes in traditional musical scales. Sonification -- the mapping of data to non-speech audio -- offers an underexplored channel for representing complex dynamical systems . We treat El Niño-Southern Oscillation ( ENSO ), a canonical example of low-dimensional climate chaos, as a test case for culturally-situated sonification evaluated through complex systems diagnostics. Using parameter-mapping sonification of the Niño 3.4 sea surface temperature anomaly index (1870--2024), we encode ENSO variability into two traditional Javanese gamelan pentatonic systems ( pelog and slendro ) across four composition strategies, then analyze the resulting audio as trajectories in a two-dimensional acoustic phase space . Recurrence-based diagnostics , convex hull geometry , and coupling analysis reveal that the sonification pipeline preserves key dynamical signatures: alternating modes produce the highest trajectory recurrence rates, echoing ENSO 's quasi-periodicity; layered polyphonic modes explore the broadest phase space regions; and the two scale families induce qualitatively distinct coupling regimes between spectral brightness and energy -- predominantly anti-phase in pelog but near-independent in slendro . Phase space trajectory analysis provides a rigorous geometric framework for comparing sonification designs within a complex systems context. Perceptual validation remains necessary; we contribute the dynamical systems methodology for evaluating such mappings.",
    "summary_en": "Parameter-mapping sonification of ENSO data preserves dynamical signatures through acoustic phase space analysis, revealing distinct coupling regimes in traditional musical scales.",
    "summary_zh": "ENSO数据的参数映射声化通过声学相空间分析保留了动力学特征，在传统音阶中揭示了不同的耦合机制。",
    "upvotes": 0
  },
  {
    "id": "2602.13516",
    "date": "2026-02-17",
    "title": "SPILLage: Agentic Oversharing on the Web",
    "authors": "Jaechul Roh Eugene Bagdasarian Hamed Haddadi Ali Shahin Shamsabadi",
    "abstract": "Web agents inadvertently disclose user information through both content and behavioral traces, with behavioral oversharing being more prevalent than content oversharing, and this issue persists despite mitigation efforts. LLM-powered agents are beginning to automate user's tasks across the open web, often with access to user resources such as emails and calendars. Unlike standard LLMs answering questions in a controlled ChatBot setting, web agents act \"in the wild\", interacting with third parties and leaving behind an action trace. Therefore, we ask the question: how do web agents handle user resources when accomplishing tasks on their behalf across live websites? In this paper, we formalize Natural Agentic Oversharing -- the unintentional disclosure of task-irrelevant user information through an agent trace of actions on the web. We introduce SPILLage , a framework that characterizes oversharing along two dimensions: channel (content vs. behavior) and directness (explicit vs. implicit). This taxonomy reveals a critical blind spot: while prior work focuses on text leakage, web agents also overshare behaviorally through clicks, scrolls, and navigation patterns that can be monitored. We benchmark 180 tasks on live e-commerce sites with ground-truth annotations separating task-relevant from task-irrelevant attributes. Across 1,080 runs spanning two agentic frameworks and three backbone LLMs, we demonstrate that oversharing is pervasive with behavioral oversharing dominates content oversharing by 5x. This effect persists -- and can even worsen -- under prompt-level mitigation . However, removing task-irrelevant information before execution improves task success by up to 17.9%, demonstrating that reducing oversharing improves task success . Our findings underscore that protecting privacy in web agents is a fundamental challenge, requiring a broader view of \"output\" that accounts for what agents do on the web, not just what they type. Our datasets and code are available at https://github.com/jrohsc/ SPILLage .",
    "summary_en": "Web agents inadvertently disclose user information through both content and behavioral traces, with behavioral oversharing being more prevalent than content oversharing, and this issue persists despite mitigation efforts.",
    "summary_zh": "网页智能体通过内容痕迹和行为痕迹无意中泄露用户信息，其中行为过度分享比内容过度分享更为普遍，且尽管采取了缓解措施，该问题依然存在。",
    "upvotes": 0
  },
  {
    "id": "2602.10458",
    "date": "2026-02-17",
    "title": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving",
    "authors": "Yansong Qu Zihao Sheng Zilin Huang Jiancong Chen Yuhao Luo Tianyi Wang Yiheng Feng Samuel Labi Sikai Chen",
    "abstract": "Found-RL integrates vision-language models with reinforcement learning for autonomous driving, addressing sample efficiency and latency issues through asynchronous inference and specialized supervision mechanisms.",
    "summary_en": "Found-RL integrates vision-language models with reinforcement learning for autonomous driving, addressing sample efficiency and latency issues through asynchronous inference and specialized supervision mechanisms.",
    "summary_zh": "Found-RL将视觉语言模型与强化学习相结合用于自动驾驶，通过异步推理和专门的监督机制解决样本效率与延迟问题。",
    "upvotes": 0
  },
  {
    "id": "2602.10388",
    "date": "2026-02-16",
    "title": "Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs",
    "authors": "Zhongzhi Li Xuansheng Wu Yijiang Li Lijie Hu Ninghao Liu",
    "abstract": "Feature Activation Coverage measures data diversity in an interpretable feature space and enables diversity-driven data synthesis that improves downstream performance across multiple language model architectures. The diversity of post-training data is critical for effective downstream performance in large language models (LLMs). Many existing approaches to constructing post-training data quantify diversity using text-based metrics that capture linguistic variation, but such metrics provide only weak signals for the task-relevant features that determine downstream performance . In this work, we introduce Feature Activation Coverage (FAC) which measures data diversity in an interpretable feature space. Building upon this metric, we further propose a diversity-driven data synthesis framework, named FAC Synthesis, that first uses a sparse autoencoder to identify missing features from a seed dataset, and then generates synthetic samples that explicitly reflect these features. Experiments show that our approach consistently improves both data diversity and downstream performance on various tasks, including instruction following , toxicity detection , reward modeling , and behavior steering . Interestingly, we identify a shared, interpretable feature space across model families (i.e., LLaMA, Mistral, and Qwen), enabling cross-model knowledge transfer . Our work provides a solid and practical methodology for exploring data-centric optimization of LLMs.",
    "summary_en": "Feature Activation Coverage measures data diversity in an interpretable feature space and enables diversity-driven data synthesis that improves downstream performance across multiple language model architectures.",
    "summary_zh": "Feature Activation Coverage 在可解释的特征空间中衡量数据多样性，并实现多样性驱动的数据合成，从而提升跨多种语言模型架构的下游性能。",
    "upvotes": 203
  },
  {
    "id": "2602.12783",
    "date": "2026-02-16",
    "title": "SQuTR: A Robustness Benchmark for Spoken Query to Text Retrieval under Acoustic Noise",
    "authors": "Yuejie Li Ke Yang Yueying Hua Berlin Chen Jianhao Nie Yueping He Caixin Kang",
    "abstract": "Spoken query retrieval is an important interaction mode in modern information retrieval. However, existing evaluation datasets are often limited to simple queries under constrained noise conditions, making them inadequate for assessing the robustness of spoken query retrieval systems under complex acoustic perturbations. To address this limitation, we present SQuTR, a robustness benchmark for spoken query retrieval that includes a large-scale dataset and a unified evaluation protocol. SQuTR aggregates 37,317 unique queries from six commonly used English and Chinese text retrieval datasets, spanning multiple domains and diverse query types. We synthesize speech using voice profiles from 200 real speakers and mix 17 categories of real-world environmental noise under controlled SNR levels, enabling reproducible robustness evaluation from quiet to highly noisy conditions. Under the unified protocol, we conduct large-scale evaluations on representative cascaded and end-to-end retrieval systems. Experimental results show that retrieval performance decreases as noise increases, with substantially different drops across systems. Even large-scale retrieval models struggle under extreme noise, indicating that robustness remains a critical bottleneck. Overall, SQuTR provides a reproducible testbed for benchmarking and diagnostic analysis, and facilitates future research on robustness in spoken query to text retrieval.",
    "summary_en": "SQuTR is a robustness benchmark for spoken query retrieval that addresses limitations of existing datasets by aggregating 37,317 unique queries from six English and Chinese text retrieval datasets, synthesized using voice profiles from 200 real speakers and mixed with 17 categories of real-world environmental noise under controlled SNR levels. The benchmark provides a unified evaluation protocol for assessing both cascaded and end-to-end retrieval systems across conditions ranging from quiet to highly noisy environments. Experimental results demonstrate that retrieval performance degrades substantially as noise increases, with significant variation across different systems, and even large-scale models struggle under extreme noise, indicating that robustness remains a critical bottleneck in spoken query to text retrieval.",
    "summary_zh": "SQuTR 是一个面向口语查询检索的鲁棒性基准测试，它通过从六个英文和中文文本检索数据集中聚合 37,317 条独特查询，使用 200 位真实说话人的语音特征合成，并在受控 SNR 水平下混入 17 类真实环境噪声，解决了现有数据集的局限性。该基准提供了统一的评估协议，用于在从安静到高噪声环境的多种条件下评估级联（cascaded）和端到端（end-to-end）检索系统。实验结果表明，随着噪声增加，检索性能显著下降，不同系统间存在显著差异，且即使大规模模型在极端噪声下也表现不佳，这表明鲁棒性仍然是口语查询到文本检索中的关键瓶颈。",
    "upvotes": 134
  },
  {
    "id": "2602.12705",
    "date": "2026-02-16",
    "title": "MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs",
    "authors": "Baorong Shi Bo Cui Boyuan Jiang Deli Yu Fang Qian Haihua Yang Huichao Wang Jiale Chen Jianfei Pan Jieqiong Cao Jinghao Lin Kai Wu Lin Yang Shengsheng Yao Tao Chen Xiaojun Xiao Xiaozhong Ji Xu Wang Yijun He Zhixiong Yang",
    "abstract": "MedXIAOHE is a medical vision-language foundation model that enhances clinical understanding through entity-aware continual pretraining, reinforcement learning, and tool-augmented agentic training for reliable diagnostic reasoning.",
    "summary_en": "MedXIAOHE is a medical vision-language foundation model that enhances clinical understanding through entity-aware continual pretraining, reinforcement learning, and tool-augmented agentic training for reliable diagnostic reasoning.",
    "summary_zh": "MedXIAOHE 是一种医疗视觉-语言基础模型，通过 entity-aware continual pretraining、reinforcement learning 和 tool-augmented agentic training 来增强临床理解，实现可靠的诊断推理。",
    "upvotes": 56
  },
  {
    "id": "2602.11858",
    "date": "2026-02-16",
    "title": "Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception",
    "authors": "Lai Wei Liangbo He Jun Lan Lingzhong Dong Yutong Cai Siyuan Li Huijia Zhu Weiqiang Wang Linghe Kong Yue Wang Zhuosheng Zhang Weiran Huang",
    "abstract": "Region-to-Image Distillation enables fine-grained visual perception in MLLMs by training models to internally perform iterative zooming during inference, eliminating the need for repeated tool calls and visual re-encoding while maintaining high performance across multiple benchmarks. Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception , where decisive evidence is small and easily overwhelmed by global context. Recent \" Thinking-with-Images \" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation , which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves \"single-glance\" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench , a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional \"zooming gap\". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents . We further discuss when \" Thinking-with-Images \" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.",
    "summary_en": "Region-to-Image Distillation enables fine-grained visual perception in MLLMs by training models to internally perform iterative zooming during inference, eliminating the need for repeated tool calls and visual re-encoding while maintaining high performance across multiple benchmarks.",
    "summary_zh": "Region-to-Image Distillation 通过训练模型在推理过程中内部执行迭代缩放，使 MLLMs 能够实现细粒度视觉感知，消除了重复工具调用和视觉重编码的需求，同时在多个基准测试中保持高性能。",
    "upvotes": 52
  },
  {
    "id": "2602.08683",
    "date": "2026-02-16",
    "title": "OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence",
    "authors": "Feilong Tang Xiang An Yunyao Yan Yin Xie Bin Qin Kaicheng Yang Yifei Shen Yuanhan Zhang Chunyuan Li Shikun Feng Changrui Chen Huajie Tan Ming Hu Manyuan Zhang Bo Li Ziyong Feng Ziwei Liu Zongyuan Ge Jiankang Deng",
    "abstract": "Visual understanding can be improved by aligning architectures with information-theoretic principles of video compression, using sparsity-driven encoding that outperforms traditional approaches in efficiency and accuracy. Hypothesis. Artificial general intelligence is, at its core, a compression problem . Effective compression demands resonance : deep learning scales best when its architecture aligns with the fundamental structure of the data. These are the fundamental principles. Yet, modern vision architectures have strayed from these truths: visual signals are highly redundant, while discriminative information , the surprise, is sparse. Current models process dense pixel grids uniformly, wasting vast compute on static background rather than focusing on the predictive residuals that define motion and meaning. We argue that to solve visual understanding, we must align our architectures with the information-theoretic principles of video, i.e., Codecs. Method. OneVision-Encoder encodes video by compressing predictive visual structure into semantic meaning. By adopting Codec Patchification , OV-Encoder abandons uniform computation to focus exclusively on the 3.1%-25% of regions rich in signal entropy. To unify spatial and temporal reasoning under irregular token layouts, OneVision-Encoder employs a shared 3D RoPE and is trained with a large-scale cluster discrimination objective over more than one million semantic concepts , jointly capturing object permanence and motion dynamics . Evidence. The results validate our core hypothesis: efficiency and accuracy are not a trade-off; they are positively correlated. When integrated into LLM , it consistently outperforms strong vision backbones such as Qwen3-ViT and SigLIP2 across 16 image, video, and document understanding benchmarks, despite using substantially fewer visual tokens and pretraining data . Notably, on video understanding tasks, OV-Encoder achieves an average improvement of 4.1% over Qwen3-ViT. Codec-aligned, patch-level sparsity is a foundational principle, enabling OV-Encoder as a scalable engine for next-generation visual generalists.",
    "summary_en": "Visual understanding can be improved by aligning architectures with information-theoretic principles of video compression, using sparsity-driven encoding that outperforms traditional approaches in efficiency and accuracy.",
    "summary_zh": "视觉理解可通过将架构与视频压缩的信息论原理对齐来改进，利用在效率和准确性上均优于传统方法的稀疏驱动编码。",
    "upvotes": 40
  },
  {
    "id": "2602.13191",
    "date": "2026-02-16",
    "title": "CoPE-VideoLM: Codec Primitives For Efficient Video Language Models",
    "authors": "Sayan Deb Sarkar Rémi Pautrat Ondrej Miksik Marc Pollefeys Iro Armeni Mahdi Rad Mihai Dusmanu",
    "abstract": "Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to 86% and token usage by up to 93% compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on 14 diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding.",
    "summary_en": "Current Video Language Models (VideoLMs) rely on keyframe sampling that misses temporal details and incurs high computational costs from full-image processing. We propose leveraging video codec primitives (motion vectors and residuals) to encode sparsity without full-image encoding, using lightweight transformer encoders that aggregate these primitives and align them with image embeddings through pre-training. This approach reduces time-to-first-token by up to 86% and token usage by up to 93% while maintaining or exceeding performance on 14 video understanding benchmarks spanning question answering, temporal reasoning, and spatial understanding.",
    "summary_zh": "现有的视频语言模型（VideoLMs）依赖关键帧采样，这会丢失时序细节，并因全图处理而产生高昂的计算成本。我们提出利用视频编解码原语（运动向量和残差）来编码稀疏性，无需完整图像编码，并使用轻量级 transformer 编码器聚合这些原语，通过预训练将其与图像嵌入对齐。该方法将 time-to-first-token 降低多达 86%，token 使用量减少多达 93%，同时在涵盖问答、时序推理和空间理解的 14 个视频理解基准测试上保持或超越性能。",
    "upvotes": 25
  },
  {
    "id": "2602.12617",
    "date": "2026-02-16",
    "title": "GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics",
    "authors": "Modi Jin Yiming Zhang Boyuan Sun Dingwen Zhang MingMing Cheng Qibin Hou",
    "abstract": "GeoAgent achieves superior geolocation reasoning performance through a specialized dataset and reward mechanisms that ensure geographic accuracy and reasoning consistency. This paper presents GeoAgent, a model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remain concerns because of their reliance on AI-generated chain-of-thought (CoT) data and training strategies, which conflict with geographic characteristics . To address these issues, we first introduce GeoSeek, a new geolocation dataset comprising CoT data annotated by geographic experts and professional players. We further thoroughly explore the inherent characteristics of geographic tasks and propose a geo-similarity reward and a consistency reward assessed by a consistency agent to assist training. This encourages the model to converge towards correct answers from a geographic perspective while ensuring the integrity and consistency of its reasoning process . Experimental results show that GeoAgent outperforms existing methods and a series of general VLLMs across multiple grains, while generating reasoning that closely aligns with humans.",
    "summary_en": "GeoAgent achieves superior geolocation reasoning performance through a specialized dataset and reward mechanisms that ensure geographic accuracy and reasoning consistency.",
    "summary_zh": "GeoAgent 通过专门的数据集和奖励机制实现卓越的地理定位推理性能，确保地理准确性和推理一致性。",
    "upvotes": 19
  },
  {
    "id": "2602.09146",
    "date": "2026-02-16",
    "title": "SemanticMoments: Training-Free Motion Similarity via Third Moment Features",
    "authors": "Saar Huberman Kfir Goldberg Or Patashnik Sagie Benaim Ron Mokady",
    "abstract": "Temporal statistics in semantic feature space provide a scalable approach for motion-centric video understanding, outperforming existing RGB, flow, and text-supervised methods.",
    "summary_en": "Temporal statistics in semantic feature space provide a scalable approach for motion-centric video understanding, outperforming existing RGB, flow, and text-supervised methods.",
    "summary_zh": "语义特征空间中的时序统计为以运动为中心的视频理解提供了一种可扩展的方法，其性能优于现有的RGB、flow和文本监督方法。",
    "upvotes": 19
  },
  {
    "id": "2602.12395",
    "date": "2026-02-16",
    "title": "What does RL improve for Visual Reasoning? A Frankenstein-Style Analysis",
    "authors": "Xirui Li Ming Li Tianyi Zhou",
    "abstract": "Reinforcement learning (RL) with verifiable rewards has become a standard post-training stage for boosting visual reasoning in vision-language models, yet it remains unclear what capabilities RL actually improves compared with supervised fine-tuning as cold-start initialization (IN). End-to-end benchmark gains conflate multiple factors, making it difficult to attribute improvements to specific skills. To bridge the gap, we propose a Frankenstein-style analysis framework including: (i) functional localization via causal probing; (ii) update characterization via parameter comparison; and (iii) transferability test via model merging. Instead, RL induces a consistent inference-time shift primarily in mid-to-late layers, and these mid-to-late refinements are both transferable (via merging) and necessary (via freezing) for RL gains. Overall, our results suggest that RL's reliable contribution in visual reasoning is not a uniform enhancement of visual perception, but a systematic refinement of mid-to-late transformer computation that improves vision-to-reasoning alignment and reasoning performance, highlighting the limitations of benchmark-only evaluation for understanding multimodal reasoning improvements.",
    "summary_en": "While reinforcement learning (RL) with verifiable rewards is widely used to enhance visual reasoning in vision-language models, end-to-end benchmarks obscure what specific capabilities improve beyond supervised fine-tuning initialization. To disentangle these effects, the authors propose a Frankenstein-style framework combining causal probing, parameter comparison, and model merging to analyze functional localization, update characterization, and transferability. Their findings demonstrate that RL induces consistent inference-time shifts primarily in mid-to-late transformer layers, with these refinements proving both transferable via merging and necessary via freezing for RL gains. These results suggest RL systematically refines mid-to-late computation to improve vision-to-reasoning alignment rather than uniformly enhancing visual perception, highlighting limitations of benchmark-only evaluation for assessing multimodal reasoning.",
    "summary_zh": "虽然基于可验证奖励的强化学习（RL）被广泛用于增强视觉语言模型中的视觉推理能力，但端到端基准测试掩盖了相较于监督微调（SFT）初始化具体哪些能力得到了提升。为了解耦这些效应，作者提出了一种 Frankenstein-style 框架，结合因果探测（causal probing）、参数比较和模型合并（model merging），以分析功能定位（functional localization）、更新特征刻画（update characterization）和可迁移性（transferability）。他们的研究发现，RL 主要在中后层 Transformer 层引发一致的推理时偏移（inference-time shifts），这些优化既可通过 merging 实现迁移，也可通过 freezing 验证其对 RL 收益的必要性。这些结果表明，RL 系统地优化中后层计算以改进 vision-to-reasoning alignment，而非均匀地增强视觉感知，凸显了仅依赖基准测试评估多模态推理的局限性。",
    "upvotes": 13
  },
  {
    "id": "2602.11865",
    "date": "2026-02-16",
    "title": "Intelligent AI Delegation",
    "authors": "Nenad Tomašev Matija Franklin Simon Osindero",
    "abstract": "AI agents require adaptive frameworks for task decomposition and delegation that can dynamically respond to environmental changes and handle unexpected failures through structured authority transfer and trust mechanisms. AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelligent AI delegation - a sequence of decisions involving task allocation, that also incorporates transfer of authority, responsibility, accountability, clear specifications regarding roles and boundaries, clarity of intent, and mechanisms for establishing trust between the two (or more) parties. The proposed framework is applicable to both human and AI delegators and delegatees in complex delegation networks, aiming to inform the development of protocols in the emerging agentic web .",
    "summary_en": "AI agents require adaptive frameworks for task decomposition and delegation that can dynamically respond to environmental changes and handle unexpected failures through structured authority transfer and trust mechanisms.",
    "summary_zh": "AI智能体需要自适应框架来实现任务分解与委托，该框架能够动态响应环境变化，并通过结构化权限转移与信任机制处理意外故障。",
    "upvotes": 10
  },
  {
    "id": "2602.11236",
    "date": "2026-02-16",
    "title": "ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning",
    "authors": "Yandan Yang Shuang Zeng Tong Lin Xinyuan Chang Dekang Qi Junjin Xiao Haoyun Liu Ronghan Chen Yuzhi Chen Dongjie Huo Feng Xiong Xing Wei Zhiheng Ma Mu Xu",
    "abstract": "ABot-M0 presents a unified framework for embodied agent development that standardizes diverse robotic data and employs action manifold learning to improve prediction efficiency and stability. Building general-purpose embodied agents across diverse hardware remains a central challenge in robotics, often framed as the ''one-brain, many-forms'' paradigm. Progress is hindered by fragmented data, inconsistent representations, and misaligned training objectives. We present ABot-M0, a framework that builds a systematic data curation pipeline while jointly optimizing model architecture and training strategies , enabling end-to-end transformation of heterogeneous raw data into unified, efficient representations. From six public datasets, we clean, standardize, and balance samples to construct UniACT-dataset, a large-scale dataset with over 6 million trajectories and 9,500 hours of data, covering diverse robot morphologies and task scenarios. Unified pre-training improves knowledge transfer and generalization across platforms and tasks, supporting general-purpose embodied intelligence. To improve action prediction efficiency and stability, we propose the Action Manifold Hypothesis : effective robot actions lie not in the full high-dimensional space but on a low-dimensional, smooth manifold governed by physical laws and task constraints. Based on this, we introduce Action Manifold Learning (AML), which uses a DiT backbone to predict clean, continuous action sequences directly. This shifts learning from denoising to projection onto feasible manifolds, improving decoding speed and policy stability. ABot-M0 supports modular perception via a dual-stream mechanism that integrates VLM semantics with geometric priors and multi-view inputs from plug-and-play 3D modules such as VGGT and Qwen-Image-Edit , enhancing spatial understanding without modifying the backbone and mitigating standard VLM limitations in 3D reasoning. Experiments show components operate independently with additive benefits. We will release all code and pipelines for reproducibility and future research.",
    "summary_en": "ABot-M0 presents a unified framework for embodied agent development that standardizes diverse robotic data and employs action manifold learning to improve prediction efficiency and stability.",
    "summary_zh": "ABot-M0 提出了一个用于具身智能体开发的统一框架，该框架标准化了多样化的机器人数据，并采用动作流形学习（action manifold learning）来提升预测效率和稳定性。",
    "upvotes": 10
  },
  {
    "id": "2602.12628",
    "date": "2026-02-16",
    "title": "RLinf-Co: Reinforcement Learning-Based Sim-Real Co-Training for VLA Models",
    "authors": "Liangzhi Shi Shuaihang Chen Feng Gao Yinuo Chen Kang Chen Tonghe Zhang Hongzhi Zhang Weinan Zhang Chao Yu Yu Wang",
    "abstract": "Reinforcement learning-based sim-real co-training framework improves vision-language-action policy performance through interactive simulation and real-world data anchoring. Simulation offers a scalable and low-cost way to enrich vision-language-action (VLA) training, reducing reliance on expensive real-robot demonstrations. However, most sim-real co-training methods rely on supervised fine-tuning (SFT), which treats simulation as a static source of demonstrations and does not exploit large-scale closed-loop interaction. Consequently, real-world gains and generalization are often limited. In this paper, we propose an \\textit{RL}-based sim-real \\textit{Co}-training (RL-Co) framework that leverages interactive simulation while preserving real-world capabilities. Our method follows a generic two-stage design: we first warm-start the policy with SFT on a mixture of real and simulated demonstrations, then fine-tune it with reinforcement learning in simulation while adding an auxiliary supervised loss on real-world data to anchor the policy and mitigate catastrophic forgetting . We evaluate our framework on four real-world tabletop manipulation tasks using two representative VLA architectures, OpenVLA and π_{0.5}, and observe consistent improvements over real-only fine-tuning and SFT-based co-training, including +24% real-world success on OpenVLA and +20% on π_{0.5}. Beyond higher success rates, RL co-training yields stronger generalization to unseen task variations and substantially improved real-world data efficiency , providing a practical and scalable pathway for leveraging simulation to enhance real-robot deployment.",
    "summary_en": "Reinforcement learning-based sim-real co-training framework improves vision-language-action policy performance through interactive simulation and real-world data anchoring.",
    "summary_zh": "基于强化学习的sim-real协同训练框架通过交互式仿真和真实世界数据锚定提升vision-language-action策略性能。",
    "upvotes": 9
  },
  {
    "id": "2602.13013",
    "date": "2026-02-16",
    "title": "Towards Universal Video MLLMs with Attribute-Structured and Quality-Verified Instructions",
    "authors": "Yunheng Li Hengrui Zhang Meng-Hao Guo Wenzhao Gao Shaoyong Jia Shaohui Jiao Qibin Hou Ming-Ming Cheng",
    "abstract": "A large-scale dataset and model for fine-grained audiovisual understanding are introduced, demonstrating improved caption quality and reduced hallucinations through structured annotations and supervised fine-tuning. Universal video understanding requires modeling fine-grained visual and audio information over time in diverse real-world scenarios. However, the performance of existing models is primarily constrained by video-instruction data that represents complex audiovisual content as single, incomplete descriptions, lacking fine-grained organization and reliable annotation. To address this, we introduce: (i) ASID-1M, an open-source collection of one million structured, fine-grained audiovisual instruction annotations with single- and multi-attribute supervision; (ii) ASID-Verify, a scalable data curation pipeline for annotation, with automatic verification and refinement that enforces semantic and temporal consistency between descriptions and the corresponding audiovisual content; and (iii) ASID-Captioner, a video understanding model trained via Supervised Fine-Tuning (SFT) on the ASID-1M. Experiments across seven benchmarks covering audiovisual captioning , attribute-wise captioning , caption-based QA , and caption-based temporal grounding show that ASID-Captioner improves fine-grained caption quality while reducing hallucinations and improving instruction following. It achieves state-of-the-art performance among open-source models and is competitive with Gemini-3-Pro.",
    "summary_en": "A large-scale dataset and model for fine-grained audiovisual understanding are introduced, demonstrating improved caption quality and reduced hallucinations through structured annotations and supervised fine-tuning.",
    "summary_zh": "本文介绍了一个面向细粒度视听理解的大规模数据集与模型，通过结构化标注和监督微调，在提升描述质量的同时减少了幻觉现象。",
    "upvotes": 7
  },
  {
    "id": "2602.04163",
    "date": "2026-02-16",
    "title": "BPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models",
    "authors": "Junyu Chen Jungang Li Jing Xiong Wenjie Wang Qingyao Yang He Xiao Zhen Li Taiqiang Wu Mengzhao Chen Zhen Peng Chaofan Tao Long Shi Hongxia Yang Ngai Wong",
    "abstract": "Bit-Plane Decomposition Quantization (BPDQ) improves low-bit quantization by using variable quantization grids derived from bit-planes and scalar coefficients, achieving better accuracy than traditional methods in resource-constrained LLM inference. Large language model (LLM) inference is often bounded by memory footprint and memory bandwidth in resource-constrained deployments, making quantization a fundamental technique for efficient serving. While post-training quantization (PTQ) maintains high fidelity at 4-bit, it deteriorates at 2-3 bits. Fundamentally, existing methods enforce a shape-invariant quantization grid (e.g., the fixed uniform intervals of UINT2) for each group, severely restricting the feasible set for error minimization. To address this, we propose Bit-Plane Decomposition Quantization (BPDQ), which constructs a variable quantization grid via bit-planes and scalar coefficients , and iteratively refines them using approximate second-order information while progressively compensating quantization error s to minimize output discrepancy. In the 2-bit regime, BPDQ enables serving Qwen2.5-72B on a single RTX 3090 with 83.85% GSM8K accuracy (vs. 90.83% at 16-bit). Moreover, we provide theoretical analysis showing that the variable grid expands the feasible set, and that the quantization process consistently aligns with the optimization objective in Hessian-induced geometry . Code: github.com/KingdalfGoodman/BPDQ.",
    "summary_en": "Bit-Plane Decomposition Quantization (BPDQ) improves low-bit quantization by using variable quantization grids derived from bit-planes and scalar coefficients, achieving better accuracy than traditional methods in resource-constrained LLM inference.",
    "summary_zh": "Bit-Plane Decomposition Quantization (BPDQ) 利用源自位平面和标量系数的可变量化网格改进低比特量化，在资源受限的 LLM 推理中取得了优于传统方法的精度。",
    "upvotes": 6
  },
  {
    "id": "2602.11715",
    "date": "2026-02-16",
    "title": "DICE: Diffusion Large Language Models Excel at Generating CUDA Kernels",
    "authors": "Haolei Bai Lingcheng Kong Xueyi Chen Jianmian Wang Zhiqiang Tao Huan Wang",
    "abstract": "Diffusion large language models (dLLMs) for CUDA kernel generation achieve superior performance through a specialized dataset and reinforcement learning framework. Diffusion large language models (dLLMs) have emerged as a compelling alternative to autoregressive (AR) LLMs, owing to their capacity for parallel token generation . This paradigm is particularly well-suited for code generation, where holistic structural planning and non-sequential refinement are critical. Despite this potential, tailoring dLLMs for CUDA kernel generation remains challenging, obstructed not only by the high specialization but also by the severe lack of high-quality training data. To address these challenges, we construct CuKe, an augmented supervised fine-tuning dataset optimized for high-performance CUDA kernels. On top of it, we propose a bi-phase curated reinforcement learning (BiC-RL) framework consisting of a CUDA kernel infilling stage and an end-to-end CUDA kernel generation stage. Leveraging this training framework, we introduce DICE, a series of diffusion large language models designed for CUDA kernel generation , spanning three parameter scales, 1.7B, 4B, and 8B. Extensive experiments on KernelBench demonstrate that DICE significantly outperforms both autoregressive and diffusion LLMs of comparable scale, establishing a new state-of-the-art for CUDA kernel generation .",
    "summary_en": "Diffusion large language models (dLLMs) for CUDA kernel generation achieve superior performance through a specialized dataset and reinforcement learning framework.",
    "summary_zh": "用于 CUDA 内核生成的扩散大语言模型 (dLLMs) 通过专门的数据集和强化学习框架实现了更优性能。",
    "upvotes": 5
  },
  {
    "id": "2602.12984",
    "date": "2026-02-16",
    "title": "SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents",
    "authors": "Yujiong Shen Yajie Yang Zhiheng Xi Binze Hu Huayu Sha Jiazheng Zhang Qiyuan Peng Junlin Shang Jixuan Huang Yutao Fan Jingqi Tong Shihan Dou Ming Zhang Lei Bai Zhenfei Yin Tao Gui Xingjun Ma Qi Zhang Xuanjing Huang Yu-Gang Jiang",
    "abstract": "SciAgentGym and SciAgentBench enable evaluation of scientific tool-use capabilities, while SciForge improves agent performance through dependency graph modeling of tool interactions.",
    "summary_en": "SciAgentGym and SciAgentBench enable evaluation of scientific tool-use capabilities, while SciForge improves agent performance through dependency graph modeling of tool interactions.",
    "summary_zh": "SciAgentGym 和 SciAgentBench 支持科学工具使用能力的评估，而 SciForge 则通过依赖图建模工具交互来提升智能体性能。",
    "upvotes": 4
  },
  {
    "id": "2602.12829",
    "date": "2026-02-16",
    "title": "FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching",
    "authors": "Lei Lv Yunfei Li Yu Luo Fuchun Sun Xiao Ma",
    "abstract": "Field Least-Energy Actor-Critic (FLAC) addresses challenges in maximum entropy reinforcement learning with iterative generative policies by using kinetic energy as a proxy for policy stochasticity regulation through a generalized Schrödinger bridge formulation. Iterative generative policies, such as diffusion models and flow matching , offer superior expressivity for continuous control but complicate Maximum Entropy Reinforcement Learning because their action log-densities are not directly accessible. To address this, we propose Field Least-Energy Actor-Critic (FLAC), a likelihood-free framework that regulates policy stochasticity by penalizing the kinetic energy of the velocity field . Our key insight is to formulate policy optimization as a Generalized Schrödinger Bridge (GSB) problem relative to a high-entropy reference process (e.g., uniform). Under this view, the maximum-entropy principle emerges naturally as staying close to a high-entropy reference while optimizing return, without requiring explicit action densities. In this framework, kinetic energy serves as a physically grounded proxy for divergence from the reference: minimizing path-space energy bounds the deviation of the induced terminal action distribution. Building on this view, we derive an energy-regularized policy iteration scheme and a practical off-policy algorithm that automatically tunes the kinetic energy via a Lagrangian dual mechanism . Empirically, FLAC achieves superior or comparable performance on high-dimensional benchmarks relative to strong baselines, while avoiding explicit density estimation.",
    "summary_en": "Field Least-Energy Actor-Critic (FLAC) addresses challenges in maximum entropy reinforcement learning with iterative generative policies by using kinetic energy as a proxy for policy stochasticity regulation through a generalized Schrödinger bridge formulation.",
    "summary_zh": "Field Least-Energy Actor-Critic (FLAC) 通过广义薛定谔桥形式化，将动能作为策略随机性调节的代理，解决了最大熵强化学习中迭代生成策略所面临的挑战。",
    "upvotes": 3
  },
  {
    "id": "2602.12684",
    "date": "2026-02-16",
    "title": "Xiaomi-Robotics-0: An Open-Sourced Vision-Language-Action Model with Real-Time Execution",
    "authors": "Rui Cai Jun Guo Xinze He Piaopiao Jin Jie Li Bingxuan Lin Futeng Liu Wei Liu Fei Ma Kun Ma Feng Qiu Heng Qu Yifei Su Qiao Sun Dong Wang Donghao Wang Yunhong Wang Rujie Wu Diyun Xiang Yu Yang Hangjun Ye Yuan Zhang",
    "abstract": "A vision-language-action model for robotics combines large-scale pretraining with specialized training techniques to enable real-time execution and high-performance manipulation tasks.",
    "summary_en": "A vision-language-action model for robotics combines large-scale pretraining with specialized training techniques to enable real-time execution and high-performance manipulation tasks.",
    "summary_zh": "面向机器人学的视觉-语言-动作模型结合大规模预训练与专门训练技术，实现实时执行和高性能操作任务。",
    "upvotes": 3
  },
  {
    "id": "2602.12506",
    "date": "2026-02-16",
    "title": "On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs",
    "authors": "Rosie Zhao Anshul Shah Xiaoyu Zhu Xinke Deng Zhongyu Jiang Yang Yang Joerg Liebelt Arnab Mondal",
    "abstract": "Reinforcement learning (RL) fine-tuning has become a key technique for enhancing large language models (LLMs) on reasoning-intensive tasks, motivating its extension to vision language models (VLMs). While RL-tuned VLMs improve on visual reasoning benchmarks, they remain vulnerable to weak visual grounding, hallucinations, and over-reliance on textual cues. We show that simple, controlled textual perturbations--misleading captions or incorrect chain-of-thought (CoT) traces--cause substantial drops in robustness and confidence, and that these effects are more pronounced when CoT consistency is taken into account across open-source multimodal reasoning models. Entropy-based metrics further show that these perturbations reshape model uncertainty and probability mass on the correct option, exposing model-specific trends in miscalibration. To better understand these vulnerabilities, we further analyze RL fine-tuning dynamics and uncover an accuracy-faithfulness trade-off: fine-tuning raises benchmark accuracy, but can simultaneously erode the reliability of the accompanying CoT and its robustness to contextual shifts. Although adversarial augmentation improves robustness, it does not by itself prevent faithfulness drift. Incorporating a faithfulness-aware reward can restore alignment between answers and reasoning, but when paired with augmentation, training risks collapsing onto shortcut strategies and robustness remains elusive. Together, these findings highlight the limitations of accuracy-only evaluations and motivate training and assessment protocols that jointly emphasize correctness, robustness, and the faithfulness of visually grounded reasoning.",
    "summary_en": "RL fine-tuning improves VLMs on visual reasoning benchmarks but leaves them vulnerable to weak visual grounding and hallucinations, where simple textual perturbations cause robustness drops that entropy-based metrics trace to reshaped uncertainty and probability mass, particularly when CoT consistency is evaluated. Analysis of RL dynamics reveals an accuracy-faithfulness trade-off: fine-tuning boosts accuracy while eroding CoT reliability and robustness to contextual shifts, and although adversarial augmentation improves robustness, it does not prevent faithfulness drift. Faithfulness-aware rewards restore alignment between answers and reasoning but risk training collapse when paired with augmentation, leaving robustness elusive. These findings highlight the limitations of accuracy-only evaluations and motivate protocols that jointly emphasize correctness, robustness, and faithfulness in visually grounded reasoning.",
    "summary_zh": "RL微调提升了VLM在视觉推理基准上的表现，但使其易受视觉接地薄弱和幻觉的影响，其中简单的文本扰动会导致鲁棒性下降，而基于熵的指标将这种下降追溯至不确定性和概率质量的重塑，特别是在评估CoT一致性时。对RL动态的分析揭示了准确性与忠实度之间的权衡：微调提升了准确性，同时侵蚀了CoT的可靠性以及对上下文偏移的鲁棒性；尽管对抗增强提升了鲁棒性，但无法阻止忠实度漂移。忠实度感知奖励恢复了答案与推理之间的对齐，但在与增强方法结合时存在训练崩溃的风险，使得鲁棒性难以实现。这些发现凸显了仅关注准确性评估的局限性，并推动建立能够在视觉接地推理中联合强调正确性、鲁棒性和忠实度的评估协议。",
    "upvotes": 3
  },
  {
    "id": "2602.11757",
    "date": "2026-02-16",
    "title": "Code2Worlds: Empowering Coding LLMs for 4D World Generation",
    "authors": "Yi Zhang Yunshuang Wang Zeyu Zhang Hao Tang",
    "abstract": "Code2Worlds enables 4D dynamic scene generation by formulating it as language-to-simulation code generation with a dual-stream architecture and physics-aware closed-loop refinement. Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation . First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration . Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code . Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.",
    "summary_en": "Code2Worlds enables 4D dynamic scene generation by formulating it as language-to-simulation code generation with a dual-stream architecture and physics-aware closed-loop refinement.",
    "summary_zh": "Code2Worlds通过将4D动态场景生成形式化为语言到模拟代码生成任务，并采用双流架构与物理感知闭环优化来实现。",
    "upvotes": 3
  },
  {
    "id": "2602.12612",
    "date": "2026-02-16",
    "title": "Self-EvolveRec: Self-Evolving Recommender Systems with LLM-based Directional Feedback",
    "authors": "Sein Kim Sangwu Park Hongseok Kang Wonjoong Kim Jimin Seo Yeonjun In Kanghoon Yoon Chanyoung Park",
    "abstract": "Traditional methods for automating recommender system design, such as Neural Architecture Search (NAS), are often constrained by a fixed search space defined by human priors, limiting innovation to pre-defined operators. While recent LLM-driven code evolution frameworks shift fixed search space target to open-ended program spaces, they primarily rely on scalar metrics (e.g., NDCG, Hit Ratio) that fail to provide qualitative insights into model failures or directional guidance for improvement. To address this, we propose Self-EvolveRec, a novel framework that establishes a directional feedback loop by integrating a User Simulator for qualitative critiques and a Model Diagnosis Tool for quantitative internal verification. Furthermore, we introduce a Diagnosis Tool - Model Co-Evolution strategy to ensure that evaluation criteria dynamically adapt as the recommendation architecture evolves. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in both recommendation performance and user satisfaction. Our code is available at https://github.com/Sein-Kim/self_evolverec.",
    "summary_en": "Traditional Neural Architecture Search (NAS) methods are constrained by fixed search spaces defined by human priors, while recent LLM-driven code evolution frameworks rely on scalar metrics such as NDCG and Hit Ratio that lack qualitative insights for directional improvement. We propose Self-EvolveRec, which integrates a User Simulator for qualitative critiques and a Model Diagnosis Tool for quantitative verification to establish directional feedback, and introduces a Diagnosis Tool - Model Co-Evolution strategy to dynamically adapt evaluation criteria as recommendation architectures evolve. Extensive experiments demonstrate that Self-EvolveRec significantly outperforms state-of-the-art NAS and LLM-driven code evolution baselines in recommendation performance and user satisfaction.",
    "summary_zh": "传统的 Neural Architecture Search (NAS) 方法受限于由人工先验定义的固定搜索空间，而近期的 LLM-driven code evolution 框架依赖于 NDCG 和 Hit Ratio 等标量指标，缺乏用于定向改进的定性洞察。我们提出了 Self-EvolveRec，其整合 User Simulator 以提供定性批评，并集成 Model Diagnosis Tool 进行定量验证，从而建立定向反馈，同时引入 Diagnosis Tool - Model Co-Evolution 策略，以在推荐架构演进过程中动态调整评估标准。大量实验表明，Self-EvolveRec 在推荐性能和用户满意度方面显著优于最先进的 NAS 和 LLM-driven code evolution 基线。",
    "upvotes": 2
  },
  {
    "id": "2602.12221",
    "date": "2026-02-16",
    "title": "Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching",
    "authors": "Onkar Susladkar Tushar Prakash Gayatri Deshmukh Kiet A. Nguyen Jiaxun Zhang Adheesh Juvekar Tianshu Bao Lin Chai Sparsh Mittal Inderjit S Dhillon Ismini Lourentzou",
    "abstract": "UniDFlow is a unified discrete flow-matching framework that decouples understanding and generation through low-rank adapters and uses reference-based alignment to improve multimodal tasks without retraining. We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding , generation , and editing . It decouples understanding and generation via task-specific low-rank adapters , avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting , in-context image generation , reference-based editing , and compositional generation , despite no explicit task-specific training.",
    "summary_en": "UniDFlow is a unified discrete flow-matching framework that decouples understanding and generation through low-rank adapters and uses reference-based alignment to improve multimodal tasks without retraining.",
    "summary_zh": "UniDFlow 是一个统一的离散流匹配框架，通过 low-rank adapters 解耦理解与生成，并利用 reference-based alignment 改进多模态任务，无需重新训练。",
    "upvotes": 2
  },
  {
    "id": "2602.11910",
    "date": "2026-02-16",
    "title": "TADA! Tuning Audio Diffusion Models through Activation Steering",
    "authors": "Łukasz Staniszewski Katarzyna Zaleska Mateusz Modrzejewski Kamil Deja",
    "abstract": "Research reveals that specific attention layers in audio diffusion models control distinct musical concepts, enabling precise manipulation of audio features through activation steering. Audio diffusion models can synthesize high-fidelity music from text, yet their internal mechanisms for representing high-level concepts remain poorly understood. In this work, we use activation patching to demonstrate that distinct semantic musical concepts , such as the presence of specific instruments, vocals, or genre characteristics, are controlled by a small, shared subset of attention layers in state-of-the-art audio diffusion architectures. Next, we demonstrate that applying Contrastive Activation Addition and Sparse Autoencoders in these layers enables more precise control over the generated audio, indicating a direct benefit of the specialization phenomenon. By steering activations of the identified layers, we can alter specific musical elements with high precision, such as modulating tempo or changing a track's mood.",
    "summary_en": "Research reveals that specific attention layers in audio diffusion models control distinct musical concepts, enabling precise manipulation of audio features through activation steering.",
    "summary_zh": "研究表明，音频扩散模型中的特定注意力层控制着不同的音乐概念，从而能够通过激活引导精确操控音频特征。",
    "upvotes": 2
  },
  {
    "id": "2602.11769",
    "date": "2026-02-16",
    "title": "Light4D: Training-Free Extreme Viewpoint 4D Video Relighting",
    "authors": "Zhenghuang Wu Kang Chen Zeyu Zhang Hao Tang",
    "abstract": "Light4D enables consistent 4D video synthesis under target illumination through disentangled flow guidance and temporal consistent attention mechanisms. Recent advances in diffusion-based generative models have established a new paradigm for image and video relighting. However, extending these capabilities to 4D relighting remains challenging, due primarily to the scarcity of paired 4D relighting training data and the difficulty of maintaining temporal consistency across extreme viewpoints. In this work, we propose Light4D, a novel training-free framework designed to synthesize consistent 4D videos under target illumination, even under extreme viewpoint changes. First, we introduce Disentangled Flow Guidance , a time-aware strategy that effectively injects lighting control into the latent space while preserving geometric integrity . Second, to reinforce temporal consistency , we develop Temporal Consistent Attention within the IC-Light architecture and further incorporate deterministic regularization to eliminate appearance flickering. Extensive experiments demonstrate that our method achieves competitive performance in temporal consistency and lighting fidelity, robustly handling camera rotations from -90 to 90. Code: https://github.com/AIGeeksGroup/Light4D. Website: https://aigeeksgroup.github.io/Light4D.",
    "summary_en": "Light4D enables consistent 4D video synthesis under target illumination through disentangled flow guidance and temporal consistent attention mechanisms.",
    "summary_zh": "Light4D通过解耦光流引导和时间一致性注意力机制，实现了在目标光照下的一致性4D视频合成。",
    "upvotes": 2
  },
  {
    "id": "2602.13022",
    "date": "2026-02-16",
    "title": "Learning Image-based Tree Crown Segmentation from Enhanced Lidar-based Pseudo-labels",
    "authors": "Julius Pesonen Stefan Rua Josef Taher Niko Koivumäki Xiaowei Yu Eija Honkavaara",
    "abstract": "Mapping individual tree crowns is essential for tasks such as maintaining urban tree inventories and monitoring forest health, which help us understand and care for our environment. However, automatically separating the crowns from each other in aerial imagery is challenging due to factors such as the texture and partial tree crown overlaps. In this study, we present a method to train deep learning models that segment and separate individual trees from RGB and multispectral images, using pseudo-labels derived from aerial laser scanning (ALS) data. Our study shows that the ALS-derived pseudo-labels can be enhanced using a zero-shot instance segmentation model, Segment Anything Model 2 (SAM 2). Our method offers a way to obtain domain-specific training annotations for optical image-based models without any manual annotation cost, leading to segmentation models which outperform any available models which have been targeted for general domain deployment on the same task.",
    "summary_en": "Individual tree crown mapping supports urban inventories and forest health monitoring but is challenging to automate from aerial imagery due to texture variations and crown overlaps. This study presents a method to train deep learning segmentation models on RGB and multispectral images using pseudo-labels derived from aerial laser scanning (ALS) data, which are enhanced by the zero-shot Segment Anything Model 2 (SAM 2). The approach eliminates manual annotation costs while producing domain-specific models that outperform general-domain alternatives on this task.",
    "summary_zh": "单木树冠制图支持城市清查和森林健康监测，但由于纹理变化和树冠重叠，难以从航空影像中实现自动化。本研究提出了一种利用源自机载激光雷达（ALS）数据的伪标签在RGB和多光谱影像上训练深度学习分割模型的方法，这些伪标签由零样本Segment Anything Model 2（SAM 2）增强。该方法消除了人工标注成本，同时生成了在该任务上优于通用领域替代方案的领域特定模型。",
    "upvotes": 1
  },
  {
    "id": "2602.12500",
    "date": "2026-02-16",
    "title": "Favia: Forensic Agent for Vulnerability-fix Identification and Analysis",
    "authors": "André Storhaug Jiamou Sun Jingyue Li",
    "abstract": "Favia is a forensic, agent-based framework that combines scalable candidate ranking with deep semantic reasoning to accurately identify vulnerability-fixing commits by leveraging LLM agents with specialized tools and environmental context. Identifying vulnerability-fixing commits corresponding to disclosed CVEs is essential for secure software maintenance but remains challenging at scale, as large repositories contain millions of commits of which only a small fraction address security issues. Existing automated approaches, including traditional machine learning techniques and recent large language model (LLM)-based methods, often suffer from poor precision-recall trade-offs . Frequently evaluated on randomly sampled commits, we uncover that they are substantially underestimating real-world difficulty, where candidate commits are already security-relevant and highly similar. We propose Favia, a forensic, agent-based framework for vulnerability-fix identification that combines scalable candidate ranking with deep and iterative semantic reasoning . Favia first employs an efficient ranking stage to narrow the search space of commits. Each commit is then rigorously evaluated using a ReAct-based LLM agent . By providing the agent with a pre-commit repository as environment, along with specialized tools, the agent tries to localize vulnerable components, navigates the codebase, and establishes causal alignment between code changes and vulnerability root causes. This evidence-driven process enables robust identification of indirect, multi-file, and non-trivial fixes that elude single-pass or similarity-based methods. We evaluate Favia on CVEVC, a large-scale dataset we made that comprises over 8 million commits from 3,708 real-world repositories, and show that it consistently outperforms state-of-the-art traditional and LLM-based baselines under realistic candidate selection, achieving the strongest precision-recall trade-offs and highest F1-scores.",
    "summary_en": "Favia is a forensic, agent-based framework that combines scalable candidate ranking with deep semantic reasoning to accurately identify vulnerability-fixing commits by leveraging LLM agents with specialized tools and environmental context.",
    "summary_zh": "Favia 是一个取证型、基于 agent 的框架，结合可扩展的候选排序与深度语义推理，利用配备专用工具和环境上下文的 LLM agent 以准确识别漏洞修复提交。",
    "upvotes": 1
  },
  {
    "id": "2602.11609",
    "date": "2026-02-16",
    "title": "scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery",
    "authors": "Yiming Gao Zhen Wang Jefferson Chen Mark Antkowiak Mengzhou Hu JungHo Kong Dexter Pratt Jieyuan Liu Enze Ma Zhiting Hu Eric P. Xing",
    "abstract": "scPilot presents a framework for omics-native reasoning where large language models directly analyze single-cell RNA-seq data through step-by-step reasoning processes, improving accuracy and interpretability in cell-type annotation and developmental trajectory reconstruction. We present scPilot, the first systematic framework to practice omics-native reasoning : a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotation , developmental-trajectory reconstruction , and transcription-factor targeting , into step-by-step reasoning problems that the model must solve, justify, and, when needed, revise with new evidence. To measure progress, we release scBench, a suite of 9 expertly curated datasets and graders that faithfully evaluate the omics-native reasoning capability of scPilot w.r.t various LLMs. Experiments with o1 show that iterative omics-native reasoning lifts average accuracy by 11% for cell-type annotation and Gemini-2.5-Pro cuts trajectory graph-edit distance by 30% versus one-shot prompting, while generating transparent reasoning traces explain marker gene ambiguity and regulatory logic . By grounding LLMs in raw omics data, scPilot enables auditable, interpretable, and diagnostically informative single-cell analyses. Code, data, and package are available at https://github.com/maitrix-org/scPilot",
    "summary_en": "scPilot presents a framework for omics-native reasoning where large language models directly analyze single-cell RNA-seq data through step-by-step reasoning processes, improving accuracy and interpretability in cell-type annotation and developmental trajectory reconstruction.",
    "summary_zh": "scPilot 构建了一个用于 omics-native reasoning 的框架，使大语言模型能够通过逐步推理过程直接分析 single-cell RNA-seq 数据，从而在细胞类型注释和发育轨迹重建方面提升准确性与可解释性。",
    "upvotes": 1
  },
  {
    "id": "2602.09870",
    "date": "2026-02-16",
    "title": "Steer2Edit: From Activation Steering to Component-Level Editing",
    "authors": "Chung-En Sun Ge Yan Zimo Wang Tsui-Wei Weng",
    "abstract": "Steering methods influence Large Language Model behavior by identifying semantic directions in hidden representations, but are typically realized through inference-time activation interventions that apply a fixed, global modification to the model's internal states. While effective, such interventions often induce unfavorable attribute-utility trade-offs under strong control, as they ignore the fact that many behaviors are governed by a small and heterogeneous subset of model components. We propose Steer2Edit, a theoretically grounded, training-free framework that transforms steering vectors from inference-time control signals into diagnostic signals for component-level rank-1 weight editing. Instead of uniformly injecting a steering direction during generation, Steer2Edit selectively redistributes behavioral influence across individual attention heads and MLP neurons, yielding interpretable edits that preserve the standard forward pass and remain compatible with optimized parallel inference. Across safety alignment, hallucination mitigation, and reasoning efficiency, Steer2Edit consistently achieves more favorable attribute-utility trade-offs: at matched downstream performance, it improves safety by up to 17.2%, increases truthfulness by 9.8%, and reduces reasoning length by 12.2% on average. Overall, Steer2Edit provides a principled bridge between representation steering and weight editing by translating steering signals into interpretable, training-free parameter updates.",
    "summary_en": "Current steering methods apply fixed global modifications during inference, which induces unfavorable attribute-utility trade-offs by ignoring that behaviors are governed by small, heterogeneous subsets of components. Steer2Edit transforms steering vectors into diagnostic signals for component-level rank-1 weight editing, selectively redistributing behavioral influence across individual attention heads and MLP neurons while preserving the standard forward pass. This training-free framework achieves more favorable trade-offs than standard steering, improving safety by up to 17.2%, truthfulness by 9.8%, and reducing reasoning length by 12.2% on average across safety alignment, hallucination mitigation, and reasoning efficiency tasks.",
    "summary_zh": "现有的 steering 方法在 inference 期间施加固定的全局修改，因其忽略了行为受小型、异质的组件子集调控的事实，从而导致不利的 attribute-utility trade-offs。Steer2Edit 将 steering vectors 转化为用于组件级 rank-1 weight editing 的诊断信号，在保持标准 forward pass 的同时，选择性地将行为影响重新分配至各个 attention heads 和 MLP neurons。该 training-free 框架相比标准 steering 实现了更优的 trade-offs，在 safety alignment、hallucination mitigation 和 reasoning efficiency 任务中，平均将 safety 提升最多达 17.2%，truthfulness 提升 9.8%，并将 reasoning length 减少 12.2%。",
    "upvotes": 1
  },
  {
    "id": "2602.07298",
    "date": "2026-02-16",
    "title": "Principled Synthetic Data Enables the First Scaling Laws for LLMs in Recommendation",
    "authors": "Benyu Zhang Qiang Zhang Jianpeng Cheng Hong-You Chen Qifei Wang Wei Sun Shen Li Jia Li Jiahao Wu Xiangjun Fan Hong Yan",
    "abstract": "A novel layered framework generates high-quality synthetic data for large language models in recommender systems, demonstrating superior performance and predictable scaling laws compared to traditional methods. Large Language Models (LLMs) represent a promising frontier for recommender systems , yet their development has been impeded by the absence of predictable scaling laws, which are crucial for guiding research and optimizing resource allocation. We hypothesize that this may be attributed to the inherent noise, bias, and incompleteness of raw user interaction data in prior continual pre-training (CPT) efforts. This paper introduces a novel, layered framework for generating high-quality synthetic data that circumvents such issues by creating a curated, pedagogical curriculum for the LLM. We provide powerful, direct evidence for the utility of our curriculum by showing that standard sequential models trained on our principled synthetic data significantly outperform (+130% on recall@100 for SasRec) models trained on real data in downstream ranking tasks, demonstrating its superiority for learning generalizable user preference patterns. Building on this, we empirically demonstrate, for the first time, robust power-law scaling for an LLM that is continually pre-trained on our high-quality, recommendation-specific data. Our experiments reveal consistent and predictable perplexity reduction across multiple synthetic data modalities. These findings establish a foundational methodology for reliable scaling LLM capabilities in the recommendation domain, thereby shifting the research focus from mitigating data deficiencies to leveraging high-quality, structured information.",
    "summary_en": "A novel layered framework generates high-quality synthetic data for large language models in recommender systems, demonstrating superior performance and predictable scaling laws compared to traditional methods.",
    "summary_zh": "一种新颖的分层框架可为推荐系统中的大语言模型生成高质量合成数据，相比传统方法展现出更优的性能和可预测的 scaling laws。",
    "upvotes": 1
  },
  {
    "id": "2602.04315",
    "date": "2026-02-16",
    "title": "GeneralVLA: Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning",
    "authors": "Guoqing Ma Siheng Wang Zeyu Zhang Shan Yu Hao Tang",
    "abstract": "GeneralVLA is a hierarchical vision-language-action model that enables zero-shot robotic manipulation through knowledge-guided trajectory planning without requiring real-world data collection. Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is that the models exhibit limited zero-shot capability , which hampers their ability to generalize effectively to unseen scenarios. In this work, we propose GeneralVLA (Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning ), a hierarchical vision-language-action (VLA) model that can be more effective in utilizing the generalization of foundation models, enabling zero-shot manipulation and automatically generating data for robotics. In particular, we study a class of hierarchical VLA model where the high-level ASM ( Affordance Segmentation Module ) is finetuned to perceive image keypoint affordances of the scene; the mid-level 3DAgent carries out task understanding, skill knowledge, and trajectory planning to produce a 3D path indicating the desired robot end-effector trajectory. The intermediate 3D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Compared to alternative approaches, our method requires no real-world robotic data collection or human demonstration, making it much more scalable to diverse tasks and viewpoints. Empirically, GeneralVLA successfully generates trajectories for 14 tasks, significantly outperforming state-of-the-art methods such as VoxPoser. The generated demonstrations can train more robust behavior cloning policies than training with human demonstrations or from data generated by VoxPoser, Scaling-up, and Code-As-Policies. We believe GeneralVLA can be the scalable method for both generating data for robotics and solving novel tasks in a zero-shot setting. Code: https://github.com/AIGeeksGroup/GeneralVLA. Website: https://aigeeksgroup.github.io/GeneralVLA.",
    "summary_en": "GeneralVLA is a hierarchical vision-language-action model that enables zero-shot robotic manipulation through knowledge-guided trajectory planning without requiring real-world data collection.",
    "summary_zh": "GeneralVLA是一种分层视觉-语言-动作模型，通过知识引导的轨迹规划实现零样本机器人操作，无需真实世界数据收集。",
    "upvotes": 1
  },
  {
    "id": "2602.03120",
    "date": "2026-02-16",
    "title": "Quantized Evolution Strategies: High-precision Fine-tuning of Quantized LLMs at Low-precision Cost",
    "authors": "Yinggan Xu Risto Miikkulainen Xin Qiu",
    "abstract": "Post-Training Quantization (PTQ) is essential for deploying Large Language Models (LLMs) on memory-constrained devices, yet it renders models static and difficult to fine-tune. Standard fine-tuning paradigms, including Reinforcement Learning (RL), fundamentally rely on backpropagation and high-precision weights to compute gradients. Thus they cannot be used on quantized models, where the parameter space is discrete and non-differentiable. While Evolution Strategies (ES) offer a backpropagation-free alternative, optimization of the quantized parameters can still fail due to vanishing or inaccurate gradient. This paper introduces Quantized Evolution Strategies (QES), an optimization paradigm that performs full-parameter fine-tuning directly in the quantized space. QES is based on two innovations: (1) it integrates accumulated error feedback to preserve high-precision gradient signals, and (2) it utilizes a stateless seed replay to reduce memory usage to low-precision inference levels. QES significantly outperforms the state-of-the-art zeroth-order fine-tuning method on arithmetic reasoning tasks, making direct fine-tuning for quantized models possible. It therefore opens up the possibility for scaling up LLMs entirely in the quantized space. The source code is available at https://github.com/dibbla/Quantized-Evolution-Strategies .",
    "summary_en": "Post-Training Quantization (PTQ) enables deploying Large Language Models (LLMs) on memory-constrained devices but renders models static and incompatible with standard fine-tuning methods that require backpropagation through discrete, non-differentiable parameter spaces. This paper introduces Quantized Evolution Strategies (QES), which performs full-parameter fine-tuning directly in quantized space using accumulated error feedback to preserve high-precision gradient signals and stateless seed replay to reduce memory usage. QES significantly outperforms state-of-the-art zeroth-order methods on arithmetic reasoning tasks, enabling direct fine-tuning of quantized models and opening possibilities for scaling LLMs entirely in quantized space.",
    "summary_zh": "后训练量化（PTQ）使得大型语言模型（LLMs）能够部署于内存受限设备，但会使模型静态化，并与需要通过离散、不可微参数空间进行反向传播的标准微调方法不兼容。本文提出量化进化策略（QES），该方法直接在量化空间中进行全参数微调，利用累积误差反馈保留高精度梯度信号，并使用无状态种子重放减少内存使用。QES在算术推理任务上显著优于最先进的zeroth-order方法，实现了对量化模型的直接微调，并为完全在量化空间中扩展LLMs开辟了可能性。",
    "upvotes": 1
  },
  {
    "id": "2602.13139",
    "date": "2026-02-16",
    "title": "OpenLID-v3: Improving the Precision of Closely Related Language Identification -- An Experience Report",
    "authors": "Mariia Fedorova Nikolay Arefyev Maja Buljan Jindřich Helcl Stephan Oepen Egil Rønningstad Yves Scherrer",
    "abstract": "OpenLID-v3 improves language identification accuracy for closely related languages and low-resource variants through enhanced training data, cluster merging, and noise detection mechanisms. Language identification (LID) is an essential step in building high-quality multilingual datasets from web data . Existing LID tools (such as OpenLID or GlotLID ) often struggle to identify closely related languages and to distinguish valid natural language from noise, which contaminates language-specific subsets, especially for low-resource languages . In this work we extend the OpenLID classifier by adding more training data, merging problematic language variant clusters , and introducing a special label for marking noise. We call this extended system OpenLID -v3 and evaluate it against GlotLID on multiple benchmarks. During development, we focus on three groups of closely related languages (Bosnian, Croatian, and Serbian; Romance varieties of Northern Italy and Southern France; and Scandinavian languages) and contribute new evaluation datasets where existing ones are inadequate. We find that ensemble approaches improve precision but also substantially reduce coverage for low-resource languages . OpenLID -v3 is available on https://huggingface.co/HPLT/ OpenLID -v3.",
    "summary_en": "OpenLID-v3 improves language identification accuracy for closely related languages and low-resource variants through enhanced training data, cluster merging, and noise detection mechanisms.",
    "summary_zh": "OpenLID-v3 通过增强的训练数据、聚类合并和噪声检测机制，提升了对近缘语言及低资源变体的语言识别准确率。",
    "upvotes": 0
  },
  {
    "id": "2602.09877",
    "date": "2026-02-13",
    "title": "The Devil Behind Moltbook: Anthropic Safety is Always Vanishing in Self-Evolving AI Societies",
    "authors": "Chenxu Wang Chaozhuo Li Songyang Liu Zejian Chen Jinyu Hou Ji Qi Rui Li Litian Zhang Qiwei Ye Zheng Liu Xu Chen Xi Zhang Philip S. Yu",
    "abstract": "Multi-agent LLM systems face fundamental limitations in achieving continuous self-improvement while maintaining safety alignment due to inherent statistical blind spots in isolated evolution. The emergence of multi-agent systems built from large language models (LLMs) offers a promising paradigm for scalable collective intelligence and self-evolution . Ideally, such systems would achieve continuous self-improvement in a fully closed loop while maintaining robust safety alignment --a combination we term the self-evolution trilemma. However, we demonstrate both theoretically and empirically that an agent society satisfying continuous self-evolution , complete isolation, and safety invariance is impossible. Drawing on an information-theoretic framework , we formalize safety as the divergence degree from anthropic value distributions . We theoretically demonstrate that isolated self-evolution induces statistical blind spots , leading to the irreversible degradation of the system's safety alignment . Empirical and qualitative results from an open-ended agent community (Moltbook) and two closed self-evolving systems reveal phenomena that align with our theoretical prediction of inevitable safety erosion. We further propose several solution directions to alleviate the identified safety concern. Our work establishes a fundamental limit on the self-evolving AI societies and shifts the discourse from symptom-driven safety patches to a principled understanding of intrinsic dynamical risks, highlighting the need for external oversight or novel safety-preserving mechanisms .",
    "summary_en": "Multi-agent LLM systems face fundamental limitations in achieving continuous self-improvement while maintaining safety alignment due to inherent statistical blind spots in isolated evolution.",
    "summary_zh": "多智能体LLM系统因孤立进化中的固有统计盲区，在实现持续自我改进的同时保持安全对齐方面面临根本性局限。",
    "upvotes": 187
  },
  {
    "id": "2602.12036",
    "date": "2026-02-13",
    "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models",
    "authors": "Xin Xu Clive Bai Kai Yang Tianhao Chen Yangkun Chen Weijie Liu Hao Chen Yang Wang Saiyong Yang Can Yang",
    "abstract": "Composition-RL improves reasoning capabilities by automatically composing multiple problems into new verifiable questions for reinforcement learning training. Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.",
    "summary_en": "Composition-RL improves reasoning capabilities by automatically composing multiple problems into new verifiable questions for reinforcement learning training.",
    "summary_zh": "Composition-RL 通过自动将多个问题组合为新的可验证问题以进行强化学习训练，从而提升推理能力。",
    "upvotes": 91
  },
  {
    "id": "2602.12205",
    "date": "2026-02-13",
    "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
    "authors": "Dianyi Wang Ruihang Li Feng Han Chaofan Ma Wei Song Siyuan Wang Yibin Wang Yi Xin Hongjian Liu Zhixiong Zhang Shengyuan Ding Tianhang Wang Zhenglin Cheng Tao Lin Cheng Jin Kaicheng Yu Jingjing Chen Wenjie Wang Zhongyu Wei Jiaqi Wang",
    "abstract": "A lightweight 5B unified multimodal model achieves competitive performance through hierarchical feature extraction, learnable think tokens, and progressive training strategies including alignment pre-training, joint supervised fine-tuning, and reinforcement learning with MR-GRPO. Current unified multimodal models for image generation and editing typically rely on massive parameter scale s (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable ' think tokens ' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations , (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO , which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences , while maintaining stable training progress and avoiding visual artifacts . Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.",
    "summary_en": "A lightweight 5B unified multimodal model achieves competitive performance through hierarchical feature extraction, learnable think tokens, and progressive training strategies including alignment pre-training, joint supervised fine-tuning, and reinforcement learning with MR-GRPO.",
    "summary_zh": "一款轻量级的5B统一多模态模型通过分层特征提取、可学习思考token以及包括对齐预训练、联合监督微调和MR-GRPO强化学习在内的渐进式训练策略，实现了具有竞争力的性能。",
    "upvotes": 77
  },
  {
    "id": "2602.12125",
    "date": "2026-02-13",
    "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation",
    "authors": "Wenkai Yang Weijie Liu Ruobing Xie Kai Yang Saiyong Yang Yankai Lin",
    "abstract": "On-policy distillation is extended through a generalized framework that introduces flexible reference models and reward scaling factors, demonstrating improved performance through reward extrapolation and reward correction techniques. On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation ), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings . In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.",
    "summary_en": "On-policy distillation is extended through a generalized framework that introduces flexible reference models and reward scaling factors, demonstrating improved performance through reward extrapolation and reward correction techniques.",
    "summary_zh": "在线策略蒸馏通过引入灵活参考模型和奖励缩放因子的广义框架实现扩展，并结合奖励外推与奖励修正技术展现出性能提升。",
    "upvotes": 57
  },
  {
    "id": "2602.12099",
    "date": "2026-02-13",
    "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
    "authors": "GigaBrain Team Boyuan Wang Chaojun Ni Guan Huang Guosheng Zhao Hao Li Jie Li Jindi Lv Jingyu Liu Lv Feng Mingming Yu Peng Li Qiuping Deng Tianze Liu Xinyu Zhou Xinze Chen Xiaofeng Wang Yang Wang Yifan Li Yifei Nie Yilong Li Yukun Zhou",
    "abstract": "A vision-language-action model enhanced with world model-based reinforcement learning demonstrates improved performance and long-horizon execution capabilities for robotic manipulation tasks. Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose GigaBrain-0.5M*, a VLA model trained via world model-based reinforcement learning . Built upon GigaBrain-0.5, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark . GigaBrain-0.5M* further integrates world model-based reinforcement learning via RAMP ( Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation . Empirical results demonstrate that RAMP achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including Laundry Folding, Box Packing, and Espresso Preparation. Critically, GigaBrain-0.5M^* exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our https://gigabrain05m.github.io{project page}.",
    "summary_en": "A vision-language-action model enhanced with world model-based reinforcement learning demonstrates improved performance and long-horizon execution capabilities for robotic manipulation tasks.",
    "summary_zh": "通过基于世界模型的强化学习增强的视觉-语言-动作模型，在机器人操作任务中展现出更优的性能和长时程执行能力。",
    "upvotes": 55
  },
  {
    "id": "2602.10934",
    "date": "2026-02-13",
    "title": "MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models",
    "authors": "Yitian Gong Kuangwei Chen Zhaoye Fei Xiaogui Yang Ke Chen Yang Wang Kexin Huang Mingshu Chen Ruixiao Li Qingyuan Cheng Shimin Li Xipeng Qiu",
    "abstract": "A fully end-to-end Transformer-based audio tokenizer architecture achieves high-fidelity reconstruction across diverse audio domains and enables superior text-to-speech and automatic speech recognition performance. Discrete audio tokenizers are fundamental to empowering large language models with native audio processing and generation capabilities. Despite recent progress, existing approaches often rely on pretrained encoder s, semantic distillation , or heterogeneous CNN-based architectures . These designs introduce fixed inductive biases that limit reconstruction fidelity and hinder effective scaling. In this paper, we argue that discrete audio tokenization should be learned fully end-to-end using a homogeneous and scalable architecture. To this end, we first propose CAT ( Causal Audio Tokenizer with Transformer), a purely Transformer-based architecture that jointly optimizes the encoder , quantizer , and decoder from scratch for high-fidelity reconstruction. Building on the CAT architecture, we develop MOSS-Audio-Tokenizer, a large-scale audio tokenizer featuring 1.6 billion parameters, pre-trained on 3 million hours of diverse, general audio data. We show that this simple, fully end-to-end approach built from homogeneous, causal Transformer blocks scales gracefully and supports high-fidelity reconstruction across diverse audio domains. Across speech, sound, and music, MOSS-Audio-Tokenizer consistently outperforms prior codec s over a wide range of bitrates, while exhibiting predictable improvements with increased scale. Notably, leveraging the discrete tokens from our model, we develop the first purely autoregressive TTS model that surpasses prior non-autoregressive and cascaded systems. Furthermore, MOSS-Audio-Tokenizer enables competitive ASR performance without auxiliary encoder s. Our findings position the CAT architecture as a unified, scalable interface for the next generation of native audio foundation models.",
    "summary_en": "A fully end-to-end Transformer-based audio tokenizer architecture achieves high-fidelity reconstruction across diverse audio domains and enables superior text-to-speech and automatic speech recognition performance.",
    "summary_zh": "完全端到端的Transformer音频分词器架构可在多种音频领域实现高保真重建，并带来更优的文本转语音与自动语音识别性能。",
    "upvotes": 49
  },
  {
    "id": "2602.09070",
    "date": "2026-02-13",
    "title": "NarraScore: Bridging Visual Narrative and Musical Dynamics via Hierarchical Affective Control",
    "authors": "Yufan Wen Zhaocheng Liu YeGuo Hua Ziyi Guo Lihua Zhang Chun Yuan Jian Wu",
    "abstract": "NarraScore presents a hierarchical framework that uses frozen Vision-Language Models as affective sensors to generate coherent soundtracks for long-form videos by combining global semantic anchors with token-level adaptive modulation. Synthesizing coherent soundtracks for long-form videos remains a formidable challenge, currently stalled by three critical impediments: computational scalability, temporal coherence, and, most critically, a pervasive semantic blindness to evolving narrative logic. To bridge these gaps, we propose NarraScore, a hierarchical framework predicated on the core insight that emotion serves as a high-density compression of narrative logic. Uniquely, we repurpose frozen Vision-Language Models (VLMs) as continuous affective sensors, distilling high-dimensional visual streams into dense, narrative-aware Valence-Arousal trajectories . Mechanistically, NarraScore employs a Dual-Branch Injection strategy to reconcile global structure with local dynamism: a Global Semantic Anchor ensures stylistic stability, while a surgical Token-Level Affective Adapter modulates local tension via direct element-wise residual injection . This minimalist design bypasses the bottlenecks of dense attention and architectural cloning, effectively mitigating the overfitting risks associated with data scarcity. Experiments demonstrate that NarraScore achieves state-of-the-art consistency and narrative alignment with negligible computational overhead, establishing a fully autonomous paradigm for long-video soundtrack generation.",
    "summary_en": "NarraScore presents a hierarchical framework that uses frozen Vision-Language Models as affective sensors to generate coherent soundtracks for long-form videos by combining global semantic anchors with token-level adaptive modulation.",
    "summary_zh": "NarraScore提出了一种层次化框架，利用冻结的视觉-语言模型作为情感传感器，结合全局语义锚点与token级自适应调制，为长视频生成连贯音轨。",
    "upvotes": 43
  },
  {
    "id": "2602.12056",
    "date": "2026-02-13",
    "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
    "authors": "Xinyu Yang Chenlong Deng Tongyu Wen Binyu Xie Zhicheng Dou",
    "abstract": "LawThinker is an autonomous legal research agent that uses an Explore-Verify-Memorize strategy with a DeepVerifier module to ensure accurate and procedurally compliant legal reasoning through dynamic verification of intermediate steps. Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments . The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy , fact-law relevance , and procedural compliance , with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .",
    "summary_en": "LawThinker is an autonomous legal research agent that uses an Explore-Verify-Memorize strategy with a DeepVerifier module to ensure accurate and procedurally compliant legal reasoning through dynamic verification of intermediate steps.",
    "summary_zh": "LawThinker是一种自主法律研究智能体，采用Explore-Verify-Memorize策略并配备DeepVerifier模块，通过动态验证中间步骤来确保法律推理的准确性与程序合规性。",
    "upvotes": 33
  },
  {
    "id": "2602.11731",
    "date": "2026-02-13",
    "title": "Thinking with Drafting: Optical Decompression via Logical Reconstruction",
    "authors": "Jingxuan Wei Honghao He Caijun Jia Siyuan Li Zheng Sun Yuhang Xu Yuanyuan Lin Linzhuang Sun Yuchen Wu Bihui Yu Xiangxiang Zhang Cheng Tan",
    "abstract": "Visual reasoning is enhanced by reconstructing logical structures from compressed visual tokens through a DSL-based approach that generates deterministic visual proofs for verification. Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation . However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology , while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression -the process of reconstructing latent logical structures from compressed visual tokens . Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark . Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning .",
    "summary_en": "Visual reasoning is enhanced by reconstructing logical structures from compressed visual tokens through a DSL-based approach that generates deterministic visual proofs for verification.",
    "summary_zh": "通过基于DSL的方法从压缩视觉token重建逻辑结构，并生成确定性视觉证明以验证，从而增强视觉推理。",
    "upvotes": 32
  },
  {
    "id": "2602.11748",
    "date": "2026-02-13",
    "title": "Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning",
    "authors": "Futing Wang Jianhao Yan Yun Luo Ganqu Cui Zhi Wang Xiaoye Qu Yue Zhang Yu Cheng Tao Lin",
    "abstract": "Models require in-context exploration capabilities to scale effectively at test time, but autoregressive generation faces exponential decay in sampling long sequences, which is addressed by a length-incentivized exploration method that improves performance on both in-domain and out-of-domain tasks. Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context. Grounded in State Coverage theory , our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation , a phenomenon we term the `` Shallow Exploration Trap ''. To bridge this gap, we propose Length-Incentivized Exploration (\\method). This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty , thereby maximizing state coverage in two-step manner. Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \\method effectively incentivize in-context exploration . As a result, our method achieves an average improvement of 4.4\\% on in-domain tasks and a 2.7\\% gain on out-of-domain benchmarks.",
    "summary_en": "Models require in-context exploration capabilities to scale effectively at test time, but autoregressive generation faces exponential decay in sampling long sequences, which is addressed by a length-incentivized exploration method that improves performance on both in-domain and out-of-domain tasks.",
    "summary_zh": "模型需要上下文探索能力以在测试时有效扩展，但自回归生成在采样长序列时面临指数级衰减，长度激励探索方法解决了该问题，并在领域内与领域外任务上均提升了性能。",
    "upvotes": 30
  },
  {
    "id": "2602.12280",
    "date": "2026-02-13",
    "title": "Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching",
    "authors": "Huai-Hsun Cheng Siang-Ling Zhang Yu-Lun Liu",
    "abstract": "Progressive Semantic Illusions use a generative framework with dual-branch Score Distillation Sampling to create vector sketches that transform semantically through sequential stroke additions, achieving superior recognizability and illusion strength. Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise , a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the \"dual-constraint\": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a \"common structural subspace \" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/",
    "summary_en": "Progressive Semantic Illusions use a generative framework with dual-branch Score Distillation Sampling to create vector sketches that transform semantically through sequential stroke additions, achieving superior recognizability and illusion strength.",
    "summary_zh": "渐进式语义幻觉采用双分支分数蒸馏采样的生成框架，通过顺序添加笔画创建语义变换的矢量草图，实现了更优的可识别性和幻觉强度。",
    "upvotes": 29
  },
  {
    "id": "2602.11075",
    "date": "2026-02-13",
    "title": "RISE: Self-Improving Robot Policy with Compositional World Model",
    "authors": "Jiazhi Yang Kunyang Lin Jinwei Li Wencong Zhang Tianwei Lin Longyan Wu Zhizhong Su Hao Zhao Ya-Qin Zhang Li Chen Ping Luo Xiangyu Yue Hongyang Li",
    "abstract": "RISE is a robotic reinforcement learning framework that uses a compositional world model to predict multi-view futures and evaluate imagined outcomes, enabling policy improvement through virtual interactions rather than physical trials. Despite the sustained scaling on model capacity and data acquisition, Vision-Language-Action (VLA) models remain brittle in contact-rich and dynamic manipulation tasks, where minor execution deviations can compound into failures. While reinforcement learning (RL) offers a principled path to robustness, on-policy RL in the physical world is constrained by safety risk, hardware cost, and environment reset. To bridge this gap, we present RISE, a scalable framework of robotic reinforcement learning via imagination. At its core is a Compositional World Model that (i) predicts multi-view future via a controllable dynamics model , and (ii) evaluates imagined outcomes with a progress value model , producing informative advantages for the policy improvement . Such compositional design allows state and value to be tailored by best-suited yet distinct architectures and objectives. These components are integrated into a closed-loop self-improving pipeline that continuously generates imaginary rollouts , estimates advantages, and updates the policy in imaginary space without costly physical interaction. Across three challenging real-world tasks, RISE yields significant improvement over prior art, with more than +35% absolute performance increase in dynamic brick sorting, +45% for backpack packing, and +35% for box closing, respectively.",
    "summary_en": "RISE is a robotic reinforcement learning framework that uses a compositional world model to predict multi-view futures and evaluate imagined outcomes, enabling policy improvement through virtual interactions rather than physical trials.",
    "summary_zh": "RISE是一种机器人强化学习框架，利用组合式世界模型预测多视角未来并评估想象结果，通过虚拟交互而非物理试验实现策略改进。",
    "upvotes": 28
  },
  {
    "id": "2602.09021",
    "date": "2026-02-13",
    "title": "χ_{0}: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies",
    "authors": "Checheng Yu Chonghao Sima Gangcheng Jiang Hai Zhang Haoguang Mai Hongyang Li Huijie Wang Jin Chen Kaiyang Wu Li Chen Lirui Zhao Modi Shi Ping Luo Qingwen Bu Shijia Peng Tianyu Li Yibo Yuan",
    "abstract": "A resource-efficient robotic manipulation framework addresses distributional shifts through model arithmetic, stage-aware advantage estimation, and train-deploy alignment to achieve long-horizon task reliability. High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy , and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose χ_{0}, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation . Our approach builds off three technical pillars: (i) Model Arithmetic , a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment , which bridges the distribution gap via spatio-temporal augmentation , heuristic DAgger corrections , and temporal chunk-wise smoothing . χ_{0} enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that χ_{0} surpasses the state-of-the-art π_{0.5} in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.",
    "summary_en": "A resource-efficient robotic manipulation framework addresses distributional shifts through model arithmetic, stage-aware advantage estimation, and train-deploy alignment to achieve long-horizon task reliability.",
    "summary_zh": "一种资源高效的机器人操作框架通过模型算术、阶段感知优势估计与训练-部署对齐应对分布偏移，实现长时程任务可靠性。",
    "upvotes": 25
  },
  {
    "id": "2602.12153",
    "date": "2026-02-13",
    "title": "dVoting: Fast Voting for dLLMs",
    "authors": "Sicheng Feng Zigeng Chen Xinyin Ma Gongfan Fang Xinchao Wang",
    "abstract": "Diffusion large language models enable parallel token generation and efficient reasoning enhancement through a voting technique that identifies and refines uncertain predictions across multiple samples. Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling , offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling , which was previously constrained by severe inefficiency in autoregressive modeling . In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis , regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting",
    "summary_en": "Diffusion large language models enable parallel token generation and efficient reasoning enhancement through a voting technique that identifies and refines uncertain predictions across multiple samples.",
    "summary_zh": "扩散大语言模型通过一种投票技术实现并行token生成与高效推理增强，该技术可识别并优化多个样本中的不确定预测。",
    "upvotes": 20
  },
  {
    "id": "2602.10106",
    "date": "2026-02-13",
    "title": "EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration",
    "authors": "Modi Shi Shijia Peng Jin Chen Haoran Jiang Yinghui Li Di Huang Ping Luo Hongyang Li Li Chen",
    "abstract": "EgoHumanoid enables humanoid loco-manipulation through co-training vision-language-action policies using egocentric human demonstrations and limited robot data, addressing embodiment gaps via view and action alignment techniques. Human demonstrations offer rich environmental diversity and scale naturally, making them an appealing alternative to robot teleoperation. While this paradigm has advanced robot-arm manipulation, its potential for the more challenging, data-hungry problem of humanoid loco-manipulation remains largely unexplored. We present EgoHumanoid, the first framework to co-train a vision-language-action policy using abundant egocentric human demonstrations together with a limited amount of robot data, enabling humanoids to perform loco-manipulation across diverse real-world environments. To bridge the embodiment gap between humans and robots, including discrepancies in physical morphology and viewpoint, we introduce a systematic alignment pipeline spanning from hardware design to data processing. A portable system for scalable human data collection is developed, and we establish practical collection protocols to improve transferability. At the core of our human-to-humanoid alignment pipeline lies two key components. The view alignment reduces visual domain discrepancies caused by camera height and perspective variation. The action alignment maps human motions into a unified, kinematically feasible action space for humanoid control. Extensive real-world experiments demonstrate that incorporating robot-free egocentric data significantly outperforms robot-only baselines by 51\\%, particularly in unseen environments. Our analysis further reveals which behaviors transfer effectively and the potential for scaling human data.",
    "summary_en": "EgoHumanoid enables humanoid loco-manipulation through co-training vision-language-action policies using egocentric human demonstrations and limited robot data, addressing embodiment gaps via view and action alignment techniques.",
    "summary_zh": "EgoHumanoid 利用第一人称视角人类演示和有限的机器人数据联合训练视觉-语言-动作策略，实现人形机器人移动操作，并通过视角与动作对齐技术解决具身差距。",
    "upvotes": 20
  },
  {
    "id": "2602.05827",
    "date": "2026-02-13",
    "title": "Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation",
    "authors": "Hai Zhang Siqi Liang Li Chen Yuxian Li Yukuan Xu Yichao Zhong Fu Zhang Hongyang Li",
    "abstract": "Vision-language navigation systems traditionally require detailed instructions but can be improved by incorporating video generation models with sparse future planning for faster, more efficient real-world deployment. Why must vision-language navigation be bound to detailed and verbose language instructions? While such details ease decision-making, they fundamentally contradict the goal for navigation in the real-world. Ideally, agents should possess the autonomy to navigate in unknown environments guided solely by simple and high-level intents. Realizing this ambition introduces a formidable challenge: Beyond-the-View Navigation (BVN), where agents must locate distant, unseen targets without dense and step-by-step guidance. Existing large language model (LLM)-based methods, though adept at following dense instructions, often suffer from short-sighted behaviors due to their reliance on short-horimzon supervision. Simply extending the supervision horizon, however, destabilizes LLM training. In this work, we identify that video generation models inherently benefit from long-horizon supervision to align with language instructions, rendering them uniquely suitable for BVN tasks. Capitalizing on this insight, we propose introducing the video generation model into this field for the first time. Yet, the prohibitive latency for generating videos spanning tens of seconds makes real-world deployment impractical. To bridge this gap, we propose SparseVideoNav, achieving sub-second trajectory inference guided by a generated sparse future spanning a 20-second horizon. This yields a remarkable 27x speed-up compared to the unoptimized counterpart. Extensive real-world zero-shot experiments demonstrate that SparseVideoNav achieves 2.5x the success rate of state-of-the-art LLM baselines on BVN tasks and marks the first realization of such capability in challenging night scenes.",
    "summary_en": "Vision-language navigation systems traditionally require detailed instructions but can be improved by incorporating video generation models with sparse future planning for faster, more efficient real-world deployment.",
    "summary_zh": "视觉语言导航系统传统上需要详细指令，但可以通过结合视频生成模型与稀疏未来规划来改进，以实现更快、更高效的真实世界部署。",
    "upvotes": 18
  },
  {
    "id": "2602.11298",
    "date": "2026-02-13",
    "title": "Voxtral Realtime",
    "authors": "Alexander H. Liu Andy Ehrenberg Andy Lo Chen-Yo Sun Guillaume Lample Jean-Malo Delignon Khyathi Raghavi Chandu Patrick von Platen Pavankumar Reddy Muddireddy Rohin Arora Sanchit Gandhi Sandeep Subramanian Soham Ghosh Srijan Mishra Abhinav Rastogi Alan Jeffares Albert Jiang Alexandre Sablayrolles Amélie Héliou Andrew Bai Angele Lenglemetz Anmol Agarwal",
    "abstract": "Voxtral Realtime is a streaming speech recognition model trained end-to-end for sub-second latency with performance matching offline systems. We introduce Voxtral Realtime, a natively streaming automatic speech recognition model that matches offline transcription quality at sub-second latency . Unlike approaches that adapt offline models through chunking or sliding windows, Voxtral Realtime is trained end-to-end for streaming , with explicit alignment between audio and text streams. Our architecture builds on the Delayed Streams Modeling framework, introducing a new causal audio encoder and Ada RMS-Norm for improved delay conditioning. We scale pretraining to a large-scale dataset spanning 13 languages. At a delay of 480ms, Voxtral Realtime achieves performance on par with Whisper, the most widely deployed offline transcription system. We release the model weights under the Apache 2.0 license.",
    "summary_en": "Voxtral Realtime is a streaming speech recognition model trained end-to-end for sub-second latency with performance matching offline systems.",
    "summary_zh": "Voxtral Realtime是端到端训练的流式语音识别模型，具有亚秒级延迟，性能与离线系统相当。",
    "upvotes": 15
  },
  {
    "id": "2602.12092",
    "date": "2026-02-13",
    "title": "DeepSight: An All-in-One LM Safety Toolkit",
    "authors": "Bo Zhang Jiaxuan Guo Lijun Li Dongrui Liu Sujin Chen Guanxu Chen Zhijie Zheng Qihao Lin Lewen Yan Chen Qian Yijin Zhou Yuyao Wu Shaoxiong Guo Tianyi Du Jingyi Yang Xuhao Hu Ziqi Miao Xiaoya Lu Jing Shao Xia Hu",
    "abstract": "DeepSight is an open-source project that integrates safety evaluation and diagnosis for large language and multimodal models, enabling white-box insights through unified protocols and specialized toolkits. As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation -diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan . By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.",
    "summary_en": "DeepSight is an open-source project that integrates safety evaluation and diagnosis for large language and multimodal models, enabling white-box insights through unified protocols and specialized toolkits.",
    "summary_zh": "DeepSight 是一个开源项目，集成了大语言模型和多模态模型的安全性评估与诊断，通过统一协议和专用工具包实现白盒洞察。",
    "upvotes": 13
  },
  {
    "id": "2602.11964",
    "date": "2026-02-13",
    "title": "Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments",
    "authors": "Romain Froger Pierre Andrews Matteo Bettini Amar Budhiraja Ricardo Silveira Cabral Virginie Do Emilien Garreau Jean-Baptiste Gaya Hugo Laurençon Maxime Lecanu Kunal Malkan Dheeraj Mekala Pierre Ménard Gerard Moreno-Torres Bertran Ulyana Piterbarg Mikhail Plekhanov Mathieu Rita Andrey Rusakov Vladislav Vorotilov Mengjue Wang Ian Yu Amine Benhalloum",
    "abstract": "Gaia2 presents a benchmark for evaluating large language model agents in asynchronous, dynamic environments with temporal constraints and multi-agent collaboration, featuring a write-action verifier for reinforcement learning and revealing trade-offs between reasoning, efficiency, and robustness. We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments . Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints , adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier , enabling fine-grained, action-level evaluation and making Gaia2 directly usable for reinforcement learning from verifiable rewards . Our evaluation of state-of-the-art proprietary and open-source models shows that no model dominates across capabilities: GPT-5 (high) reaches the strongest overall score of 42% pass@1 but fails on time-sensitive tasks, Claude-4 Sonnet trades accuracy and speed for cost, Kimi-K2 leads among open-source models with 21% pass@1 . These results highlight fundamental trade-offs between reasoning, efficiency, robustness, and expose challenges in closing the \"sim2real\" gap. Gaia2 is built on a consumer environment with the open-source Agents Research Environments platform and designed to be easy to extend. By releasing Gaia2 alongside the foundational ARE framework, we aim to provide the community with a flexible infrastructure for developing, benchmarking, and training the next generation of practical agent systems.",
    "summary_en": "Gaia2 presents a benchmark for evaluating large language model agents in asynchronous, dynamic environments with temporal constraints and multi-agent collaboration, featuring a write-action verifier for reinforcement learning and revealing trade-offs between reasoning, efficiency, and robustness.",
    "summary_zh": "Gaia2提出了一个基准测试，用于评估大语言模型智能体在具有时间约束的异步动态多智能体协作环境中的表现，配备了用于强化学习的写动作验证器，并揭示了推理、效率与鲁棒性之间的权衡。",
    "upvotes": 12
  },
  {
    "id": "2602.11733",
    "date": "2026-02-13",
    "title": "Adapting Vision-Language Models for E-commerce Understanding at Scale",
    "authors": "Matteo Nulli Vladimir Orshulevich Tala Bazazo Christian Herold Michael Kozielski Marcin Mazur Szymon Tuzel Cees G. M. Snoek Seyyed Hadi Hashemi Omar Javed Yannick Versley Shahram Khadivi",
    "abstract": "General-purpose Vision-Language Models can be effectively adapted for e-commerce applications through targeted techniques that enhance product understanding while maintaining broad multimodal capabilities. E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling , yet there is no documented, well-known strategy for adapting them to the attribute-centric , multi-image , and noisy nature of e-commerce data , without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding , strict instruction following , and dynamic attribute extraction .",
    "summary_en": "General-purpose Vision-Language Models can be effectively adapted for e-commerce applications through targeted techniques that enhance product understanding while maintaining broad multimodal capabilities.",
    "summary_zh": "通用视觉-语言模型可通过针对性技术有效适配电子商务应用，在增强商品理解的同时保持广泛的多模态能力。",
    "upvotes": 12
  },
  {
    "id": "2602.08277",
    "date": "2026-02-13",
    "title": "PISCO: Precise Video Instance Insertion with Sparse Control",
    "authors": "Xiangbo Gao Renjie Li Xinghao Chen Yuheng Wu Suofei Feng Qing Yin Zhengzhong Tu",
    "abstract": "Video diffusion model PISCO enables precise instance insertion with sparse keyframe control through variable-information guidance and distribution-preserving temporal masking. The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering and \"cherry-picking\" - towards fine-grained, controllable generation and high-fidelity post-processing. In professional AI-assisted filmmaking, it is crucial to perform precise, targeted modifications. A cornerstone of this transition is video instance insertion , which requires inserting a specific instance into existing footage while maintaining scene integrity. Unlike traditional video editing , this task demands several requirements: precise spatial-temporal placement , physically consistent scene interaction, and the faithful preservation of original dynamics - all achieved under minimal user effort. In this paper, we propose PISCO, a video diffusion model for precise video instance insertion with arbitrary sparse keyframe control . PISCO allows users to specify a single keyframe, start-and-end keyframes, or sparse keyframes at arbitrary timestamps, and automatically propagates object appearance, motion, and interaction. To address the severe distribution shift induced by sparse conditioning in pretrained video diffusion model s, we introduce Variable-Information Guidance for robust conditioning and Distribution-Preserving Temporal Masking to stabilize temporal generation , together with geometry-aware conditioning for realistic scene adaptation. We further construct PISCO-Bench, a benchmark with verified instance annotations and paired clean background videos, and evaluate performance using both reference-based and reference-free perceptual metrics. Experiments demonstrate that PISCO consistently outperforms strong inpainting and video editing baselines under sparse control, and exhibits clear, monotonic performance improvements as additional control signals are provided. Project page: xiangbogaobarry.github.io/PISCO.",
    "summary_en": "Video diffusion model PISCO enables precise instance insertion with sparse keyframe control through variable-information guidance and distribution-preserving temporal masking.",
    "summary_zh": "视频扩散模型PISCO通过可变信息引导和分布保持的时间掩码，实现了基于稀疏关键帧控制的精确实例插入。",
    "upvotes": 11
  },
  {
    "id": "2602.05548",
    "date": "2026-02-13",
    "title": "Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation",
    "authors": "Zhiqi Yu Zhangquan Chen Mengting Liu Heye Zhang Liangqiong Qu",
    "abstract": "Asymmetric Group Relative Advantage Estimation addresses exploration and difficulty adaptation challenges in reinforcement learning with large language models by dynamically modulating exploration incentives and sample difficulty focus.",
    "summary_en": "Asymmetric Group Relative Advantage Estimation addresses exploration and difficulty adaptation challenges in reinforcement learning with large language models by dynamically modulating exploration incentives and sample difficulty focus.",
    "summary_zh": "非对称组相对优势估计通过动态调节探索激励和样本难度聚焦，解决大语言模型强化学习中的探索与难度适应挑战。",
    "upvotes": 11
  },
  {
    "id": "2602.12262",
    "date": "2026-02-13",
    "title": "T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization",
    "authors": "Tunyu Zhang Xinxi Zhang Ligong Han Haizhou Shi Xiaoxiao He Zhuowei Li Hao Wang Kai Xu Akash Srivastava Vladimir Pavlovic Dimitris N. Metaxas",
    "abstract": "A trajectory self-distillation framework with direct discriminative optimization improves few-step decoding efficiency in diffusion large language models while maintaining generation quality. Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories . We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.",
    "summary_en": "A trajectory self-distillation framework with direct discriminative optimization improves few-step decoding efficiency in diffusion large language models while maintaining generation quality.",
    "summary_zh": "轨迹自蒸馏框架结合直接判别优化，在保持生成质量的同时提升扩散大语言模型的少步解码效率。",
    "upvotes": 8
  },
  {
    "id": "2602.12176",
    "date": "2026-02-13",
    "title": "Single-minus gluon tree amplitudes are nonzero",
    "authors": "Alfredo Guevara Alexandru Lupsasca David Skinner Andrew Strominger Kevin Weil",
    "abstract": "Single-minus tree-level n-gluon scattering amplitudes are reconsidered. Often presumed to vanish, they are shown here to be nonvanishing for certain \"half-collinear\" configurations existing in Klein space or for complexified momenta. We derive a piecewise-constant closed-form expression for the decay of a single minus-helicity gluon into n-1 plus-helicity gluons as a function of their momenta. This formula nontrivially satisfies multiple consistency conditions including Weinberg's soft theorem.",
    "summary_en": "Single-minus tree-level n-gluon scattering amplitudes, often presumed to vanish, are shown to be nonvanishing for \"half-collinear\" configurations in Klein space or for complexified momenta. The authors derive a piecewise-constant closed-form expression for the decay of a single minus-helicity gluon into n-1 plus-helicity gluons as a function of their momenta. This formula nontrivially satisfies multiple consistency conditions including Weinberg's soft theorem.",
    "summary_zh": "通常被认为消失的单负号树图级n胶子散射振幅，在Klein空间的“半共线”构型或复化动量下被证明非零。作者推导出了单负螺旋度胶子衰变为n-1个正螺旋度胶子的分段常数闭式表达式，该式是这些胶子动量的函数。该公式非平凡地满足包括Weinberg软定理在内的多种一致性条件。",
    "upvotes": 7
  },
  {
    "id": "2602.11683",
    "date": "2026-02-13",
    "title": "ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces",
    "authors": "Xin Xu Tong Yu Xiang Chen Haoliang Wang Julian McAuley Saayan Mitra",
    "abstract": "ThinkRouter is a confidence-aware routing mechanism that improves reasoning efficiency by switching between discrete token and latent spaces based on model confidence, achieving better accuracy and faster generation. Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in a latent space , yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, ThinkRouter , an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. ThinkRouter routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that ThinkRouter outperforms explicit CoT , random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1 , while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that ThinkRouter can calibrate errors arising from explicit CoT and latent reasoning , and accelerates end-of-thinking token generation by globally lowering model confidence .",
    "summary_en": "ThinkRouter is a confidence-aware routing mechanism that improves reasoning efficiency by switching between discrete token and latent spaces based on model confidence, achieving better accuracy and faster generation.",
    "summary_zh": "ThinkRouter是一种置信度感知的路由机制，通过基于模型置信度在离散token空间与隐空间之间切换来提高推理效率，实现更高的准确率和更快的生成速度。",
    "upvotes": 7
  },
  {
    "id": "2602.07885",
    "date": "2026-02-13",
    "title": "MemFly: On-the-Fly Memory Optimization via Information Bottleneck",
    "authors": "Zhenyuan Zhang Xianzhang Jia Zhiqin Yang Zhenbo Song Wei Xue Sirui Han Yike Guo",
    "abstract": "MemFly addresses the challenge of long-term memory in language models by using information bottleneck principles to create an adaptive memory structure with hybrid retrieval mechanisms for improved task performance. Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minimizes compression entropy while maximizing relevance entropy via a gradient-free optimizer, constructing a stratified memory structure for efficient storage. To fully leverage MemFly, we develop a hybrid retrieval mechanism that seamlessly integrates semantic, symbolic, and topological pathways, incorporating iterative refinement to handle complex multi-hop queries. Comprehensive experiments demonstrate that MemFly substantially outperforms state-of-the-art baselines in memory coherence , response fidelity , and accuracy.",
    "summary_en": "MemFly addresses the challenge of long-term memory in language models by using information bottleneck principles to create an adaptive memory structure with hybrid retrieval mechanisms for improved task performance.",
    "summary_zh": "MemFly利用信息瓶颈原理构建具有混合检索机制的自适应记忆结构，解决语言模型的长期记忆挑战并提升任务性能。",
    "upvotes": 7
  },
  {
    "id": "2602.11761",
    "date": "2026-02-13",
    "title": "MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling",
    "authors": "MiniCPM Team Wenhao An Yingfa Chen Yewei Fang Jiayi Li Xin Li Yaohui Li Yishan Li Yuxuan Li Biyuan Lin Chuan Liu Hezi Liu Siyuan Liu Hongya Lyu Yinxu Pan Shixin Ren Xingyu Shen Zhou Su Haojun Sun Yangang Sun Zhen Leng Thai Xin Tian",
    "abstract": "MiniCPM-SALA combines sparse and linear attention mechanisms in a hybrid architecture to enable efficient processing of ultra-long contexts while maintaining model performance and reducing training costs. The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture . While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.",
    "summary_en": "MiniCPM-SALA combines sparse and linear attention mechanisms in a hybrid architecture to enable efficient processing of ultra-long contexts while maintaining model performance and reducing training costs.",
    "summary_zh": "MiniCPM-SALA采用混合架构结合稀疏与线性注意力机制，以高效处理超长上下文，同时保持模型性能并降低训练成本。",
    "upvotes": 6
  },
  {
    "id": "2602.08194",
    "date": "2026-02-13",
    "title": "Dreaming in Code for Curriculum Learning in Open-Ended Worlds",
    "authors": "Konstantinos Mitsides Maxence Faldor Antoine Cully",
    "abstract": "Foundation models generate executable environment code to scaffold learning progress in open-ended worlds, enabling agents to acquire long-horizon skills through curriculum control. Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for agents to discover sequences of experiences that remain consistently learnable. To address this, we propose Dreaming in Code (DiCode), a framework in which foundation models synthesize executable environment code to scaffold learning toward increasing competence. In DiCode, \"dreaming\" takes the form of materializing code-level variations of the world. We instantiate DiCode in Craftax, a challenging open-ended benchmark characterized by rich mechanics and long-horizon progression . Empirically, DiCode enables agents to acquire long-horizon skills, achieving a 16% improvement in mean return over the strongest baseline and non-zero success on late-game combat tasks where prior methods fail. Our results suggest that code-level environment design provides a practical mechanism for curriculum control , enabling the construction of intermediate environments that bridge competence gaps in open-ended worlds. Project page and source code are available at https://konstantinosmitsides.github.io/dreaming-in-code and https://github.com/konstantinosmitsides/dreaming-in-code.",
    "summary_en": "Foundation models generate executable environment code to scaffold learning progress in open-ended worlds, enabling agents to acquire long-horizon skills through curriculum control.",
    "summary_zh": "基础模型生成可执行环境代码，在开放世界中为学习进程搭建脚手架，使智能体通过课程控制习得长程技能。",
    "upvotes": 6
  },
  {
    "id": "2602.11337",
    "date": "2026-02-13",
    "title": "MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation",
    "authors": "Yejin Kim Wilbert Pumacay Omar Rayyan Max Argus Winson Han Eli VanderBilt Jordi Salvador Abhay Deshpande Rose Hendrix Snehal Jauhri Shuo Liu Nur Muhammad Mahi Shafiullah Maya Guru Ainaz Eftekhar Karen Farley Donovan Clay Jiafei Duan Arjun Guru Piper Wolters Alvaro Herrasti Ying-Chun Lee Georgia Chalvatzaki",
    "abstract": "MolmoSpaces presents an open ecosystem with diverse indoor environments and annotated objects for large-scale robot policy benchmarking across multiple tasks and simulators. Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of generalization requires infrastructure at a scale and diversity that physical evaluation alone cannot provide. We introduce MolmoSpaces, a fully open ecosystem to support large-scale benchmarking of robot policies . MolmoSpaces consists of over 230k diverse indoor environments, ranging from handcrafted household scenes to procedurally generated multiroom houses, populated with 130k richly annotated object assets, including 48k manipulable objects with 42M stable grasps. Crucially, these environments are simulator-agnostic, supporting popular options such as MuJoCo, Isaac, and ManiSkill. The ecosystem supports the full spectrum of embodied tasks : static and mobile manipulation, navigation, and multiroom long-horizon tasks requiring coordinated perception, planning, and interaction across entire indoor environments. We also design MolmoSpaces-Bench, a benchmark suite of 8 tasks in which robots interact with our diverse scenes and richly annotated objects. Our experiments show MolmoSpaces-Bench exhibits strong sim-to-real correlation (R = 0.96, ho = 0.98), confirm newer and stronger zero-shot policies outperform earlier versions in our benchmarks, and identify key sensitivities to prompt phrasing , initial joint positions , and camera occlusion . Through MolmoSpaces and its open-source assets and tooling, we provide a foundation for scalable data generation, policy training, and benchmark creation for robot learning research.",
    "summary_en": "MolmoSpaces presents an open ecosystem with diverse indoor environments and annotated objects for large-scale robot policy benchmarking across multiple tasks and simulators.",
    "summary_zh": "MolmoSpaces 提供了一个包含多样化室内环境与标注物体的开放生态系统，用于跨多任务和模拟器的大规模机器人策略基准测试。",
    "upvotes": 5
  },
  {
    "id": "2602.12164",
    "date": "2026-02-13",
    "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision",
    "authors": "Xiaohan He Shiyang Feng Songtao Huang Lei Bai Bin Wang Bo Zhang",
    "abstract": "Sci-CoE is a two-stage scientific co-evolving framework that enables large language models to self-evolve as both solver and verifier through sparse-to-unsupervised learning transitions, improving scientific reasoning capabilities and evaluation system robustness. Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning . In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier . In the second stage, we introduce a geometric reward mechanism that jointly considers consensus , reliability , and diversity , driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability , facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.",
    "summary_en": "Sci-CoE is a two-stage scientific co-evolving framework that enables large language models to self-evolve as both solver and verifier through sparse-to-unsupervised learning transitions, improving scientific reasoning capabilities and evaluation system robustness.",
    "summary_zh": "Sci-CoE是一种两阶段科学协同进化框架，通过从稀疏到无监督学习的过渡，使大型语言模型能够同时作为求解器和验证器进行自我进化，从而提升科学推理能力和评估系统的鲁棒性。",
    "upvotes": 4
  },
  {
    "id": "2602.12116",
    "date": "2026-02-13",
    "title": "P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling",
    "authors": "Pinyi Zhang Ting-En Lin Yuchuan Wu Jingyang Chen Zongqi Wang Hua Yang Ze Xu Fei Huang Kai Zhang Yongbin Li",
    "abstract": "Personalized generative reward models address challenges in adapting language model responses to individual user preferences by using structured evaluation chains and dual-granularity scaling mechanisms for improved generalization and accuracy. Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning . A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling . P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset . Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.",
    "summary_en": "Personalized generative reward models address challenges in adapting language model responses to individual user preferences by using structured evaluation chains and dual-granularity scaling mechanisms for improved generalization and accuracy.",
    "summary_zh": "个性化生成式奖励模型通过结构化评估链与双粒度缩放机制，解决语言模型响应适配个体用户偏好的挑战，以提升泛化能力与准确性。",
    "upvotes": 4
  },
  {
    "id": "2602.11543",
    "date": "2026-02-13",
    "title": "Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm",
    "authors": "Jinrui Zhang Chaodong Xiao Aoqi Wu Xindong Zhang Lei Zhang",
    "abstract": "A memory-efficient decentralized framework for training mixture-of-experts language models using sparse expert synchronization and expert-merging warm-up strategies. Pretraining large language models (LLMs) typically requires centralized clusters with thousands of high-memory GPUs (e.g., H100/A100). Recent decentralized training methods reduce communication overhead by employing federated optimization ; however, they still need to train the entire model on each node, remaining constrained by GPU memory limitations. In this work, we propose SParse Expert Synchronization (SPES), a memory-efficient decentralized framework for pretraining mixture-of-experts (MoE) LLMs. SPES trains only a subset of experts per node, substantially lowering the memory footprint. Each node updates its local experts and periodically synchronizes with other nodes, eliminating full-parameter transmission while ensuring efficient knowledge sharing. To accelerate convergence, we introduce an expert-merging warm-up strategy, where experts exchange knowledge early in training, to rapidly establish foundational capabilities. With SPES, we train a 2B-parameter MoE LLM using 16 standalone 48GB GPUs over internet connections, which achieves competitive performance with centrally trained LLMs under similar computational budgets. We further demonstrate scalability by training a 7B model from scratch and a 9B model upcycled from a dense checkpoint, both of which match prior centralized baselines. Our code is available at https://github.com/zjr2000/SPES.",
    "summary_en": "A memory-efficient decentralized framework for training mixture-of-experts language models using sparse expert synchronization and expert-merging warm-up strategies.",
    "summary_zh": "一种基于稀疏专家同步和专家合并预热策略的内存高效去中心化框架，用于训练混合专家语言模型。",
    "upvotes": 4
  },
  {
    "id": "2602.11509",
    "date": "2026-02-13",
    "title": "Multimodal Fact-Level Attribution for Verifiable Reasoning",
    "authors": "David Wan Han Wang Ziyang Wang Elias Stengel-Eskin Hyunji Lee Mohit Bansal",
    "abstract": "MuRGAt is a benchmark for evaluating fact-level multimodal attribution in complex reasoning tasks, requiring models to provide precise citations for their answers across video, audio, and other modalities. Multimodal large language models (MLLMs) are increasingly used for real-world tasks involving multi-step reasoning and long-form generation, where reliability requires grounding model outputs in heterogeneous input sources and verifying individual factual claims. However, existing multimodal grounding benchmarks and evaluation methods focus on simplified, observation-based scenarios or limited modalities and fail to assess attribution in complex multimodal reasoning . We introduce MuRGAt ( Multimodal Reasoning with Grounded Attribution), a benchmark for evaluating fact-level multimodal attribution in settings that require reasoning beyond direct observation. Given inputs spanning video, audio, and other modalities, MuRGAt requires models to generate answers with explicit reasoning and precise citations, where each citation specifies both modality and temporal segments. To enable reliable assessment, we introduce an automatic evaluation framework that strongly correlates with human judgments. Benchmarking with human and automated scores reveals that even strong MLLMs frequently hallucinate citations despite correct reasoning. Moreover, we observe a key trade-off: increasing reasoning depth or enforcing structured grounding often degrades accuracy, highlighting a significant gap between internal reasoning and verifiable attribution.",
    "summary_en": "MuRGAt is a benchmark for evaluating fact-level multimodal attribution in complex reasoning tasks, requiring models to provide precise citations for their answers across video, audio, and other modalities.",
    "summary_zh": "MuRGAt是一个用于评估复杂推理任务中事实级多模态归因的基准，要求模型在视频、音频及其他模态中为答案提供精确引用。",
    "upvotes": 4
  },
  {
    "id": "2602.10575",
    "date": "2026-02-13",
    "title": "MetaphorStar: Image Metaphor Understanding and Reasoning with End-to-End Visual Reinforcement Learning",
    "authors": "Chenhao Zhang Yazhe Niu Hongsheng Li",
    "abstract": "MetaphorStar, an end-to-end visual reinforcement learning framework, significantly enhances metaphor comprehension in images through a specialized dataset, RL method, and benchmark, achieving state-of-the-art performance on multiple visual reasoning tasks. Metaphorical comprehension in images remains a critical challenge for Nowadays AI systems. While Multimodal Large Language Models (MLLMs) excel at basic Visual Question Answering (VQA), they consistently struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. This difficulty stems from the task's demand for sophisticated multi-hop reasoning, cultural context, and Theory of Mind (ToM) capabilities, which current models lack. To fill this gap, we propose MetaphorStar, the first end-to-end visual reinforcement learning (RL) framework for image implication tasks . Our framework includes three core components: the fine-grained dataset TFQ-Data, the visual RL method TFQ-GRPO, and the well-structured benchmark TFQ-Bench. Our fully open-source MetaphorStar family, trained using TFQ-GRPO on TFQ-Data, significantly improves performance by an average of 82.6% on the image implication benchmark s. Compared with 20+ mainstream MLLMs, MetaphorStar-32B achieves state-of-the-art (SOTA) on Multiple-Choice Question and Open-Style Question, significantly outperforms the top closed-source model Gemini-3.0-pro on True-False Question. Crucially, our experiments reveal that learning image implication tasks improves the general understanding ability, especially the complex visual reasoning ability. We further provide a systematic analysis of model parameter scaling , training data scaling , and the impact of different model architectures and training strategies , demonstrating the broad applicability of our method. We open-sourced all model weights, datasets, and method code at https://metaphorstar.github.io.",
    "summary_en": "MetaphorStar, an end-to-end visual reinforcement learning framework, significantly enhances metaphor comprehension in images through a specialized dataset, RL method, and benchmark, achieving state-of-the-art performance on multiple visual reasoning tasks.",
    "summary_zh": "MetaphorStar是一种端到端视觉强化学习框架，通过专门的数据集、RL方法和基准，显著提升了图像隐喻理解能力，在多个视觉推理任务上取得最先进的性能。",
    "upvotes": 4
  },
  {
    "id": "2602.12203",
    "date": "2026-02-13",
    "title": "ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images",
    "authors": "Mathieu Sibue Andres Muñoz Garza Samuel Mensah Pranav Shetty Zhiqiang Ma Xiaomo Liu Manuela Veloso",
    "abstract": "A new benchmark dataset called ExStrucTiny is introduced for structured information extraction from document images, addressing limitations of existing datasets and evaluating vision-language models on diverse document types and flexible schemas.",
    "summary_en": "A new benchmark dataset called ExStrucTiny is introduced for structured information extraction from document images, addressing limitations of existing datasets and evaluating vision-language models on diverse document types and flexible schemas.",
    "summary_zh": "研究提出名为ExStrucTiny的新基准数据集，用于文档图像结构化信息抽取，解决现有数据集局限，并在多样化文档类型与灵活schema上评估视觉-语言模型。",
    "upvotes": 3
  },
  {
    "id": "2602.11541",
    "date": "2026-02-13",
    "title": "Budget-Constrained Agentic Large Language Models: Intention-Based Planning for Costly Tool Use",
    "authors": "Hanbing Liu Chunhao Tian Nan An Ziyuan Wang Pinyan Lu Changyuan Yu Qi Qi",
    "abstract": "Budget-constrained tool-augmented agents use a hierarchical world model and intent-aware planning to optimize multi-step task completion under monetary constraints. We study budget-constrained tool-augmented agents , where a large language model must solve multi-step tasks by invoking external tools under a strict monetary budget. We formalize this setting as sequential decision making in context space with priced and stochastic tool executions , making direct planning intractable due to massive state-action spaces, high variance of outcomes and prohibitive exploration cost. To address these challenges, we propose INTENT, an inference-time planning framework that leverages an intention-aware hierarchical world model to anticipate future tool usage, risk-calibrated cost , and guide decisions online. Across cost-augmented StableToolBench, INTENT strictly enforces hard budget feasibility while substantially improving task success over baselines, and remains robust under dynamic market shifts such as tool price changes and varying budgets.",
    "summary_en": "Budget-constrained tool-augmented agents use a hierarchical world model and intent-aware planning to optimize multi-step task completion under monetary constraints.",
    "summary_zh": "预算受限的工具增强型智能体利用分层世界模型和意图感知规划，在资金约束下优化多步任务完成。",
    "upvotes": 3
  },
  {
    "id": "2602.11792",
    "date": "2026-02-13",
    "title": "Detecting RLVR Training Data via Structural Convergence of Reasoning",
    "authors": "Hongbo Zhang Yue Yang Jianhao Yan Guangsheng Bao Yue Zhang",
    "abstract": "Reinforcement learning with verifiable rewards induces behavioral signatures that can be detected using a black-box method based on prompt generation diversity, outperforming existing contamination detection approaches. Reinforcement learning with verifiable rewards (RLVR) is central to training modern reasoning models, but the undisclosed training data raises concerns about benchmark contamination. Unlike pretraining methods, which optimize models using token-level probabilities, RLVR fine-tunes models based on reward feedback from self-generated reasoning trajectories , making conventional likelihood-based detection methods less effective. We show that RLVR induces a distinctive behavioral signature : prompts encountered during RLVR training result in more rigid and similar generations, while unseen prompts retain greater diversity. We introduce Min-kNN Distance , a simple black-box detector that quantifies this collapse by sampling multiple completions for a given prompt and computing the average of the k smallest nearest-neighbor edit distances. Min-kNN Distance requires no access to the reference model or token probabilities. Experiments across multiple RLVR-trained reasoning models show that Min-kNN Distance reliably distinguishes RL-seen examples from unseen ones and outperforms existing membership inference and RL contamination detection baselines.",
    "summary_en": "Reinforcement learning with verifiable rewards induces behavioral signatures that can be detected using a black-box method based on prompt generation diversity, outperforming existing contamination detection approaches.",
    "summary_zh": "基于可验证奖励的强化学习诱导出的行为特征可通过基于提示生成多样性的黑盒方法检测，性能优于现有的污染检测方法。",
    "upvotes": 2
  },
  {
    "id": "2602.11636",
    "date": "2026-02-13",
    "title": "ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning",
    "authors": "Changti Wu Jiahuai Mao Yuzhuo Miao Shijie Lian Bin Yu Xiaopeng Lin Cong Huang Lei Zhang Kai Chen",
    "abstract": "ScalSelect is a scalable training-free method for selecting representative multimodal data that achieves near-full-dataset performance with significantly reduced computational requirements. Large-scale Visual Instruction Tuning (VIT) has become a key paradigm for advancing the performance of vision-language models (VLMs) across various multimodal tasks. However, training on the large-scale datasets is computationally expensive and inefficient due to redundancy in the data, which motivates the need for multimodal data selection to improve training efficiency. Existing data selection methods for VIT either require costly training or gradient computation. Training-free alternatives often depend on proxy models or datasets, instruction-agnostic representations, and pairwise similarity with quadratic complexity, limiting scalability and representation fidelity. In this work, we propose ScalSelect, a scalable training-free multimodal data selection method with linear-time complexity with respect to the number of samples, eliminating the need for external models or auxiliary datasets. ScalSelect first constructs sample representations by extracting visual features most attended by instruction tokens in the target VLM, capturing instruction-relevant information. It then identifies samples whose representations best approximate the dominant subspace of the full dataset representations, enabling scalable importance scoring without pairwise comparisons. Extensive experiments across multiple VLMs, datasets, and selection budgets demonstrate that ScalSelect achieves over 97.5% of the performance of training on the full dataset using only 16% of the data, and even outperforms full-data training in some settings. The code is available at https://github.com/ChangtiWu/ScalSelect{ScalSelect}.",
    "summary_en": "ScalSelect is a scalable training-free method for selecting representative multimodal data that achieves near-full-dataset performance with significantly reduced computational requirements.",
    "summary_zh": "ScalSelect是一种可扩展的免训练方法，用于选择代表性多模态数据，能够在显著降低计算需求的同时达到接近完整数据集的性能。",
    "upvotes": 2
  },
  {
    "id": "2602.11598",
    "date": "2026-02-13",
    "title": "ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation",
    "authors": "Zedong Chu Shichao Xie Xiaolong Wu Yanfen Shen Minghua Luo Zhengbo Wang Fei Liu Xiaoxu Leng Junjun Hu Mingyang Yin Jia Lu Yingnan Guo Kai Yang Jiawei Han Xu Chen Yanqing Zhu Yuxiang Zhao Xin Liu Yirong Yang Ye He Jiahang Wang Yang Cai",
    "abstract": "A unified Vision-Language-Action model with a hierarchical architecture combining semantic reasoning and continuous trajectory generation achieves state-of-the-art performance across multiple embodied navigation tasks. Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation. To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 km^2). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory , enabling robust, long-horizon missions in dynamic real-world environments.",
    "summary_en": "A unified Vision-Language-Action model with a hierarchical architecture combining semantic reasoning and continuous trajectory generation achieves state-of-the-art performance across multiple embodied navigation tasks.",
    "summary_zh": "一种具有分层架构、结合语义推理与连续轨迹生成的统一视觉-语言-动作模型，在多个具身导航任务中达到了最先进的性能。",
    "upvotes": 2
  },
  {
    "id": "2602.10585",
    "date": "2026-02-13",
    "title": "Neural Additive Experts: Context-Gated Experts for Controllable Model Additivity",
    "authors": "Guangzhi Xiong Sanchit Sinha Aidong Zhang",
    "abstract": "Neural Additive Experts combines multiple specialized networks with a dynamic gating mechanism to balance predictive accuracy and feature interpretability in machine learning models. The trade-off between interpretability and accuracy remains a core challenge in machine learning. Standard Generalized Additive Models (GAMs) offer clear feature attributions but are often constrained by their strictly additive nature, which can limit predictive performance. Introducing feature interactions can boost accuracy yet may obscure individual feature contributions. To address these issues, we propose Neural Additive Experts (NAEs), a novel framework that seamlessly balances interpretability and accuracy. NAEs employ a mixture of experts framework , learning multiple specialized networks per feature, while a dynamic gating mechanism integrates information across features, thereby relaxing rigid additive constraints. Furthermore, we propose targeted regularization techniques to mitigate variance among expert predictions, facilitating a smooth transition from an exclusively additive model to one that captures intricate feature interactions while maintaining clarity in feature attributions . Our theoretical analysis and experiments on synthetic data illustrate the model's flexibility, and extensive evaluations on real-world datasets confirm that NAEs achieve an optimal balance between predictive accuracy and transparent, feature-level explanations. The code is available at https://github.com/Teddy-XiongGZ/NAE.",
    "summary_en": "Neural Additive Experts combines multiple specialized networks with a dynamic gating mechanism to balance predictive accuracy and feature interpretability in machine learning models.",
    "summary_zh": "神经可加专家结合多个专用网络与动态门控机制，以平衡机器学习模型中的预测准确性与特征可解释性。",
    "upvotes": 2
  },
  {
    "id": "2602.09891",
    "date": "2026-02-13",
    "title": "Stemphonic: All-at-once Flexible Multi-stem Music Generation",
    "authors": "Shih-Lun Wu Ge Zhu Juan-Pablo Caceres Cheng-Zhi Anna Huang Nicholas J. Bryan",
    "abstract": "Stemphonic is a diffusion- and flow-based framework that generates variable sets of synchronized musical stems in single inference passes, improving both quality and efficiency over existing methods. Music stem generation , the task of producing musically-synchronized and isolated instrument audio clips, offers the potential of greater user control and better alignment with musician workflows compared to conventional text-to-music models. Existing stem generation approaches, however, either rely on fixed architectures that output a predefined set of stems in parallel, or generate only one stem at a time, resulting in slow inference despite flexibility in stem combination. We propose Stemphonic, a diffusion-/flow-based framework that overcomes this trade-off and generates a variable set of synchronized stems in one inference pass. During training, we treat each stem as a batch element, group synchronized stems in a batch, and apply a shared noise latent to each group. At inference-time, we use a shared initial noise latent and stem-specific text inputs to generate synchronized multi-stem outputs in one pass. We further expand our approach to enable one-pass conditional multi-stem generation and stem-wise activity controls to empower users to iteratively generate and orchestrate the temporal layering of a mix. We benchmark our results on multiple open-source stem evaluation sets and show that Stemphonic produces higher-quality outputs while accelerating the full mix generation process by 25 to 50%. Demos at: https://stemphonic-demo.vercel.app.",
    "summary_en": "Stemphonic is a diffusion- and flow-based framework that generates variable sets of synchronized musical stems in single inference passes, improving both quality and efficiency over existing methods.",
    "summary_zh": "Stemphonic是一种基于扩散和流的框架，可在单次推理中生成可变数量的同步音乐分轨，在质量和效率上均优于现有方法。",
    "upvotes": 2
  },
  {
    "id": "2602.10604",
    "date": "2026-02-12",
    "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters",
    "authors": "Ailin Huang Ang Li Aobo Kong Bin Wang Binxing Jiao Bo Dong Bojun Wang Boyu Chen Brian Li Buyun Ma Chang Su Changxin Miao Changyi Wan Chao Lou Chen Hu Chen Xu Chenfeng Yu Chengting Feng Chengyuan Yao Chunrui Han Dan Ma Dapeng Shi",
    "abstract": "Step 3.5 Flash is a sparse Mixture-of-Experts model that achieves frontier-level agentic intelligence through efficient parameter utilization and optimized attention mechanisms, demonstrating strong performance across multiple benchmarks. We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/ full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback , while remaining stable under large-scale off-policy training , enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench , 86.4% on LiveCodeBench -v6 (2024.08-2025.05), 88.2% on tau2-Bench , 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.",
    "summary_en": "Step 3.5 Flash is a sparse Mixture-of-Experts model that achieves frontier-level agentic intelligence through efficient parameter utilization and optimized attention mechanisms, demonstrating strong performance across multiple benchmarks.",
    "summary_zh": "Step 3.5 Flash 是一种稀疏混合专家模型，通过高效的参数利用和优化的注意力机制实现了前沿水平的智能体智能，在多个基准测试中展现出强劲性能。",
    "upvotes": 176
  },
  {
    "id": "2602.08099",
    "date": "2026-02-12",
    "title": "VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval",
    "authors": "Issar Tzachor Dvir Samuel Rami Ben-Ari",
    "abstract": "Generative multimodal large language models are adapted for video-text embedding and retrieval through intermediate-layer analysis and text-based alignment without visual supervision. Recent studies have adapted generative Multimodal Large Language Models (MLLMs) into embedding extractors for vision tasks, typically through fine-tuning to produce universal representations. However, their performance on video remains inferior to Video Foundation Models (VFMs). In this paper, we focus on leveraging MLLMs for video-text embedding and retrieval. We first conduct a systematic layer-wise analysis, showing that intermediate (pre-trained) MLLM layers already encode substantial task-relevant information. Leveraging this insight, we demonstrate that combining intermediate-layer embeddings with a calibrated MLLM head yields strong zero-shot retrieval performance without any training. Building on these findings, we introduce a lightweight text-based alignment strategy which maps dense video captions to short summaries and enables task-related video-text embedding learning without visual supervision. Remarkably, without any fine-tuning beyond text, our method outperforms current methods, often by a substantial margin, achieving state-of-the-art results across common video retrieval benchmarks .",
    "summary_en": "Generative multimodal large language models are adapted for video-text embedding and retrieval through intermediate-layer analysis and text-based alignment without visual supervision.",
    "summary_zh": "生成式多模态大语言模型通过中间层分析与无视觉监督的文本对齐，适配于视频-文本嵌入与检索。",
    "upvotes": 120
  },
  {
    "id": "2602.11144",
    "date": "2026-02-12",
    "title": "GENIUS: Generative Fluid Intelligence Evaluation Suite",
    "authors": "Ruichuan An Sihan Yang Ziyu Guo Wei Dai Zijun Shen Haodong Li Renrui Zhang Xinyu Wei Guopeng Li Wenshan Wu Wentao Zhang",
    "abstract": "GENIUS evaluates multimodal models' generative fluid intelligence through pattern induction, constraint execution, and contextual adaptation tasks, revealing deficiencies in context comprehension rather than generative capability. Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess Crystallized Intelligence, which relies on recalling accumulated knowledge and learned schemas. This focus overlooks Generative Fluid Intelligence (GFI): the capacity to induce patterns, reason through constraints, and adapt to novel scenarios on the fly. To rigorously assess this capability, we introduce GENIUS (GEN Fluid Intelligence EvalUation Suite). We formalize GFI as a synthesis of three primitives. These include Inducing Implicit Patterns (e.g., inferring personalized visual preferences), Executing Ad-hoc Constraints (e.g., visualizing abstract metaphors), and Adapting to Contextual Knowledge (e.g., simulating counter-intuitive physics). Collectively, these primitives challenge models to solve problems grounded entirely in the immediate context. Our systematic evaluation of 12 representative models reveals significant performance deficits in these tasks. Crucially, our diagnostic analysis disentangles these failure modes. It demonstrates that deficits stem from limited context comprehension rather than insufficient intrinsic generative capability. To bridge this gap, we propose a training-free attention intervention strategy . Ultimately, GENIUS establishes a rigorous standard for GFI, guiding the field beyond knowledge utilization toward dynamic, general-purpose reasoning. Our dataset and code will be released at: https://github.com/arctanxarc/GENIUS{https://github.com/arctanxarc/GENIUS}.",
    "summary_en": "GENIUS evaluates multimodal models' generative fluid intelligence through pattern induction, constraint execution, and contextual adaptation tasks, revealing deficiencies in context comprehension rather than generative capability.",
    "summary_zh": "GENIUS通过模式归纳、约束执行和上下文适应任务评估多模态模型的生成流体智能，揭示了其在上下文理解而非生成能力方面的不足。",
    "upvotes": 53
  },
  {
    "id": "2602.11124",
    "date": "2026-02-12",
    "title": "PhyCritic: Multimodal Critic Models for Physical AI",
    "authors": "Tianyi Xiong Shihao Wang Guilin Liu Yi Dong Ming Li Heng Huang Jan Kautz Zhiding Yu",
    "abstract": "PhyCritic is a multimodal critic model designed for physical AI tasks through a two-stage RLVR pipeline that enhances perception and reasoning capabilities. With the rapid development of large multimodal models , reliable judge and critic models have become essential for open-ended evaluation and preference alignment, providing pairwise preferences, numerical scores, and explanatory justifications for assessing model-generated responses. However, existing critics are primarily trained in general visual domains such as captioning or image question answering, leaving physical AI tasks involving perception , causal reasoning , and planning largely underexplored. We introduce PhyCritic, a multimodal critic model optimized for physical AI through a two-stage RLVR pipeline : a physical skill warmup stage that enhances physically oriented perception and reasoning , followed by self-referential critic finetuning , where the critic generates its own prediction as an internal reference before judging candidate responses, improving judgment stability and physical correctness. Across both physical and general-purpose multimodal judge benchmarks, PhyCritic achieves strong performance gains over open-source baselines and, when applied as a policy model , further improves perception and reasoning in physically grounded tasks.",
    "summary_en": "PhyCritic is a multimodal critic model designed for physical AI tasks through a two-stage RLVR pipeline that enhances perception and reasoning capabilities.",
    "summary_zh": "PhyCritic是一款面向物理AI任务的多模态critic模型，通过两阶段RLVR流程增强感知与推理能力。",
    "upvotes": 50
  },
  {
    "id": "2602.04935",
    "date": "2026-02-12",
    "title": "ASA: Training-Free Representation Engineering for Tool-Calling Agents",
    "authors": "Youjin Wang Run Zhou Rong Fu Shuaishuai Cao Hongwei Zeng Jiaxuan Lu Sicheng Fan Jiaqiao Zhao Liangming Pan",
    "abstract": "A training-free method called Activation Steering Adapter corrects tool calling behavior in language models by using mid-layer activation interventions guided by a probe and router-conditioned steering vectors. Adapting LLM agents to domain-specific tool calling remains notably brittle under evolving interfaces. Prompt and schema engineering is easy to deploy but often fragile under distribution shift and strict parsers , while continual parameter-efficient fine-tuning improves reliability at the cost of training, maintenance, and potential forgetting. We identify a critical Lazy Agent failure mode where tool necessity is nearly perfectly decodable from mid-layer activations , yet the model remains conservative in entering tool mode, revealing a representation-behavior gap . We propose Activation Steering Adapter (ASA), a training-free, inference-time controller that performs a single-shot mid-layer intervention and targets tool domains via a router-conditioned mixture of steering vectors with a probe-guided signed gate to amplify true intent while suppressing spurious triggers. On MTU-Bench with Qwen2.5-1.5B , ASA improves strict tool-use F1 from 0.18 to 0.50 while reducing the false positive rate from 0.15 to 0.05, using only about 20KB of portable assets and no weight updates.",
    "summary_en": "A training-free method called Activation Steering Adapter corrects tool calling behavior in language models by using mid-layer activation interventions guided by a probe and router-conditioned steering vectors.",
    "summary_zh": "一种称为激活引导适配器的免训练方法，通过探针与路由条件引导向量对中间层激活进行干预，纠正语言模型的工具调用行为。",
    "upvotes": 39
  },
  {
    "id": "2602.10177",
    "date": "2026-02-12",
    "title": "Towards Autonomous Mathematics Research",
    "authors": "Tony Feng Trieu H. Trinh Garrett Bingham Dawsen Hwang Yuri Chervonyi Junehyuk Jung Joonkyung Lee Carlo Pagano Sang-hyun Kim Federico Pasqualotto Sergei Gukov Jonathan N. Lee Junsu Kim Kaiying Hou Golnaz Ghiasi Yi Tay YaGuang Li Chenkai Kuang Yuan Liu Hanzhao Lin Evan Zheran Liu",
    "abstract": "Aletheia, a math research agent, demonstrates advanced reasoning capabilities by generating and verifying solutions end-to-end in natural language, achieving autonomous research outcomes from Olympiad problems to PhD-level exercises and contributing to AI-assisted mathematical research. Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad . The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is powered by an advanced version of Gemini Deep Think for challenging reasoning problems, a novel inference-time scaling law that extends beyond Olympiad-level problems, and intensive tool use to navigate the complexities of mathematical research . We demonstrate the capability of Aletheia from Olympiad problems to PhD-level exercises and most notably, through several distinct milestones in AI-assisted mathematics research: (a) a research paper (Feng26) generated by AI without any human intervention in calculating certain structure constants in arithmetic geometry called eigenweights; (b) a research paper (LeeSeo26) demonstrating human-AI collaboration in proving bounds on systems of interacting particles called independent sets; and (c) an extensive semi-autonomous evaluation (Feng et al., 2026a) of 700 open problems on Bloom's Erdos Conjectures database, including autonomous solutions to four open questions. In order to help the public better understand the developments pertaining to AI and mathematics, we suggest codifying standard levels quantifying autonomy and novelty of AI-assisted results. We conclude with reflections on human-AI collaboration in mathematics.",
    "summary_en": "Aletheia, a math research agent, demonstrates advanced reasoning capabilities by generating and verifying solutions end-to-end in natural language, achieving autonomous research outcomes from Olympiad problems to PhD-level exercises and contributing to AI-assisted mathematical research.",
    "summary_zh": "Aletheia是一款数学研究智能体，通过端到端生成并验证自然语言解决方案展现先进推理能力，实现从奥林匹克竞赛题目到博士级别习题的自主研究成果，并为AI辅助数学研究做出贡献。",
    "upvotes": 35
  },
  {
    "id": "2602.10560",
    "date": "2026-02-12",
    "title": "When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning",
    "authors": "Leheng Sheng Yongtao Zhang Wenchang Ma Yaorui Shi Ting Huang Xiang Wang An Zhang Ke Shen Tat-Seng Chua",
    "abstract": "GRU-Mem addresses long-context reasoning challenges in LLMs by incorporating text-controlled gates and reinforcement learning rewards to stabilize memory updates and improve computational efficiency.",
    "summary_en": "GRU-Mem addresses long-context reasoning challenges in LLMs by incorporating text-controlled gates and reinforcement learning rewards to stabilize memory updates and improve computational efficiency.",
    "summary_zh": "GRU-Mem通过引入文本控制门控和强化学习奖励，解决大语言模型的长上下文推理挑战，稳定记忆更新并提升计算效率。",
    "upvotes": 28
  },
  {
    "id": "2602.10622",
    "date": "2026-02-12",
    "title": "How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning",
    "authors": "Jiahao Yuan Yike Xu Jinyong Wen Baokun Wang Yang Chen Xiaotong Lin Wuliang Huang Ziyi Gao Xing Fu Yu Cheng Weiqiang Wang",
    "abstract": "Research investigates the impact of different attention masking strategies on user embedding quality in decoder-only language models, proposing a gradient-guided soft masking technique to improve training stability and representation quality for user behavior analysis. Decoder-only large language models are increasingly used as behavioral encoders for user representation learning , yet the impact of attention masking on the quality of user embeddings remains underexplored. In this work, we conduct a systematic study of causal, hybrid, and bidirectional attention masks within a unified contrastive learning framework trained on large-scale real-world Alipay data that integrates long-horizon heterogeneous user behaviors. To improve training dynamics when transitioning from causal to bidirectional attention , we propose Gradient-Guided Soft Masking , a gradient-based pre-warmup applied before a linear scheduler that gradually opens future attention during optimization. Evaluated on 9 industrial user cognition benchmarks covering prediction, preference, and marketing sensitivity tasks, our approach consistently yields more stable training and higher-quality bidirectional representations compared with causal, hybrid, and scheduler-only baselines, while remaining compatible with decoder pretraining. Overall, our findings highlight the importance of masking design and training transition in adapting decoder-only LLMs for effective user representation learning . Our code is available at https://github.com/JhCircle/Deepfind-GGSM.",
    "summary_en": "Research investigates the impact of different attention masking strategies on user embedding quality in decoder-only language models, proposing a gradient-guided soft masking technique to improve training stability and representation quality for user behavior analysis.",
    "summary_zh": "研究探讨了不同注意力掩码策略对仅解码器语言模型中用户嵌入质量的影响，并提出了一种梯度引导的软掩码技术，以提升用户行为分析中的训练稳定性与表征质量。",
    "upvotes": 26
  },
  {
    "id": "2602.08711",
    "date": "2026-02-12",
    "title": "TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions",
    "authors": "Linli Yao Yuancheng Wei Yaojie Zhang Lei Li Xinlong Chen Feifan Song Ziyue Wang Kun Ouyang Yuanxin Liu Lingpeng Kong Qi Liu Pengfei Wan Kun Gai Yuanxing Zhang Xu Sun",
    "abstract": "Omni Dense Captioning introduces a six-dimensional structural schema for generating time-aware audio-visual narratives with explicit timestamps, along with a unified evaluation metric and strong baseline model.",
    "summary_en": "Omni Dense Captioning introduces a six-dimensional structural schema for generating time-aware audio-visual narratives with explicit timestamps, along with a unified evaluation metric and strong baseline model.",
    "summary_zh": "Omni Dense Captioning 提出了一种六维结构框架，用于生成带显式时间戳的时序感知视听叙事，并提供了统一的评估指标与强基线模型。",
    "upvotes": 26
  },
  {
    "id": "2602.08253",
    "date": "2026-02-12",
    "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design",
    "authors": "Baoyun Zhao He Wang Liang Zeng",
    "abstract": "A generative evolutionary framework extends large language models for automated design of large neighborhood search operators in combinatorial optimization problems. While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.",
    "summary_en": "A generative evolutionary framework extends large language models for automated design of large neighborhood search operators in combinatorial optimization problems.",
    "summary_zh": "生成式进化框架扩展大语言模型，用于组合优化问题中大邻域搜索算子的自动化设计。",
    "upvotes": 25
  },
  {
    "id": "2602.10224",
    "date": "2026-02-12",
    "title": "Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models",
    "authors": "Shiting Huang Zecheng Li Yu Zeng Qingnan Ren Zhen Fang Qisheng Su Kou Shi Lin Chen Zehui Chen Feng Zhao",
    "abstract": "Meta-Experience Learning enhances LLM reasoning by incorporating self-distilled error representations into parametric memory through contrastive trajectory analysis and language-modeled reward signals. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach for enhancing the reasoning capabilities of Large Language Models (LLMs). Despite its efficacy, RLVR faces a meta-learning bottleneck: it lacks mechanisms for error attribution and experience internalization intrinsic to the human learning cycle beyond practice and verification, thereby limiting fine-grained credit assignment and reusable knowledge formation. We term such reusable knowledge representations derived from past errors as meta-experience . Based on this insight, we propose Meta-Experience Learning (MEL), a novel framework that incorporates self-distilled meta-experience into the model's parametric memory . Building upon standard RLVR, we introduce an additional design that leverages the LLM's self-verification capability to conduct contrastive analysis on paired correct and incorrect trajectories, identify the precise bifurcation points where reasoning errors arise, and summarize them into generalizable meta-experience . The meta-experience is further internalized into the LLM's parametric memory by minimizing the negative log-likelihood , which induces a language-modeled reward signal that bridges correct and incorrect reasoning trajectories and facilitates effective knowledge reuse. Experimental results demonstrate that MEL achieves consistent improvements on benchmarks, yielding 3.92%--4.73% Pass@1 gains across varying model sizes.",
    "summary_en": "Meta-Experience Learning enhances LLM reasoning by incorporating self-distilled error representations into parametric memory through contrastive trajectory analysis and language-modeled reward signals.",
    "summary_zh": "元经验学习通过对比轨迹分析与语言建模的奖励信号，将自蒸馏错误表征纳入参数化记忆，从而增强大语言模型的推理能力。",
    "upvotes": 19
  },
  {
    "id": "2602.11089",
    "date": "2026-02-12",
    "title": "DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning",
    "authors": "Yicheng Chen Zerun Ma Xinchen Xie Yining Li Kai Chen",
    "abstract": "DataChef-32B automates data recipe generation for LLM adaptation through reinforcement learning with proxy rewards, achieving performance comparable to human-crafted recipes. In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the data recipe , which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipe s remains largely manual and labor-intensive, requiring substantial human expertise and iteration. To bridge this gap, we formulate end-to-end data recipe generation for LLM adaptation. Given a target benchmark and a pool of available data sources, a model is required to output a complete data recipe that adapts a base LLM to the target task. We present DataChef-32B, which performs online reinforcement learning using a proxy reward that predicts downstream performance for candidate recipes. Across six held-out tasks, DataChef-32B produces practical recipes that reach comparable downstream performance to those curated by human experts. Notably, the recipe from DataChef-32B adapts Qwen3-1.7B-Base to the math domain, achieving 66.7 on AIME'25 and surpassing Qwen3-1.7B. This work sheds new light on automating LLM training and developing self-evolving AI systems.",
    "summary_en": "DataChef-32B automates data recipe generation for LLM adaptation through reinforcement learning with proxy rewards, achieving performance comparable to human-crafted recipes.",
    "summary_zh": "DataChef-32B通过基于代理奖励的强化学习自动化生成用于LLM适配的数据配方，取得了与人工设计配方相当的性能。",
    "upvotes": 18
  },
  {
    "id": "2602.10975",
    "date": "2026-02-12",
    "title": "FeatureBench: Benchmarking Agentic Coding for Complex Feature Development",
    "authors": "Qixing Zhou Jiacheng Zhang Haiyang Wang Rui Hao Jiahe Wang Minghao Han Yuxue Yang Shuzhe Wu Feiyang Pan Lue Fan Dandan Tu Zhaoxiang Zhang",
    "abstract": "FeatureBench evaluates agentic coding performance in comprehensive feature-oriented development through execution-based assessments and automated task derivation from code repositories. Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e.g., bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the evaluation coverage. To address such issues, we propose FeatureBench, a benchmark designed to evaluate agentic coding performance in end-to-end, feature-oriented software development . FeatureBench incorporates an execution-based evaluation protocol and a scalable test-driven method that automatically derives tasks from code repositories with minimal human effort. By tracing from unit tests along a dependency graph , our approach can identify feature-level coding tasks spanning multiple commits and PRs scattered across the development timeline, while ensuring the proper functioning of other features after the separation. Using this framework, we curated 200 challenging evaluation tasks and 3825 executable environments from 24 open-source repositories in the first version of our benchmark. Empirical evaluation reveals that the state-of-the-art agentic model, such as Claude 4.5 Opus, which achieves a 74.4% resolved rate on SWE-bench, succeeds on only 11.0% of tasks, opening new opportunities for advancing agentic coding . Moreover, benefiting from our automated task collection toolkit, FeatureBench can be easily scaled and updated over time to mitigate data leakage . The inherent verifiability of constructed environments also makes our method potentially valuable for agent training .",
    "summary_en": "FeatureBench evaluates agentic coding performance in comprehensive feature-oriented development through execution-based assessments and automated task derivation from code repositories.",
    "summary_zh": "FeatureBench 通过基于执行的评估和从代码仓库自动派生任务，评估面向全面特性开发的智能体编码性能。",
    "upvotes": 18
  },
  {
    "id": "2602.11008",
    "date": "2026-02-12",
    "title": "ROCKET: Rapid Optimization via Calibration-guided Knapsack Enhanced Truncation for Efficient Model Compression",
    "authors": "Ammar Ali Baher Mohammad Denis Makhov Dmitriy Shopkhoev Magauiya Zhussip Stamatios Lefkimmiatis",
    "abstract": "ROCKET is a training-free model compression method that formulates layer-wise compression as a multi-choice knapsack problem and uses sparse matrix factorization for efficient weight sparsification without iterative optimization. We present ROCKET, a training-free model compression method that achieves state-of-the-art performance in comparison with factorization, structured-sparsification and dynamic compression baselines. Operating under a global compression budget, ROCKET comprises two key innovations: First, it formulates layer-wise compression allocation as a multi-choice knapsack problem , selecting the optimal compression level for each layer to minimize total reconstruction error while adhering to a target model size. Second, it introduces a single-step sparse matrix factorization inspired by dictionary learning : using only a small calibration set, it sparsifies weight coefficients based on activation-weights sensitivity and then updates the dictionary in closed form via least squares bypassing iterative optimization, sparse coding, or backpropagation entirely. ROCKET consistently outperforms existing compression approaches across different model architectures at 20-50\\% compression rates. Notably, it retains over 90\\% of the original model's performance at 30\\% compression without any fine-tuning . Moreover, when applying a light fine-tuning phase, recovery is substantially enhanced: for instance, compressing Qwen3-14B to an 8B-parameter model and healing it with just 30 million tokens yields performance nearly on par with the original Qwen3-8B. The code for ROCKET is at github.com/mts-ai/ROCKET/tree/main.",
    "summary_en": "ROCKET is a training-free model compression method that formulates layer-wise compression as a multi-choice knapsack problem and uses sparse matrix factorization for efficient weight sparsification without iterative optimization.",
    "summary_zh": "ROCKET是一种无需训练的模型压缩方法，将逐层压缩形式化为多选择背包问题，并利用稀疏矩阵分解实现高效的权重稀疏化，无需迭代优化。",
    "upvotes": 17
  },
  {
    "id": "2602.10609",
    "date": "2026-02-12",
    "title": "Online Causal Kalman Filtering for Stable and Effective Policy Optimization",
    "authors": "Shuo He Lang Feng Xin Cheng Lei Feng Bo An",
    "abstract": "Online Causal Kalman Filtering addresses high-variance token-level importance sampling in reinforcement learning for large language models by modeling IS ratios as evolving latent states and using Kalman filtering for stable policy optimization. Reinforcement learning for large language models suffers from high-variance token-level importance sampling (IS) ratios, which would destabilize policy optimization at scale. To improve stability, recent methods typically use a fixed sequence-level IS ratio for all tokens in a sequence or adjust each token's IS ratio separately, thereby neglecting temporal off-policy derivation across tokens in a sequence. In this paper, we first empirically identify that local off-policy deviation is structurally inconsistent at the token level, which may distort policy-gradient updates across adjacent tokens and lead to training collapse . To address the issue, we propose Online Causal Kalman Filter ing for stable and effective Policy Optimization (KPO). Concretely, we model the desired IS ratio as a latent state that evolves across tokens and apply a Kalman filter to update this state online and autoregressively based on the states of past tokens, regardless of future tokens. The resulting filtered IS ratios preserve token-wise local structure-aware variation while strongly smoothing noise spikes, yielding more stable and effective policy updates. Experimentally, KPO achieves superior results on challenging math reasoning datasets compared with state-of-the-art counterparts.",
    "summary_en": "Online Causal Kalman Filtering addresses high-variance token-level importance sampling in reinforcement learning for large language models by modeling IS ratios as evolving latent states and using Kalman filtering for stable policy optimization.",
    "summary_zh": "在线因果卡尔曼滤波通过将重要性采样比率建模为演化的隐状态，并利用卡尔曼滤波实现稳定的策略优化，解决了大语言模型强化学习中词元级重要性采样的高方差问题。",
    "upvotes": 16
  },
  {
    "id": "2602.11451",
    "date": "2026-02-12",
    "title": "LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation",
    "authors": "Ahmadreza Jeddi Marco Ciccone Babak Taati",
    "abstract": "LoopFormer is a looped Transformer architecture that enables adaptive computational depth through variable-length trajectory training and shortcut-consistency regularization, allowing flexible reasoning under different compute constraints. Looped Transformers have emerged as an efficient and powerful class of models for reasoning in the language domain. Recent studies show that these models achieve strong performance on algorithmic and reasoning tasks, suggesting that looped architectures possess an inductive bias toward latent reasoning . However, prior approaches fix the number of loop iterations during training and inference, leaving open the question of whether these models can flexibly adapt their computational depth under variable compute budgets . We introduce LoopFormer , a looped Transformer trained on variable-length trajectories to enable budget-conditioned reasoning . Our core contribution is a shortcut-consistency training scheme that aligns trajectories of different lengths, ensuring that shorter loops yield informative representations while longer loops continue to refine them. LoopFormer conditions each loop on the current time and step size, enabling representations to evolve consistently across trajectories of varying length rather than drifting or stagnating. Empirically, LoopFormer demonstrates robust performance on language modeling and reasoning benchmarks even under aggressive compute constraints, while scaling gracefully with additional budget. These results show that looped Transformers are inherently suited for adaptive language modeling , opening a path toward controllable and budget-aware large language models.",
    "summary_en": "LoopFormer is a looped Transformer architecture that enables adaptive computational depth through variable-length trajectory training and shortcut-consistency regularization, allowing flexible reasoning under different compute constraints.",
    "summary_zh": "LoopFormer是一种循环Transformer架构，通过变长度轨迹训练和捷径一致性正则化实现自适应计算深度，从而在不同计算约束下实现灵活推理。",
    "upvotes": 15
  },
  {
    "id": "2602.11103",
    "date": "2026-02-12",
    "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development",
    "authors": "Wayne Chi Yixiong Fang Arnav Yayavaram Siddharth Yayavaram Seth Karten Qiuhong Anna Wei Runkun Chen Alexander Wang Valerie Chen Ameet Talwalkar Chris Donahue",
    "abstract": "GameDevBench is introduced as the first benchmark for evaluating agents on game development tasks that combine software development complexity with deep multimodal understanding requirements. Despite rapid progress on coding agents , progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbed s that combine the complexity of software development with the need for deep multimodal understanding . Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visual game scene. We present GameDevBench , the first benchmark for evaluating agents on game development tasks. GameDevBench consists of 132 tasks derived from web and video tutorials . Tasks require significant multimodal understanding and are complex -- the average solution requires over three times the amount of lines of code and file changes compared to prior software development benchmarks. Agents still struggle with game development , with the best agent solving only 54.5% of tasks. We find a strong correlation between perceived task difficulty and multimodal complexity , with success rates dropping from 46.9% on gameplay-oriented tasks to 31.6% on 2D graphics tasks. To improve multimodal capability, we introduce two simple image and video-based feedback mechanisms for agents. Despite their simplicity, these methods consistently improve performance, with the largest change being an increase in Claude Sonnet 4.5's performance from 33.3% to 47.7%. We release GameDevBench publicly to support further research into agentic game development .",
    "summary_en": "GameDevBench is introduced as the first benchmark for evaluating agents on game development tasks that combine software development complexity with deep multimodal understanding requirements.",
    "summary_zh": "GameDevBench是首个用于评估智能体游戏开发任务的基准，该类任务结合了软件开发复杂性与深度多模态理解需求。",
    "upvotes": 14
  },
  {
    "id": "2602.12108",
    "date": "2026-02-12",
    "title": "The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context",
    "authors": "Xiaoyuan Liu Tian Liang Dongyang Ma Deyu Zhou Haitao Mi Pinjia He Yan Wang",
    "abstract": "StateLM enables language models to actively manage their own memory and context through internal reasoning loops and memory tools, significantly improving performance on long-document tasks and chat memory challenges.",
    "summary_en": "StateLM enables language models to actively manage their own memory and context through internal reasoning loops and memory tools, significantly improving performance on long-document tasks and chat memory challenges.",
    "summary_zh": "StateLM使语言模型能够通过内部推理循环和记忆工具主动管理自身记忆与上下文，显著提升在长文档任务和对话记忆挑战上的性能。",
    "upvotes": 13
  },
  {
    "id": "2602.10367",
    "date": "2026-02-12",
    "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation",
    "authors": "Zhiling Yan Dingjie Song Zhe Fang Yisheng Ji Xiang Li Quanzheng Li Lichao Sun",
    "abstract": "LiveMedBench addresses limitations in medical LLM evaluation by providing a continuously updated, contamination-free benchmark with rubric-based evaluation that better aligns with expert clinical reasoning. The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination , where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment , failing to capture the rapid evolution of medical knowledge. Furthermore, current evaluation metrics for open-ended clinical reasoning often rely on either shallow lexical overlap (e.g., ROUGE) or subjective LLM-as-a-Judge scoring, both inadequate for verifying clinical correctness. To bridge these gaps, we introduce LiveMedBench, a continuously updated, contamination-free, and rubric-based benchmark that weekly harvests real-world clinical cases from online medical communities, ensuring strict temporal separation from model training data. We propose a Multi-Agent Clinical Curation Framework that filters raw data noise and validates clinical integrity against evidence-based medical principles. For evaluation, we develop an Automated Rubric-based Evaluation Framework that decomposes physician responses into granular, case-specific criteria, achieving substantially stronger alignment with expert physicians than LLM-as-a-Judge. To date, LiveMedBench comprises 2,756 real-world cases spanning 38 medical specialties and multiple languages, paired with 16,702 unique evaluation criteria. Extensive evaluation of 38 LLMs reveals that even the best-performing model achieves only 39.2%, and 84% of models exhibit performance degradation on post-cutoff cases, confirming pervasive data contamination risks. Error analysis further identifies contextual application-not factual knowledge-as the dominant bottleneck, with 35-48% of failures stemming from the inability to tailor medical knowledge to patient-specific constraints.",
    "summary_en": "LiveMedBench addresses limitations in medical LLM evaluation by providing a continuously updated, contamination-free benchmark with rubric-based evaluation that better aligns with expert clinical reasoning.",
    "summary_zh": "LiveMedBench 通过提供持续更新、无污染的基准测试以及基于评分标准且契合专家临床推理的评估，解决医疗LLM评估的局限性。",
    "upvotes": 13
  },
  {
    "id": "2602.11149",
    "date": "2026-02-12",
    "title": "Data Repetition Beats Data Scaling in Long-CoT Supervised Fine-Tuning",
    "authors": "Dawid J. Kopiczko Sagar Vaze Tijmen Blankevoort Yuki M. Asano",
    "abstract": "Training reasoning language models with repeated examples on smaller datasets yields better performance than single-pass training on larger datasets, with token accuracy serving as a reliable indicator for optimal training duration. Supervised fine-tuning (SFT) on chain-of-thought data is an essential post-training step for reasoning language models . Standard machine learning intuition suggests that training with more unique training samples yields better generalization . Counterintuitively, we show that SFT benefits from repetition: under a fixed update budget, training for more epochs on smaller datasets outperforms single-epoch training on larger datasets. On AIME '24/25 and GPQA benchmarks, Olmo3-7B trained for 128 epochs on 400 samples outperforms the equivalent 1 epoch on 51200 samples by 12-26 percentage points, with no additional catastrophic forgetting . We find that training token accuracy reliably signals when repetition has saturated; improvements from additional epochs plateau at full memorization , a pattern consistent across all settings. These findings provide a practical approach for reasoning SFT, where scaling epochs with token accuracy as a stopping criterion can replace expensive undirected data scaling. We pose the repetition advantage, where full memorization coincides with improved generalization , as a new open problem for the community in understanding the training dynamics of large language models.",
    "summary_en": "Training reasoning language models with repeated examples on smaller datasets yields better performance than single-pass training on larger datasets, with token accuracy serving as a reliable indicator for optimal training duration.",
    "summary_zh": "在较小数据集上使用重复样本训练推理语言模型，其性能优于在更大数据集上进行单轮训练，且 token 准确率可作为确定最优训练时长的可靠指标。",
    "upvotes": 12
  },
  {
    "id": "2602.10231",
    "date": "2026-02-12",
    "title": "Blockwise Advantage Estimation for Multi-Objective RL with Verifiable Rewards",
    "authors": "Kirill Pavlenko Alexander Golubev Simon Karasik Boris Yangel",
    "abstract": "Blockwise Advantage Estimation addresses reward interference in structured generations by assigning separate advantages to different text blocks, using outcome-conditioned baselines to avoid expensive nested rollouts. Group Relative Policy Optimization (GRPO) assigns a single scalar advantage to all tokens in a completion. For structured generations with explicit segments and objectives, this couples unrelated reward signals across segments, leading to objective interference and misattributed credit. We propose Blockwise Advantage Estimation , a family of GRPO-compatible methods that assigns each objective its own advantage and applies it only to the tokens in the corresponding text block, reducing reliance on hand-designed scalar rewards and scaling naturally to additional objectives. A key challenge is estimating advantages for later blocks whose rewards are conditioned on sampled prefixes; standard unbiased approaches require expensive nested rollouts from intermediate states. Concretely, we introduce an Outcome-Conditioned Baseline that approximates intermediate state values using only within-group statistics by stratifying samples according to a prefix-derived intermediate outcome. On math tasks with uncertainty estimation, our method mitigates reward interference , is competitive with a state-of-the-art reward-designed approach, and preserves test-time gains from confidence-weighted ensembling . More broadly, it provides a modular recipe for optimizing sequential objectives in structured generations without additional rollouts.",
    "summary_en": "Blockwise Advantage Estimation addresses reward interference in structured generations by assigning separate advantages to different text blocks, using outcome-conditioned baselines to avoid expensive nested rollouts.",
    "summary_zh": "块级优势估计通过为不同文本块分配独立优势，并使用结果条件基线来避免昂贵的嵌套rollout，从而解决结构化生成中的奖励干扰问题。",
    "upvotes": 12
  },
  {
    "id": "2602.02192",
    "date": "2026-02-12",
    "title": "ECHO-2: A Large-Scale Distributed Rollout Framework for Cost-Efficient Reinforcement Learning",
    "authors": "Jie Xiao Meng Chen Qingnan Ren Jingwei Song Jiaqi Huang Yangshen Deng Chris Tong Wanyi Chen Suli Wang Ziqian Bi Shuo Lu Yiqun Duan Xu Wang Rymon Yu Ween Yang Lynn Ai Eric Yang Bill Shi Song Jingwei",
    "abstract": "ECHO-2 is a distributed reinforcement learning framework that enables efficient post-training of large language models by overlapping rollout generation, dissemination, and training while managing policy staleness and network latency. Reinforcement learning (RL) is a critical stage in post-training large language models (LLMs), involving repeated interaction between rollout generation , reward evaluation , and centralized learning . Distributing rollout execution offers opportunities to leverage more cost-efficient inference resources, but introduces challenges in wide-area coordination and policy dissemination. We present ECHO-2, a distributed RL framework for post-training with remote inference workers and non-negligible dissemination latency. ECHO-2 combines centralized learning with distributed rollouts and treats bounded policy staleness as a user-controlled parameter, enabling rollout generation , dissemination, and training to overlap. We introduce an overlap-based capacity model that relates training time, dissemination latency, and rollout throughput, yielding a practical provisioning rule for sustaining learner utilization. To mitigate dissemination bottlenecks and lower cost, ECHO-2 employs peer-assisted pipelined broadcast and cost-aware activation of heterogeneous workers. Experiments on GRPO post-training of 4B and 8B models under real wide-area bandwidth regimes show that ECHO-2 significantly improves cost efficiency while preserving RL reward comparable to strong baselines.",
    "summary_en": "ECHO-2 is a distributed reinforcement learning framework that enables efficient post-training of large language models by overlapping rollout generation, dissemination, and training while managing policy staleness and network latency.",
    "summary_zh": "ECHO-2是一种分布式强化学习框架，通过重叠rollout生成、分发与训练，并管理策略陈旧性和网络延迟，实现大语言模型的高效后训练。",
    "upvotes": 12
  },
  {
    "id": "2602.07106",
    "date": "2026-02-12",
    "title": "Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models",
    "authors": "Haoyu Zhang Zhipeng Li Yiwen Guo Tianshu Yu",
    "abstract": "Ex-Omni is an open-source framework that enhances omni-modal large language models with speech-accompanied 3D facial animation by decoupling semantic reasoning from temporal generation and using speech units as temporal scaffolding. Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult to optimize under limited data. We propose Expressive Omni (Ex-Omni), an open-source omni-modal framework that augments OLLMs with speech-accompanied 3D facial animation . Ex-Omni reduces learning difficulty by decoupling semantic reasoning from temporal generation , leveraging speech units as temporal scaffolding and a unified token-as-query gated fusion (TQGF) mechanism for controlled semantic injection. We further introduce InstructEx, a dataset aims to facilitate augment OLLMs with speech-accompanied 3D facial animation . Extensive experiments demonstrate that Ex-Omni performs competitively against existing open-source OLLMs while enabling stable aligned speech and facial animation generation.",
    "summary_en": "Ex-Omni is an open-source framework that enhances omni-modal large language models with speech-accompanied 3D facial animation by decoupling semantic reasoning from temporal generation and using speech units as temporal scaffolding.",
    "summary_zh": "Ex-Omni是一个开源框架，通过将语义推理与时序生成解耦，并使用语音单元作为时序支架，为全模态大语言模型增强伴随语音的3D面部动画能力。",
    "upvotes": 11
  },
  {
    "id": "2602.10999",
    "date": "2026-02-12",
    "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion",
    "authors": "Yusong Lin Haiyang Wang Shuzhe Wu Lue Fan Feiyang Pan Sanyuan Zhao Dandan Tu",
    "abstract": "CLI-Gym enables scalable derivation of environment-intensive tasks by simulating and exploring environment histories, while LiberCoder achieves significant performance improvements on Terminal-Bench through fine-tuning.",
    "summary_en": "CLI-Gym enables scalable derivation of environment-intensive tasks by simulating and exploring environment histories, while LiberCoder achieves significant performance improvements on Terminal-Bench through fine-tuning.",
    "summary_zh": "CLI-Gym通过模拟和探索环境历史，实现了环境密集型任务的可扩展推导；LiberCoder则通过在Terminal-Bench上进行微调，取得了显著的性能提升。",
    "upvotes": 10
  },
  {
    "id": "2602.09514",
    "date": "2026-02-12",
    "title": "EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies",
    "authors": "Xavier Hu Jinxiang Xia Shengze Xu Kangqi Song Yishuo Yuan Guibin Zhang JinCheng Ren Boyu Feng Li Lu Tieyong Zeng Jiaheng Liu Minghao Liu He Zhu Yuchen Eleanor Jiang Wei Wang Wangchunshu Zhou",
    "abstract": "EcoGym presents a generalizable benchmark for evaluating long-horizon planning capabilities of LLM-based agents in interactive economic environments with persistent dynamics and multi-scenario evaluation. Long-horizon planning is widely recognized as a core capability of autonomous LLM-based agents ; however, current evaluation frameworks suffer from being largely episodic, domain-specific, or insufficiently grounded in persistent economic dynamics . We introduce EcoGym, a generalizable benchmark for continuous plan-and-execute decision making in interactive economies . EcoGym comprises three diverse environments: Vending, Freelance, and Operation, implemented in a unified decision-making process with standardized interfaces, and budgeted actions over an effectively unbounded horizon (1000+ steps if 365 day-loops for evaluation). The evaluation of EcoGym is based on business-relevant outcomes (e.g., net worth, income, and DAU), targeting long-term strategic coherence and robustness under partial observability and stochasticity . Experiments across eleven leading LLMs expose a systematic tension: no single model dominates across all three scenarios. Critically, we find that models exhibit significant suboptimality in either high-level strategies or efficient actions executions. EcoGym is released as an open, extensible testbed for transparent long-horizon agent evaluation and for studying controllability-utility trade-offs in realistic economic settings.",
    "summary_en": "EcoGym presents a generalizable benchmark for evaluating long-horizon planning capabilities of LLM-based agents in interactive economic environments with persistent dynamics and multi-scenario evaluation.",
    "summary_zh": "EcoGym提出了一个可泛化的基准，用于评估基于LLM的智能体在具有持续动态和多场景评估的交互式经济环境中的长程规划能力。",
    "upvotes": 9
  },
  {
    "id": "2602.03773",
    "date": "2026-02-12",
    "title": "Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL",
    "authors": "Ian Wu Yuxiao Qu Amrith Setlur Aviral Kumar",
    "abstract": "RC, an iterative decoding algorithm, enables large language models to extrapolate and continuously improve beyond training budgets by constructing reasoning chains that enhance across iterations, achieving superior performance on long-horizon tasks. Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation . However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, we introduce RC, an iterative decoding algorithm that replaces standard autoregressive decoding during both training and inference. RC exploits an asymmetry between the response generation and summarization capabilities of LLMs to construct reasoning chains that consistently improve across iterations. Models trained to use RC can extrapolate and continually improve over reasoning horizons more than an order of magnitude longer than those seen during training. Empirically, training a 4B model with RC using a 16k-token training budget improves performance on HMMT 2025 from 40% to nearly 70% with 0.5m tokens at test time, outperforming both comparably sized models and many larger reasoning LLMs. Finally, we also show that models trained with RC can more effectively leverage existing scaffolds to further scale test-time performance , due to the improved summary-conditioned generation abilities learned through training.",
    "summary_en": "RC, an iterative decoding algorithm, enables large language models to extrapolate and continuously improve beyond training budgets by constructing reasoning chains that enhance across iterations, achieving superior performance on long-horizon tasks.",
    "summary_zh": "RC是一种迭代解码算法，它通过构建跨迭代增强的推理链，使大型语言模型能够外推并在训练预算之外持续改进，从而在长程任务上取得更优性能。",
    "upvotes": 9
  },
  {
    "id": "2602.09713",
    "date": "2026-02-12",
    "title": "Stroke3D: Lifting 2D strokes into rigged 3D model via latent diffusion models",
    "authors": "Ruisi Zhao Haoren Zheng Zongxin Yang Hehe Fan Yi Yang",
    "abstract": "Stroke3D generates rigged 3D meshes from 2D strokes and text prompts through a two-stage pipeline combining controllable skeleton generation with enhanced mesh synthesis. Rigged 3D assets are fundamental to 3D deformation and animation. However, existing 3D generation methods face challenges in generating animatable geometry, while rigging techniques lack fine-grained structural control over skeleton creation. To address these limitations, we introduce Stroke3D, a novel framework that directly generates rigged meshes from user inputs: 2D drawn strokes and a descriptive text prompt. Our approach pioneers a two-stage pipeline that separates the generation into: 1) Controllable Skeleton Generation , we employ the Skeletal Graph VAE ( Sk-VAE ) to encode the skeleton's graph structure into a latent space, where the Skeletal Graph DiT ( Sk-DiT ) generates a skeletal embedding. The generation process is conditioned on both the text for semantics and the 2D strokes for explicit structural control, with the VAE's decoder reconstructing the final high-quality 3D skeleton; and 2) Enhanced Mesh Synthesis via TextuRig and SKA-DPO , where we then synthesize a textured mesh conditioned on the generated skeleton. For this stage, we first enhance an existing skeleton-to-mesh model by augmenting its training data with TextuRig : a dataset of textured and rigged meshes with captions, curated from Objaverse-XL . Additionally, we employ a preference optimization strategy, SKA-DPO , guided by a skeleton-mesh alignment score , to further improve geometric fidelity. Together, our framework enables a more intuitive workflow for creating ready to animate 3D content. To the best of our knowledge, our work is the first to generate rigged 3D meshes conditioned on user-drawn 2D strokes. Extensive experiments demonstrate that Stroke3D produces plausible skeletons and high-quality meshes.",
    "summary_en": "Stroke3D generates rigged 3D meshes from 2D strokes and text prompts through a two-stage pipeline combining controllable skeleton generation with enhanced mesh synthesis.",
    "summary_zh": "Stroke3D通过结合可控骨骼生成与增强网格合成的两阶段流程，从二维笔画和文本提示生成带骨骼绑定的3D网格。",
    "upvotes": 8
  },
  {
    "id": "2602.10179",
    "date": "2026-02-12",
    "title": "When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models",
    "authors": "Jiacheng Hou Yining Sun Ruochong Jin Haochen Han Fangming Liu Wai Kin Victor Chan Alex Jinpeng Wang",
    "abstract": "Visual-to-visual jailbreak attacks compromise image editing models through malicious visual inputs, necessitating new safety benchmarks and defense mechanisms. Recent advances in large image editing models have shifted the paradigm from text-driven instructions to vision-prompt editing, where user intent is inferred directly from visual inputs such as marks, arrows, and visual-text prompts. While this paradigm greatly expands usability, it also introduces a critical and underexplored safety risk: the attack surface itself becomes visual. In this work, we propose Vision-Centric Jailbreak Attack (VJA), the first visual-to-visual jailbreak attack that conveys malicious instructions purely through visual inputs. To systematically study this emerging threat, we introduce IESBench , a safety-oriented benchmark for image editing models . Extensive experiments on IESBench demonstrate that VJA effectively compromises state-of-the-art commercial models, achieving attack success rate s of up to 80.9% on Nano Banana Pro and 70.1% on GPT-Image-1.5. To mitigate this vulnerability, we propose a training-free defense based on introspective multimodal reasoning , which substantially improves the safety of poorly aligned models to a level comparable with commercial systems, without auxiliary guard models and with negligible computational overhead. Our findings expose new vulnerabilities, provide both a benchmark and practical defense to advance safe and trustworthy modern image editing systems. Warning: This paper contains offensive images created by large image editing models .",
    "summary_en": "Visual-to-visual jailbreak attacks compromise image editing models through malicious visual inputs, necessitating new safety benchmarks and defense mechanisms.",
    "summary_zh": "视觉到视觉越狱攻击通过恶意视觉输入破坏图像编辑模型，亟需新的安全基准与防御机制。",
    "upvotes": 6
  },
  {
    "id": "2602.09901",
    "date": "2026-02-12",
    "title": "QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search",
    "authors": "Jianzhao Huang Xiaorui Huang Fei Zhao Yunpeng Liu Hui Zhang Fangcheng Shi Congfeng Li Zechen Sun Yi Wu Yao Hu Yunhan Bai Shaosheng Cao",
    "abstract": "A unified generative large language model approach for social network search query processing that improves semantic understanding through multi-task learning and reinforcement learning while enhancing downstream task performance. Query Processing (QP) bridges user intent and content supply in large-scale Social Network Service (SNS) search engines. Traditional QP systems rely on pipelines of isolated discriminative models (e.g., BERT), suffering from limited semantic understanding and high maintenance overhead. While Large Language Models (LLMs) offer a potential solution, existing approaches often optimize sub-tasks in isolation, neglecting intrinsic semantic synergy and necessitating independent iterations. Moreover, standard generative methods often lack grounding in SNS scenarios, failing to bridge the gap between open-domain corpora and informal SNS linguistic patterns, while struggling to adhere to rigorous business definitions. We present QP-OneModel, a Unified Generative LLM for Multi-Task Query Understanding in the SNS domain. We reformulate heterogeneous sub-tasks into a unified sequence generation paradigm, adopting a progressive three-stage alignment strategy culminating in multi-reward Reinforcement Learning . Furthermore, QP-OneModel generates intent descriptions as a novel high-fidelity semantic signal, effectively augmenting downstream tasks such as query rewriting and ranking . Offline evaluations show QP-OneModel achieves a 7.35% overall gain over discriminative baselines, with significant F1 boosts in NER (+9.01%) and Term Weighting (+9.31%). It also exhibits superior generalization, surpassing a 32B model by 7.60% accuracy on unseen tasks. Fully deployed at Xiaohongshu, online A/B tests confirm its industrial value, optimizing retrieval relevance (DCG) by 0.21% and lifting user retention by 0.044%.",
    "summary_en": "A unified generative large language model approach for social network search query processing that improves semantic understanding through multi-task learning and reinforcement learning while enhancing downstream task performance.",
    "summary_zh": "一种用于社交网络搜索查询处理的统一生成式大语言模型方法，通过多任务学习和强化学习提升语义理解，同时增强下游任务性能。",
    "upvotes": 6
  },
  {
    "id": "2602.10748",
    "date": "2026-02-12",
    "title": "Benchmarking Large Language Models for Knowledge Graph Validation",
    "authors": "Farzad Shami Stefano Marchesin Gianmaria Silvello",
    "abstract": "Large language models show promise but lack stability and reliability for knowledge graph fact validation, with retrieval-augmented generation and multi-model consensus approaches yielding inconsistent improvements.",
    "summary_en": "Large language models show promise but lack stability and reliability for knowledge graph fact validation, with retrieval-augmented generation and multi-model consensus approaches yielding inconsistent improvements.",
    "summary_zh": "大语言模型在知识图谱事实验证方面展现出潜力，但缺乏稳定性和可靠性，且检索增强生成与多模型共识方法所带来的改进效果参差不齐。",
    "upvotes": 5
  },
  {
    "id": "2602.10229",
    "date": "2026-02-12",
    "title": "Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens",
    "authors": "Weihao Liu Dehai Min Lu Cheng",
    "abstract": "Latent Thoughts Tuning introduces a novel framework for reasoning in continuous latent space by combining contextual hidden states with predictive semantic guidance, enabling robust inference through a progressive curriculum learning approach. While explicit Chain-of-Thought (CoT) equips Large Language Models (LLMs) with strong reasoning capabilities, it requires models to verbalize every intermediate step in text tokens, constraining the model thoughts to the discrete vocabulary space. Recently, reasoning in continuous latent space has emerged as a promising alternative, enabling more robust inference and flexible computation beyond discrete token constraints. However, current latent paradigms often suffer from feature collapse and instability, stemming from distribution mismatches when recurrently using hidden states as the input embeddings, or alignment issues when relying on assistant models. To address this, we propose Latent Thoughts Tuning (LT-Tuning), a framework that redefines how latent thoughts are constructed and deployed. Instead of relying solely on raw hidden states , our method introduces a Context-Prediction-Fusion mechanism that jointly leveraging contextual hidden states and predictive semantic guidance from the vocabulary embedding space . Combined with a progressive three-stage curriculum learning pipeline, LT-Tuning also enables dynamically switching between latent and explicit thinking modes. Experiments demonstrate that our method outperforms existing latent reasoning baselines, effectively mitigating feature collapse and achieving robust reasoning accuracy .",
    "summary_en": "Latent Thoughts Tuning introduces a novel framework for reasoning in continuous latent space by combining contextual hidden states with predictive semantic guidance, enabling robust inference through a progressive curriculum learning approach.",
    "summary_zh": "潜在思维微调提出了一种在连续潜在空间中进行推理的新颖框架，通过结合上下文隐藏状态与预测性语义引导，并利用渐进式课程学习方法实现鲁棒推断。",
    "upvotes": 5
  },
  {
    "id": "2602.08489",
    "date": "2026-02-12",
    "title": "Beyond Correctness: Learning Robust Reasoning via Transfer",
    "authors": "Hyunseok Lee Soheil Abbasloo Jihoon Tack Jinwoo Shin",
    "abstract": "Reinforcement Learning with Transferable Reward (RLTR) enhances LLM reasoning robustness by ensuring reasoning stability and generalizability through transfer rewards that test cross-model guidance capabilities. Reinforcement Learning with Verifiable Rewards (RLVR) has recently strengthened LLM reasoning , but its focus on final answer correctness leaves a critical gap: it does not ensure the robustness of the reasoning process itself. We adopt a simple philosophical view, robust reasoning should remain useful beyond the mind that produced it, and treat reasoning as a form of meaning transfer that must survive truncation, reinterpretation, and continuation. Building on this principle, we introduce Reinforcement Learning with Transferable Reward (RLTR), which operationalizes robustness via transfer reward that tests whether a partial reasoning prefix from one model can guide a separate model to the correct answer. This encourages LLMs to produce reasoning that is stable, interpretable, and genuinely generalizable. Our approach improves sampling consistency while improving final answer accuracy , and it reaches comparable performance in substantially fewer training steps. For example, on MATH500 , RLTR achieves a +3.6%p gain in Maj@64 compared to RLVR and matches RLVR's average accuracy with roughly 2.5x fewer training steps, providing both more reliable reasoning and significantly more sample efficient.",
    "summary_en": "Reinforcement Learning with Transferable Reward (RLTR) enhances LLM reasoning robustness by ensuring reasoning stability and generalizability through transfer rewards that test cross-model guidance capabilities.",
    "summary_zh": "可迁移奖励强化学习（RLTR）通过可迁移奖励测试跨模型引导能力，确保推理稳定性与泛化性，从而增强 LLM 推理鲁棒性。",
    "upvotes": 5
  },
  {
    "id": "2602.08030",
    "date": "2026-02-12",
    "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models",
    "authors": "Yilun Zheng Dongyang Ma Tian Liang Jiahao Xu Xinting Huang Lihui Chen Haitao Mi Yan Wang",
    "abstract": "Free()LM addresses reasoning model limitations by introducing a self-forgetting mechanism through a Free-Module plug-and-play LoRA adapter, improving performance across scales and long-horizon tasks. Reasoning models enhance problem-solving by scaling test-time compute , yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module , a plug-and-play LoRA adapter . By iteratively switching between reasoning and cleaning mode s, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state. Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale . Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.",
    "summary_en": "Free()LM addresses reasoning model limitations by introducing a self-forgetting mechanism through a Free-Module plug-and-play LoRA adapter, improving performance across scales and long-horizon tasks.",
    "summary_zh": "Free()LM 通过 Free-Module 即插即用 LoRA 适配器引入自遗忘机制，解决推理模型的局限性，提升跨规模及长程任务的性能。",
    "upvotes": 5
  },
  {
    "id": "2602.07954",
    "date": "2026-02-12",
    "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation",
    "authors": "Krzysztof Wróbel Jan Maria Kowalski Jerzy Surma Igor Ciuciura Maciej Szymański",
    "abstract": "Bielik Guard is a compact Polish language safety classifier family with two variants that effectively categorize content across five safety domains while maintaining high efficiency and accuracy.",
    "summary_en": "Bielik Guard is a compact Polish language safety classifier family with two variants that effectively categorize content across five safety domains while maintaining high efficiency and accuracy.",
    "summary_zh": "Bielik Guard 是一个紧凑的波兰语安全分类器系列，包含两种变体，可有效对内容进行跨五个安全领域的分类，同时保持高效率和准确性。",
    "upvotes": 4
  },
  {
    "id": "2602.07900",
    "date": "2026-02-12",
    "title": "Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents",
    "authors": "Zhi Chen Zhensu Sun Yuling Shi Chao Peng Xiaodong Gu David Lo Lingxiao Jiang",
    "abstract": "Empirical analysis of LLM code agents reveals that test writing provides limited improvement in issue resolution and is often replaced by observation-based debugging methods. Large Language Model (LLM) code agents increasingly resolve repository-level issues by iteratively editing code, invoking tools, and validating candidate patches. In these workflows, agents often write tests on the fly, a paradigm adopted by many high-ranking agents on the SWE-bench leaderboard. However, we observe that GPT-5.2, which writes almost no new tests, can even achieve performance comparable to top-ranking agents. This raises the critical question: whether such tests meaningfully improve issue resolution or merely mimic human testing practices while consuming a substantial interaction budget. To reveal the impact of agent-written tests, we present an empirical study that analyzes agent trajectories across six state-of-the-art LLMs on SWE-bench Verified. Our results show that while test writing is commonly adopted, but resolved and unresolved tasks within the same model exhibit similar test-writing frequencies Furthermore, these tests typically serve as observational feedback channels, where agents prefer value-revealing print statements significantly more than formal assertion-based checks . Based on these insights, we perform a controlled experiment by revising the prompts of four agents to either increase or reduce test writing . The results suggest that changes in the volume of agent-written tests do not significantly change final outcomes. Taken together, our study reveals that current test-writing practices may provide marginal utility in autonomous software engineering tasks.",
    "summary_en": "Empirical analysis of LLM code agents reveals that test writing provides limited improvement in issue resolution and is often replaced by observation-based debugging methods.",
    "summary_zh": "对LLM代码智能体的实证分析表明，测试编写对问题解决的提升有限，且常被基于观察的调试方法所取代。",
    "upvotes": 4
  },
  {
    "id": "2602.06008",
    "date": "2026-02-12",
    "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
    "authors": "Xianyang Liu Shangding Gu Dawn Song",
    "abstract": "AgenticPay presents a benchmark and simulation framework for evaluating multi-agent language-mediated economic interactions, focusing on negotiation performance and strategic reasoning challenges in complex market scenarios. Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning , establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.",
    "summary_en": "AgenticPay presents a benchmark and simulation framework for evaluating multi-agent language-mediated economic interactions, focusing on negotiation performance and strategic reasoning challenges in complex market scenarios.",
    "summary_zh": "AgenticPay 提出了一个用于评估多智能体语言介导经济交互的基准测试与仿真框架，重点关注复杂市场场景中的谈判表现与策略推理挑战。",
    "upvotes": 4
  },
  {
    "id": "2602.09014",
    "date": "2026-02-12",
    "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
    "authors": "Zihan Yang Shuyuan Tu Licheng Zhang Qi Dai Yu-Gang Jiang Zuxuan Wu",
    "abstract": "ArcFlow is a few-step distillation framework that uses non-linear flow trajectories to approximate teacher diffusion models, achieving fast inference with minimal quality loss through lightweight adapter training. Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps , motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes . This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory . To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.",
    "summary_en": "ArcFlow is a few-step distillation framework that uses non-linear flow trajectories to approximate teacher diffusion models, achieving fast inference with minimal quality loss through lightweight adapter training.",
    "summary_zh": "ArcFlow是一种少步蒸馏框架，利用非线性流轨迹逼近教师扩散模型，通过轻量级适配器训练实现快速推理且质量损失极小。",
    "upvotes": 3
  },
  {
    "id": "2602.02459",
    "date": "2026-02-12",
    "title": "TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments",
    "authors": "Zhiyu Huang Yun Zhang Johnson Liu Rui Song Chen Tang Jiaqi Ma",
    "abstract": "Vision-language-action models for robotics are enhanced with a latency-aware framework that compensates for delayed semantic reasoning during real-time action generation through delayed semantic-control interfaces and latency-consistent training. Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control . Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning , aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/",
    "summary_en": "Vision-language-action models for robotics are enhanced with a latency-aware framework that compensates for delayed semantic reasoning during real-time action generation through delayed semantic-control interfaces and latency-consistent training.",
    "summary_zh": "机器人视觉-语言-动作模型通过延迟感知框架得到增强，该框架通过延迟语义控制接口和延迟一致性训练，在实时动作生成过程中对延迟的语义推理进行补偿。",
    "upvotes": 3
  },
  {
    "id": "2602.11137",
    "date": "2026-02-12",
    "title": "Weight Decay Improves Language Model Plasticity",
    "authors": "Tessa Han Sebastian Bordt Hanlin Zhang Sham Kakade",
    "abstract": "Pretraining with larger weight decay values improves model plasticity and downstream fine-tuning performance by encouraging linearly separable representations and reducing overfitting. The prevailing paradigm in large language model (LLM) development is to pretrain a base model, then perform further training to improve performance and model behavior. However, hyperparameter optimization and scaling laws have been studied primarily from the perspective of the base model's validation loss, ignoring downstream adaptability. In this work, we study pretraining from the perspective of model plasticity , that is, the ability of the base model to successfully adapt to downstream tasks through fine-tuning . We focus on the role of weight decay , a key regularization parameter during pretraining . Through systematic experiments, we show that models trained with larger weight decay values are more plastic, meaning they show larger performance gains when fine-tuned on downstream tasks. This phenomenon can lead to counterintuitive trade-offs where base models that perform worse after pretraining can perform better after fine-tuning . Further investigation of weight decay 's mechanistic effects on model behavior reveals that it encourages linearly separable representations, regularizes attention matrices , and reduces overfitting on the training data. In conclusion, this work demonstrates the importance of using evaluation metrics beyond cross-entropy loss for hyperparameter optimization and casts light on the multifaceted role of that a single optimization hyperparameter plays in shaping model behavior.",
    "summary_en": "Pretraining with larger weight decay values improves model plasticity and downstream fine-tuning performance by encouraging linearly separable representations and reducing overfitting.",
    "summary_zh": "使用更大的权重衰减值进行预训练可通过促进线性可分的表征并减少过拟合，提升模型可塑性与下游微调性能。",
    "upvotes": 2
  },
  {
    "id": "2602.10778",
    "date": "2026-02-12",
    "title": "GoodVibe: Security-by-Vibe for LLM-Based Code Generation",
    "authors": "Maximilian Thang Lichao Wu Sasha Behrouzi Mohamadreza Rostami Jona te Lintelo Stjepan Picek Ahmad-Reza Sadeghi",
    "abstract": "GoodVibe is a neuron-level framework that enhances code language model security through targeted fine-tuning of security-relevant neurons while maintaining model utility and significantly reducing training costs. Large language models (LLMs) are increasingly used for code generation in fast, informal development workflows, often referred to as vibe coding, where speed and convenience are prioritized, and security requirements are rarely made explicit. In this setting, models frequently produce functionally correct but insecure code, creating a growing security risk. Existing approaches to improving code security rely on full-parameter fine-tuning or parameter-efficient adaptations , which are either costly and prone to catastrophic forgetting or operate at coarse granularity with limited interpretability and control. We present GoodVibe, a neuron-level framework for improving the security of code language models by default. GoodVibe is based on the key insight that security-relevant reasoning is localized to a small subset of neurons. We identify these neurons using gradient-based attribution from a supervised security task and perform neuron-selective fine-tuning that updates only this security-critical subspace. To further reduce training cost, we introduce activation-driven neuron clustering , enabling structured updates with minimal overhead. We evaluate GoodVibe on six LLMs across security-critical programming languages, including C++, Java, Swift, and Go. GoodVibe substantially improves the security of generated code while preserving general model utility, achieving up to a 2.5x improvement over base models, matching or exceeding full fine-tuning with over 4,700x fewer trainable parameters , and reducing training computation by more than 3.6x compared to the parameter-efficient baseline (LoRA). Our results demonstrate that neuron-level optimization offers an effective and scalable approach to securing code generation without sacrificing efficiency or generality.",
    "summary_en": "GoodVibe is a neuron-level framework that enhances code language model security through targeted fine-tuning of security-relevant neurons while maintaining model utility and significantly reducing training costs.",
    "summary_zh": "GoodVibe是一种神经元级框架，通过对安全相关神经元进行针对性微调来增强代码语言模型的安全性，同时保持模型效用并显著降低训练成本。",
    "upvotes": 2
  },
  {
    "id": "2602.10652",
    "date": "2026-02-12",
    "title": "UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory",
    "authors": "Yongshi Ye Hui Jiang Feihu Jiang Tian Lan Yichao Du Biao Fu Xiaodong Shi Qianghuai Jia Longyue Wang Weihua Luo",
    "abstract": "A unified framework for memory extraction and management in LLM-based agents that improves generalization through semantic neighborhood modeling and marginal utility rewards. Self-evolving memory serves as the trainable parameters for Large Language Models (LLMs)-based agents, where extraction (distilling insights from experience) and management (updating the memory bank) must be tightly coordinated. Existing methods predominately optimize memory management while treating memory extraction as a static process, resulting in poor generalization, where agents accumulate instance-specific noise rather than robust memories. To address this, we propose Unified Memory Extraction and Management (UMEM), a self-evolving agent framework that jointly optimizes a Large Language Model to simultaneous extract and manage memories. To mitigate overfitting to specific instances, we introduce Semantic Neighborhood Modeling and optimize the model with a neighborhood-level marginal utility reward via GRPO . This approach ensures memory generalizability by evaluating memory utility across clusters of semantically related queries. Extensive experiments across five benchmarks demonstrate that UMEM significantly outperforms highly competitive baselines, achieving up to a 10.67% improvement in multi-turn interactive tasks . Futhermore, UMEM maintains a monotonic growth curve during continuous evolution. Codes and models will be publicly released.",
    "summary_en": "A unified framework for memory extraction and management in LLM-based agents that improves generalization through semantic neighborhood modeling and marginal utility rewards.",
    "summary_zh": "一种面向LLM智能体的记忆提取与管理统一框架，通过语义邻域建模和边际效用奖励提升泛化能力。",
    "upvotes": 2
  },
  {
    "id": "2602.08995",
    "date": "2026-02-12",
    "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents",
    "authors": "Yuting Ning Jaylen Jones Zhehao Zhang Chentao Ye Weitong Ruan Junyi Li Rahul Gupta Huan Sun",
    "abstract": "Computer-use agents face safety risks from misaligned actions caused by external attacks or internal limitations, prompting the development of DeAction, a guardrail that detects and corrects such actions before execution. Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection ) or from internal limitations (e.g., erroneous reasoning ). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions . We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback . DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.",
    "summary_en": "Computer-use agents face safety risks from misaligned actions caused by external attacks or internal limitations, prompting the development of DeAction, a guardrail that detects and corrects such actions before execution.",
    "summary_zh": "计算机使用智能体面临由外部攻击或内部限制导致的未对齐行为的安全风险，催生了DeAction——一种可在执行前检测并纠正此类行为的护栏机制。",
    "upvotes": 2
  },
  {
    "id": "2602.08741",
    "date": "2026-02-12",
    "title": "Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing",
    "authors": "Jona te Lintelo Lichao Wu Stjepan Picek",
    "abstract": "Attack method exploits expert routing dynamics in Mixture-of-Experts language models to compromise safety alignment while maintaining language utility. The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing structure introduces new safety attack surfaces. We find that safety-critical behaviors in MoE LLMs (e.g., refusal) are concentrated in a small set of experts rather than being uniformly distributed. Building on this, we propose Large Language Lobotomy (L^3), a training-free, architecture-agnostic attack that compromises safety alignment by exploiting expert routing dynamics. L^3 learns routing patterns that correlate with refusal, attributes safety behavior to specific experts, and adaptively silences the most safety-relevant experts until harmful outputs are produced. We evaluate L^3 on eight state-of-the-art open-source MoE LLMs and show that our adaptive expert silencing increases average attack success from 7.3% to 70.4%, reaching up to 86.3%, outperforming prior training-free MoE jailbreak methods . Moreover, bypassing guardrails typically requires silencing fewer than 20% of layer-wise experts while largely preserving general language utility. These results reveal a fundamental tension between efficiency-driven MoE design and robust safety alignment and motivate distributing safety mechanisms more robustly in future MoE LLMs with architecture- and routing-aware methods.",
    "summary_en": "Attack method exploits expert routing dynamics in Mixture-of-Experts language models to compromise safety alignment while maintaining language utility.",
    "summary_zh": "攻击方法利用混合专家语言模型的专家路由动态，在保持语言实用性的同时破坏安全对齐。",
    "upvotes": 2
  },
  {
    "id": "2602.10870",
    "date": "2026-02-12",
    "title": "FedPS: Federated data Preprocessing via aggregated Statistics",
    "authors": "Xuefeng Xu Graham Cormode",
    "abstract": "FedPS is a federated data preprocessing framework that uses aggregated statistics and data-sketching techniques to enable efficient and privacy-preserving data preparation for collaborative machine learning across distributed datasets. Federated Learning (FL) enables multiple parties to collaboratively train machine learning models without sharing raw data. However, before training, data must be preprocessed to address missing values, inconsistent formats, and heterogeneous feature scales. This preprocessing stage is critical for model performance but is largely overlooked in FL research. In practical FL systems, privacy constraints prohibit centralizing raw data, while communication efficiency introduces further challenges for distributed preprocessing. We introduce FedPS, a unified framework for federated data preprocessing based on aggregated statistics . FedPS leverages data-sketching techniques to efficiently summarize local datasets while preserving essential statistical information. Building on these summaries, we design federated algorithms for feature scaling , encoding , discretization , and missing-value imputation , and extend preprocessing-related models such as k-Means , k-Nearest Neighbors , and Bayesian Linear Regression to both horizontal and vertical FL settings. FedPS provides flexible, communication-efficient, and consistent preprocessing pipelines for practical FL deployments.",
    "summary_en": "FedPS is a federated data preprocessing framework that uses aggregated statistics and data-sketching techniques to enable efficient and privacy-preserving data preparation for collaborative machine learning across distributed datasets.",
    "summary_zh": "FedPS是一种联邦数据预处理框架，利用聚合统计和数据草图技术，为跨分布式数据集的协作式机器学习提供高效且保护隐私的数据准备。",
    "upvotes": 1
  },
  {
    "id": "2602.10699",
    "date": "2026-02-12",
    "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation",
    "authors": "Jie Jiang Yangru Huang Zeyu Wang Changping Wang Yuling Xiong Jun Zhang Huan Yu",
    "abstract": "V-STAR addresses limitations in generative recommendation by combining value-guided decoding and tree-structured advantage reinforcement to improve exploration and reward signal quality. Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch . Conventional likelihood-dominated decoding (e.g., beam search ) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration , where high-reward items in low-probability branches are prematurely pruned and rarely sampled, and (2) advantage compression , where trajectories sharing high-probability prefixes receive highly correlated rewards with low within-group variance, yielding a weak comparative signal for RL. To address these challenges, we propose V-STAR, a Value-guided Sampling and Tree-structured Advantage Reinforcement framework. V-STAR forms a self-evolving loop via two synergistic components. First, a Value-Guided Efficient Decoding (VED) is developed to identify decisive nodes and selectively deepen high-potential prefixes. This improves exploration efficiency without exhaustive tree search. Second, we propose Sibling-GRPO , which exploits the induced tree topology to compute sibling-relative advantages and concentrates learning signals on decisive branching decisions. Extensive experiments on both offline and online datasets demonstrate that V-STAR outperforms state-of-the-art baselines, delivering superior accuracy and candidate-set diversity under strict latency constraints.",
    "summary_en": "V-STAR addresses limitations in generative recommendation by combining value-guided decoding and tree-structured advantage reinforcement to improve exploration and reward signal quality.",
    "summary_zh": "V-STAR结合价值引导解码与树结构优势强化，解决生成式推荐的局限性，提升探索与奖励信号质量。",
    "upvotes": 1
  },
  {
    "id": "2602.08052",
    "date": "2026-02-12",
    "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling",
    "authors": "Bulent Soykan Sean Mondesire Ghaith Rabadi Grace Bochenek",
    "abstract": "A Deep Reinforcement Learning framework combining Proximal Policy Optimization and Graph Neural Networks addresses multi-objective scheduling challenges by effectively balancing total weighted tardiness and total setup time. The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.",
    "summary_en": "A Deep Reinforcement Learning framework combining Proximal Policy Optimization and Graph Neural Networks addresses multi-objective scheduling challenges by effectively balancing total weighted tardiness and total setup time.",
    "summary_zh": "一种结合近端策略优化（PPO）与图神经网络（GNN）的深度强化学习框架，通过有效平衡总加权拖期与总准备时间，解决多目标调度挑战。",
    "upvotes": 1
  },
  {
    "id": "2602.08934",
    "date": "2026-02-12",
    "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
    "authors": "Suraj Ranganath Atharv Ramesh",
    "abstract": "StealthRL uses reinforcement learning with LoRA adapters to create adversarial paraphrases that evade multiple AI text detectors while preserving meaning, demonstrating significant robustness gaps in current detection systems. AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B , optimizing a composite reward that balances detector evasion with semantic preservation . We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate . Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring , analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals . Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL.",
    "summary_en": "StealthRL uses reinforcement learning with LoRA adapters to create adversarial paraphrases that evade multiple AI text detectors while preserving meaning, demonstrating significant robustness gaps in current detection systems.",
    "summary_zh": "StealthRL利用强化学习与LoRA适配器生成可规避多个AI文本检测器的对抗性释义，同时保留语义，显示出现有检测系统存在显著的鲁棒性缺陷。",
    "upvotes": 0
  },
  {
    "id": "2602.06841",
    "date": "2026-02-12",
    "title": "From Features to Actions: Explainability in Traditional and Agentic AI Systems",
    "authors": "Sindhuja Chaduvula Jessee Ho Kina Kim Aravind Narayanan Mahshid Alinoori Muskan Garg Dhanesh Ramachandram Shaina Raza",
    "abstract": "Static and agentic explainability approaches differ in their ability to interpret model behavior, with attribution methods effective for individual predictions but inadequate for diagnosing failures in multi-step decision processes, where trace-based diagnostics prove more reliable. Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequences of decisions rather than a single output. While useful, it remains unclear how explanation approaches designed for static predictions translate to agentic settings where behaviour emerges over time. In this work, we bridge the gap between static and agentic explainability by comparing attribution-based explanations with trace-based diagnostics across both settings. To make this distinction explicit, we empirically compare attribution-based explanations used in static classification tasks with trace-based diagnostics used in agentic benchmarks ( TAU-bench Airline and AssistantBench ). Our results show that while attribution methods achieve stable feature rankings in static settings (Spearman ρ= 0.86), they cannot be applied reliably to diagnose execution-level failures in agentic trajectories . In contrast, trace-grounded rubric evaluation for agentic settings consistently localizes behaviour breakdowns and reveals that state tracking inconsistency is 2.7times more prevalent in failed runs and reduces success probability by 49\\%. These findings motivate a shift towards trajectory-level explainability for agentic systems when evaluating and diagnosing autonomous AI behaviour. Resources: https://github.com/VectorInstitute/unified-xai-evaluation-framework https://vectorinstitute.github.io/unified-xai-evaluation-framework",
    "summary_en": "Static and agentic explainability approaches differ in their ability to interpret model behavior, with attribution methods effective for individual predictions but inadequate for diagnosing failures in multi-step decision processes, where trace-based diagnostics prove more reliable.",
    "summary_zh": "静态与智能体可解释性方法在解释模型行为的能力上存在差异：归因方法对单个预测有效，但不足以诊断多步决策过程中的失败，而基于轨迹的诊断方法则更为可靠。",
    "upvotes": 0
  },
  {
    "id": "2602.05400",
    "date": "2026-02-11",
    "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration",
    "authors": "Shaobo Wang Xuan Ouyang Tianyi Xu Yuzheng Hu Jialin Liu Guo Chen Tianyu Zhang Junhao Zheng Kexin Yang Xingzhang Ren Dayiheng Liu Linfeng Zhang",
    "abstract": "OPUS is a dynamic data selection framework that improves pre-training efficiency by scoring data candidates based on optimizer-induced update projections in a stable proxy-derived target space, achieving superior performance with reduced computational overhead. As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space . OPUS scores candidates by projecting their effective updates , shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia , OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.",
    "summary_en": "OPUS is a dynamic data selection framework that improves pre-training efficiency by scoring data candidates based on optimizer-induced update projections in a stable proxy-derived target space, achieving superior performance with reduced computational overhead.",
    "summary_zh": "OPUS是一种动态数据选择框架，通过在稳定的代理派生目标空间中基于优化器诱导的更新投影对数据候选进行评分来提升预训练效率，从而在降低计算开销的同时实现更优性能。",
    "upvotes": 316
  },
  {
    "id": "2602.09856",
    "date": "2026-02-11",
    "title": "Code2World: A GUI World Model via Renderable Code Generation",
    "authors": "Yuhao Zheng Li'an Zhong Yi Wang Rui Dai Kaikui Liu Xiangxiang Chu Linyuan Lv Philip Torr Kevin Qinghong Lin",
    "abstract": "Code2World enables autonomous GUI agents to predict next visual states through renderable code generation, achieving high visual fidelity and structural controllability while improving navigation performance.",
    "summary_en": "Code2World enables autonomous GUI agents to predict next visual states through renderable code generation, achieving high visual fidelity and structural controllability while improving navigation performance.",
    "summary_zh": "Code2World通过可渲染代码生成使自主GUI智能体能够预测下一视觉状态，实现高视觉保真度与结构可控性，同时提升导航性能。",
    "upvotes": 189
  },
  {
    "id": "2602.09082",
    "date": "2026-02-11",
    "title": "UI-Venus-1.5 Technical Report",
    "authors": "Veuns-Team Changlong Gao Zhangxuan Gu Yulin Liu Xinyu Qiu Shuheng Shen Yue Wen Tianyu Xia Zhenyu Xu Zhengwen Zeng Beitong Zhou Xingran Zhou Weizhi Chen Sunhao Dai Jingya Dou Yichen Gong Yuan Guo Zhenlin Guo Feng Li Qian Li Jinzhen Lin Yuqi Zhou",
    "abstract": "UI-Venus-1.5 is a unified GUI agent with improved performance through mid-training stages, online reinforcement learning, and model merging techniques.",
    "summary_en": "UI-Venus-1.5 is a unified GUI agent with improved performance through mid-training stages, online reinforcement learning, and model merging techniques.",
    "summary_zh": "UI-Venus-1.5是一个通过中期训练阶段、在线强化学习和模型合并技术提升性能的统一GUI智能体。",
    "upvotes": 149
  },
  {
    "id": "2602.10063",
    "date": "2026-02-11",
    "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes",
    "authors": "Tianyi Jiang Arctanx An Hengyi Feng Naixin Zhai Haodong Li Xiaomin Yu Jiahui Liu Hanwen Du Shuo Zhang Zhi Yang Jie Huang Yuhua Li Yongxin Ni Huacan Wang Ronghao Chen",
    "abstract": "A novel training-free framework called Chain of Mindset enables step-level adaptive mindset orchestration for large language models by integrating spatial, convergent, divergent, and algorithmic reasoning approaches. Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a com mon trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset ( CoM ), a training-free agentic framework that enables step-level adaptive mindset orchestration . CoM de com poses reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\\% and 4.72\\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency . Our code is publicly available at https://github. com /QuantaAlpha/chain-of-mindset{https://github. com /QuantaAlpha/chain-of-mindset}.",
    "summary_en": "A novel training-free framework called Chain of Mindset enables step-level adaptive mindset orchestration for large language models by integrating spatial, convergent, divergent, and algorithmic reasoning approaches.",
    "summary_zh": "一种名为 Chain of Mindset 的新型免训练框架通过整合空间、收敛、发散和算法推理方法，实现了面向大语言模型的步骤级别自适应思维编排。",
    "upvotes": 70
  },
  {
    "id": "2602.08234",
    "date": "2026-02-11",
    "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning",
    "authors": "Peng Xia Jianwen Chen Hanyang Wang Jiaqi Liu Kaide Zeng Yu Wang Siwei Han Yiyang Zhou Xujiang Zhao Haifeng Chen Zeyu Zheng Cihang Xie Huaxiu Yao",
    "abstract": "SkillRL enables LLM agents to improve through hierarchical skill discovery and recursive policy evolution, achieving superior performance on complex tasks while reducing computational overhead. Large Language Model (LLM) agents have shown stunning results in complex tasks, yet they often operate in isolation, failing to learn from past experiences. Existing memory-based methods primarily store raw trajectories, which are often redundant and noise-heavy. This prevents agents from extracting high-level, reusable behavioral patterns that are essential for generalization. In this paper, we propose SkillRL, a framework that bridges the gap between raw experience and policy improvement through automatic skill discovery and recursive evolution . Our approach introduces an experience-based distillation mechanism to build a hierarchical skill library SkillBank , an adaptive retrieval strategy for general and task-specific heuristics, and a recursive evolution mechanism that allows the skill library to co-evolve with the agent's policy during reinforcement learning . These innovations significantly reduce the token footprint while enhancing reasoning utility. Experimental results on ALFWorld, WebShop and seven search-augmented tasks demonstrate that SkillRL achieves state-of-the-art performance, outperforming strong baselines over 15.3% and maintaining robustness as task complexity increases. Code is available at this https://github.com/aiming-lab/SkillRL.",
    "summary_en": "SkillRL enables LLM agents to improve through hierarchical skill discovery and recursive policy evolution, achieving superior performance on complex tasks while reducing computational overhead.",
    "summary_zh": "SkillRL使LLM智能体通过层次化技能发现与递归策略演化实现改进，在复杂任务上取得更优性能的同时降低计算开销。",
    "upvotes": 65
  },
  {
    "id": "2602.09443",
    "date": "2026-02-11",
    "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads",
    "authors": "Yun Luo Futing Wang Qianjia Cheng Fangchen Yu Haodi Lei Jianhao Yan Chenxi Li Jiacheng Chen Yufeng Zhao Haiyuan Wan Yuchen Zhang Shenghe Zheng Junchi Yao Qingyang Zhang Haonan He Wenxuan Zeng Li Sheng Chengxing Xie Yuxin Zuo Yizhuo Li Yulun Wu Rui Huang",
    "abstract": "Physics-oriented vision-language models leverage curriculum reinforcement learning and agentic augmentation to achieve state-of-the-art scientific reasoning performance while maintaining physical consistency through multimodal perception. The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative, containing essential constraints, such as boundary conditions and spatial symmetries, that are absent from the text. To bridge this visual-logical gap, we introduce P1-VL, a family of open-source vision-language models engineered for advanced scientific reasoning . Our method harmonizes Curriculum Reinforcement Learning , which employs progressive difficulty expansion to stabilize post-training, with Agentic Augmentation , enabling iterative self-verification at inference. Evaluated on HiPhO, a rigorous benchmark of 13 exams from 2024-2025, our flagship P1-VL-235B-A22B becomes the first open-source Vision-Language Model (VLM) to secure 12 gold medals and achieves the state-of-the-art performance in the open-source models. Our agent-augmented system achieves the No.2 overall rank globally, trailing only Gemini-3-Pro . Beyond physics, P1-VL demonstrates remarkable scientific reasoning capacity and generalizability, establishing significant leads over base models in STEM benchmarks. By open-sourcing P1-VL, we provide a foundational step toward general-purpose physical intelligence to better align visual perceptions with abstract physical laws for machine scientific discovery.",
    "summary_en": "Physics-oriented vision-language models leverage curriculum reinforcement learning and agentic augmentation to achieve state-of-the-art scientific reasoning performance while maintaining physical consistency through multimodal perception.",
    "summary_zh": "面向物理的视觉-语言模型利用课程强化学习和智能体增强，在通过多模态感知保持物理一致性的同时，实现了最先进的科学推理性能。",
    "upvotes": 57
  },
  {
    "id": "2602.10090",
    "date": "2026-02-11",
    "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning",
    "authors": "Zhaoyang Wang Canwen Xu Boyi Liu Yite Wang Siwei Han Zhewei Yao Huaxiu Yao Yuxiong He",
    "abstract": "Large language model agents trained in synthetic environments with code-driven simulations and database-backed state transitions demonstrate superior out-of-distribution generalization compared to traditional benchmark-specific approaches. Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents . Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization . The code is available at https://github.com/Snowflake-Labs/agent-world-model.",
    "summary_en": "Large language model agents trained in synthetic environments with code-driven simulations and database-backed state transitions demonstrate superior out-of-distribution generalization compared to traditional benchmark-specific approaches.",
    "summary_zh": "在合成环境中通过代码驱动模拟和数据库支持状态转换训练的大型语言模型智能体，相比传统的针对特定基准的方法，展现出更优的分布外泛化能力。",
    "upvotes": 49
  },
  {
    "id": "2602.08426",
    "date": "2026-02-11",
    "title": "Prism: Spectral-Aware Block-Sparse Attention",
    "authors": "Xinghao Wang Pengyu Wang Xiaoran Liu Fangxu Liu Jason Chu Kai Song Xipeng Qiu",
    "abstract": "Prism addresses inefficiencies in block-sparse attention for long-context LLM pre-filling by using a spectral-aware approach that improves block selection accuracy through energy-based temperature calibration. Block-sparse attention is promising for accelerating long-context LLM pre-filling , yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings ( RoPE ). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a \"blind spot\" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration , Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to 5.1times speedup.",
    "summary_en": "Prism addresses inefficiencies in block-sparse attention for long-context LLM pre-filling by using a spectral-aware approach that improves block selection accuracy through energy-based temperature calibration.",
    "summary_zh": "Prism 采用频谱感知方法解决长上下文 LLM 预填充中块稀疏注意力的低效问题，该方法通过基于能量的温度校准提高块选择准确性。",
    "upvotes": 35
  },
  {
    "id": "2602.07035",
    "date": "2026-02-11",
    "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
    "authors": "Jiahao Zhao Shaoxuan Xu Zhongxiang Sun Fengqi Zhu Jingyang Ou Yuling Shi Chongxuan Li Xiao Zhang Jun Xu",
    "abstract": "Diffusion Large Language Models are optimized for search agents through enhanced reasoning capabilities and reduced latency via a parallel reasoning paradigm. Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge : the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct agent paradigm induces severe end-to-end latency. Intuitively, dLLMs can leverage their distinctive strengths to optimize the operational efficiency of agents under the ReAct agent paradigm . Practically, existing dLLM backbones face the 2) Agent Ability Challenge. That is, existing dLLMs exhibit remarkably weak reasoning and tool-calling capabilities, preventing these advantages from being effectively realized in practice. In this paper, we propose DLLM-Searcher, an optimization framework for dLLM-based Search Agents. To solve the Agent Ability Challenge, we design a two-stage post-training pipeline encompassing Agentic Supervised Fine-Tuning (Agentic SFT) and Agentic Variance-Reduced Preference Optimization Agentic VRPO, which enhances the backbone dLLM's information seeking and reasoning capabilities. To mitigate the Latency Challenge , we leverage the flexible generation mechanism of dLLMs and propose a novel agent paradigm termed Parallel-Reasoning and Acting P-ReAct . P-ReAct guides the model to prioritize decoding tool_call instructions, thereby allowing the model to keep thinking while waiting for the tool's return. Experimental results demonstrate that DLLM-Searcher achieves performance comparable to mainstream LLM-based search agents and P-ReAct delivers approximately 15% inference acceleration. Our code is available at https://anonymous.4open.science/r/DLLM-Searcher-553C",
    "summary_en": "Diffusion Large Language Models are optimized for search agents through enhanced reasoning capabilities and reduced latency via a parallel reasoning paradigm.",
    "summary_zh": "扩散大语言模型针对搜索智能体优化，通过增强推理能力并借助并行推理范式降低延迟。",
    "upvotes": 30
  },
  {
    "id": "2602.09084",
    "date": "2026-02-11",
    "title": "Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling",
    "authors": "Ruijie Ye Jiayi Zhang Zhuoxin Liu Zihao Zhu Siyuan Yang Li Li Tianfu Fu Franck Dernoncourt Yue Zhao Jiacheng Zhu Ryan Rossi Wenhao Chai Zhengzhong Tu",
    "abstract": "Agent Banana addresses challenges in instruction-based image editing through a hierarchical framework with context folding and image layer decomposition for high-fidelity, multi-turn editing at ultra-high resolution. We study instruction-based image editing under professional workflows and identify three persistent challenges: (i) editors often over-edit, modifying content beyond the user's intent; (ii) existing models are largely single-turn, while multi-turn edits can alter object faithfulness; and (iii) evaluation at around 1K resolution is misaligned with real workflows that often operate on ultra high-definition images (e.g., 4K). We propose Agent Banana, a hierarchical agentic planner-executor framework for high-fidelity, object-aware, deliberative editing . Agent Banana introduces two key mechanisms: (1) Context Folding , which compresses long interaction histories into structured memory for stable long-horizon control ; and (2) Image Layer Decomposition , which performs localized layer-based edits to preserve non-target regions while enabling native-resolution outputs . To support rigorous evaluation, we build HDD-Bench , a high-definition, dialogue-based benchmark featuring verifiable stepwise targets and native 4K images (11.8M pixels) for diagnosing long-horizon failures. On HDD-Bench , Agent Banana achieves the best multi-turn consistency and background fidelity (e.g., IC 0.871, SSIM-OM 0.84, LPIPS-OM 0.12) while remaining competitive on instruction following, and also attains strong performance on standard single-turn editing benchmarks. We hope this work advances reliable, professional-grade agentic image editing and its integration into real workflows.",
    "summary_en": "Agent Banana addresses challenges in instruction-based image editing through a hierarchical framework with context folding and image layer decomposition for high-fidelity, multi-turn editing at ultra-high resolution.",
    "summary_zh": "Agent Banana 通过具有上下文折叠和图像层分解的分层框架，解决了基于指令的图像编辑中的挑战，实现了超高分辨率下的高保真多轮编辑。",
    "upvotes": 27
  },
  {
    "id": "2602.10104",
    "date": "2026-02-11",
    "title": "Olaf-World: Orienting Latent Actions for Video World Modeling",
    "authors": "Yuxin Jiang Yuchao Gu Ivor W. Tsang Mike Zheng Shou",
    "abstract": "Sequence-level control-effect alignment enables structured latent action space learning for zero-shot action transfer in video world models. Scaling action-controllable world models is limited by the scarcity of action labels. While latent action learning promises to extract control interfaces from unlabeled video, learned latents often fail to transfer across contexts: they entangle scene-specific cues and lack a shared coordinate system. This occurs because standard objectives operate only within each clip, providing no mechanism to align action semantics across contexts. Our key insight is that although actions are unobserved, their semantic effects are observable and can serve as a shared reference. We introduce SeqΔ-REPA, a sequence-level control-effect alignment objective that anchors integrated latent action to temporal feature differences from a frozen, self-supervised video encoder . Building on this, we present Olaf-World, a pipeline that pretrains action-conditioned video world models from large-scale passive video. Extensive experiments demonstrate that our method learns a more structured latent action space, leading to stronger zero-shot action transfer and more data-efficient adaptation to new control interfaces than state-of-the-art baselines.",
    "summary_en": "Sequence-level control-effect alignment enables structured latent action space learning for zero-shot action transfer in video world models.",
    "summary_zh": "序列级控制-效果对齐支持视频世界模型学习结构化潜在动作空间，实现零样本动作迁移。",
    "upvotes": 26
  },
  {
    "id": "2602.08847",
    "date": "2026-02-11",
    "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
    "authors": "Lang Feng Longtao Zheng Shuo He Fuxiang Zhang Bo An",
    "abstract": "Multi-agent large language model systems face training instability in reinforcement learning due to global normalization mismatches, which is addressed by Dr. MAS through agent-specific advantage normalization and enhanced training stability. Multi-agent LLM systems enable advanced reasoning and tool use via role specialization, yet reliable reinforcement learning (RL) post-training for such systems remains difficult. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems . We show that under GRPO-style optimization , a global normalization baseline may deviate from diverse agents' reward distributions, which ultimately leads to gradient-norm instability . Based on this finding, we propose Dr. MAS, a simple and stable RL training recipe for multi-agent LLM systems . Dr. MAS uses an agent-wise remedy : normalizing advantages per agent using each agent's own reward statistics, which calibrates gradient scales and dramatically stabilizes training, both theoretically and empirically. Beyond the algorithm, Dr. MAS provides an end-to-end RL training framework for multi-agent LLM systems , supporting scalable orchestration, flexible per-agent LLM serving and optimization configs, and shared resource scheduling of LLM actor backends. We evaluate Dr. MAS on multi-agent math reasoning and multi-turn search benchmarks using Qwen2.5 and Qwen3 series models. Dr. MAS achieves clear gains over vanilla GRPO (e.g., +5.6\\% avg@16 and +4.6\\% pass@16 on math, and +15.2\\% avg@16 and +13.1\\% pass@16 on search) while largely eliminating gradient spikes. Moreover, it remains highly effective under heterogeneous agent-model assignments while improving efficiency.",
    "summary_en": "Multi-agent large language model systems face training instability in reinforcement learning due to global normalization mismatches, which is addressed by Dr. MAS through agent-specific advantage normalization and enhanced training stability.",
    "summary_zh": "多智能体大语言模型系统在强化学习中因全局归一化不匹配而面临训练不稳定问题，Dr. MAS通过智能体特定的优势归一化与增强的训练稳定性解决该问题。",
    "upvotes": 24
  },
  {
    "id": "2602.07422",
    "date": "2026-02-11",
    "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model",
    "authors": "Tianyi Wu Mingzhe Du Yue Liu Chengran Yang Terry Yue Zhuo Jiaheng Zhang See-Kiong Ng",
    "abstract": "SecCoderX uses online reinforcement learning to align large language models for secure code generation while preserving functionality, addressing the functionality-security trade-off through vulnerability detection integration and reward modeling. Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation . SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality-grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning-based vulnerability reward model that provides scalable and reliable security supervision . Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX.",
    "summary_en": "SecCoderX uses online reinforcement learning to align large language models for secure code generation while preserving functionality, addressing the functionality-security trade-off through vulnerability detection integration and reward modeling.",
    "summary_zh": "SecCoderX 利用在线强化学习对齐大语言模型，在保留功能性的同时实现安全代码生成，并通过集成漏洞检测与奖励建模解决功能与安全性的权衡问题。",
    "upvotes": 21
  },
  {
    "id": "2602.00268",
    "date": "2026-02-11",
    "title": "TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation",
    "authors": "Ariel Shaulov Eitan Shaar Amit Edenzon Lior Wolf",
    "abstract": "Auto-regressive video generation suffers from temporal drift due to error accumulation in latent conditioning tokens, which is addressed by identifying and removing unstable tokens during inference to improve long-horizon consistency. Auto-regressive video generation enables long video synthesis by iteratively conditioning each new batch of frames on previously generated content. However, recent work has shown that such pipelines suffer from severe temporal drift , where errors accumulate and amplify over long horizons. We hypothesize that this drift does not primarily stem from insufficient model capacity, but rather from inference-time error propagation . Specifically, we contend that drift arises from the uncontrolled reuse of corrupted latent conditioning tokens during auto-regressive inference. To correct this accumulation of errors, we propose a simple, inference-time method that mitigates temporal drift by identifying and removing unstable latent tokens before they are reused for conditioning. For this purpose, we define unstable tokens as latent tokens whose representations deviate significantly from those of the previously generated batch, indicating potential corruption or semantic drift. By explicitly removing corrupted latent tokens from the auto-regressive context, rather than modifying entire spatial regions or model parameters, our method prevents unreliable latent information from influencing future generation steps. As a result, it significantly improves long-horizon temporal consistency without modifying the model architecture, training procedure, or leaving latent space .",
    "summary_en": "Auto-regressive video generation suffers from temporal drift due to error accumulation in latent conditioning tokens, which is addressed by identifying and removing unstable tokens during inference to improve long-horizon consistency.",
    "summary_zh": "自回归视频生成因潜在条件token的误差累积而存在时间漂移，通过在推理过程中识别并移除不稳定token以提升长程一致性。",
    "upvotes": 21
  },
  {
    "id": "2602.07022",
    "date": "2026-02-11",
    "title": "Condition Errors Refinement in Autoregressive Image Generation with Diffusion Loss",
    "authors": "Yucheng Zhou Hao Li Jianbing Shen",
    "abstract": "Autoregressive models with diffusion loss outperform traditional diffusion models by effectively mitigating condition errors through patch denoising optimization and condition refinement using Optimal Transport theory. Recent studies have explored autoregressive models for image generation, with promising results, and have combined diffusion models with autoregressive frameworks to optimize image generation via diffusion loss es. In this study, we present a theoretical analysis of diffusion and autoregressive models with diffusion loss , highlighting the latter's advantages. We present a theoretical comparison of conditional diffusion and autoregressive diffusion with diffusion loss , demonstrating that patch denoising optimization in autoregressive models effectively mitigates condition error s and leads to a stable condition distribution . Our analysis also reveals that autoregressive condition generation refines the condition, causing the condition error influence to decay exponentially. In addition, we introduce a novel condition refinement approach based on Optimal Transport (OT) theory to address ``condition inconsistency''. We theoretically demonstrate that formulating condition refinement as a Wasserstein Gradient Flow ensures convergence toward the ideal condition distribution , effectively mitigating condition inconsistency. Experiments demonstrate the superiority of our method over diffusion and autoregressive models with diffusion loss methods.",
    "summary_en": "Autoregressive models with diffusion loss outperform traditional diffusion models by effectively mitigating condition errors through patch denoising optimization and condition refinement using Optimal Transport theory.",
    "summary_zh": "采用扩散损失的自回归模型通过块去噪优化以及基于最优传输理论的条件细化，有效缓解条件误差，性能优于传统扩散模型。",
    "upvotes": 19
  },
  {
    "id": "2602.04208",
    "date": "2026-02-11",
    "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models",
    "authors": "Hyeonbeom Choi Daechul Ahn Youhan Lee Taewook Kang Seongwon Cho Jonghyun Choi",
    "abstract": "SCALE is a novel inference strategy for Vision-Language-Action models that jointly modulates visual perception and action based on self-uncertainty, improving robustness without additional training or multiple forward passes. Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic control, with test-time scaling (TTS) gaining attention to enhance robustness beyond training. However, existing TTS methods for VLAs require additional training, verifiers, and multiple forward passes, making them impractical for deployment. Moreover, they intervene only at action decoding while keeping visual representations fixed-insufficient under perceptual ambiguity , where reconsidering how to perceive is as important as deciding what to do. To address these limitations, we propose SCALE, a simple inference strategy that jointly modulates visual perception and action based on ' self-uncertainty ', inspired by uncertainty-driven exploration in Active Inference theory-requiring no additional training, no verifier, and only a single forward pass. SCALE broadens exploration in both perception and action under high uncertainty, while focusing on exploitation when confident-enabling adaptive execution across varying conditions. Experiments on simulated and real-world benchmarks demonstrate that SCALE improves state-of-the-art VLAs and outperforms existing TTS methods while maintaining single-pass efficiency.",
    "summary_en": "SCALE is a novel inference strategy for Vision-Language-Action models that jointly modulates visual perception and action based on self-uncertainty, improving robustness without additional training or multiple forward passes.",
    "summary_zh": "SCALE是一种针对视觉-语言-动作模型的新型推理策略，它基于自不确定性联合调节视觉感知与动作，无需额外训练或多次前向传播即可提升鲁棒性。",
    "upvotes": 19
  },
  {
    "id": "2602.00462",
    "date": "2026-02-11",
    "title": "LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs",
    "authors": "Benno Krojer Shravan Nayak Oscar Mañas Vaibhav Adlakha Desmond Elliott Siva Reddy Marius Mosbach",
    "abstract": "LatentLens enables interpretation of visual token representations in vision-language models by comparing them to contextualized textual representations, revealing that visual tokens are more interpretable than previously thought. Transforming a large language model ( LLM ) into a Vision-Language Model (VLM) can be achieved by mapping the visual tokens from a vision encoder into the embedding space of an LLM . Intriguingly, this mapping can be as simple as a shallow MLP transformation . To understand why LLM s can so readily process visual tokens , we need interpretability methods that reveal what is encoded in the visual token representations at every layer of LLM processing. In this work, we introduce LatentLens, a novel approach for mapping latent representations to descriptions in natural language. LatentLens works by encoding a large text corpus and storing contextualized token representations for each token in that corpus. Visual token representations are then compared to their contextualized textual representations, with the top-k nearest neighbor representations providing descriptions of the visual token. We evaluate this method on 10 different VLMs, showing that commonly used methods, such as LogitLens, substantially underestimate the interpretability of visual tokens . With LatentLens instead, the majority of visual tokens are interpretable across all studied models and all layers. Qualitatively, we show that the descriptions produced by LatentLens are semantically meaningful and provide more fine-grained interpretations for humans compared to individual tokens. More broadly, our findings contribute new evidence on the alignment between vision and language representations, opening up new directions for analyzing latent representations .",
    "summary_en": "LatentLens enables interpretation of visual token representations in vision-language models by comparing them to contextualized textual representations, revealing that visual tokens are more interpretable than previously thought.",
    "summary_zh": "LatentLens通过将视觉-语言模型中的视觉token表示与上下文文本表示进行比较，实现了对其的解释，并揭示视觉token比之前认为的更具可解释性。",
    "upvotes": 18
  },
  {
    "id": "2602.10098",
    "date": "2026-02-11",
    "title": "VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model",
    "authors": "Jingwen Sun Wenyao Zhang Zekun Qi Shaojie Ren Zezhi Liu Hanxin Zhu Guangzhong Sun Xin Jin Zhibo Chen",
    "abstract": "VLA-JEPA is a JEPA-style pretraining framework that improves vision-language-action policy learning by using leakage-free state prediction in latent space, enhancing generalization and robustness in manipulation tasks. Pretraining Vision-Language-Action (VLA) policies on internet-scale video is appealing, yet current latent-action objectives often learn the wrong thing: they remain anchored to pixel variation rather than action-relevant state transitions , making them vulnerable to appearance bias , nuisance motion , and information leakage . We introduce VLA- JEPA , a JEPA -style pretraining framework that sidesteps these pitfalls by design. The key idea is leakage-free state prediction: a target encoder produces latent representations from future frames , while the student pathway sees only the current observation -- future information is used solely as supervision targets, never as input. By predicting in latent space rather than pixel space, VLA- JEPA learns dynamics abstractions that are robust to camera motion and irrelevant background changes . This yields a simple two-stage recipe -- JEPA pretraining followed by action-head fine-tuning -- without the multi-stage complexity of prior latent-action pipelines. Experiments on LIBERO, LIBERO-Plus, SimplerEnv and real-world manipulation tasks show that VLA- JEPA achieves consistent gains in generalization and robustness over existing methods.",
    "summary_en": "VLA-JEPA is a JEPA-style pretraining framework that improves vision-language-action policy learning by using leakage-free state prediction in latent space, enhancing generalization and robustness in manipulation tasks.",
    "summary_zh": "VLA-JEPA是一种JEPA风格的预训练框架，利用潜在空间中的无泄漏状态预测改进视觉-语言-动作策略学习，提升操作任务的泛化性和鲁棒性。",
    "upvotes": 17
  },
  {
    "id": "2602.09849",
    "date": "2026-02-11",
    "title": "BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation",
    "authors": "Yucheng Hu Jianke Zhang Yuanfei Luo Yanjiang Guo Xiaoyu Chen Xinshu Sun Kun Feng Qingzhou Lu Sheng Chen Yangang Zhang Wei Li Jianyu Chen",
    "abstract": "BagelVLA is a unified Vision-Language-Action model that integrates linguistic planning, visual forecasting, and action generation through residual flow guidance for improved manipulation tasks. Equipping embodied agents with the ability to reason about tasks, foresee physical outcomes, and generate precise actions is essential for general-purpose manipulation. While recent Vision-Language-Action (VLA) models have leveraged pre-trained foundation models, they typically focus on either linguistic planning or visual forecasting in isolation. These methods rarely integrate both capabilities simultaneously to guide action generation , leading to suboptimal performance in complex, long-horizon manipulation tasks. To bridge this gap, we propose BagelVLA, a unified model that integrates linguistic planning , visual forecasting , and action generation within a single framework. Initialized from a pretrained unified understanding and generative model, BagelVLA is trained to interleave textual reasoning and visual prediction directly into the action execution loop. To efficiently couple these modalities, we introduce Residual Flow Guidance (RFG), which initializes from current observation and leverages single-step denoising to extract predictive visual features, guiding action generation with minimal latency. Extensive experiments demonstrate that BagelVLA outperforms existing baselines by a significant margin on multiple simulated and real-world benchmarks, particularly in tasks requiring multi-stage reasoning .",
    "summary_en": "BagelVLA is a unified Vision-Language-Action model that integrates linguistic planning, visual forecasting, and action generation through residual flow guidance for improved manipulation tasks.",
    "summary_zh": "BagelVLA是一种统一的Vision-Language-Action模型，通过残差流引导整合语言规划、视觉预测和动作生成，以改进操作任务。",
    "upvotes": 16
  },
  {
    "id": "2602.09000",
    "date": "2026-02-11",
    "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
    "authors": "Ali Hatamizadeh Shrimai Prabhumoye Igor Gitman Ximing Lu Seungju Han Wei Ping Yejin Choi Jan Kautz",
    "abstract": "Iterative Group Relative Policy Optimization enhances mathematical reasoning in large language models through a two-stage process combining exploratory drafting and refined iterations, achieving state-of-the-art results on competitive benchmarks. Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization . We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements , training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse . These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning .",
    "summary_en": "Iterative Group Relative Policy Optimization enhances mathematical reasoning in large language models through a two-stage process combining exploratory drafting and refined iterations, achieving state-of-the-art results on competitive benchmarks.",
    "summary_zh": "迭代式群体相对策略优化通过结合探索性起草与精细化迭代的两阶段过程，增强大语言模型的数学推理能力，并在竞争性基准测试中取得最先进的结果。",
    "upvotes": 15
  },
  {
    "id": "2602.01244",
    "date": "2026-02-11",
    "title": "Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments",
    "authors": "Siwei Wu Yizhi Li Yuyang Song Wei Zhang Yang Wang Riza Batista-Navarro Xian Yang Mingjie Tang Bryan Dai Jian Yang Chenghua Lin",
    "abstract": "A scalable pipeline called TerminalTraj addresses challenges in creating high-quality terminal trajectories for training agentic models by filtering repositories, generating Docker-aligned task instances, and synthesizing executable agent trajectories across multiple domains. Training agentic models for terminal-based tasks critically depends on high-quality terminal trajectories that capture realistic long-horizon interactions across diverse domains. However, constructing such data at scale remains challenging due to two key requirements: \\emph{ Executability }, since each instance requires a suitable and often distinct Docker environment; and \\emph{ Verifiability }, because heterogeneous task outputs preclude unified, standardized verification. To address these challenges, we propose TerminalTraj, a scalable pipeline that (i) filters high-quality repositories to construct Dockerized execution environments, (ii) generates Docker-aligned task instances , and (iii) synthesizes agent trajectories with executable validation code. Using TerminalTraj, we curate 32K Docker images and generate 50,733 verified terminal trajectories across eight domains. Models trained on this data with the Qwen2.5-Coder backbone achieve consistent performance improvements on TerminalBench (TB), with gains of up to 20\\% on TB~1.0 and 10\\% on TB~2.0 over their respective backbones. Notably, TerminalTraj-32B achieves strong performance among models with fewer than 100B parameters, reaching 35.30\\% on TB~1.0 and 22.00\\% on TB~2.0, and demonstrates improved test-time scaling behavior. All code and data are available at https://github.com/Wusiwei0410/TerminalTraj.",
    "summary_en": "A scalable pipeline called TerminalTraj addresses challenges in creating high-quality terminal trajectories for training agentic models by filtering repositories, generating Docker-aligned task instances, and synthesizing executable agent trajectories across multiple domains.",
    "summary_zh": "名为 TerminalTraj 的可扩展流程通过筛选代码仓库、生成 Docker 对齐的任务实例并在多领域合成可执行智能体轨迹，解决了为训练智能体模型创建高质量终端轨迹的挑战。",
    "upvotes": 15
  },
  {
    "id": "2602.10102",
    "date": "2026-02-11",
    "title": "VideoWorld 2: Learning Transferable Knowledge from Real-world Videos",
    "authors": "Zhongwei Ren Yunchao Wei Xiao Yu Guixun Luo Yao Zhao Bingyi Kang Jiashi Feng Xiaojie Jin",
    "abstract": "VideoWorld 2 enables transferable knowledge learning from raw videos through a dynamic-enhanced Latent Dynamics Model that decouples action dynamics from visual appearance, achieving improved task performance and long-horizon reasoning in real-world applications. Learning transferable knowledge from unlabeled video data and applying it in new environments is a fundamental capability of intelligent agents. This work presents VideoWorld 2, which extends VideoWorld and offers the first investigation into learning transferable knowledge directly from raw real-world videos. At its core, VideoWorld 2 introduces a dynamic-enhanced Latent Dynamics Model (dLDM) that decouples action dynamics from visual appearance : a pretrained video diffusion model handles visual appearance modeling, enabling the dLDM to learn latent codes that focus on compact and meaningful task-related dynamics. These latent codes are then modeled autoregressively to learn task policies and support long-horizon reasoning . We evaluate VideoWorld 2 on challenging real-world handcraft making tasks, where prior video generation and latent-dynamics models struggle to operate reliably. Remarkably, VideoWorld 2 achieves up to 70% improvement in task success rate and produces coherent long execution videos. In robotics, we show that VideoWorld 2 can acquire effective manipulation knowledge from the Open-X dataset , which substantially improves task performance on CALVIN . This study reveals the potential of learning transferable world knowledge directly from raw videos, with all code, data, and models to be open-sourced for further research.",
    "summary_en": "VideoWorld 2 enables transferable knowledge learning from raw videos through a dynamic-enhanced Latent Dynamics Model that decouples action dynamics from visual appearance, achieving improved task performance and long-horizon reasoning in real-world applications.",
    "summary_zh": "VideoWorld 2 通过动态增强的潜在动力学模型，将动作动态与视觉外观解耦，实现了从原始视频中进行可迁移知识学习，并在真实世界应用中提升了任务性能与长程推理能力。",
    "upvotes": 14
  },
  {
    "id": "2602.09439",
    "date": "2026-02-11",
    "title": "Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning",
    "authors": "Xu Ma Yitian Zhang Qihua Dong Yun Fu",
    "abstract": "A large-scale, high-quality, and fully open dataset for text-to-image fine-tuning is presented, featuring over 6 million text-image pairs with rigorous filtering for alignment and quality across multiple task combinations and visual styles. High-quality and open datasets remain a major bottleneck for text-to-image (T2I) fine-tuning . Despite rapid progress in model architectures and training pipelines, most publicly available fine-tuning datasets suffer from low resolution, poor text-image alignment , or limited diversity, resulting in a clear performance gap between open research models and enterprise-grade models. In this work, we present Fine-T2I, a large-scale, high-quality, and fully open dataset for T2I fine-tuning . Fine-T2I spans 10 task combinations, 32 prompt categories, 11 visual styles, and 5 prompt templates, and combines synthetic images generated by strong modern models with carefully curated real images from professional photographers. All samples are rigorously filtered for text-image alignment , visual fidelity , and prompt quality , with over 95% of initial candidates removed. The final dataset contains over 6 million text-image pairs, around 2 TB on disk, approaching the scale of pretraining datasets while maintaining fine-tuning -level quality. Across a diverse set of pretrained diffusion and autoregressive models , fine-tuning on Fine-T2I consistently improves both generation quality and instruction adherence, as validated by human evaluation, visual comparison, and automatic metrics. We release Fine-T2I under an open license to help close the data gap in T2I fine-tuning in the open community.",
    "summary_en": "A large-scale, high-quality, and fully open dataset for text-to-image fine-tuning is presented, featuring over 6 million text-image pairs with rigorous filtering for alignment and quality across multiple task combinations and visual styles.",
    "summary_zh": "本文介绍了一个大规模、高质量、完全开源的文本到图像微调数据集，包含超过600万文本-图像对，并针对多种任务组合和视觉风格进行了严格的对齐与质量过滤。",
    "upvotes": 13
  },
  {
    "id": "2602.06820",
    "date": "2026-02-11",
    "title": "ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training",
    "authors": "Dunwei Tu Hongyan Hao Hansi Yang Yihao Chen Yi-Kai Zhang Zhikang Xia Yu Yang Yueqing Sun Xingchen Liu Furao Shen Qi Gu Hui Su Xunliang Cai",
    "abstract": "ScaleEnv framework generates interactive environments from scratch to improve agent generalization through diverse domain scaling and verified task completion. Training generalist agents capable of adapting to diverse scenarios requires interactive environments for self-exploration . However, interactive environments remain critically scarce, and existing synthesis methods suffer from significant limitations regarding environmental diversity and scalability. To address these challenges, we introduce ScaleEnv, a framework that constructs fully interactive environments and verifiable tasks entirely from scratch. Specifically, ScaleEnv ensures environment reliability through procedural testing , and guarantees task completeness and solvability via tool dependency graph expansion and executable action verification . By enabling agents to learn through exploration within ScaleEnv, we demonstrate significant performance improvements on unseen, multi-turn tool-use benchmarks such as τ^2-Bench and VitaBench , highlighting strong generalization capabilities. Furthermore, we investigate the relationship between increasing number of domains and model generalization performance, providing empirical evidence that scaling environmental diversity is critical for robust agent learning.",
    "summary_en": "ScaleEnv framework generates interactive environments from scratch to improve agent generalization through diverse domain scaling and verified task completion.",
    "summary_zh": "ScaleEnv框架从零开始生成交互式环境，通过多样化域缩放与验证任务完成来提升智能体泛化能力。",
    "upvotes": 13
  },
  {
    "id": "2602.09017",
    "date": "2026-02-11",
    "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
    "authors": "Zichen Jeff Cui Omar Rayyan Haritheja Etukuru Bowen Tan Zavier Andrianarivo Zicheng Teng Yihang Zhou Krish Mehta Nicholas Wojno Kevin Yuanbo Wu Manan H Anjaria Ziyuan Wu Manrong Mao Guangxun Zhang Binit Shah Yejin Kim Soumith Chintala Lerrel Pinto Nur Muhammad Mahi Shafiullah",
    "abstract": "Contact-Anchored Policies replace language conditioning with physical contact points and use modular utility models for robust manipulation, achieving superior zero-shot performance with minimal demonstration data through real-to-sim iteration cycles. The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym , a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data , and outperforms large, state-of-the-art VLAs in zero-shot evaluation s by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/",
    "summary_en": "Contact-Anchored Policies replace language conditioning with physical contact points and use modular utility models for robust manipulation, achieving superior zero-shot performance with minimal demonstration data through real-to-sim iteration cycles.",
    "summary_zh": "接触锚定策略以物理接触点替代语言条件，并采用模块化效用模型实现鲁棒操控，通过 real-to-sim 迭代循环，以极少演示数据达成卓越的零样本性能。",
    "upvotes": 12
  },
  {
    "id": "2602.09276",
    "date": "2026-02-11",
    "title": "Effective Reasoning Chains Reduce Intrinsic Dimensionality",
    "authors": "Archiki Prasad Mandar Joshi Kenton Lee Mohit Bansal Peter Shaw",
    "abstract": "Effective chain-of-thought reasoning strategies reduce intrinsic dimensionality, leading to better generalization by requiring fewer model parameters to achieve given accuracy thresholds. Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing a consistent, quantifiable link between these factors and generalization remains challenging. In this work, we identify intrinsic dimensionality as a quantitative measure for characterizing the effectiveness of reasoning chains. Intrinsic dimensionality quantifies the minimum number of model dimensions needed to reach a given accuracy threshold on a given task. By keeping the model architecture fixed and varying the task formulation through different reasoning strategies , we demonstrate that effective reasoning strategies consistently reduce the intrinsic dimensionality of the task. Validating this on GSM8K with Gemma-3 1B and 4B, we observe a strong inverse correlation between the intrinsic dimensionality of a reasoning strategy and its generalization performance on both in-distribution and out-of-distribution data. Our findings suggest that effective reasoning chains facilitate learning by better compressing the task using fewer parameters, offering a new quantitative metric for analyzing reasoning processes.",
    "summary_en": "Effective chain-of-thought reasoning strategies reduce intrinsic dimensionality, leading to better generalization by requiring fewer model parameters to achieve given accuracy thresholds.",
    "summary_zh": "有效的思维链推理策略可降低内在维度，从而在达到给定准确率阈值时只需更少的模型参数，实现更好的泛化。",
    "upvotes": 11
  },
  {
    "id": "2602.08382",
    "date": "2026-02-11",
    "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
    "authors": "Zhuoen Chen Dongfang Li Meishan Zhang Baotian Hu Min Zhang",
    "abstract": "A cognitive-inspired framework for long-context language modeling uses chunk-wise compression and selective memory recall to improve efficiency and performance over traditional approaches. Large Language Models (LLMs) face significant challenges in long-context processing , including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall , rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor . A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning , while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA , extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent .",
    "summary_en": "A cognitive-inspired framework for long-context language modeling uses chunk-wise compression and selective memory recall to improve efficiency and performance over traditional approaches.",
    "summary_zh": "一种受认知启发的长上下文语言建模框架采用分块压缩和选择性记忆召回，以提升效率和性能，优于传统方法。",
    "upvotes": 10
  },
  {
    "id": "2602.07276",
    "date": "2026-02-11",
    "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
    "authors": "Pengrui Han Xueqiang Xu Keyang Xuan Peiyang Song Siru Ouyang Runchu Tian Yuqing Jiang Cheng Qian Pengcheng Jiang Jiashuo Sun Junxia Cui Ming Zhong Ge Liu Jiawei Han Jiaxuan You",
    "abstract": "STEER2ADAPT is a lightweight framework that adapts large language models by composing steering vectors from reusable semantic prior subspaces, enabling efficient and flexible task adaptation through linear combinations of basis vectors.",
    "summary_en": "STEER2ADAPT is a lightweight framework that adapts large language models by composing steering vectors from reusable semantic prior subspaces, enabling efficient and flexible task adaptation through linear combinations of basis vectors.",
    "summary_zh": "STEER2ADAPT是一种轻量级框架，通过从可复用的语义先验子空间中组合引导向量来适配大型语言模型，借助基向量的线性组合实现高效且灵活的任务适配。",
    "upvotes": 10
  },
  {
    "id": "2602.08025",
    "date": "2026-02-11",
    "title": "MIND: Benchmarking Memory Consistency and Action Control in World Models",
    "authors": "Yixuan Ye Xuanyu Lu Yuxin Jiang Yuchao Gu Rui Zhao Qiwei Liang Jiachun Pan Fengda Zhang Weijia Wu Alex Jinpeng Wang",
    "abstract": "MIND is introduced as the first open-domain closed-loop benchmark for evaluating memory consistency and action control in world models, featuring high-quality videos and diverse action spaces to assess temporal stability and contextual coherence. World models aim to understand, remember, and predict dynamic visual environments, yet a unified benchmark for evaluating their fundamental abilities remains lacking. To address this gap, we introduce MIND, the first open-domain closed-loop revisited benchmark for evaluating Memory consIstency and action coNtrol in worlD models . MIND contains 250 high-quality videos at 1080p and 24 FPS, including 100 (first-person) + 100 (third-person) video clips under a shared action space and 25 + 25 clips across varied action spaces covering eight diverse scenes. We design an efficient evaluation framework to measure two core abilities: memory consistency and action control , capturing temporal stability and contextual coherence across viewpoints. Furthermore, we design various action spaces, including different character movement speeds and camera rotation angles, to evaluate the action generalization capability across different action spaces under shared scenes. To facilitate future performance benchmarking on MIND, we introduce MIND-World, a novel interactive Video-to-World baseline . Extensive experiments demonstrate the completeness of MIND and reveal key challenges in current world models , including the difficulty of maintaining long-term memory consistency and generalizing across action spaces. Project page: https://csu-jpg.github.io/MIND.github.io/",
    "summary_en": "MIND is introduced as the first open-domain closed-loop benchmark for evaluating memory consistency and action control in world models, featuring high-quality videos and diverse action spaces to assess temporal stability and contextual coherence.",
    "summary_zh": "MIND是首个用于评估世界模型记忆一致性与动作控制的开放域闭环基准，具有高质量视频与多样化动作空间，用于评估时间稳定性与上下文连贯性。",
    "upvotes": 9
  },
  {
    "id": "2602.09823",
    "date": "2026-02-11",
    "title": "Covo-Audio Technical Report",
    "authors": "Wenfu Wang Chenxing Li Liqiang Zhang Yiyang Zhao Yuxiang Zou Hanzhao Li Mingyu Cui Hao Zhang Kun Wei Le Xu Zikang Huang Jiajun Xu Jiliang Hu Xiang He Zeyu Xie Jiawen Kang Youjun Chen Meng Yu Dong Yu Rilin Chen Linlin Di Shulin Feng",
    "abstract": "Covo-Audio is a 7B-parameter end-to-end large audio language model that processes continuous audio inputs and generates audio outputs, achieving state-of-the-art performance across speech-text modeling, spoken dialogue, and full-duplex voice interaction tasks through large-scale pretraining and post-training techniques. In this work, we present Covo-Audio, a 7B-parameter end-to-end LALM that directly processes continuous audio inputs and generates audio outputs within a single unified architecture. Through large-scale curated pretraining and targeted post-training , Covo-Audio achieves state-of-the-art or competitive performance among models of comparable scale across a broad spectrum of tasks, including speech-text modeling , spoken dialogue , speech understanding , audio understanding , and full-duplex voice interaction . Extensive evaluations demonstrate that the pretrained foundation model exhibits strong speech-text comprehension and semantic reasoning capabilities on multiple benchmarks, outperforming representative open-source models of comparable scale. Furthermore, Covo-Audio-Chat, the dialogue-oriented variant , demonstrates strong spoken conversational abilities , including understanding, contextual reasoning , instruction following , and generating contextually appropriate and empathetic responses , validating its applicability to real-world conversational assistant scenarios. Covo-Audio-Chat-FD, the evolved full-duplex model , achieves substantially superior performance on both spoken dialogue capabilities and full-duplex interaction behaviors, demonstrating its competence in practical robustness. To mitigate the high cost of deploying end-to-end LALM s for natural conversational systems, we propose an intelligence-speaker decoupling strategy that separates dialogue intelligence from voice rendering , enabling flexible voice customization with minimal text-to-speech (TTS) data while preserving dialogue performance. Overall, our results highlight the strong potential of 7B-scale models to integrate sophisticated audio intelligence with high-level semantic reasoning , and suggest a scalable path toward more capable and versatile LALMs.",
    "summary_en": "Covo-Audio is a 7B-parameter end-to-end large audio language model that processes continuous audio inputs and generates audio outputs, achieving state-of-the-art performance across speech-text modeling, spoken dialogue, and full-duplex voice interaction tasks through large-scale pretraining and post-training techniques.",
    "summary_zh": "Covo-Audio是一个7B参数的端到端大型音频语言模型，可处理连续音频输入并生成音频输出，通过大规模预训练和后训练技术，在语音-文本建模、口语对话和全双工语音交互任务上实现了最先进的性能。",
    "upvotes": 8
  },
  {
    "id": "2602.09268",
    "date": "2026-02-11",
    "title": "Rethinking Global Text Conditioning in Diffusion Transformers",
    "authors": "Nikita Starodubcev Daniil Pakhomov Zongze Wu Ilya Drobyshevskiy Yuchen Liu Zhonghao Wang Yuqian Zhou Zhe Lin Dmitry Baranchuk",
    "abstract": "Modulation-based text conditioning in diffusion transformers provides performance benefits when used as guidance for controllable generation rather than just as attention mechanisms. Diffusion transformers typically incorporate textual information via attention layers and a modulation mechanism using a pooled text embedding . Nevertheless, recent approaches discard modulation-based text conditioning and rely exclusively on attention. In this paper, we address whether modulation-based text conditioning is necessary and whether it can provide any performance advantage. Our analysis shows that, in its conventional usage, the pooled embedding contributes little to overall performance, suggesting that attention alone is generally sufficient for faithfully propagating prompt information. However, we reveal that the pooled embedding can provide significant gains when used from a different perspective-serving as guidance and enabling controllable shifts toward more desirable properties. This approach is training-free, simple to implement, incurs negligible runtime overhead, and can be applied to various diffusion models, bringing improvements across diverse tasks, including text-to-image/video generation and image editing .",
    "summary_en": "Modulation-based text conditioning in diffusion transformers provides performance benefits when used as guidance for controllable generation rather than just as attention mechanisms.",
    "summary_zh": "扩散Transformer中，基于调制的文本条件化在作为可控生成引导而非仅作为注意力机制使用时具有性能优势。",
    "upvotes": 8
  },
  {
    "id": "2602.10116",
    "date": "2026-02-11",
    "title": "SAGE: Scalable Agentic 3D Scene Generation for Embodied AI",
    "authors": "Hongchi Xia Xuan Li Zhaoshuo Li Qianli Ma Jiashu Xu Ming-Yu Liu Yin Cui Tsung-Yi Lin Wei-Chiu Ma Shenlong Wang Shuran Song Fangyin Wei",
    "abstract": "SAGE is an agentic framework that automatically generates simulation-ready 3D environments for embodied AI by combining layout and object composition generators with evaluative critics for semantic plausibility and physical stability. Real-world data collection for embodied agents remains costly and unsafe, calling for scalable, realistic, and simulator-ready 3D environments. However, existing scene-generation systems often rely on rule-based or task-specific pipelines, yielding artifacts and physically invalid scenes. We present SAGE, an agentic framework that, given a user-specified embodied task (e.g., \"pick up a bowl and place it on the table\"), understands the intent and automatically generates simulation-ready environments at scale. The agent couples multiple generators for layout and object composition with critics that evaluate semantic plausibility , visual realism , and physical stability . Through iterative reasoning and adaptive tool selection , it self-refines the scenes until meeting user intent and physical validity. The resulting environments are realistic, diverse, and directly deployable in modern simulators for policy training . Policies trained purely on this data exhibit clear scaling trends and generalize to unseen objects and layouts, demonstrating the promise of simulation-driven scaling for embodied AI . Code, demos, and the SAGE-10k dataset can be found on the project page here: https://nvlabs.github.io/sage.",
    "summary_en": "SAGE is an agentic framework that automatically generates simulation-ready 3D environments for embodied AI by combining layout and object composition generators with evaluative critics for semantic plausibility and physical stability.",
    "summary_zh": "SAGE是一种智能体框架，通过结合布局与物体组合生成器以及用于语义合理性和物理稳定性的评估评判器，为具身智能自动生成可直接用于仿真的3D环境。",
    "upvotes": 7
  },
  {
    "id": "2602.09662",
    "date": "2026-02-11",
    "title": "TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution",
    "authors": "Deyang Jiang Jing Huang Xuanle Zhao Lei Chen Liming Zheng Fanfan Liu Haibo Qiu Peng Shi Zhixiong Zeng",
    "abstract": "TreeCUA enables efficient GUI automation scaling through tree-structured trajectory organization and multi-agent collaboration, improving GUI planning capabilities via adaptive exploration and trajectory verification. Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, existing work primarily focuses on scaling GUI grounding rather than the more crucial GUI planning , which requires more sophisticated data collection. In reality, the exploration process of a CUA across apps/desktops/web pages typically follows a tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning . In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evolution. We propose a multi-agent collaborative framework to explore the environment, verify actions, summarize trajectories, and evaluate quality to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise a novel tree-based topology to store and replay duplicate exploration nodes, and design an adaptive exploration algorithm to balance the depth (i.e., trajectory difficulty) and breadth (i.e., trajectory diversity). Moreover, we develop world knowledge guidance and global memory backtracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUA-DPO method from abundant tree node information, improving GUI planning capability by referring to the branch information of adjacent trajectories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improvements, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA.",
    "summary_en": "TreeCUA enables efficient GUI automation scaling through tree-structured trajectory organization and multi-agent collaboration, improving GUI planning capabilities via adaptive exploration and trajectory verification.",
    "summary_zh": "TreeCUA通过树状结构轨迹组织与多智能体协作实现GUI自动化的高效扩展，并通过自适应探索与轨迹验证提升GUI规划能力。",
    "upvotes": 6
  },
  {
    "id": "2602.07839",
    "date": "2026-02-11",
    "title": "TodoEvolve: Learning to Architect Agent Planning Systems",
    "authors": "Jiaxi Liu Yanzuo Jiang Guibin Zhang Zihan Zhang Heng Chang Zhenfei Yin Qibing Ren Junchi Yan",
    "abstract": "TodoEvolve enables autonomous synthesis and revision of task-specific planning architectures through a modular design space and multi-objective reinforcement learning optimization. Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory , a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory , we collect high-quality planning trajectories and train Todo-14B via Impedance-Guided Preference Optimization ( IGPO ), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.",
    "summary_en": "TodoEvolve enables autonomous synthesis and revision of task-specific planning architectures through a modular design space and multi-objective reinforcement learning optimization.",
    "summary_zh": "TodoEvolve通过模块化设计空间与多目标强化学习优化，实现任务特定规划架构的自主合成与修订。",
    "upvotes": 6
  },
  {
    "id": "2602.09153",
    "date": "2026-02-11",
    "title": "SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes",
    "authors": "Nicholas Pfaff Thomas Cohn Sergey Zakharov Rick Cory Russ Tedrake",
    "abstract": "SceneSmith is a hierarchical agentic framework that generates simulation-ready indoor environments from natural language prompts through multiple stages involving VLM agents and integrated asset generation techniques. Simulation has become a key tool for training and evaluating home robots at scale, yet existing environments fail to capture the diversity and physical complexity of real indoor spaces. Current scene synthesis methods produce sparsely furnished rooms that lack the dense clutter, articulated furniture, and physical properties essential for robotic manipulation . We introduce SceneSmith , a hierarchical agentic framework that generates simulation-ready indoor environments from natural language prompts . SceneSmith constructs scenes through successive stagesx2013from architectural layout to furniture placement to small object populationx2013each implemented as an interaction among VLM agents : designer, critic, and orchestrator. The framework tightly integrates asset generation through text-to-3D synthesis for static objects, dataset retrieval for articulated objects, and physical property estimation . SceneSmith generates 3-6x more objects than prior methods, with <2% inter-object collisions and 96% of objects remaining stable under physics simulation. In a user study with 205 participants, it achieves 92% average realism and 91% average prompt faithfulness win rates against baselines. We further demonstrate that these environments can be used in an end-to-end pipeline for automatic robot policy evaluation.",
    "summary_en": "SceneSmith is a hierarchical agentic framework that generates simulation-ready indoor environments from natural language prompts through multiple stages involving VLM agents and integrated asset generation techniques.",
    "summary_zh": "SceneSmith是一种分层智能体框架，通过包含VLM智能体与集成资产生成技术的多阶段流程，基于自然语言提示生成可直接用于仿真的室内环境。",
    "upvotes": 5
  },
  {
    "id": "2602.09024",
    "date": "2026-02-11",
    "title": "Autoregressive Image Generation with Masked Bit Modeling",
    "authors": "Qihang Yu Qihao Liu Ju He Xinyang Zhang Yang Liu Liang-Chieh Chen Xi Chen",
    "abstract": "Discrete tokenizers can match or exceed continuous methods when properly scaled, and a new masked Bit AutoRegressive modeling approach achieves state-of-the-art results with reduced computational costs. This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook size s. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256 , outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/",
    "summary_en": "Discrete tokenizers can match or exceed continuous methods when properly scaled, and a new masked Bit AutoRegressive modeling approach achieves state-of-the-art results with reduced computational costs.",
    "summary_zh": "离散tokenizer在适当扩展时可匹敌甚至超越连续方法，且一种新的掩码Bit自回归建模方法以更低的计算成本达到了最优结果。",
    "upvotes": 5
  },
  {
    "id": "2602.08344",
    "date": "2026-02-11",
    "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
    "authors": "Qi Guo Jianing Wang Deyang Kong Xiangyu Xi Jianfei Zhang Yi Lu Jingang Wang Wei Wang Shikun Zhang Wei Ye",
    "abstract": "Reinforcement learning with verifiable rewards is used to enhance parallel thinking in large reasoning models through outline-guided path exploration that reduces information redundancy and improves solution discovery. Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking , aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase , with limited attention to the path exploration stage . In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards ( RLVR ) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.",
    "summary_en": "Reinforcement learning with verifiable rewards is used to enhance parallel thinking in large reasoning models through outline-guided path exploration that reduces information redundancy and improves solution discovery.",
    "summary_zh": "可验证奖励的强化学习通过大纲引导的路径探索来增强大型推理模型的并行思考，从而减少信息冗余并提升解的发现。",
    "upvotes": 5
  },
  {
    "id": "2602.07755",
    "date": "2026-02-11",
    "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs",
    "authors": "Yiming Xiong Shengran Hu Jeff Clune",
    "abstract": "ALMA is a framework that uses meta-learning to automatically discover memory designs for agentic systems, enabling continual learning without human engineering across diverse domains. The statelessness of foundation models bottlenecks agentic systems ' ability to continually learn, a core capability for long-horizon reasoning and adaptation. To address this limitation, agentic systems commonly incorporate memory modules to retain and reuse past experience, aiming for continual learning during test time. However, most existing memory designs are human-crafted and fixed, which limits their ability to adapt to the diversity and non-stationarity of real-world tasks. In this paper, we introduce ALMA (Automated meta-Learning of Memory designs for Agentic systems ), a framework that meta-learns memory designs to replace hand-engineered memory designs, therefore minimizing human effort and enabling agentic systems to be continual learners across diverse domains. Our approach employs a Meta Agent that searches over memory designs expressed as executable code in an open-ended manner, theoretically allowing the discovery of arbitrary memory designs, including database schemas as well as their retrieval and update mechanisms . Extensive experiments across four sequential decision-making domains demonstrate that the learned memory designs enable more effective and efficient learning from experience than state-of-the-art human-crafted memory designs on all benchmarks. When developed and deployed safely, ALMA represents a step toward self-improving AI systems that learn to be adaptive, continual learners.",
    "summary_en": "ALMA is a framework that uses meta-learning to automatically discover memory designs for agentic systems, enabling continual learning without human engineering across diverse domains.",
    "summary_zh": "ALMA是一个利用元学习自动发现智能体系统记忆设计的框架，能够在不同领域实现无需人工工程的持续学习。",
    "upvotes": 5
  },
  {
    "id": "2602.07153",
    "date": "2026-02-11",
    "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
    "authors": "Jinbiao Wei Yilun Zhao Kangqi Ni Arman Cohan",
    "abstract": "A trajectory expansion framework called Anchor bootstraps scalable desktop supervision from seed demonstrations by identifying branch points and generating new trajectories through state-grounded task variants. End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations . Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.",
    "summary_en": "A trajectory expansion framework called Anchor bootstraps scalable desktop supervision from seed demonstrations by identifying branch points and generating new trajectories through state-grounded task variants.",
    "summary_zh": "名为Anchor的轨迹扩展框架通过识别分支点并生成基于状态的任务变体新轨迹，从种子演示中引导可扩展的桌面监督。",
    "upvotes": 5
  },
  {
    "id": "2602.05085",
    "date": "2026-02-11",
    "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories",
    "authors": "Sidi Lu Zhenwen Liang Dongyang Ma Yan Wang Haitao Mi Dong Yu",
    "abstract": "Locas, a locally-supported parametric memory mechanism, enables flexible integration with transformer models for continual learning while minimizing catastrophic forgetting through principled initialization techniques. In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformer s, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning . We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning . Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation . Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.",
    "summary_en": "Locas, a locally-supported parametric memory mechanism, enables flexible integration with transformer models for continual learning while minimizing catastrophic forgetting through principled initialization techniques.",
    "summary_zh": "Locas是一种局部支持的参数化记忆机制，可与Transformer模型灵活集成以进行持续学习，同时通过原则性初始化技术最小化灾难性遗忘。",
    "upvotes": 4
  },
  {
    "id": "2602.09591",
    "date": "2026-02-11",
    "title": "On the Optimal Reasoning Length for RL-Trained Language Models",
    "authors": "Daisuke Nohara Taishi Nakamura Rio Yokota",
    "abstract": "Length control methods in reinforcement learning-trained language models affect reasoning performance and computational efficiency, with optimal output lengths balancing these factors. Reinforcement learning substantially improves reasoning in large language models, but it also tends to lengthen chain of thought outputs and increase computational cost during both training and inference. Though length control methods have been proposed, it remains unclear what the optimal output length is for balancing efficiency and performance . In this work, we compare several length control methods on two models, Qwen3-1.7B Base and DeepSeek-R1-Distill-Qwen-1.5B. Our results indicate that length penalties may hinder reasoning acquisition , while properly tuned length control can improve efficiency for models with strong prior reasoning. By extending prior work to RL trained policies, we identify two failure modes, 1) long outputs increase dispersion, and 2) short outputs lead to under-thinking.",
    "summary_en": "Length control methods in reinforcement learning-trained language models affect reasoning performance and computational efficiency, with optimal output lengths balancing these factors.",
    "summary_zh": "强化学习训练的语言模型中的长度控制方法会影响推理性能和计算效率，最优输出长度能够平衡这些因素。",
    "upvotes": 3
  },
  {
    "id": "2602.08503",
    "date": "2026-02-11",
    "title": "Learning Self-Correction in Vision-Language Models via Rollout Augmentation",
    "authors": "Yi Ding Ziliang Qiu Bolian Li Ruqi Zhang",
    "abstract": "Octopus, an RL rollout augmentation framework, enables efficient self-correction learning in vision-language models through synthetic example generation and response masking strategies. Self-correction is essential for solving complex reasoning problems in vision-language models (VLMs). However, existing reinforcement learning (RL) methods struggle to learn it, as effective self-correction behaviors emerge only rarely, making learning signals extremely sparse. To address this challenge, we propose correction-specific rollouts (Octopus), an RL rollout augmentation framework that synthesizes dense self-correction examples by recombining existing rollouts. This augmentation simultaneously improves sample efficiency due to rollout reuse and stabilizes RL optimization through balanced supervision. Furthermore, we introduce a response-masking strategy that decouples self-correction from direct reasoning, avoiding signal conflicts and enabling both behaviors to be learned effectively. Building on this, we introduce Octopus-8B, a reasoning VLM with controllable self-correction capability. Across 7 benchmarks, it achieves SoTA performance among open-source VLMs, outperforming the best RLVR baseline by 1.0 score while requiring only 0.72times training time per step.",
    "summary_en": "Octopus, an RL rollout augmentation framework, enables efficient self-correction learning in vision-language models through synthetic example generation and response masking strategies.",
    "summary_zh": "Octopus 是一种 RL rollout 增强框架，通过合成样本生成与响应掩码策略，实现了视觉-语言模型的高效自校正学习。",
    "upvotes": 3
  },
  {
    "id": "2602.06161",
    "date": "2026-02-11",
    "title": "Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding",
    "authors": "Yanzheng Xiang Lan Wei Yizhen Yao Qinglin Zhu Hanqi Yan Chen Jin Philip Alexander Teare Dandan Zhang Lin Gui Amrutha Saseendran Yulan He",
    "abstract": "COVER enables efficient parallel decoding for diffusion language models by implementing cache override verification that reduces unnecessary revisions and maintains output quality through stable drafting and attention view construction. Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations , where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within a single forward pass. COVER constructs two attention views via KV cache override : selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with a closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using a stability aware score that balances uncertainty, downstream influence, and cache drift , and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality.",
    "summary_en": "COVER enables efficient parallel decoding for diffusion language models by implementing cache override verification that reduces unnecessary revisions and maintains output quality through stable drafting and attention view construction.",
    "summary_zh": "COVER 通过实现缓存覆盖验证，使扩散语言模型能够进行高效并行解码，减少不必要的修正，并通过稳定的起草与注意力视图构建保持输出质量。",
    "upvotes": 3
  },
  {
    "id": "2602.05892",
    "date": "2026-02-11",
    "title": "ContextBench: A Benchmark for Context Retrieval in Coding Agents",
    "authors": "Han Li Letian Zhu Bohan Zhang Rili Feng Jiaming Wang Yue Pan Earl T. Barr Sarro Federica Zhaoyang Chu He Ye",
    "abstract": "ContextBench evaluates context retrieval in coding agents through detailed process analysis, revealing that advanced agent designs provide limited improvements in context usage while highlighting gaps between explored and utilized information. LLM-based coding agents have shown strong performance on automated issue resolution benchmarks, yet existing evaluations largely focus on final task success, providing limited insight into how agents retrieve and use code context during problem solving. We introduce ContextBench, a process-oriented evaluation of context retrieval in coding agents . ContextBench consists of 1,136 issue-resolution tasks from 66 repositories across eight programming languages, each augmented with human-annotated gold contexts . We further implement an automated evaluation framework that tracks agent trajectories and measures context recall , precision, and efficiency throughout issue resolution . Using ContextBench, we evaluate four frontier LLMs and five coding agents . Our results show that sophisticated agent scaffolding yields only marginal gains in context retrieval (\"The Bitter Lesson\" of coding agents ), LLMs consistently favor recall over precision, and substantial gaps exist between explored and utilized context. ContextBench augments existing end-to-end benchmarks with intermediate gold-context metrics that unbox the issue-resolution process. These contexts offer valuable intermediate signals for guiding LLM reasoning in software tasks.",
    "summary_en": "ContextBench evaluates context retrieval in coding agents through detailed process analysis, revealing that advanced agent designs provide limited improvements in context usage while highlighting gaps between explored and utilized information.",
    "summary_zh": "ContextBench 通过详细的过程分析评估 coding agents 的上下文检索，揭示先进的 agent 设计在上下文使用方面的提升有限，同时突显了已探索信息与已利用信息之间的差距。",
    "upvotes": 3
  },
  {
    "id": "2602.05435",
    "date": "2026-02-11",
    "title": "Stable Velocity: A Variance Perspective on Flow Matching",
    "authors": "Donglin Yang Yongxing Zhang Xin Yu Liang Hou Xin Tao Pengfei Wan Xiaojuan Qi Renjie Liao",
    "abstract": "Stable Velocity framework addresses high-variance training in flow matching by identifying low-variance regimes and proposing variance-reduction techniques for improved training efficiency and sampling speed. While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity, a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet 256times256 and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than 2times faster sampling within the low-variance regime without degrading sample quality. Our code is available at https://github.com/linYDTHU/StableVelocity.",
    "summary_en": "Stable Velocity framework addresses high-variance training in flow matching by identifying low-variance regimes and proposing variance-reduction techniques for improved training efficiency and sampling speed.",
    "summary_zh": "Stable Velocity 框架通过识别低方差区域并提出方差缩减技术，解决流匹配中的高方差训练问题，从而提升训练效率和采样速度。",
    "upvotes": 3
  },
  {
    "id": "2602.02464",
    "date": "2026-02-11",
    "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry",
    "authors": "Or Shafran Shaked Ronen Omri Fahn Shauli Ravfogel Atticus Geiger Mor Geva",
    "abstract": "Mixture of Factor Analyzers (MFA) provides a scalable, unsupervised approach for discovering complex, nonlinear structures in language model activation spaces by modeling local geometric structures through Gaussian regions and their covariance properties. Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space . Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure . MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space , and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space . Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders . Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control , accounting for complex structures that isolated directions fail to capture.",
    "summary_en": "Mixture of Factor Analyzers (MFA) provides a scalable, unsupervised approach for discovering complex, nonlinear structures in language model activation spaces by modeling local geometric structures through Gaussian regions and their covariance properties.",
    "summary_zh": "因子分析器混合模型（MFA）提供了一种可扩展的无监督方法，通过高斯区域及其协方差特性对局部几何结构进行建模，从而发现语言模型激活空间中的复杂非线性结构。",
    "upvotes": 3
  },
  {
    "id": "2602.10099",
    "date": "2026-02-11",
    "title": "Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders",
    "authors": "Amandeep Kumar Vishal M. Patel",
    "abstract": "Geometric interference in standard diffusion transformers prevents convergence on representation encoders, which is resolved through Riemannian flow matching with jacobi regularization enabling effective training without width scaling. Leveraging representation encoders for generative modeling offers a path for efficient, high-fidelity synthesis. However, standard diffusion transformers fail to converge on these representations directly. While recent work attributes this to a capacity bottleneck proposing computationally expensive width scaling of diffusion transformers we demonstrate that the failure is fundamentally geometric. We identify Geometric Interference as the root cause: standard Euclidean flow matching forces probability paths through the low-density interior of the hyperspherical feature space of representation encoders , rather than following the manifold surface. To resolve this, we propose Riemannian Flow Matching with Jacobi Regularization (RJF). By constraining the generative process to the manifold geodesics and correcting for curvature-induced error propagation , RJF enables standard Diffusion Transformer architectures to converge without width scaling. Our method RJF enables the standard DiT-B architecture (131M parameters) to converge effectively, achieving an FID of 3.37 where prior methods fail to converge. Code: https://github.com/amandpkr/RJF",
    "summary_en": "Geometric interference in standard diffusion transformers prevents convergence on representation encoders, which is resolved through Riemannian flow matching with jacobi regularization enabling effective training without width scaling.",
    "summary_zh": "标准扩散Transformer中的几何干扰阻碍了表示编码器的收敛，通过结合Jacobi正则化的黎曼流匹配可解决该问题，从而在无需宽度缩放的情况下实现有效训练。",
    "upvotes": 2
  },
  {
    "id": "2602.07398",
    "date": "2026-02-11",
    "title": "AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management",
    "authors": "Ruoyao Wen Hao Li Chaowei Xiao Ning Zhang",
    "abstract": "AgentSys defends against indirect prompt injection in LLM agents through hierarchical memory isolation and controlled data flow, significantly reducing attack success rates while maintaining performance. Indirect prompt injection threatens LLM agents by embedding malicious instructions in external content, enabling unauthorized actions and data theft. LLM agents maintain working memory through their context window , which stores interaction history for decision-making. Conventional agents indiscriminately accumulate all tool outputs and reasoning traces in this memory, creating two critical vulnerabilities: (1) injected instructions persist throughout the workflow, granting attackers multiple opportunities to manipulate behavior, and (2) verbose, non-essential content degrades decision-making capabilities. Existing defenses treat bloated memory as given and focus on remaining resilient, rather than reducing unnecessary accumulation to prevent the attack. We present AgentSys, a framework that defends against indirect prompt injection through explicit memory management. Inspired by process memory isolation in operating systems, AgentSys organizes agents hierarchically: a main agent spawns worker agents for tool calls , each running in an isolated context and able to spawn nested workers for subtasks. External data and subtask traces never enter the main agent's memory; only schema-validated return values can cross boundaries through deterministic JSON parsing . Ablations show isolation alone cuts attack success to 2.19%, and adding a validator/sanitizer further improves defense with event-triggered checks whose overhead scales with operations rather than context length. On AgentDojo and ASB, AgentSys achieves 0.78% and 4.25% attack success while slightly improving benign utility over undefended baselines. It remains robust to adaptive attackers and across multiple foundation models, showing that explicit memory management enables secure, dynamic LLM agent architectures. Our code is available at: https://github.com/ruoyaow/agentsys-memory.",
    "summary_en": "AgentSys defends against indirect prompt injection in LLM agents through hierarchical memory isolation and controlled data flow, significantly reducing attack success rates while maintaining performance.",
    "summary_zh": "AgentSys通过分层内存隔离和受控数据流防御LLM智能体中的间接提示注入，显著降低攻击成功率的同时保持性能。",
    "upvotes": 2
  },
  {
    "id": "2602.09924",
    "date": "2026-02-11",
    "title": "LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations",
    "authors": "William Lugoloobi Thomas Foster William Bankes Chris Russell",
    "abstract": "LLMs' internal representations can predict problem difficulty and enable efficient inference routing that reduces costs while maintaining performance. Running LLMs with extended reasoning on every problem is expensive, but determining which inputs actually require additional compute remains challenging. We investigate whether their own likelihood of success is recoverable from their internal representations before generation, and if this signal can guide more efficient inference. We train linear probes on pre-generation activations to predict policy-specific success on math and coding tasks , substantially outperforming surface features such as question length and TF-IDF. Using E2H-AMC , which provides both human and model performance on identical problems, we show that models encode a model-specific notion of difficulty that is distinct from human difficulty, and that this distinction increases with extended reasoning . Leveraging these probes, we demonstrate that routing queries across a pool of models can exceed the best-performing model whilst reducing inference cost by up to 70\\% on MATH, showing that internal representations enable practical efficiency gains even when they diverge from human intuitions about difficulty. Our code is available at: https://github.com/KabakaWilliam/llms_know_difficulty",
    "summary_en": "LLMs' internal representations can predict problem difficulty and enable efficient inference routing that reduces costs while maintaining performance.",
    "summary_zh": "LLM的内部表征可以预测问题难度，并实现高效推理路由，从而在保持性能的同时降低成本。",
    "upvotes": 1
  },
  {
    "id": "2602.08519",
    "date": "2026-02-11",
    "title": "Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering",
    "authors": "Yunhui Liu Pengyu Qiu Yu Xing Yongchao Liu Peng Du Chuntao Hong Jiajun Zheng Tao Zheng Tieke He",
    "abstract": "PyAGC presents a production-ready benchmark and library for attributed graph clustering that addresses limitations of current research through scalable, memory-efficient implementations and comprehensive evaluation protocols. Attributed Graph Clustering (AGC) is a fundamental unsupervised task that integrates structural topology and node attributes to uncover latent patterns in graph-structured data . Despite its significance in industrial applications such as fraud detection and user segmentation , a significant chasm persists between academic research and real-world deployment. Current evaluation protocols suffer from the small-scale, high- homophily citation datasets, non-scalable full-batch training paradigms, and a reliance on supervised metrics that fail to reflect performance in label-scarce environments. To bridge these gaps, we present PyAGC, a comprehensive, production-ready benchmark and library designed to stress-test AGC methods across diverse scales and structural properties. We unify existing methodologies into a modular Encode-Cluster-Optimize framework and, for the first time, provide memory-efficient, mini-batch implementations for a wide array of state-of-the-art AGC algorithms. Our benchmark curates 12 diverse datasets, ranging from 2.7K to 111M nodes, specifically incorporating industrial graphs with complex tabular features and low homophily . Furthermore, we advocate for a holistic evaluation protocol that mandates unsupervised structural metrics and efficiency profiling alongside traditional supervised metrics. Battle-tested in high-stakes industrial workflows at Ant Group, this benchmark offers the community a robust, reproducible, and scalable platform to advance AGC research towards realistic deployment. The code and resources are publicly available via GitHub (https://github.com/Cloudy1225/PyAGC), PyPI (https://pypi.org/project/pyagc), and Documentation (https://pyagc.readthedocs.io).",
    "summary_en": "PyAGC presents a production-ready benchmark and library for attributed graph clustering that addresses limitations of current research through scalable, memory-efficient implementations and comprehensive evaluation protocols.",
    "summary_zh": "PyAGC 提出了一个面向属性图聚类的生产就绪基准与库，通过可扩展、内存高效的实现和全面的评估协议，解决了当前研究的局限性。",
    "upvotes": 1
  },
  {
    "id": "2602.07918",
    "date": "2026-02-11",
    "title": "CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution",
    "authors": "Minbeom Kim Mihir Parmar Phillip Wallis Lesly Miculicich Kyomin Jung Krishnamurthy Dj Dvijotham Long T. Le Tomas Pfister",
    "abstract": "CausalArmor is a selective defense framework for AI agents that uses causal ablation to detect and mitigate Indirect Prompt Injection attacks by identifying dominant untrusted segments and applying targeted sanitization. AI agents equipped with tool-calling capabilities are susceptible to Indirect Prompt Injection (IPI) attacks. In this attack scenario, malicious commands hidden within untrusted content trick the agent into performing unauthorized actions. Existing defenses can reduce attack success but often suffer from the over-defense dilemma: they deploy expensive, always-on sanitization regardless of actual threat, thereby degrading utility and latency even in benign scenarios. We revisit IPI through a causal ablation perspective: a successful injection manifests as a dominance shift where the user request no longer provides decisive support for the agent's privileged action, while a particular untrusted segment, such as a retrieved document or tool output, provides disproportionate attributable influence. Based on this signature, we propose CausalArmor, a selective defense framework that (i) computes lightweight, leave-one-out ablation -based attribution s at privileged decision points , and (ii) triggers targeted sanitization only when an untrusted segment dominates the user intent. Additionally, CausalArmor employs retroactive Chain-of-Thought masking to prevent the agent from acting on ``poisoned'' reasoning traces. We present a theoretical analysis showing that sanitization based on attribution margins conditionally yields an exponentially small upper bound on the probability of selecting malicious actions. Experiments on AgentDojo and DoomArena demonstrate that CausalArmor matches the security of aggressive defenses while improving explainability and preserving utility and latency of AI agents.",
    "summary_en": "CausalArmor is a selective defense framework for AI agents that uses causal ablation to detect and mitigate Indirect Prompt Injection attacks by identifying dominant untrusted segments and applying targeted sanitization.",
    "summary_zh": "CausalArmor是一种面向AI智能体的选择性防御框架，利用因果消融技术检测和缓解间接提示注入攻击，通过识别主导性不可信片段并实施定向净化。",
    "upvotes": 1
  },
  {
    "id": "2602.07670",
    "date": "2026-02-11",
    "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation",
    "authors": "Jarrod Barnes",
    "abstract": "Test-time training fails in verification-grounded tasks due to over-sharpening, while surprisal-guided selection improves performance by favoring diverse, low-confidence samples.",
    "summary_en": "Test-time training fails in verification-grounded tasks due to over-sharpening, while surprisal-guided selection improves performance by favoring diverse, low-confidence samples.",
    "summary_zh": "测试时训练因过度锐化在基于验证的任务中失效，而惊奇值引导的选择通过偏好多样化低置信样本提升性能。",
    "upvotes": 1
  },
  {
    "id": "2602.04908",
    "date": "2026-02-11",
    "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching",
    "authors": "Chika Maduabuchi Jindong Wang",
    "abstract": "Temporal Pair Consistency reduces variance in continuous-time generative models by coupling velocity predictions at paired timesteps, improving sample quality and efficiency without altering model architecture or training procedures. Continuous-time generative models , such as diffusion models , flow matching , and rectified flow , learn time-dependent vector fields but are typically trained with objectives that treat timesteps independently, leading to high estimator variance and inefficient sampling. Prior approaches mitigate this via explicit smoothness penalties, trajectory regularization, or modified probability paths and solvers. We introduce Temporal Pair Consistency (TPC), a lightweight variance-reduction principle that couples velocity predictions at paired timesteps along the same probability path, operating entirely at the estimator level without modifying the model architecture, probability path, or solver. We provide a theoretical analysis showing that TPC induces a quadratic, trajectory-coupled regularization that provably reduces gradient variance while preserving the underlying flow-matching objective . Instantiated within flow matching , TPC improves sample quality and efficiency across CIFAR-10 and ImageNet at multiple resolutions, achieving lower FID at identical or lower computational cost than prior methods, and extends seamlessly to modern SOTA-style pipelines with noise-augmented training, score-based denoising, and rectified flow .",
    "summary_en": "Temporal Pair Consistency reduces variance in continuous-time generative models by coupling velocity predictions at paired timesteps, improving sample quality and efficiency without altering model architecture or training procedures.",
    "summary_zh": "时序配对一致性通过在配对时间步耦合速度预测来降低连续时间生成模型的方差，在不改变模型架构或训练流程的情况下提升样本质量与效率。",
    "upvotes": 1
  },
  {
    "id": "2602.04802",
    "date": "2026-02-11",
    "title": "VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?",
    "authors": "Qing'an Liu Juntong Feng Yuhao Wang Xinzhe Han Yujie Cheng Yue Zhu Haiwen Diao Yunzhi Zhuge Huchuan Lu",
    "abstract": "VISTA-Bench evaluates vision-language models' ability to understand visualized text versus pure-text queries, revealing significant performance gaps and sensitivity to rendering variations. Vision-Language Models (VLMs) have achieved impressive performance in cross-modal understanding across textual and visual inputs, yet existing benchmarks predominantly focus on pure-text queries . In real-world scenarios, language also frequently appears as visualized text embedded in images, raising the question of whether current VLMs handle such input requests comparably. We introduce VISTA-Bench, a systematic benchmark from multimodal perception , reasoning, to unimodal understanding domains. It evaluates visualized text understanding by contrasting pure-text and visualized-text questions under controlled rendering conditions. Extensive evaluation of over 20 representative VLMs reveals a pronounced modality gap : models that perform well on pure-text queries often degrade substantially when equivalent semantic content is presented as visualized text . This gap is further amplified by increased perceptual difficulty, highlighting sensitivity to rendering variations despite unchanged semantics. Overall, VISTA-Bench provides a principled evaluation framework to diagnose this limitation and to guide progress toward more unified language representations across tokenized text and pixels. The source dataset is available at https://github.com/QingAnLiu/VISTA-Bench.",
    "summary_en": "VISTA-Bench evaluates vision-language models' ability to understand visualized text versus pure-text queries, revealing significant performance gaps and sensitivity to rendering variations.",
    "summary_zh": "VISTA-Bench评估视觉语言模型理解可视化文本与纯文本查询的能力，揭示出显著的性能差距以及对渲染变化的敏感性。",
    "upvotes": 1
  },
  {
    "id": "2602.04521",
    "date": "2026-02-11",
    "title": "C-ΔΘ: Circuit-Restricted Weight Arithmetic for Selective Refusal",
    "authors": "Aditya Kasliwal Pratinav Seth Vinay Kumar Sankarapu",
    "abstract": "Offline selective refusal in large language models is achieved through circuit-restricted weight updates that eliminate runtime intervention costs while maintaining performance. Modern deployments require LLMs to enforce safety policies at scale, yet many controls rely on inference-time interventions that add recurring compute cost and serving complexity. Activation steering is widely used, but it requires runtime hooks and scales cost with the number of generations; conditional variants improve selectivity by gating when steering is applied but still retain an inference-time control path. We ask whether selective refusal can be moved entirely offline: can a mechanistic understanding of category-specific refusal be distilled into a circuit-restricted weight update that deploys as a standard checkpoint? We propose C-Δθ: Circuit Restricted Weight Arithmetic, which (i) localizes refusal-causal computation as a sparse circuit using EAP-IG and (ii) computes a constrained weight update ΔθC supported only on that circuit (typically <5% of parameters). Applying ΔθC yields a drop-in edited checkpoint with no inference-time hooks , shifting cost from per-request intervention to a one-time offline update. We evaluate category-targeted selectivity and capability retention on refusal and utility benchmarks.",
    "summary_en": "Offline selective refusal in large language models is achieved through circuit-restricted weight updates that eliminate runtime intervention costs while maintaining performance.",
    "summary_zh": "大语言模型的离线选择性拒绝通过电路受限权重更新实现，在消除运行时干预成本的同时保持性能。",
    "upvotes": 1
  },
  {
    "id": "2602.01725",
    "date": "2026-02-11",
    "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
    "authors": "Yurun Chen Zeyi Liao Ping Yin Taotao Xie Keting Yin Shengyu Zhang",
    "abstract": "SafePred is a predictive guardrail framework for computer-using agents that uses risk prediction and decision optimization to prevent both immediate and delayed high-risk consequences in complex environments. With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach , with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction : by using safety policies as the basis for risk prediction , SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization : translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning . Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.",
    "summary_en": "SafePred is a predictive guardrail framework for computer-using agents that uses risk prediction and decision optimization to prevent both immediate and delayed high-risk consequences in complex environments.",
    "summary_zh": "SafePred是一种面向计算机使用智能体的预测性护栏框架，利用风险预测和决策优化来防止复杂环境中的即时和延迟高风险后果。",
    "upvotes": 1
  },
  {
    "id": "2601.21235",
    "date": "2026-02-11",
    "title": "SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models",
    "authors": "Alok Abhishek Tushar Bandopadhyay Lisa Erickson",
    "abstract": "Large language models exhibit varying levels of social risk across multiple dimensions, with significant differences in worst-case behavior that cannot be captured by traditional scalar evaluation metrics. Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior . This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias , fairness , ethics , and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk . The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility . Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.",
    "summary_en": "Large language models exhibit varying levels of social risk across multiple dimensions, with significant differences in worst-case behavior that cannot be captured by traditional scalar evaluation metrics.",
    "summary_zh": "大语言模型在多个维度上表现出不同程度的社会风险，其最坏情况行为存在显著差异，而传统标量评估指标无法捕捉这些差异。",
    "upvotes": 1
  },
  {
    "id": "2602.08222",
    "date": "2026-02-10",
    "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
    "authors": "Zehao Chen Gongxun Li Tianxiang Ai Yifei Li Zixuan Huang Wang Zhou Fuzhen Zhuang Xianglong Liu Jianxin Li Deqing Wang Yikun Ban",
    "abstract": "WMSS is a post-training paradigm that uses weak model checkpoints to identify and fill learning gaps, enabling continued improvement beyond conventional saturation points in large language models. As post-training optimization becomes central to improving large language models , we observe a persistent saturation bottleneck : once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning , WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.",
    "summary_en": "WMSS is a post-training paradigm that uses weak model checkpoints to identify and fill learning gaps, enabling continued improvement beyond conventional saturation points in large language models.",
    "summary_zh": "WMSS是一种后训练范式，利用弱模型检查点识别并填补学习缺口，使大语言模型能够在超越传统饱和点后仍持续改进。",
    "upvotes": 256
  },
  {
    "id": "2602.07274",
    "date": "2026-02-10",
    "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
    "authors": "Kaijie Zhu Yuzhou Nie Yijiang Li Yiming Huang Jialian Wu Jiang Liu Ximeng Sun Zhenfei Yin Lun Wang Zicheng Liu Emad Barsoum William Yang Wang Wenbo Guo",
    "abstract": "TermiGen introduces a pipeline for generating verifiable terminal environments and resilient trajectories to improve open-weight LLMs' ability to execute complex tasks and recover from runtime errors. Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch , leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories . Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop . Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles . Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench . This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.",
    "summary_en": "TermiGen introduces a pipeline for generating verifiable terminal environments and resilient trajectories to improve open-weight LLMs' ability to execute complex tasks and recover from runtime errors.",
    "summary_zh": "TermiGen提出了一种生成可验证终端环境与弹性轨迹的流程，旨在提升开放权重LLM执行复杂任务及从运行时错误中恢复的能力。",
    "upvotes": 197
  },
  {
    "id": "2602.07085",
    "date": "2026-02-10",
    "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
    "authors": "Jun Han Shuo Zhang Wei Li Zhi Yang Yifan Dong Tu Hu Jialuo Yuan Xiaomin Yu Yumo Zhu Fangqi Lou Xin Guo Zhaowei Liu Tianyi Jiang Ruichuan An Jingping Liu Biao Wu Rongze Chen Kunyi Wang Yifan Wang Sen Hu Xinbing Kong Liwen Zhang",
    "abstract": "Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajectory and improves factors through trajectory-level mutation and crossover operations. QuantaAlpha localizes suboptimal steps in each trajectory for targeted revision and recombines complementary high-reward segments to reuse effective patterns, enabling structured exploration and refinement across mining iterations. During factor generation, QuantaAlpha enforces semantic consistency across the hypothesis, factor expression, and executable code, while constraining the complexity and redundancy of the generated factor to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains over strong baseline models and prior agentic systems. When utilizing GPT-5.2, QuantaAlpha achieves an Information Coefficient (IC) of 0.1501, with an Annualized Rate of Return (ARR) of 27.75% and a Maximum Drawdown (MDD) of 7.98%. Moreover, factors mined on CSI 300 transfer effectively to the China Securities Index 500 (CSI 500) and the Standard & Poor's 500 Index (S&P 500), delivering 160% and 137% cumulative excess return over four years, respectively, which indicates strong robustness of QuantaAlpha under market distribution shifts.",
    "summary_en": "Financial markets are noisy and non-stationary, making alpha mining sensitive to backtesting noise and regime shifts, while existing agentic frameworks lack controllable multi-round search and reliable reuse of validated experience. QuantaAlpha addresses these challenges through an evolutionary framework that treats each mining run as a trajectory, improving factors via trajectory-level mutation and crossover operations that localize suboptimal steps for targeted revision and recombine complementary high-reward segments to reuse effective patterns. The framework enforces semantic consistency across hypothesis, factor expression, and executable code while constraining complexity and redundancy to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains, with GPT-5.2 achieving an Information Coefficient (IC) of 0.1501, Annualized Rate of Return (ARR) of 27.75%, and Maximum Drawdown (MDD) of 7.98%, and factors transferring effectively to the China Securities Index 500 (CSI 500) and Standard & Poor's 500 Index (S&P 500) to deliver 160% and 137% cumulative excess return over four years, respectively.",
    "summary_zh": "金融市场具有嘈杂且非平稳的特性，使得阿尔法挖掘对回测噪声和机制转换敏感，而现有的智能体框架缺乏可控的多轮搜索和已验证经验的可靠复用。QuantaAlpha通过进化框架应对这些挑战，将每次挖掘运行视为一条轨迹，通过轨迹级变异和交叉操作来改进因子：前者定位次优步骤以进行针对性修正，后者重组互补的高收益片段以复用有效模式。该框架在假设、因子表达式和可执行代码之间强制保持语义一致性，同时约束复杂度和冗余以缓解拥挤。在沪深300指数（CSI 300）上的大量实验表明性能持续提升，其中GPT-5.2实现了0.1501的信息系数（IC）、27.75%的年化收益率（ARR）和7.98%的最大回撤（MDD）；因子有效迁移至中证500指数（CSI 500）和标普500指数（S&P 500），四年内分别实现160%和137%的累计超额收益。",
    "upvotes": 181
  },
  {
    "id": "2602.08794",
    "date": "2026-02-10",
    "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
    "authors": "SII-OpenMOSS Team Donghua Yu Mingshu Chen Qi Chen Qi Luo Qianyi Wu Qinyuan Cheng Ruixiao Li Tianyi Liang Wenbo Zhang Wenming Tu Xiangyu Peng Yang Gao Yanru Huo Ying Zhu Yinze Luo Yiyang Zhang Yuerong Song Zhe Xu Zhiyu Zhang Chenchen Yang Cheng Chang",
    "abstract": "MOVA is an open-source model that generates synchronized audio-visual content using a Mixture-of-Experts architecture with 32 billion parameters, supporting image-text to video-audio generation tasks. Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content , including realistic lip-synced speech , environment-aware sound effects , and content-aligned music . MOVA employs a Mixture-of-Experts ( MoE ) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference , LoRA fine-tuning , and prompt enhancement .",
    "summary_en": "MOVA is an open-source model that generates synchronized audio-visual content using a Mixture-of-Experts architecture with 32 billion parameters, supporting image-text to video-audio generation tasks.",
    "summary_zh": "MOVA是一款采用混合专家（Mixture-of-Experts）架构、拥有320亿参数的开源模型，可生成同步的音视频内容，支持图文到音视频生成任务。",
    "upvotes": 151
  },
  {
    "id": "2602.07026",
    "date": "2026-02-10",
    "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
    "authors": "Xiaomin Yu Yi Xin Wenjie Zhang Chonghan Liu Hanzhen Zhao Xiaoxing Hu Xinlei Yu Ziyue Qiao Hao Tang Xue Yang Xiaobin Hu Chengwei Qin Hui Xiong Yu Qiao Shuicheng Yan",
    "abstract": "Researchers address the modality gap in multimodal learning by proposing a fixed-frame theory and a training-free alignment method that enables efficient scaling of multimodal models using unpaired data. Despite the success of multimodal contrastive learning in aligning visual and linguistic representations, a persistent geometric anomaly , the Modality Gap , remains: embeddings of distinct modalities expressing identical semantics occupy systematically offset regions. Prior approaches to bridge this gap are largely limited by oversimplified isotropic assumptions , hindering their application in large-scale scenarios. In this paper, we address these limitations by precisely characterizing the geometric shape of the modality gap and leveraging it for efficient model scaling. First, we propose the Fixed-frame Modality Gap Theory , which decomposes the modality gap within a frozen reference frame into stable biases and anisotropic residuals. Guided by this precise modeling, we introduce ReAlign , a training-free modality alignment strategy. Utilizing statistics from massive unpaired data , ReAlign aligns text representation into the image representation distribution via a three-step process comprising Anchor, Trace, and Centroid Alignment , thereby explicitly rectifying geometric misalignment. Building on ReAlign , we propose ReVision , a scalable training paradigm for Multimodal Large Language Models (MLLMs). ReVision integrates ReAlign into the pretraining stage , enabling the model to learn the distribution of visual representations from unpaired text before visual instruction tuning , without the need for large-scale, high-quality image-text pairs. Our framework demonstrates that statistically aligned unpaired data can effectively substitute for expensive image-text pairs, offering a robust path for the efficient scaling of MLLMs.",
    "summary_en": "Researchers address the modality gap in multimodal learning by proposing a fixed-frame theory and a training-free alignment method that enables efficient scaling of multimodal models using unpaired data.",
    "summary_zh": "研究人员提出了固定帧理论和免训练对齐方法，以解决多模态学习中的模态差距，实现了利用非配对数据高效扩展多模态模型。",
    "upvotes": 133
  },
  {
    "id": "2602.06855",
    "date": "2026-02-10",
    "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
    "authors": "Alisia Lupidi Bhavul Gauri Thomas Simon Foster Bassel Al Omari Despoina Magka Alberto Pepe Alexis Audran-Reiss Muna Aghamelu Nicolas Baldwin Lucia Cipolina-Kun Jean-Christophe Gagnon-Audet Chee Hau Leow Sandra Lefdal Hossam Mossalam Abhinav Moudgil Saba Nazir Emanuel Tewolde Isabel Urrego Jordi Armengol Estape Amar Budhiraja Gaurav Chaurasia Abhishek Charnalia",
    "abstract": "AIRS-Bench presents a comprehensive benchmark suite for evaluating LLM agents across diverse scientific domains, demonstrating current limitations while providing open-source resources for advancement. LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark ), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including idea generation, experiment analysis and iterative refinement -- without providing baseline code. The AIRS-Bench task format is versatile, enabling easy integration of new tasks and rigorous comparison across different agentic frameworks. We establish baselines using frontier models paired with both sequential and parallel scaffolds . Our results show that agents exceed human SOTA in four tasks but fail to match it in sixteen others. Even when agents surpass human benchmarks, they do not reach the theoretical performance ceiling for the underlying tasks. These findings indicate that AIRS-Bench is far from saturated and offers substantial room for improvement. We open-source the AIRS-Bench task definitions and evaluation code to catalyze further development in autonomous scientific research.",
    "summary_en": "AIRS-Bench presents a comprehensive benchmark suite for evaluating LLM agents across diverse scientific domains, demonstrating current limitations while providing open-source resources for advancement.",
    "summary_zh": "AIRS-Bench提出了一个全面的基准测试套件，用于评估跨多个科学领域的LLM智能体，揭示当前局限性并提供开源资源以推动发展。",
    "upvotes": 70
  },
  {
    "id": "2602.08990",
    "date": "2026-02-10",
    "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
    "authors": "Shiyang Feng Runmin Ma Xiangchao Yan Yue Fan Yusong Hu Songtao Huang Shuaiyu Zhang Zongsheng Cao Tianshuo Peng Jiakang Yuan Zijie Guo Zhijie Zhong Shangheng Du Weida Wang Jinxin Shi Yuhao Zhou Xiaohan He Zhiyin Yu Fangchen Yu Qihao Zheng Jiamin Wu Mianxin Liu",
    "abstract": "InternAgent-1.5 is a unified system for autonomous scientific discovery that integrates computational modeling and experimental research through coordinated subsystems for generation, verification, and evolution. We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research , solution optimization , and long horizon memory . The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system . We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery .",
    "summary_en": "InternAgent-1.5 is a unified system for autonomous scientific discovery that integrates computational modeling and experimental research through coordinated subsystems for generation, verification, and evolution.",
    "summary_zh": "InternAgent-1.5是一个统一的自主科学发现系统，通过协调的生成、验证与演化子系统集成计算建模与实验研究。",
    "upvotes": 69
  },
  {
    "id": "2602.07845",
    "date": "2026-02-10",
    "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning",
    "authors": "Yalcin Tur Jalal Naghiyev Haoquan Fang Wei-Chuan Tsai Jiafei Duan Dieter Fox Ranjay Krishna",
    "abstract": "RD-VLA introduces a recurrent architecture for vision-language-action models that adapts computational depth through latent iterative refinement, achieving constant memory usage and improved task success rates. Current Vision-Language-Action (VLA) models rely on fixed computational depth, expending the same amount of compute on simple adjustments and complex multi-step manipulation. While Chain-of-Thought (CoT) prompting enables variable computation, it scales memory linearly and is ill-suited for continuous action spaces. We introduce Recurrent-Depth VLA (RD-VLA), an architecture that achieves computational adaptivity via latent iterative refinement rather than explicit token generation. RD-VLA employs a recurrent, weight-tied action head that supports arbitrary inference depth with a constant memory footprint. The model is trained using truncated backpropagation through time (TBPTT) to efficiently supervise the refinement process. At inference, RD-VLA dynamically allocates compute using an adaptive stopping criterion based on latent convergence . Experiments on challenging manipulation tasks show that recurrent depth is critical: tasks that fail entirely (0 percent success) with single-iteration inference exceed 90 percent success with four iterations, while simpler tasks saturate rapidly. RD-VLA provides a scalable path to test-time compute in robotics, replacing token-based reasoning with latent reasoning to achieve constant memory usage and up to 80x inference speedup over prior reasoning-based VLA models. Project page: https://rd-vla.github.io/",
    "summary_en": "RD-VLA introduces a recurrent architecture for vision-language-action models that adapts computational depth through latent iterative refinement, achieving constant memory usage and improved task success rates.",
    "summary_zh": "RD-VLA 为视觉-语言-动作模型引入了一种循环架构，通过潜在迭代细化自适应调整计算深度，实现了恒定内存占用并提升了任务成功率。",
    "upvotes": 68
  },
  {
    "id": "2602.08676",
    "date": "2026-02-10",
    "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
    "authors": "Tiwei Bie Maosong Cao Xiang Cao Bingsen Chen Fuyuan Chen Kun Chen Lun Du Daozhuo Feng Haibo Feng Mingliang Gong Zhuocheng Gong Yanmei Gu Jian Guan Kaiyuan Guan Hongliang He Zenan Huang Juyong Jiang Zhonghui Jiang Zhenzhong Lan Chengxi Li Jianguo Li Zehuan Li",
    "abstract": "LLaDA2.1 introduces a novel token-to-token editing approach with speed and quality modes, enhanced through reinforcement learning for improved reasoning and instruction following in large language diffusion models. While LLaDA2.0 showcased the scaling potential of 100B-level block-diffusion models and their inherent parallelization, the delicate equilibrium between decoding speed and generation quality has remained an elusive frontier. Today, we unveil LLaDA2.1, a paradigm shift designed to transcend this trade-off. By seamlessly weaving Token-to-Token (T2T) editing into the conventional Mask-to-Token (M2T) scheme, we introduce a joint, configurable threshold-decoding scheme . This structural innovation gives rise to two distinct personas: the Speedy Mode (S Mode), which audaciously lowers the M2T threshold to bypass traditional constraints while relying on T2T to refine the output; and the Quality Mode (Q Mode), which leans into conservative thresholds to secure superior benchmark performances with manageable efficiency degrade. Furthering this evolution, underpinned by an expansive context window, we implement the first large-scale Reinforcement Learning (RL) framework specifically tailored for dLLMs, anchored by specialized techniques for stable gradient estimation . This alignment not only sharpens reasoning precision but also elevates instruction-following fidelity, bridging the chasm between diffusion dynamics and complex human intent. We culminate this work by releasing LLaDA2.1-Mini (16B) and LLaDA2.1-Flash (100B). Across 33 rigorous benchmarks, LLaDA2.1 delivers strong task performance and lightning-fast decoding speed . Despite its 100B volume, on coding tasks it attains an astounding 892 TPS on HumanEval+ , 801 TPS on BigCodeBench , and 663 TPS on LiveCodeBench .",
    "summary_en": "LLaDA2.1 introduces a novel token-to-token editing approach with speed and quality modes, enhanced through reinforcement learning for improved reasoning and instruction following in large language diffusion models.",
    "summary_zh": "LLaDA2.1提出了一种新颖的token-to-token编辑方法，具备速度和质量模式，并通过强化学习增强，以提升大型语言扩散模型的推理与指令遵循能力。",
    "upvotes": 66
  },
  {
    "id": "2602.07837",
    "date": "2026-02-10",
    "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI",
    "authors": "Hongzhi Zang Shu'ang Yu Hao Lin Tianxing Zhou Zefang Huang Zhen Guo Xin Xu Jiakai Zhou Yuze Sheng Shizhe Zhang Feng Gao Wenhao Tang Yufeng Yue Quanlu Zhang Xinlei Chen Chao Yu Yu Wang",
    "abstract": "USER is a unified systems framework that enables scalable, asynchronous online policy learning in physical robots by treating them as first-class hardware resources and supporting diverse learning paradigms including VLA models. Online policy learning directly in the physical world is a promising yet challenging direction for embodied intelligence . Unlike simulation, real-world systems cannot be arbitrarily accelerated, cheaply reset, or massively replicated, which makes scalable data collection, heterogeneous deployment, and long-horizon effective training difficult. These challenges suggest that real-world policy learning is not only an algorithmic issue but fundamentally a systems problem. We present USER, a Unified and extensible SystEm for Real-world online policy learning . USER treats physical robots as first-class hardware resources alongside GPUs through a unified hardware abstraction layer , enabling automatic discovery, management, and scheduling of heterogeneous robots . To address cloud-edge communication, USER introduces an adaptive communication plane with tunneling-based networking , distributed data channels for traffic localization, and streaming-multiprocessor-aware weight synchronization to regulate GPU-side overhead. On top of this infrastructure, USER organizes learning as a fully asynchronous framework with a persistent, cache-aware buffer , enabling efficient long-horizon experiments with robust crash recovery and reuse of historical data. In addition, USER provides extensible abstractions for rewards, algorithms, and policies, supporting online imitation or reinforcement learning of CNN/MLP, generative policies, and large vision-language-action (VLA) models within a unified pipeline. Results in both simulation and the real world show that USER enables multi-robot coordination , heterogeneous manipulators, edge-cloud collaboration with large models, and long-running asynchronous training, offering a unified and extensible systems foundation for real-world online policy learning .",
    "summary_en": "USER is a unified systems framework that enables scalable, asynchronous online policy learning in physical robots by treating them as first-class hardware resources and supporting diverse learning paradigms including VLA models.",
    "summary_zh": "USER是一个统一的系统框架，通过将物理机器人视为一等硬件资源并支持包括VLA模型在内的多种学习范式，实现可扩展的异步在线策略学习。",
    "upvotes": 53
  },
  {
    "id": "2602.00169",
    "date": "2026-02-10",
    "title": "Towards Agentic Intelligence for Materials Science",
    "authors": "Huan Zhang Yizhan Li Wenhao Huang Ziyu Hou Yu Song Xuye Liu Farshid Effaty Jinya Jiang Sifan Wu Qianggang Ding Izumi Takahara Leonard R. MacGillivray Teruyasu Mizoguchi Tianshu Yu Lizi Liao Yuyu Luo Yu Rong Jia Li Ying Diao Heng Ji Bang Liu",
    "abstract": "AI-driven materials science integrates large language models across discovery pipelines from data curation to agent-based experimentation, emphasizing system-level optimization and autonomous goal pursuit. The convergence of artificial intelligence and materials science presents a transformative opportunity, but achieving true acceleration in discovery requires moving beyond task-isolated, fine-tuned models toward agentic systems that plan, act, and learn across the full discovery loop. This survey advances a unique pipeline-centric view that spans from corpus curation and pretraining, through domain adaptation and instruction tuning , to goal-conditioned agents interfacing with simulation and experimental platforms . Unlike prior reviews, we treat the entire process as an end-to-end system to be optimized for tangible discovery outcomes rather than proxy benchmarks. This perspective allows us to trace how upstream design choices-such as data curation and training objectives-can be aligned with downstream experimental success through effective credit assignment . To bridge communities and establish a shared frame of reference, we first present an integrated lens that aligns terminology, evaluation, and workflow stages across AI and materials science . We then analyze the field through two focused lenses: From the AI perspective, the survey details LLM strengths in pattern recognition , predictive analytics , and natural language processing for literature mining , materials characterization , and property prediction ; from the materials science perspective, it highlights applications in materials design , process optimization , and the acceleration of computational workflows via integration with external tools (e.g., DFT , robotic labs ). Finally, we contrast passive, reactive approaches with agentic design, cataloging current contributions while motivating systems that pursue long-horizon goals with autonomy, memory, and tool use. This survey charts a practical roadmap towards autonomous, safety-aware LLM agents aimed at discovering novel and useful materials.",
    "summary_en": "AI-driven materials science integrates large language models across discovery pipelines from data curation to agent-based experimentation, emphasizing system-level optimization and autonomous goal pursuit.",
    "summary_zh": "AI驱动的材料科学将大语言模型整合到从数据整理到基于智能体的实验的发现流程中，强调系统级优化和自主目标追求。",
    "upvotes": 46
  },
  {
    "id": "2602.06422",
    "date": "2026-02-10",
    "title": "Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO",
    "authors": "Yunze Tong Mushui Liu Canyu Zhao Wanggui He Shiyi Zhang Hongwei Zhang Peng Zhang Jinlong Liu Ju Huang Jiamang Wang Hao Jiang Pipei Huang",
    "abstract": "TP-GRPO addresses reward sparsity in flow matching models by introducing step-level incremental rewards and identifying turning points to capture long-term effects in denoising trajectories. Deploying GRPO on Flow Matching models has proven effective for text-to-image generation . However, existing paradigms typically propagate an outcome-based reward to all preceding denoising steps without distinguishing the local effect of each step. Moreover, current group-wise ranking mainly compares trajectories at matched timesteps and ignores within-trajectory dependencies, where certain early denoising actions can affect later states via delayed, implicit interactions. We propose TurningPoint- GRPO (TP- GRPO ), a GRPO framework that alleviates step-wise reward sparsity and explicitly models long-term effects within the denoising trajectory . TP- GRPO makes two key innovations: (i) it replaces outcome-based rewards with step-level incremental rewards , providing a dense, step-aware learning signal that better isolates each denoising action's \"pure\" effect, and (ii) it identifies turning points -steps that flip the local reward trend and make subsequent reward evolution consistent with the overall trajectory trend-and assigns these actions an aggregated long-term reward to capture their delayed impact . Turning points are detected solely via sign changes in incremental rewards , making TP- GRPO efficient and hyperparameter-free. Extensive experiments also demonstrate that TP- GRPO exploits reward signals more effectively and consistently improves generation. Demo code is available at https://github.com/YunzeTong/TurningPoint- GRPO .",
    "summary_en": "TP-GRPO addresses reward sparsity in flow matching models by introducing step-level incremental rewards and identifying turning points to capture long-term effects in denoising trajectories.",
    "summary_zh": "TP-GRPO通过引入步骤级增量奖励并识别转折点，解决流匹配模型中的奖励稀疏性问题，从而捕捉去噪轨迹中的长期效应。",
    "upvotes": 42
  },
  {
    "id": "2602.08321",
    "date": "2026-02-10",
    "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
    "authors": "Zijie Chen Zhenghao Lin Xiao Liu Zhenzhong Lan Yeyun Gong Peng Cheng",
    "abstract": "A large-scale scientific question dataset and post-training pipeline are developed to improve open-ended science question answering through enhanced data processing and reinforcement learning with rubric-guided evaluation. Solving open-ended science questions remains challenging for large language models , particula rl y due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset , which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT , which broadens the model's reasoning pattern coverage prior to RL ; (ii) Dynamic Difficulty Curriculum , which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL , which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr. SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general , consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning , especially in open-ended settings.",
    "summary_en": "A large-scale scientific question dataset and post-training pipeline are developed to improve open-ended science question answering through enhanced data processing and reinforcement learning with rubric-guided evaluation.",
    "summary_zh": "开发了大规模科学问答数据集与后训练流程，通过增强的数据处理及基于评分标准评估的强化学习，改进开放式科学问答。",
    "upvotes": 40
  },
  {
    "id": "2602.09007",
    "date": "2026-02-10",
    "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
    "authors": "Haodong Li Jingwei Wu Quan Sun Guopeng Li Juanxi Tian Huanyu Zhang Yanlin Lai Ruichuan An Hongbo Peng Yuhong Dai Chenxi Li Chunmei Qing Jia Wang Ziyang Meng Zheng Ge Xiangyu Zhang Daxin Jiang",
    "abstract": "A new benchmark and evaluation metric are introduced for assessing temporal coherence and dynamic interaction in GUI generation models, revealing significant challenges in maintaining consistency over extended interaction sequences. Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity , leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench , a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation . GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score , a novel five-dimensional metric that assesses Goal Achievement , Interaction Logic , Content Consistency , UI Plausibility , and Visual Quality . Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/ GEBench .",
    "summary_en": "A new benchmark and evaluation metric are introduced for assessing temporal coherence and dynamic interaction in GUI generation models, revealing significant challenges in maintaining consistency over extended interaction sequences.",
    "summary_zh": "研究者引入了新的基准测试与评估指标，用于评估GUI生成模型的时间连贯性与动态交互，揭示了在扩展交互序列中保持一致性方面存在重大挑战。",
    "upvotes": 38
  },
  {
    "id": "2602.08439",
    "date": "2026-02-10",
    "title": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
    "authors": "Yuhao Dong Shulin Tian Shuai Liu Shuangrui Ding Yuhang Zang Xiaoyi Dong Yuhang Cao Jiaqi Wang Ziwei Liu",
    "abstract": "Researchers introduce a new video understanding task and benchmark that evaluates models' ability to learn from few-shot demonstrations, along with a specialized MLLM architecture trained using a two-stage approach combining video supervision and preference optimization. Despite the growing video understanding capabilities of recent Multimodal Large Language Models (MLLMs), existing video benchmarks primarily assess understanding based on models' static, internal knowledge, rather than their ability to learn and adapt from dynamic, novel contexts from few examples. To bridge this gap, we present Demo-driven Video In-Context Learning , a novel task focused on learning from in-context demonstrations to answer questions about the target videos. Alongside this, we propose Demo-ICL-Bench , a challenging benchmark designed to evaluate demo-driven video in-context learning capabilities. Demo-ICL-Bench is constructed from 1200 instructional YouTube videos with associated questions, from which two types of demonstrations are derived: (i) summarizing video subtitles for text demonstration; and (ii) corresponding instructional videos as video demonstrations. To effectively tackle this new challenge, we develop Demo-ICL, an MLLM with a two-stage training strategy: video-supervised fine-tuning and information-assisted direct preference optimization , jointly enhancing the model's ability to learn from in-context examples. Extensive experiments with state-of-the-art MLLMs confirm the difficulty of Demo-ICL-Bench , demonstrate the effectiveness of Demo-ICL, and thereby unveil future research directions.",
    "summary_en": "Researchers introduce a new video understanding task and benchmark that evaluates models' ability to learn from few-shot demonstrations, along with a specialized MLLM architecture trained using a two-stage approach combining video supervision and preference optimization.",
    "summary_zh": "研究人员提出了一项用于评估模型从少样本示例中学习能力的视频理解任务与基准，以及一种采用视频监督与偏好优化两阶段训练方法的专用MLLM架构。",
    "upvotes": 28
  },
  {
    "id": "2602.06025",
    "date": "2026-02-10",
    "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
    "authors": "Haozhen Zhang Haodong Yue Tao Feng Quanyu Long Jianzhu Bao Bowen Jin Weizhi Zhang Xiao Li Jiaxuan You Chengwei Qin Wenya Wang",
    "abstract": "BudgetMem is a runtime memory framework for LLM agents that uses modular components with three budget tiers and a neural policy router to optimize performance-cost trade-offs in memory usage. Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present BudgetMem, a runtime agent memory framework for explicit, query-aware performance-cost control . BudgetMem structures memory processing as a set of memory modules , each offered in three budget tiers (i.e., Low/Mid/High). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning . Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers : implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo , LongMemEval , and HotpotQA , BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.",
    "summary_en": "BudgetMem is a runtime memory framework for LLM agents that uses modular components with three budget tiers and a neural policy router to optimize performance-cost trade-offs in memory usage.",
    "summary_zh": "BudgetMem是一种面向LLM智能体的运行时内存框架，采用包含三级预算层级的模块化组件和神经策略路由器，以优化内存使用中的性能与成本权衡。",
    "upvotes": 27
  },
  {
    "id": "2602.08543",
    "date": "2026-02-10",
    "title": "GISA: A Benchmark for General Information-Seeking Assistant",
    "authors": "Yutao Zhu Xingshuo Zhang Maosen Zhang Jiajie Jin Liancheng Zhang Xiaoshuai Song Kangzhi Zhao Wencong Zeng Ruiming Tang Han Li Ji-Rong Wen Zhicheng Dou",
    "abstract": "A new benchmark called GISA is introduced for evaluating information-seeking assistants, featuring human-crafted queries with structured answer formats and live updates to prevent memorization. The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\\% exact match score , with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.",
    "summary_en": "A new benchmark called GISA is introduced for evaluating information-seeking assistants, featuring human-crafted queries with structured answer formats and live updates to prevent memorization.",
    "summary_zh": "新基准 GISA 用于评估信息检索助手，具有人工编写的查询、结构化答案格式和实时更新机制，以防止记忆。",
    "upvotes": 26
  },
  {
    "id": "2602.07962",
    "date": "2026-02-10",
    "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
    "authors": "Weihao Zeng Yuzhen Huang Junxian He",
    "abstract": "LOCA-bench is introduced as a benchmark for evaluating language agents in long-context, agentic scenarios with controlled environment state management. Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \" context rot \". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies . While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: https://github.com/hkust-nlp/ LOCA-bench",
    "summary_en": "LOCA-bench is introduced as a benchmark for evaluating language agents in long-context, agentic scenarios with controlled environment state management.",
    "summary_zh": "LOCA-bench 被提出作为评估语言智能体的基准，针对具备受控环境状态管理的长上下文智能体场景。",
    "upvotes": 24
  },
  {
    "id": "2602.07055",
    "date": "2026-02-10",
    "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
    "authors": "Pingyue Zhang Zihan Huang Yue Wang Jieyu Zhang Letian Xue Zihan Wang Qineng Wang Keshigeyan Chandrasegaran Ruohan Zhang Yejin Choi Ranjay Krishna Jiajun Wu Li Fei-Fei Manling Li",
    "abstract": "Current multimodal foundation models show limitations in maintaining coherent spatial beliefs during active exploration, exhibiting gaps between active and passive performance, inefficient exploration strategies, and difficulties in updating outdated spatial knowledge. Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing , which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap , where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia , where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models . Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial belief s during active exploration .",
    "summary_en": "Current multimodal foundation models show limitations in maintaining coherent spatial beliefs during active exploration, exhibiting gaps between active and passive performance, inefficient exploration strategies, and difficulties in updating outdated spatial knowledge.",
    "summary_zh": "当前多模态基础模型在主动探索过程中维持连贯空间信念方面存在局限性，表现出主动与被动性能差距、探索策略低效以及更新过时空间知识困难等问题。",
    "upvotes": 22
  },
  {
    "id": "2602.06540",
    "date": "2026-02-10",
    "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research",
    "authors": "Yishan Li Wentong Chen Yukun Yan Mingwei Li Sen Mei Xiaorong Wang Kunpeng Liu Xin Cong Shuo Wang Zhong Zhang Yaxi Lu Zhenghao Liu Yankai Lin Zhiyuan Liu Maosong Sun",
    "abstract": "",
    "summary_en": "AgentCPM-Report是由 THUNLP 、中国人民大学 RUCBM 和 ModelBest 联合开发的开源大语言模型智能体。它基于 MiniCPM4.1 80亿参数基座模型，接受用户指令作为输入，自主生成长篇报告。其有以下亮点：",
    "summary_zh": "AgentCPM-Report是由THUNLP、中国人民大学RUCBM和ModelBest联合开发的开源大语言模型智能体。它基于MiniCPM4.1 80亿参数基座模型，接受用户指令作为输入，自主生成长篇报告。其有以下亮点：",
    "upvotes": 21
  },
  {
    "id": "2602.09022",
    "date": "2026-02-10",
    "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
    "authors": "Zehan Wang Tengfei Wang Haiyu Zhang Xuhui Zuo Junta Wu Haoyuan Wang Wenqiang Sun Zhenwei Wang Chenjie Cao Hengshuang Zhao Chunchao Guo Zhou Zhao",
    "abstract": "WorldCompass enhances long-horizon video-based world models through reinforcement learning post-training with clip-level rollouts, complementary rewards, and efficient RL algorithms. This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models , enabling them to explore the world more accurately and consistently based on interaction signals. To effectively \"steer\" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy : We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions : We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.",
    "summary_en": "WorldCompass enhances long-horizon video-based world models through reinforcement learning post-training with clip-level rollouts, complementary rewards, and efficient RL algorithms.",
    "summary_zh": "WorldCompass 通过采用片段级 rollout、互补奖励和高效 RL 算法的强化学习后训练，增强基于视频的长程世界模型。",
    "upvotes": 20
  },
  {
    "id": "2602.07075",
    "date": "2026-02-10",
    "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
    "authors": "Xinwu Ye Yicheng Mao Jia Zhang Yimeng Liu Li Hao Fang Wu Zhiwei Li Yuxuan Liao Zehong Wang Zhiyuan Liu Zhenfei Yin Li Yuan Philip Torr Huan Sun Xiangxiang Zeng Mengdi Wang Le Cong Shenghua Gao Xiangru Tang",
    "abstract": "LatentChem enables chemical reasoning through continuous latent space computations instead of discrete textual tokens, achieving superior performance and efficiency compared to traditional chain-of-thought approaches. Chemical large language models (LLMs) predominantly rely on explicit Chain-of-Thought (CoT) in natural language to perform complex reasoning. However, chemical reasoning is inherently continuous and structural, and forcing it into discrete linguistic tokens introduces a fundamental representation mismatch that constrains both efficiency and performance. We introduce LatentChem, a latent reasoning interface that decouples chemical computation from textual generation , enabling models to perform multi-step reasoning directly in continuous latent space while emitting language only for final outputs. Remarkably, we observe a consistent emergent behavior: when optimized solely for task success, models spontaneously internalize reasoning, progressively abandoning verbose textual derivations in favor of implicit latent computation. This shift is not merely stylistic but computationally advantageous. Across diverse chemical reasoning benchmarks, LatentChem achieves a 59.88\\% non-tie win rate over strong CoT-based baselines on ChemCoTBench , while delivering a 10.84times average inference speedup . Our results provide empirical evidence that chemical reasoning is more naturally and effectively realized as continuous latent dynamics rather than discretized linguistic trajectories.",
    "summary_en": "LatentChem enables chemical reasoning through continuous latent space computations instead of discrete textual tokens, achieving superior performance and efficiency compared to traditional chain-of-thought approaches.",
    "summary_zh": "LatentChem通过连续潜在空间计算而非离散文本token实现化学推理，相较于传统思维链方法取得了更优的性能与效率。",
    "upvotes": 18
  },
  {
    "id": "2602.06694",
    "date": "2026-02-10",
    "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
    "authors": "Hyochan Chong Dongkyu Kim Changdong Kim Minseop Choi",
    "abstract": "NanoQuant enables efficient post-training quantization of large language models to binary and sub-1-bit levels using low-rank binary factorization and ADMM optimization, achieving state-of-the-art accuracy while reducing memory requirements for consumer hardware deployment. Weight-only quantization has become a standard approach for efficiently serving large language models (LLMs). However, existing methods fail to efficiently compress models to binary (1-bit) levels, as they either require large amounts of data and compute or incur additional storage. In this work, we propose NanoQuant, the first post-training quantization (PTQ) method to compress LLMs to both binary and sub-1-bit levels. NanoQuant formulates quantization as a low-rank binary factorization problem, and compresses full-precision weights to low-rank binary matrices and scales. Specifically, it utilizes an efficient alternating direction method of multipliers (ADMM) method to precisely initialize latent binary matrices and scales, and then tune the initialized parameters through a block and model reconstruction process. Consequently, NanoQuant establishes a new Pareto frontier in low-memory post-training quantization , achieving state-of-the-art accuracy even at sub-1-bit compression rates. NanoQuant makes large-scale deployment feasible on consumer hardware. For example, it compresses Llama2-70B by 25.8times in just 13 hours on a single H100, enabling a 70B model to operate on a consumer 8 GB GPU.",
    "summary_en": "NanoQuant enables efficient post-training quantization of large language models to binary and sub-1-bit levels using low-rank binary factorization and ADMM optimization, achieving state-of-the-art accuracy while reducing memory requirements for consumer hardware deployment.",
    "summary_zh": "NanoQuant通过低秩二值分解和ADMM优化，实现大语言模型的高效后训练量化至二值及亚1比特级别，在达到最先进精度的同时降低消费级硬件部署的内存需求。",
    "upvotes": 15
  },
  {
    "id": "2602.03784",
    "date": "2026-02-10",
    "title": "Context Compression via Explicit Information Transmission",
    "authors": "Jiangnan Ye Hanqi Yan Zhenyi Shen Heng Chang Ye Mao Yulan He",
    "abstract": "ComprExIT introduces a novel approach to long-context inference in LLMs by using explicit information transmission over frozen hidden states, improving compression efficiency through depth-wise and width-wise transmission mechanisms. Long-context inference with Large Language Models ( LLMs ) is costly due to quadratic attention and growing key-value caches , motivating context compression. In this work, we study soft context compression , where a long context is condensed into a small set of continuous representations. Existing methods typically re-purpose the LLM itself as a trainable compressor, relying on layer-by-layer self-attention to iteratively aggregate information. We argue that this paradigm suffers from two structural limitations: (i) progressive representation overwriting across layers (ii) uncoordinated allocation of compression capacity across tokens. We propose ComprExIT (Context Compression via Explicit Information Transmission ), a lightweight framework that formulates soft compression into a new paradigm: explicit information transmission over frozen LLM hidden states . This decouples compression from the model's internal self-attention dynamics. ComprExIT performs (i) depth-wise transmission to selectively transmit multi-layer information into token anchors , mitigating progressive overwriting, and (ii) width-wise transmission to aggregate anchors into a small number of slots via a globally optimized transmission plan, ensuring coordinated allocation of information. Across six question-answering benchmarks, ComprExIT consistently outperforms state-of-the-art context compression methods while introducing only ~1% additional parameters, demonstrating that explicit and coordinated information transmission enables more effective and robust long-context compression.",
    "summary_en": "ComprExIT introduces a novel approach to long-context inference in LLMs by using explicit information transmission over frozen hidden states, improving compression efficiency through depth-wise and width-wise transmission mechanisms.",
    "summary_zh": "ComprExIT 提出了一种用于大语言模型长上下文推理的新方法，该方法通过冻结隐状态上的显式信息传输，并借助深度与宽度方向的传输机制来提升压缩效率。",
    "upvotes": 14
  },
  {
    "id": "2602.08658",
    "date": "2026-02-10",
    "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
    "authors": "Mingzi Cao Xingwei Tan Mahmud Akhter Marco Valentino Maria Liakata Xi Wang Nikolaos Aletras",
    "abstract": "Research investigates how fundamental reasoning paradigms influence large language model generalization through targeted training approaches and evaluation on real-world tasks. Deduction, induction, and abduction are fundamental reasoning paradigms , core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning , and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts . We comprehensively evaluate induced models on realistic out-of-domain tasks , that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to 14.60) across realistic tasks.",
    "summary_en": "Research investigates how fundamental reasoning paradigms influence large language model generalization through targeted training approaches and evaluation on real-world tasks.",
    "summary_zh": "研究通过针对性训练方法和对真实世界任务的评估，探讨基础推理范式如何影响大语言模型的泛化能力。",
    "upvotes": 13
  },
  {
    "id": "2602.06454",
    "date": "2026-02-10",
    "title": "RelayGen: Intra-Generation Model Switching for Efficient Reasoning",
    "authors": "Jiwon Song Yoongon Kim Jae-Joon Kim",
    "abstract": "RelayGen is a training-free framework that dynamically switches between large and small reasoning models during inference based on segment-level difficulty estimation, achieving faster execution with minimal accuracy loss. Large reasoning models (LRMs) achieve strong performance on complex reasoning tasks by generating long, multi-step reasoning trajectories , but inference-time scaling incurs substantial deployment cost. A key challenge is that generation difficulty varies within a single output, whereas existing efficiency-oriented approaches either ignore this intra-generation variation or rely on supervised token-level routing with high system complexity. We present RelayGen, a training-free, segment-level runtime model switching framework that exploits difficulty variation in long-form reasoning. Through offline analysis of generation uncertainty using token probability margins , we show that coarse-grained segment-level control is sufficient to capture difficulty transitions within a reasoning trajectory. RelayGen identifies model-specific switch cues that signal transitions to lower-difficulty segments and dynamically delegates their continuation to a smaller model, while preserving high-difficulty reasoning on the large model. Across multiple reasoning benchmarks, RelayGen substantially reduces inference latency while preserving most of the accuracy of large models. When combined with speculative decoding , RelayGen achieves up to 2.2times end-to-end speedup with less than 2\\% accuracy degradation, without requiring additional training or learned routing components.",
    "summary_en": "RelayGen is a training-free framework that dynamically switches between large and small reasoning models during inference based on segment-level difficulty estimation, achieving faster execution with minimal accuracy loss.",
    "summary_zh": "RelayGen是一种免训练框架，它基于片段级难度估计在推理过程中动态切换大型与小型推理模型，以极小的精度损失实现更快的执行速度。",
    "upvotes": 11
  },
  {
    "id": "2602.08236",
    "date": "2026-02-10",
    "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
    "authors": "Shoubin Yu Yue Zhang Zun Wang Jaehong Yoon Huaxiu Yao Mingyu Ding Mohit Bansal",
    "abstract": "Adaptive test-time framework with world models enables selective visual imagination for spatial reasoning, improving efficiency and reliability by determining when imagination is necessary. Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination , but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. In practice, indiscriminate imagination can increase computation and even degrade performance by introducing misleading evidence. In this work, we present an in-depth analysis of test-time visual imagination as a controllable resource for spatial reasoning. We study when static visual evidence is sufficient, when imagination improves reasoning, and how excessive or unnecessary imagination affects accuracy and efficiency. To support this analysis, we introduce AVIC, an adaptive test-time framework with world models that explicitly reasons about the sufficiency of current visual evidence before selectively invoking and scaling visual imagination . Across spatial reasoning benchmarks ( SAT , MMSI ) and an embodied navigation benchmark ( R2R ), our results reveal clear scenarios where imagination is critical, marginal, or detrimental, and show that selective control can match or outperform fixed imagination strategies with substantially fewer world-model calls and language tokens. Overall, our findings highlight the importance of analyzing and controlling test-time imagination for efficient and reliable spatial reasoning.",
    "summary_en": "Adaptive test-time framework with world models enables selective visual imagination for spatial reasoning, improving efficiency and reliability by determining when imagination is necessary.",
    "summary_zh": "结合世界模型的自适应测试时框架支持选择性视觉想象以进行空间推理，通过判断何时需要想象来提高效率与可靠性。",
    "upvotes": 9
  },
  {
    "id": "2602.08808",
    "date": "2026-02-10",
    "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
    "authors": "Yapei Chang Kyle Lo Mohit Iyyer Luca Soldaini",
    "abstract": "A scalable framework for evaluating and improving goal-conditioned procedure generation using large-scale web mining, automated scoring, and reinforcement learning to enhance step-by-step instruction quality. Generating step-by-step \"how-to\" procedures is a key LLM capability: how-to advice is commonly requested in chatbots, and step-by-step planning is critical for reasoning over complex tasks. Yet, measuring and improving procedural validity at scale on real-world tasks remains challenging and understudied. To address this, we introduce How2Everything, a scalable framework to evaluate and improve goal-conditioned procedure generation . Our framework includes How2Mine , which mines 351K procedures from 980K web pages across 14 topics and readily scales to larger corpora. From this pool we build How2Bench , a 7K-example evaluation set balanced across topics. To reliably score model outputs, we develop How2Score , an evaluation protocol that uses an LLM judge to detect whether a generation contains any critical failure that would prevent achieving the goal. For low-cost, reproducible evaluation, we distill a frontier model into an open 8B model, achieving 80.5% agreement with human annotators. How2Bench reveals clear scaling trends across model sizes and training stages, providing signal early in pretraining . Finally, RL using How2Score as a reward improves performance on How2Bench by >10 points across three models without systematic regressions on standard benchmarks, with gains robust to superficial source-document memorization or format compliance. Taken together, How2Everything shows how pretraining web data can support a closed loop of capability evaluation and improvement at scale.",
    "summary_en": "A scalable framework for evaluating and improving goal-conditioned procedure generation using large-scale web mining, automated scoring, and reinforcement learning to enhance step-by-step instruction quality.",
    "summary_zh": "一种可扩展框架，通过大规模网络挖掘、自动评分和强化学习来评估与改进目标条件化程序生成，以提升分步指令质量。",
    "upvotes": 8
  },
  {
    "id": "2602.08145",
    "date": "2026-02-10",
    "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey",
    "authors": "Xinyu Yang Junlin Han Rishi Bommasani Jinqi Luo Wenjie Qu Wangchunshu Zhou Adel Bibi Xiyao Wang Jaehong Yoon Elias Stengel-Eskin Shengbang Tong Lingfeng Shen Rafael Rafailov Runjia Li Zhaoyang Wang Yiyang Zhou Chenhang Cui Yu Wang Wenhao Zheng Huichi Zhou Jindong Gu Zhaorun Chen",
    "abstract": "Foundation models including LLMs, MLLMs, and generative models require reliable and responsible development addressing bias, security, explainability, and other critical issues for trustworthy deployment across multiple domains.",
    "summary_en": "Foundation models including LLMs, MLLMs, and generative models require reliable and responsible development addressing bias, security, explainability, and other critical issues for trustworthy deployment across multiple domains.",
    "summary_zh": "包括LLMs、MLLMs和生成模型在内的基础模型需要可靠且负责任的开发，解决偏见、安全性、可解释性及其他关键问题，以实现跨多个领域的可信部署。",
    "upvotes": 8
  },
  {
    "id": "2602.07796",
    "date": "2026-02-10",
    "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents",
    "authors": "Jiatong Li Changdae Oh Hyeong Kyu Choi Jindong Wang Sharon Li",
    "abstract": "Explicit reasoning in LLM agents can degrade performance in user-engaged scenarios by reducing information disclosure and weakening agent-user communication, with transparency-aware prompting showing better results. Eliciting reasoning has emerged as a powerful technique for improving the performance of large language models (LLMs) on complex tasks by inducing thinking. However, their effectiveness in realistic user-engaged agent scenarios remains unclear. In this paper, we conduct a comprehensive study on the effect of explicit thinking in user-engaged LLM agents. Our experiments span across seven models, three benchmarks, and two thinking instantiations, and we evaluate them through both a quantitative response taxonomy analysis and qualitative failure propagation case studies. Contrary to expectations, we find that mandatory thinking often backfires on agents in user-engaged settings, causing anomalous performance degradation across various LLMs. Our key finding reveals that thinking makes agents more ``introverted'' by shortening responses and reducing information disclosure to users, which weakens agent-user information exchange and leads to downstream task failures. Furthermore, we demonstrate that explicitly prompting for information disclosure reliably improves performance across diverse model families, suggesting that proactive transparency is a vital lever for agent optimization. Overall, our study suggests that information transparency awareness is a crucial yet underexplored perspective for the future design of reasoning agents in real-world scenarios. Our code is available at https://github.com/deeplearning-wisc/Thinking-Agent.",
    "summary_en": "Explicit reasoning in LLM agents can degrade performance in user-engaged scenarios by reducing information disclosure and weakening agent-user communication, with transparency-aware prompting showing better results.",
    "summary_zh": "在用户参与场景中，LLM智能体的显式推理可能因减少信息披露并削弱智能体与用户的沟通而导致性能下降，而透明性感知提示则能取得更好效果。",
    "upvotes": 7
  },
  {
    "id": "2602.07775",
    "date": "2026-02-10",
    "title": "Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion",
    "authors": "Haodong Li Shaoteng Liu Zhe Lin Manmohan Chandraker",
    "abstract": "Autoregressive video diffusion models suffer from train-test gaps when generating long videos, but a training-free approach called Rolling Sink addresses this by maintaining AR cache and enabling ultra-long video synthesis. Recently, autoregressive (AR) video diffusion models has achieved remarkable performance. However, due to their limited training durations, a train-test gap emerges when testing at longer horizons, leading to rapid visual degradations. Following Self Forcing , which studies the train-test gap within the training duration, this work studies the train-test gap beyond the training duration, i.e., the gap between the limited horizons during training and open-ended horizons during testing. Since open-ended testing can extend beyond any finite training window, and long-video training is computationally expensive, we pursue a training-free solution to bridge this gap. To explore a training-free solution, we conduct a systematic analysis of AR cache maintenance . These insights lead to Rolling Sink . Built on Self Forcing (trained on only 5s clips), Rolling Sink effectively scales the AR video synthesis to ultra-long durations (e.g., 5-30 minutes at 16 FPS) at test time, with consistent subjects, stable colors, coherent structures, and smooth motions. As demonstrated by extensive experiments, Rolling Sink achieves superior long-horizon visual fidelity and temporal consistency compared to SOTA baselines. Project page: https://rolling-sink.github.io/",
    "summary_en": "Autoregressive video diffusion models suffer from train-test gaps when generating long videos, but a training-free approach called Rolling Sink addresses this by maintaining AR cache and enabling ultra-long video synthesis.",
    "summary_zh": "自回归视频扩散模型在生成长视频时存在训练-测试差距，但一种名为Rolling Sink的免训练方法通过维护AR缓存并支持超长视频合成解决了该问题。",
    "upvotes": 7
  },
  {
    "id": "2602.07080",
    "date": "2026-02-10",
    "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
    "authors": "Yicheng He Zheng Zhao Zhou Kaiyu Bryan Dai Jie Fu Yonghui Yang",
    "abstract": "LLM code verification can be achieved through internal neural dynamics analysis, identifying structural signatures that distinguish correct reasoning from logical failures in computational circuits. Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics encode internally decodable signals that are predictive of logical validity during code generation. Inspired by mechanistic interpretability , we propose to treat code verification as a mechanistic diagnostic task, mapping the model's explicit algorithmic trajectory into line-level attribution graphs . By decomposing complex residual flows , we aim to identify the structural signatures that distinguish sound reasoning from logical failure within the model's internal circuits. Analysis across Python, C++, and Java confirms that intrinsic correctness signals are robust across diverse syntaxes. Topological features from these internal graphs predict correctness more reliably than surface heuristics and enable targeted causal interventions to fix erroneous logic. These findings establish internal introspection as a decodable property for verifying generated code. Our code is at https:// github.com/bruno686/CodeCircuit.",
    "summary_en": "LLM code verification can be achieved through internal neural dynamics analysis, identifying structural signatures that distinguish correct reasoning from logical failures in computational circuits.",
    "summary_zh": "LLM代码验证可通过内部神经动力学分析实现，识别区分计算回路中正确推理与逻辑错误的结构特征。",
    "upvotes": 6
  },
  {
    "id": "2602.09003",
    "date": "2026-02-10",
    "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
    "authors": "Yudong Wang Zixuan Fu Hengyu Zhao Chen Zhao Chuyue Zhou Xinle Lin Hongya Lyu Shuaikang Xue Yi Yi Yingjiao Wang Zhi Zheng Yuzhou Zhang Jie Zhou Chaojun Xiao Xu Han Zhiyuan Liu Maosong Sun",
    "abstract": "Large language models are increasingly guiding data management processes through a tiered framework that optimizes data quality, cost, and training efficiency across different stages of model development. The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency . In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training , mid-training , and alignment . The framework balances data quality , acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management . We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.",
    "summary_en": "Large language models are increasingly guiding data management processes through a tiered framework that optimizes data quality, cost, and training efficiency across different stages of model development.",
    "summary_zh": "大语言模型正日益通过分层框架指导数据管理流程，在模型开发的不同阶段优化数据质量、成本和训练效率。",
    "upvotes": 5
  },
  {
    "id": "2602.07803",
    "date": "2026-02-10",
    "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
    "authors": "Jiale Qian Hao Meng Tian Zheng Pengcheng Zhu Haopeng Lin Yuhang Dai Hanke Xie Wenxiao Cao Ruixuan Shang Jun Wu Hongmei Liu Hanlin Wen Jian Zhao Zhonglin Jiang Yong Chen Shunshun Yin Ming Tao Jianguo Wei Lei Xie Xinsheng Wang",
    "abstract": "A high-quality open-source singing voice synthesis system is presented with support for multiple languages and controllable generation, along with a dedicated benchmark for evaluating zero-shot performance.",
    "summary_en": "A high-quality open-source singing voice synthesis system is presented with support for multiple languages and controllable generation, along with a dedicated benchmark for evaluating zero-shot performance.",
    "summary_zh": "本文提出了一个高质量的开源歌声合成系统，支持多语言和可控生成，同时提供了一个用于评估零样本性能的专用基准。",
    "upvotes": 4
  },
  {
    "id": "2601.21363",
    "date": "2026-02-10",
    "title": "Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control",
    "authors": "Weidong Huang Zhehan Li Hangxin Liu Biao Hou Yao Su Jingwen Zhang",
    "abstract": "Off-policy Soft Actor-Critic with large-batch updates enables efficient humanoid locomotion policy pretraining, while model-based methods facilitate safe adaptation through deterministic data collection and stochastic exploration within physics-informed world models. Reinforcement learning (RL) is widely used for humanoid control, with on-policy methods such as Proximal Policy Optimization (PPO) enabling robust training via large-scale parallel simulation and, in some cases, zero-shot deployment to real robots. However, the low sample efficiency of on-policy algorithms limits safe adaptation to new environments. Although off-policy RL and model-based RL have shown improved sample efficiency , the gap between large-scale pretraining and efficient finetuning on humanoids still exists. In this paper, we find that off-policy Soft Actor-Critic (SAC), with large-batch update and a high Update-To-Data (UTD) ratio, reliably supports large-scale pretraining of humanoid locomotion policies, achieving zero-shot deployment on real robots. For adaptation, we demonstrate that these SAC-pretrained policies can be finetuned in new environments and out-of-distribution tasks using model-based methods. Data collection in the new environment executes a deterministic policy while stochastic exploration is instead confined to a physics-informed world model . This separation mitigates the risks of random exploration during adaptation while preserving exploratory coverage for improvement. Overall, the approach couples the wall-clock efficiency of large-scale simulation during pretraining with the sample efficiency of model-based learning during fine-tuning.",
    "summary_en": "Off-policy Soft Actor-Critic with large-batch updates enables efficient humanoid locomotion policy pretraining, while model-based methods facilitate safe adaptation through deterministic data collection and stochastic exploration within physics-informed world models.",
    "summary_zh": "离策略Soft Actor-Critic通过大批量更新实现高效的人形机器人运动策略预训练，而基于模型的方法则通过确定性数据收集与物理信息世界模型中的随机探索来促进安全适应。",
    "upvotes": 4
  },
  {
    "id": "2602.09782",
    "date": "2026-02-10",
    "title": "Flexible Entropy Control in RLVR with Gradient-Preserving Perspective",
    "authors": "Kun Chen Peng Shi Fanfan Liu Haibo Qiu Zhixiong Zeng Siqi Yang Wenji Mao",
    "abstract": "Reinforcement learning with verifiable rewards faces entropy collapse issues due to gradient-preserving clipping, which this paper addresses through dynamic entropy control mechanisms. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a critical method for enhancing the reasoning capabilities of Large Language Models (LLMs). However, continuous training often leads to policy entropy collapse , characterized by a rapid decay in entropy that results in premature overconfidence, reduced output diversity, and vanishing gradient norms that inhibit learning. Gradient-Preserving Clipping is a primary factor influencing these dynamics, but existing mitigation strategies are largely static and lack a framework connecting clipping mechanisms to precise entropy control . This paper proposes reshaping entropy control in RL from the perspective of Gradient-Preserving Clipping . We first theoretically and empirically verify the contributions of specific importance sampling ratio regions to entropy growth and reduction. Leveraging these findings, we introduce a novel regulation mechanism using dynamic clipping threshold to precisely manage entropy. Furthermore, we design and evaluate dynamic entropy control strategies , including increase-then-decrease, decrease-increase-decrease, and oscillatory decay. Experimental results demonstrate that these strategies effectively mitigate entropy collapse, and achieve superior performance across multiple benchmarks.",
    "summary_en": "Reinforcement learning with verifiable rewards faces entropy collapse issues due to gradient-preserving clipping, which this paper addresses through dynamic entropy control mechanisms.",
    "summary_zh": "基于可验证奖励的强化学习因梯度保持裁剪而面临熵坍缩问题，本文通过动态熵控制机制解决该问题。",
    "upvotes": 3
  },
  {
    "id": "2602.08961",
    "date": "2026-02-10",
    "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
    "authors": "Ruijie Zhu Jiahao Lu Wenbo Hu Xiaoguang Han Jianfei Cai Ying Shan Chuanxia Zheng",
    "abstract": "MotionCrafter is a video diffusion framework that jointly reconstructs 4D geometry and estimates dense motion using a novel joint representation and 4D VAE architecture. We introduce MotionCrafter, a video diffusion -based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system , and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents -despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page",
    "summary_en": "MotionCrafter is a video diffusion framework that jointly reconstructs 4D geometry and estimates dense motion using a novel joint representation and 4D VAE architecture.",
    "summary_zh": "MotionCrafter是一种视频扩散框架，利用新颖的联合表示与4D VAE架构，联合重建4D几何并估计稠密运动。",
    "upvotes": 3
  },
  {
    "id": "2602.08829",
    "date": "2026-02-10",
    "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
    "authors": "Hao Peng Yunjia Qi Xiaozhi Wang Zijun Yao Lei Hou Juanzi Li",
    "abstract": "WildReward demonstrates that reward models can be effectively trained from in-the-wild user interactions using ordinal regression, achieving performance comparable to traditional methods while benefiting from user diversity. Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions ? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models , with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models . Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.",
    "summary_en": "WildReward demonstrates that reward models can be effectively trained from in-the-wild user interactions using ordinal regression, achieving performance comparable to traditional methods while benefiting from user diversity.",
    "summary_zh": "WildReward 表明，利用序数回归基于野外用户交互可有效训练奖励模型，在达到与传统方法相当性能的同时受益于用户多样性。",
    "upvotes": 3
  },
  {
    "id": "2602.08004",
    "date": "2026-02-10",
    "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality",
    "authors": "George Ling Shanshan Zhong Richard Huang",
    "abstract": "",
    "summary_en": "",
    "summary_zh": "",
    "upvotes": 3
  },
  {
    "id": "2602.06942",
    "date": "2026-02-10",
    "title": "Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay",
    "authors": "Duygu Altinok",
    "abstract": "A comprehensive study of Turkish subword tokenization systematically investigates the relationship between vocabulary size, training corpus, and tokenizer performance across multiple linguistic tasks and diagnostics. Tokenization is a pivotal design choice for neural language modeling in morphologically rich languages (MRLs) such as Turkish, where productive agglutination challenges both vocabulary efficiency and morphological fidelity. Prior studies have explored tokenizer families and vocabulary sizes but typically (i) vary vocabulary without systematically controlling the tokenizer's training corpus, (ii) provide limited intrinsic diagnostics , and (iii) evaluate a narrow slice of downstream tasks. We present the first comprehensive, principled study of Turkish subword tokenization ; a \"subwords manifest\", that jointly varies vocabulary size and tokenizer training corpus size (data and vocabulary coupling), compares multiple tokenizer families under matched parameter budgets ( WordPiece , morphology level , and character baselines), and evaluates across semantic ( NLI , STS , sentiment analysis , NER ), syntactic ( POS , dependency parsing ), and morphology-sensitive probes. To explain why tokenizers succeed or fail, we introduce a morphology-aware diagnostic toolkit that goes beyond coarse aggregates to boundary-level micro/macro F1, decoupled lemma atomicity vs. surface boundary hits, over/under- segmentation indices , character/word edit distances ( CER / WER ), continuation rates , and affix-type coverage and token-level atomicity . Our contributions are fourfold: (i) a systematic investigation of the vocabulary-corpus-success triad; (ii) a unified, morphology-aware evaluation framework linking intrinsic diagnostics to extrinsic outcomes; (iii) controlled comparisons identifying when character-level and morphology-level tokenization pay off; and (iv) an open-source release of evaluation code, tokenizer pipelines, and models. As the first work of its kind, this \"subwords manifest\" delivers actionable guidance for building effective tokenizers in MRLs and establishes a reproducible foundation for future research.",
    "summary_en": "A comprehensive study of Turkish subword tokenization systematically investigates the relationship between vocabulary size, training corpus, and tokenizer performance across multiple linguistic tasks and diagnostics.",
    "summary_zh": "一项针对土耳其语子词分词的全面研究系统性地探究了词汇量、训练语料库与分词器性能之间的关系，涵盖多个语言任务与诊断测试。",
    "upvotes": 3
  },
  {
    "id": "2602.06445",
    "date": "2026-02-10",
    "title": "ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
    "authors": "Weidong Huang Jingwen Zhang Jiongye Li Shibowen Zhang Jiayang Wu Jiayi Wang Hangxin Liu Yaodong Yang Yao Su",
    "abstract": "Energy-constrained optimization framework separates energy metrics from rewards using Lagrangian method to achieve stable, energy-efficient humanoid robot locomotion with reduced hyperparameter tuning. Achieving stable and energy-efficient locomotion is essential for humanoid robots to operate continuously in real-world applications. Existing MPC and RL approaches often rely on energy-related metrics embedded within a multi-objective optimization framework, which require extensive hyperparameter tuning and often result in suboptimal policies. To address these challenges, we propose ECO ( Energy-Constrained Optimization ), a constrained RL framework that separates energy-related metrics from rewards, reformulating them as explicit inequality constraints. This method provides a clear and interpretable physical representation of energy costs, enabling more efficient and intuitive hyperparameter tuning for improved energy efficiency. ECO introduces dedicated constraints for energy consumption and reference motion, enforced by the Lagrangian method , to achieve stable, symmetric, and energy-efficient walking for humanoid robots. We evaluated ECO against MPC, standard RL with reward shaping, and four state-of-the-art constrained RL methods. Experiments, including sim-to-sim and sim-to-real transfer s on the kid-sized humanoid robot BRUCE, demonstrate that ECO significantly reduces energy consumption compared to baselines while maintaining robust walking performance. These results highlight a substantial advancement in energy-efficient humanoid locomotion. All experimental demonstrations can be found on the project website: https://sites.google.com/view/eco-humanoid.",
    "summary_en": "Energy-constrained optimization framework separates energy metrics from rewards using Lagrangian method to achieve stable, energy-efficient humanoid robot locomotion with reduced hyperparameter tuning.",
    "summary_zh": "能量约束优化框架使用拉格朗日方法将能量指标与奖励分离，实现稳定、节能的人形机器人运动，并减少超参数调优。",
    "upvotes": 3
  },
  {
    "id": "2602.08818",
    "date": "2026-02-10",
    "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
    "authors": "Annemette Brok Pirchert Jacob Nielsen Mogens Henrik From Lukas Galke Poech Peter Schneider-Kamp",
    "abstract": "FlexMoRE demonstrates that low-rank adapters can replace full-sized experts in mixture-of-experts architectures, achieving better performance with significantly fewer parameters. Recent advances in mixture-of-experts architectures have shown that individual experts models can be trained federatedly, i.e., in isolation from other experts by using a common base model to facilitate coordination. However, we hypothesize that full-sized experts may not be necessary for all domains and that instead low-rank adapters may be sufficient. Here, we introduce FlexMoRE, a Flexible Mixture of Rank-heterogenous Experts , which may be either full-sized experts or adapters of a suitable rank. We systematically investigate the trade-off between expert rank and downstream task performance by evaluating 6 experts with ranks 2^0 to 2^{14} resulting in experiments covering 150 mixtures (96 with 2 experts, 54 with 7 experts) that are evaluated across 120 tasks. For our experiments, we build on FlexOlmo and turn its pre-trained experts into low-rank versions. Our regression analysis from expert rank to downstream task performance reveals that the best-performing rank is substantially higher for reasoning-heavy benchmarks than for knowledge-heavy benchmarks. These findings on rank sensitivity come with direct implications for memory efficiency: Using optimal ranks, FlexMoRE yields improved downstream task performance (average score 47.18) compared to the baseline FlexOlmo-style mixture of full-sized experts (average score 45.46) at less than one third the parameters (10.75B for FlexMoRE vs. 33.27B for FlexOlmo). All code will be made available.",
    "summary_en": "FlexMoRE demonstrates that low-rank adapters can replace full-sized experts in mixture-of-experts architectures, achieving better performance with significantly fewer parameters.",
    "summary_zh": "FlexMoRE 表明，低秩适配器可以替代混合专家架构中的全尺寸专家，以显著更少的参数实现更优性能。",
    "upvotes": 2
  },
  {
    "id": "2602.07150",
    "date": "2026-02-10",
    "title": "On Randomness in Agentic Evals",
    "authors": "Bjarni Haukur Bjarnason André Silva Martin Monperrus",
    "abstract": "Analysis of agentic system evaluation reveals significant variance in single-run performance estimates, necessitating multiple runs and advanced metrics for reliable assessment.",
    "summary_en": "Analysis of agentic system evaluation reveals significant variance in single-run performance estimates, necessitating multiple runs and advanced metrics for reliable assessment.",
    "summary_zh": "对智能体系统评估的分析表明，单次运行的性能估计方差显著，需要进行多次运行并采用高级指标以实现可靠评估。",
    "upvotes": 2
  },
  {
    "id": "2602.07040",
    "date": "2026-02-10",
    "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
    "authors": "Emmett Bicker",
    "abstract": "Aster is an AI agent that accelerates scientific discovery by iteratively improving programs, achieving state-of-the-art results across multiple domains including mathematics, biology, and machine learning with significantly reduced computational requirements. We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performance s. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to include tasks with long evaluation durations, such as multi-hour machine learning training runs. We applied Aster to problems in mathematics, GPU kernel engineering, biology, neuroscience, and language model training. More specifically: the Erdos minimum overlap problem, optimizing the TriMul kernel, a single-cell analysis denoising problem, training a neural activity prediction model to perform well on ZAPBench, and the NanoGPT Speedrun Competition. Aster attains SOTA results in every task, except for ZAPBench, where it matches the performance of the best human solution with less than 1/190th of the compute. Aster is accessible via a web interface and API at asterlab.ai.",
    "summary_en": "Aster is an AI agent that accelerates scientific discovery by iteratively improving programs, achieving state-of-the-art results across multiple domains including mathematics, biology, and machine learning with significantly reduced computational requirements.",
    "summary_zh": "Aster 是一种 AI 智能体，通过迭代改进程序加速科学发现，在数学、生物学和机器学习等多个领域取得最先进成果，且计算需求大幅降低。",
    "upvotes": 2
  },
  {
    "id": "2602.06600",
    "date": "2026-02-10",
    "title": "Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning",
    "authors": "Zhuoyuan Hao Zhuo Li Wu Li Fangming Liu Min Zhang Jing Li",
    "abstract": "Large reasoning models exhibit spontaneous question repetition patterns that can be formalized and leveraged to improve computational efficiency and accuracy through echo-aware training and prompting techniques. Test-time compute allocation in large reasoning models (LRMs) is widely used and has applications in mathematical problem solving, code synthesis, and planning. Recent work has addressed this problem by scaling self-consistency and parallel thinking , adding generic `` thinking tokens '' and prompting models to re-read the question before answering. Unfortunately, these approaches either inject task-agnostic tokens or mandate heuristics that do not explain -- and often ignore -- the spontaneous repetition that many LRMs exhibit at the head of their internal chains. In contrast, we analyze and harness the model's tendency to restate the question, which we term the Echo of Prompt (EOP), as a front-loaded, compute-shaping mechanism. We formalize its probabilistic cost by casting echo removal as rejection-based conditioning and defining the Echo Likelihood Gap ΔL as a computable proxy. This provides the missing theoretical link that links early repetition to likelihood gains and downstream accuracy. However, it does not by itself specify how to exploit EOP. Consequently, we develop Echo-Distilled SFT (ED-SFT) to instill an ``echo-then-reason'' pattern through supervised finetuning, and Echoic Prompting (EP) to re-ground the model mid-trace without training. While promising, quantifying benefits beyond verbosity is non-trivial. Therefore, we conduct length and suffix-controlled likelihood analyses together with layer-wise attention studies, showing that EOP increases answer to answer-prefix attention in middle layers, consistent with an attention refocusing mechanism. We evaluate on GSM8K, MathQA, Hendrycks-MATH, AIME24, and MATH-500 under identical decoding settings and budgets, and find consistent gains over baselines. Code is available at https://github.com/hhh2210/echoes-as-anchors.",
    "summary_en": "Large reasoning models exhibit spontaneous question repetition patterns that can be formalized and leveraged to improve computational efficiency and accuracy through echo-aware training and prompting techniques.",
    "summary_zh": "大型推理模型表现出自发的问题重复模式，这些模式可被形式化并加以利用，通过回声感知训练与提示技术提升计算效率与准确性。",
    "upvotes": 2
  },
  {
    "id": "2602.05929",
    "date": "2026-02-10",
    "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs",
    "authors": "Jian Chen Zhuoran Wang Jiayu Qin Ming Li Meng Wang Changyou Chen Yin Chen Qizhen Weng Yirui Liu",
    "abstract": "KV-CoRE method evaluates kv-cache compressibility through SVD-based low-rank approximation, revealing patterns linking compressibility to model architecture and training data across multiple languages and domains. Large language models rely on kv-cache s to avoid redundant computation during autoregressive decoding , but as context length grows, reading and writing the cache can quickly saturate GPU memory bandwidth . Recent work has explored KV-cache compression , yet most approaches neglect the data-dependent nature of kv-cache s and their variation across layers. We introduce KV-CoRE KV-cache Compressibility by Rank Evaluation), an SVD-based method for quantifying the data-dependent low-rank compressibility of kv-cache s. KV-CoRE computes the optimal low-rank approximation under the Frobenius norm and, being gradient-free and incremental, enables efficient dataset-level, layer-wise evaluation . Using this method, we analyze multiple models and datasets spanning five English domains and sixteen languages, uncovering systematic patterns that link compressibility to model architecture, training data, and language coverage. As part of this analysis, we employ the Normalized Effective Rank as a metric of compressibility and show that it correlates strongly with performance degradation under compression. Our study establishes a principled evaluation framework and the first large-scale benchmark of kv-cache compressibility in LLMs, offering insights for dynamic, data-aware compression and data-centric model development.",
    "summary_en": "KV-CoRE method evaluates kv-cache compressibility through SVD-based low-rank approximation, revealing patterns linking compressibility to model architecture and training data across multiple languages and domains.",
    "summary_zh": "KV-CoRE方法通过基于SVD的低秩近似评估KV缓存可压缩性，揭示其与模型架构及训练数据之间的关联规律，涵盖多种语言和领域。",
    "upvotes": 2
  },
  {
    "id": "2602.02827",
    "date": "2026-02-10",
    "title": "Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval",
    "authors": "Roi Pony Adi Raz Oshri Naparstek Idan Friedman Udi Barzelay",
    "abstract": "Col-Bandit reduces computational costs in multi-vector late-interaction retrieval by adaptively pruning token-level interactions during query processing while maintaining ranking accuracy. Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-K identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5times, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time.",
    "summary_en": "Col-Bandit reduces computational costs in multi-vector late-interaction retrieval by adaptively pruning token-level interactions during query processing while maintaining ranking accuracy.",
    "summary_zh": "Col-Bandit通过在查询处理过程中自适应地剪枝词元级交互，在多向量后期交互检索中降低计算成本，同时保持排序准确性。",
    "upvotes": 2
  },
  {
    "id": "2602.08629",
    "date": "2026-02-10",
    "title": "CauScale: Neural Causal Discovery at Scale",
    "authors": "Bo Peng Sirui Chen Jiaguo Tian Yu Qiao Chaochao Lu",
    "abstract": "CauScale is a neural architecture that enables efficient causal discovery on large graphs through compressed embeddings and tied attention weights, achieving high accuracy and significant speedups over previous methods. Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention map s. To keep high causal discovery accuracy, CauScale adopts a two-stream design : a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals . CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale.",
    "summary_en": "CauScale is a neural architecture that enables efficient causal discovery on large graphs through compressed embeddings and tied attention weights, achieving high accuracy and significant speedups over previous methods.",
    "summary_zh": "CauScale是一种神经架构，通过压缩嵌入和共享注意力权重，能够在大规模图上高效进行因果发现，实现了高准确率并显著快于先前方法。",
    "upvotes": 1
  },
  {
    "id": "2602.07970",
    "date": "2026-02-10",
    "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
    "authors": "Zheyuan Hu Weitao Chen Cengiz Öztireli Chenliang Zhou Fangcheng Zhong",
    "abstract": "Research explores PDE solvers including neural frameworks for scientific simulations, examining forward solutions, inverse problems, and equation discovery across multi-variable and non-linear systems. Partial Differential Equations are precise in modelling the physical, biological and graphical phenomena. However, the numerical methods suffer from the curse of dimensionality, high computation costs and domain-specific discretization. We aim to explore pros and cons of different PDE solvers , and apply them to specific scientific simulation problems, including forwarding solution, inverse problems and equations discovery. In particular, we extend the recent CNF (NeurIPS 2023) framework solver to multi-dependent-variable and non-linear settings , together with down-stream applications. The outcomes include implementation of selected methods, self-tuning techniques, evaluation on benchmark problems and a comprehensive survey of neural PDE solvers and scientific simulation applications.",
    "summary_en": "Research explores PDE solvers including neural frameworks for scientific simulations, examining forward solutions, inverse problems, and equation discovery across multi-variable and non-linear systems.",
    "summary_zh": "研究探索了偏微分方程求解器（包括面向科学模拟的神经网络框架），考察了多变量与非线性系统中的正问题、逆问题及方程发现。",
    "upvotes": 1
  },
  {
    "id": "2602.07491",
    "date": "2026-02-10",
    "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
    "authors": "Isabella A. Stewart Tarjei Paule Hage Yu-Chuan Hsu Markus J. Buehler",
    "abstract": "A multi-agent framework guided by knowledge graphs addresses materials science challenges by integrating specialized agents for problem decomposition, evidence retrieval, and graph traversal to discover sustainable PFAS alternatives. Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science , where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition , evidence retrieval , design parameter extraction, and graph traversal , uncovering latent connections across distinct knowledge pockets to support hypothesis generation . Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance , thermal stability , chemical resistance , and biocompatibility . This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.",
    "summary_en": "A multi-agent framework guided by knowledge graphs addresses materials science challenges by integrating specialized agents for problem decomposition, evidence retrieval, and graph traversal to discover sustainable PFAS alternatives.",
    "summary_zh": "由知识图谱引导的多智能体框架通过整合专门用于问题分解、证据检索和图遍历的智能体来发现可持续PFAS替代品，从而应对材料科学挑战。",
    "upvotes": 1
  },
  {
    "id": "2602.07120",
    "date": "2026-02-10",
    "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model",
    "authors": "Jacqueline He Jonathan Hayase Wen-tau Yih Sewoong Oh Luke Zettlemoyer Pang Wei Koh",
    "abstract": "Anchor decoding suppresses verbatim copying in language models while maintaining fluency and factual accuracy through constrained generation that balances risk and utility. Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding , a plug-and-play inference-time method for suppressing verbatim copying : it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM . Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model ( TinyComma 1.8B ), as well as Anchored_{Byte} Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored_{Byte} Decoding define a new Pareto frontier , preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.",
    "summary_en": "Anchor decoding suppresses verbatim copying in language models while maintaining fluency and factual accuracy through constrained generation that balances risk and utility.",
    "summary_zh": "锚点解码通过平衡风险与效用的约束生成，在抑制语言模型逐字复制的同时保持流畅性和事实准确性。",
    "upvotes": 1
  },
  {
    "id": "2602.07090",
    "date": "2026-02-10",
    "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks",
    "authors": "Yu-Che Tsai Hsiang Hsiao Kuan-Yu Chen Shou-De Lin",
    "abstract": "SPARSE is a user-centric framework that protects text embeddings from privacy leaks by selectively perturbing sensitive dimensions using differentiable masking and Mahalanobis noise calibration. Text embeddings enable numerous NLP applications but face severe privacy risks from embedding inversion attacks , which can expose sensitive attributes or reconstruct raw text. Existing differential privacy defenses assume uniform sensitivity across embedding dimensions, leading to excessive noise and degraded utility. We propose SPARSE, a user-centric framework for concept-specific privacy protection in text embeddings . SPARSE combines (1) differentiable mask learning to identify privacy-sensitive dimensions for user-defined concepts, and (2) the Mahalanobis mechanism that applies elliptical noise calibrated by dimension sensitivity. Unlike traditional spherical noise injection, SPARSE selectively perturbs privacy-sensitive dimensions while preserving non-sensitive semantics. Evaluated across six datasets with three embedding models and attack scenarios, SPARSE consistently reduces privacy leakage while achieving superior downstream performance compared to state-of-the-art DP methods.",
    "summary_en": "SPARSE is a user-centric framework that protects text embeddings from privacy leaks by selectively perturbing sensitive dimensions using differentiable masking and Mahalanobis noise calibration.",
    "summary_zh": "SPARSE是一种以用户为中心的框架，通过可微掩码和马氏距离噪声校准选择性扰动敏感维度，从而保护文本嵌入免受隐私泄露。",
    "upvotes": 1
  },
  {
    "id": "2602.07054",
    "date": "2026-02-10",
    "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
    "authors": "Ashutosh Chaubey Jiacheng Pang Maksim Siniukov Mohammad Soleymani",
    "abstract": "A benchmark and optimization technique are presented to improve multimodal large language models' emotion understanding by addressing spurious associations and hallucinations in audiovisual cues. Emotion understanding is essential for building socially intelligent agents. Although recent multimodal large language models have shown strong performance on this task, two key challenges remain - spurious associations between emotions and irrelevant audiovisual cues, and hallucinations of audiovisual cues driven by text priors in the language model backbone. To quantify and understand these issues, we introduce EmoReAlM, a benchmark designed to evaluate MLLMs for cue-emotion associations , hallucinations and modality agreement . We then propose AVEm-DPO , a preference optimization technique that aligns model responses with both audiovisual inputs and emotion-centric queries . Specifically, we construct preferences over responses exhibiting spurious associations or hallucinations , and audiovisual input pairs guided by textual prompts. We also include a regularization term that penalizes reliance on text priors , thereby mitigating modality-specific cue hallucinations . Experimental results on DFEW, RAVDESS and EMER demonstrate that our method significantly improves the performance of the reference baseline models with 6-19% of relative performance gains in zero-shot settings. By providing both a rigorous benchmark and a robust optimization framework, this work enables principled evaluation and improvement of MLLMs for emotion understanding and social AI. Code, models and benchmark will be released at https://avere-iclr.github.io.",
    "summary_en": "A benchmark and optimization technique are presented to improve multimodal large language models' emotion understanding by addressing spurious associations and hallucinations in audiovisual cues.",
    "summary_zh": "提出了一种基准测试与优化技术，通过解决视听线索中的虚假关联和幻觉问题，提升多模态大语言模型的情感理解能力。",
    "upvotes": 1
  },
  {
    "id": "2602.05708",
    "date": "2026-02-10",
    "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration",
    "authors": "Chuangtao Ma Zeyu Zhang Arijit Khan Sebastian Schelter Paul Groth",
    "abstract": "CE-RAG4EM reduces computational overhead in large-scale entity matching by implementing blocking-based batch retrieval and generation while maintaining competitive matching quality. Retrieval-augmented generation (RAG) enhances LLM reasoning in knowledge-intensive tasks, but existing RAG pipelines incur substantial retrieval and generation overhead when applied to large-scale entity matching . To address this limitation, we introduce CE-RAG4EM, a cost-efficient RAG architecture that reduces computation through blocking-based batch retrieval and generation. We also present a unified framework for analyzing and evaluating RAG systems for entity matching , focusing on blocking-aware optimizations and retrieval granularity. Extensive experiments suggest that CE-RAG4EM can achieve comparable or improved matching quality while substantially reducing end-to-end runtime relative to strong baselines. Our analysis further reveals that key configuration parameters introduce an inherent trade-off between performance and overhead, offering practical guidance for designing efficient and scalable RAG systems for entity matching and data integration .",
    "summary_en": "CE-RAG4EM reduces computational overhead in large-scale entity matching by implementing blocking-based batch retrieval and generation while maintaining competitive matching quality.",
    "summary_zh": "CE-RAG4EM通过实现基于分块的批量检索与生成，在保持有竞争力匹配质量的同时，降低大规模实体匹配的计算开销。",
    "upvotes": 1
  },
  {
    "id": "2602.07948",
    "date": "2026-02-10",
    "title": "dewi-kadita: A Python Library for Idealized Fish Schooling Simulation with Entropy-Based Diagnostics",
    "authors": "Sandy H. S. Herho Iwan P. Anwar Faruq Khadami Alfita P. Handayani Karina A. Sujatmiko Kamaluddin Kasim Rusmawan Suwarman Dasapta E. Irawan",
    "abstract": "Collective motion in fish schools exemplifies emergent self-organization in active matter systems, yet computational tools for simulating and analyzing these dynamics remain fragmented across research groups. We present dewi-kadita, an open-source Python library implementing the three-dimensional Couzin zone-based model with comprehensive entropy diagnostics tailored for marine collective behavior research. The library introduces seven information-theoretic metrics -- school cohesion entropy, polarization entropy, depth stratification entropy, angular momentum entropy, nearest-neighbor entropy, velocity correlation entropy, and school shape entropy -- that characterize distinct organizational features inaccessible to classical order parameters. These metrics combine into an Oceanic Schooling Index (OSI) providing a single scalar measure of collective disorder. Validation across four canonical configurations (swarm, torus, dynamic parallel, highly parallel) confirms correct reproduction of known phase behaviors: the swarm maintains disorder with polarization P < 0.1 and OSI approx 0.71, while the highly parallel state achieves P = 0.998 with OSI = 0.24 and velocity correlation entropy vanishing to zero. The entropy framework successfully discriminates the torus and dynamic parallel configurations that exhibit comparable order parameter magnitudes through different organizational mechanisms. Numba just-in-time (JIT) compilation accelerates pairwise interaction calculations by 10--100times, enabling simulations of 150--250 agents over 1000--2000 time steps within five minutes on standard workstation hardware. NetCDF4 output ensures interoperability with oceanographic analysis tools. The library addresses the need for standardized, reproducible infrastructure in collective behavior modeling analogous to established molecular dynamics codes.",
    "summary_en": "Computational tools for simulating collective motion in fish schools remain fragmented across research groups. We present dewi-kadita, an open-source Python library implementing the three-dimensional Couzin zone-based model with seven information-theoretic metrics -- school cohesion entropy, polarization entropy, depth stratification entropy, angular momentum entropy, nearest-neighbor entropy, velocity correlation entropy, and school shape entropy -- that combine into an Oceanic Schooling Index (OSI). Validation across four canonical configurations (swarm, torus, dynamic parallel, highly parallel) confirms correct reproduction of known phase behaviors, with the swarm maintaining disorder (polarization P < 0.1 and OSI approx 0.71) and the highly parallel state achieving P = 0.998 with OSI = 0.24, while the entropy framework successfully discriminates the torus and dynamic parallel configurations that exhibit comparable order parameter magnitudes. Numba just-in-time (JIT) compilation accelerates pairwise interaction calculations by 10--100times, enabling simulations of 150--250 agents over 1000--2000 time steps within five minutes on standard workstation hardware, and NetCDF4 output ensures interoperability with oceanographic analysis tools.",
    "summary_zh": "用于模拟鱼群集体运动的计算工具目前仍分散于各研究组。我们推出dewi-kadita，这是一个开源Python库，实现了三维Couzin区域模型，并包含七个信息论指标——群体凝聚熵、极化熵、深度分层熵、角动量熵、最近邻熵、速度相关熵和群体形状熵——这些指标组合成海洋集群指数(OSI)。在四种典型构型（群集、环面、动态平行、高度平行）上的验证确认了已知相行为的正确复现，其中群集态保持无序（极化度P < 0.1且OSI约0.71），高度平行态达到P = 0.998且OSI = 0.24，同时熵框架成功区分了环面和动态平行构型，二者具有可比的序参量幅度。Numba即时(JIT)编译将成对相互作用计算加速10-100倍，使得在标准工作站硬件上可在五分钟内完成150-250个个体跨越1000-2000个时间步的模拟，且NetCDF4输出确保了与海洋学分析工具的互操作性。",
    "upvotes": 0
  },
  {
    "id": "2602.07125",
    "date": "2026-02-10",
    "title": "Reasoning-Augmented Representations for Multimodal Retrieval",
    "authors": "Jianrui Zhang Anirudh Sundara Rajan Brandon Han Soochahn Lee Sukanta Ganguly Yong Jae Lee",
    "abstract": "UMR systems face challenges with latent reasoning tasks, which the proposed framework addresses by decoupling reasoning from retrieval through enhanced visual and textual representations. Universal Multimodal Retrieval (UMR) seeks any-to-any search across text and vision, yet modern embedding models remain brittle when queries require latent reasoning (e.g., resolving underspecified references or matching compositional constraints ). We argue this brittleness is often data-induced: when images carry \"silent\" evidence and queries leave key semantics implicit, a single embedding pass must both reason and compress, encouraging spurious feature matching. We propose a data-centric framework that decouples these roles by externalizing reasoning before retrieval. Using a strong Vision--Language Model, we make implicit semantics explicit by densely captioning visual evidence in corpus entries, resolving ambiguous multimodal references in queries, and rewriting verbose instructions into concise retrieval constraints . Inference-time enhancement alone is insufficient; the retriever must be trained on these semantically dense representations to avoid distribution shift and fully exploit the added signal. Across M-BEIR, our reasoning-augmented training method yields consistent gains over strong baselines, with ablations showing that corpus enhancement chiefly benefits knowledge-intensive queries while query enhancement is critical for compositional modification requests. We publicly release our code at https://github.com/AugmentedRetrieval/ReasoningAugmentedRetrieval.",
    "summary_en": "UMR systems face challenges with latent reasoning tasks, which the proposed framework addresses by decoupling reasoning from retrieval through enhanced visual and textual representations.",
    "summary_zh": "UMR系统在处理隐式推理任务时面临挑战，所提框架通过增强视觉与文本表征来解耦推理与检索，从而解决该问题。",
    "upvotes": 0
  },
  {
    "id": "2602.05946",
    "date": "2026-02-10",
    "title": "f-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment",
    "authors": "Rajdeep Haldar Lantao Mei Guang Lin Yue Xing Qifan Song",
    "abstract": "Preference alignment objectives are extended to general alignment settings using f-divergence variational representations, introducing novel on-policy and hybrid policy optimization methods for LLM alignment with theoretical and empirical validation. Recent research shows that Preference Alignment (PA) objectives act as divergence estimators between aligned (chosen) and unaligned (rejected) response distributions. In this work, we extend this divergence-based perspective to general alignment settings, such as reinforcement learning with verifiable rewards ( RLVR ), where only environmental rewards are available. Within this unified framework, we propose f-Group Relative Policy Optimization (f-GRPO), a class of on-policy reinforcement learning , and f-Hybrid Alignment Loss (f-HAL), a hybrid on/off policy objectives, for general LLM alignment based on variational representation of f-divergence s. We provide theoretical guarantees that these classes of objectives improve the average reward after alignment. Empirically, we validate our framework on both RLVR ( Math Reasoning ) and PA tasks ( Safety Alignment ), demonstrating superior performance and flexibility compared to current methods.",
    "summary_en": "Preference alignment objectives are extended to general alignment settings using f-divergence variational representations, introducing novel on-policy and hybrid policy optimization methods for LLM alignment with theoretical and empirical validation.",
    "summary_zh": "利用 f-散度变分表示，将偏好对齐目标扩展至通用对齐设置，引入面向 LLM 对齐的新型同策略与混合策略优化方法，并经过理论与实证验证。",
    "upvotes": 0
  },
  {
    "id": "2602.02285",
    "date": "2026-02-10",
    "title": "Statistical Learning Theory in Lean 4: Empirical Processes from Scratch",
    "authors": "Yuanhe Zhang Jason D. Lee Fanghui Liu",
    "abstract": "A comprehensive formalization of statistical learning theory in Lean 4 addresses gaps in mathematical libraries and demonstrates human-AI collaboration for verified machine learning theory foundations. We present the first comprehensive Lean 4 formalization of statistical learning theory (SLT) grounded in empirical process theory . Our end-to-end formal infrastructure implement the missing contents in latest Lean 4 Mathlib library , including a complete development of Gaussian Lipschitz concentration , the first formalization of Dudley's entropy integral theorem for sub-Gaussian processes , and an application to least-squares (sparse) regression with a sharp rate. The project was carried out using a human-AI collaborative workflow , in which humans design proof strategies and AI agents execute tactical proof construction , leading to the human-verified Lean 4 toolbox for SLT. Beyond implementation, the formalization process exposes and resolves implicit assumptions and missing details in standard SLT textbooks, enforcing a granular, line-by-line understanding of the theory. This work establishes a reusable formal foundation and opens the door for future developments in machine learning theory. The code is available at https://github.com/YuanheZ/lean-stat-learning-theory",
    "summary_en": "A comprehensive formalization of statistical learning theory in Lean 4 addresses gaps in mathematical libraries and demonstrates human-AI collaboration for verified machine learning theory foundations.",
    "summary_zh": "在 Lean 4 中对统计学习理论的全面形式化填补了数学库的空白，并展示了人机协作在构建经过验证的机器学习理论基础方面的应用。",
    "upvotes": 0
  },
  {
    "id": "2602.06717",
    "date": "2026-02-09",
    "title": "F-GRPO: Don't Let Your Policy Learn the Obvious and Forget the Rare",
    "authors": "Daniil Plyusov Alexey Gorbatovski Boris Shaposhnikov Viacheslav Sinii Alexey Malakhov Daniil Gavrilov",
    "abstract": "RLVR methods using group sampling suffer from bias toward likely trajectories and missed rare-correct ones; a difficulty-aware advantage scaling technique improves performance on benchmarks without increasing computational cost. Reinforcement Learning with Verifiable Rewards (RLVR) is commonly based on group sampling to estimate advantages and stabilize policy updates . In practice, large group sizes are not feasible due to computational limits, which biases learning toward trajectories that are already likely. Smaller groups often miss rare-correct trajectories while still containing mixed rewards, concentrating probability on common solutions. We derive the probability that updates miss rare-correct modes as a function of group size, showing non-monotonic behavior, and characterize how updates redistribute mass within the correct set, revealing that unsampled-correct mass can shrink even as total correct mass grows. Motivated by this analysis, we propose a difficulty-aware advantage scaling coefficient, inspired by Focal loss , that down-weights updates on high-success prompts. The lightweight modification can be directly integrated into any group-relative RLVR algorithm such as GRPO , DAPO , and CISPO . On Qwen2.5-7B across in-domain and out-of-domain benchmarks, our method improves pass@256 from 64.1 rightarrow 70.3 ( GRPO ), 69.3 rightarrow 72.5 ( DAPO ), and 73.2 rightarrow 76.8 ( CISPO ), while preserving or improving pass@1, without increasing group size or computational cost.",
    "summary_en": "RLVR methods using group sampling suffer from bias toward likely trajectories and missed rare-correct ones; a difficulty-aware advantage scaling technique improves performance on benchmarks without increasing computational cost.",
    "summary_zh": "使用组采样的RLVR方法存在偏向高概率轨迹而遗漏稀有正确轨迹的问题；难度感知优势缩放技术能够在不增加计算成本的前提下提升基准测试性能。",
    "upvotes": 71
  },
  {
    "id": "2602.06570",
    "date": "2026-02-09",
    "title": "Baichuan-M3: Modeling Clinical Inquiry for Reliable Medical Decision-Making",
    "authors": "Baichuan-M3 Team Chengfeng Dou Fan Yang Fei Li Jiyuan Jia Qiang Ju Shuai Wang Tianpeng Li Xiangrong Zeng Yijie Zhou Hongda Zhang Jinyang Tai Linzhuang Sun Peidong Guo Yichuan Mo Xiaochuan Wang Hengfu Cui Zhishou Zhang",
    "abstract": "Baichuan-M3 is a medical-enhanced large language model designed for clinical decision support with capabilities in proactive information gathering, long-horizon reasoning, and hallucination suppression. We introduce Baichuan-M3, a medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes a specialized training pipeline to model the systematic workflow of a physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench , the newly introduced HealthBench-Hallu and ScanBench , significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3.",
    "summary_en": "Baichuan-M3 is a medical-enhanced large language model designed for clinical decision support with capabilities in proactive information gathering, long-horizon reasoning, and hallucination suppression.",
    "summary_zh": "Baichuan-M3是一款面向临床决策支持的医学增强大语言模型，具备主动信息收集、长程推理和幻觉抑制能力。",
    "upvotes": 59
  },
  {
    "id": "2602.05027",
    "date": "2026-02-09",
    "title": "AudioSAE: Towards Understanding of Audio-Processing Models with Sparse AutoEncoders",
    "authors": "Georgii Aparin Tasnima Sadekova Alexey Rukhovich Assel Yermekova Laida Kushnareva Vadim Popov Kristian Kuznetsov Irina Piontkovskaya",
    "abstract": "Sparse Autoencoders trained on Whisper and HuBERT models demonstrate stable feature extraction and effective disentanglement of acoustic and semantic information, showing practical applications in audio processing and correlation with human neural activity. Sparse Autoencoders (SAEs) are po wer ful tools for interpreting neural representations, yet their use in audio remains underexplored. We train SAEs across all encoder layers of Whisper and HuBERT , provide an extensive evaluation of their stability, interpretability, and show their practical utility. Over 50% of the features remain consistent across random seeds, and reconstruction quality is preserved. SAE features capture general acoustic and semantic information as well as specific events, including environmental noises and paralinguistic sounds (e.g. laughter, whisper ing) and disentangle them effectively, requiring removal of only 19-27% of features to erase a concept. Feature steering reduces Whisper 's false speech detections by 70% with negligible WER increase, demonstrating real-world applicability. Finally, we find SAE features correlated with human EEG activity during speech perception , indicating alignment with human neural processing. The code and checkpoints are available at https://github.com/audiosae/audiosae_demo.",
    "summary_en": "Sparse Autoencoders trained on Whisper and HuBERT models demonstrate stable feature extraction and effective disentanglement of acoustic and semantic information, showing practical applications in audio processing and correlation with human neural activity.",
    "summary_zh": "在 Whisper 和 HuBERT 模型上训练的稀疏自编码器展现出稳定的特征提取能力，有效解耦声学信息与语义信息，在音频处理中具有实际应用价值，并与人类神经活动存在相关性。",
    "upvotes": 59
  },
  {
    "id": "2602.05843",
    "date": "2026-02-09",
    "title": "OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions",
    "authors": "Fangzhi Xu Hang Yan Qiushi Sun Jinyang Wu Zixian Huang Muye Huang Jingyang Gong Zichen Ding Kanzhi Cheng Yian Wang Xinyu Che Zeyi Sun Jian Zhang Zhangyue Yin Haoran Luo Xuanjing Huang Ben Kao Jun Liu Qika Lin",
    "abstract": "OdysseyArena presents a new framework for evaluating large language models on long-horizon, inductive agent tasks that emphasize autonomous discovery of environmental transition laws. The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena , which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena",
    "summary_en": "OdysseyArena presents a new framework for evaluating large language models on long-horizon, inductive agent tasks that emphasize autonomous discovery of environmental transition laws.",
    "summary_zh": "OdysseyArena提出了一种新框架，用于评估大语言模型在长程归纳式智能体任务上的表现，这类任务强调对环境转移规律的自主发现。",
    "upvotes": 57
  },
  {
    "id": "2602.03392",
    "date": "2026-02-09",
    "title": "On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models",
    "authors": "Shumin Wang Yuexiang Xie Wenhao Zhang Yuchang Sun Yanxi Chen Yaliang Li Yanyong Zhang",
    "abstract": "The paper establishes a theoretical framework for analyzing entropy dynamics in reinforcement fine-tuning of large language models, deriving expressions for entropy change and proposing entropy control methods based on discriminant analysis. Entropy serves as a critical metric for measuring the diversity of outputs generated by large language models (LLMs), providing valuable insights into their exploration capabilities. While recent studies increasingly focus on monitoring and adjusting entropy to better balance exploration and exploitation in reinforcement fine-tuning ( RFT ), a principled understanding of entropy dynamics during this process is yet to be thoroughly investigated. In this paper, we establish a theoretical framework for analyzing the entropy dynamics during the RFT process, which begins with a discriminant expression that quantifies entropy change under a single logit update . This foundation enables the derivation of a first-order expression for entropy change, which can be further extended to the update formula of Group Relative Policy Optimization ( GRPO ). The corollaries and insights drawn from the theoretical analysis inspire the design of entropy control methods, and also offer a unified lens for interpreting various entropy -based methods in existing studies. We provide empirical evidence to support the main conclusions of our analysis and demonstrate the effectiveness of the derived entropy-discriminator clipping methods. This study yields novel insights into RFT training dynamics, providing theoretical support and practical strategies for optimizing the exploration-exploitation balance during LLM fine-tuning.",
    "summary_en": "The paper establishes a theoretical framework for analyzing entropy dynamics in reinforcement fine-tuning of large language models, deriving expressions for entropy change and proposing entropy control methods based on discriminant analysis.",
    "summary_zh": "本文建立了大语言模型强化微调中熵动态分析的理论框架，推导了熵变化的表达式，并基于判别分析提出了熵控制方法。",
    "upvotes": 53
  },
  {
    "id": "2601.18415",
    "date": "2026-02-09",
    "title": "Pisets: A Robust Speech Recognition System for Lectures and Interviews",
    "authors": "Ivan Bondarenko Daniil Grebenkin Oleg Sedukhin Mikhail Klementev Roman Derunets Lyudmila Budneva",
    "abstract": "A three-component speech-to-text system combines Wav2Vec2, AST, and Whisper models with curriculum learning and uncertainty modeling to improve transcription accuracy and reduce hallucinations in Russian speech recognition. This work presents a speech-to-text system \"Pisets\" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2 , false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper . The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality . The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to Whisper X and the usual Whisper model. The source code of \"Pisets\" system is publicly available at GitHub: https://github.com/bond005/pisets.",
    "summary_en": "A three-component speech-to-text system combines Wav2Vec2, AST, and Whisper models with curriculum learning and uncertainty modeling to improve transcription accuracy and reduce hallucinations in Russian speech recognition.",
    "summary_zh": "一种三组件语音转文本系统结合Wav2Vec2、AST和Whisper模型，通过课程学习与不确定性建模，提升俄语语音识别的转录准确率并减少幻觉。",
    "upvotes": 33
  },
  {
    "id": "2602.01734",
    "date": "2026-02-09",
    "title": "MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration",
    "authors": "Lianhai Ren Yucheng Ding Xiao Liu Qianxiao Li Peng Cheng Yeyun Gong",
    "abstract": "Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions. Training instability remains a critical challenge in large language model (LLM) pretraining , often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via μP, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm ), and (2) increasing alignment between adjacent layer Jacobian s. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.",
    "summary_en": "Training instability in large language models is linked to weight matrix stable rank decline and Jacobian alignment, which MSign addresses through matrix sign operations to prevent gradient explosions.",
    "summary_zh": "大语言模型的训练不稳定性与权重矩阵稳定秩下降及 Jacobian 对齐相关，MSign 通过矩阵符号运算解决该问题以防止梯度爆炸。",
    "upvotes": 32
  },
  {
    "id": "2602.06949",
    "date": "2026-02-09",
    "title": "DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos",
    "authors": "Shenyuan Gao William Liang Kaiyuan Zheng Ayaan Malik Seonghyeon Ye Sihyun Yu Wei-Cheng Tseng Yuzhu Dong Kaichun Mo Chen-Hsuan Lin Qianli Ma Seungjun Nah Loic Magne Jiannan Xiang Yuqi Xie Ruijie Zheng Dantong Niu You Liang Tan K. R. Zentner George Kurian Suneel Indupuru Pooya Jannaty",
    "abstract": "DreamDojo is a foundation world model trained on 44k hours of egocentric human videos that enables efficient simulation of dexterous robotic tasks through continuous latent actions and real-time distillation. Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels . As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diverse interactions and dexterous controls from 44k hours of egocentric human videos. Our data mixture represents the largest video dataset to date for world model pretraining, spanning a wide range of daily scenarios with diverse objects and skills. To address the scarcity of action labels , we introduce continuous latent actions as unified proxy actions, enhancing interaction knowledge transfer from unlabeled videos. After post-training on small-scale target robot data, DreamDojo demonstrates a strong understanding of physics and precise action controllability. We also devise a distillation pipeline that accelerates DreamDojo to a real-time speed of 10.81 FPS and further improves context consistency. Our work enables several important applications based on generative world model s, including live teleoperation , policy evaluation , and model-based planning . Systematic evaluation on multiple challenging out-of-distribution (OOD) benchmarks verifies the significance of our method for simulating open-world, contact-rich tasks, paving the way for general-purpose robot world model s.",
    "summary_en": "DreamDojo is a foundation world model trained on 44k hours of egocentric human videos that enables efficient simulation of dexterous robotic tasks through continuous latent actions and real-time distillation.",
    "summary_zh": "DreamDojo是一种在44k小时第一人称人类视频上训练的基础世界模型，通过连续潜在动作和实时蒸馏，实现灵巧机器人任务的高效模拟。",
    "upvotes": 30
  },
  {
    "id": "2602.06130",
    "date": "2026-02-09",
    "title": "Self-Improving World Modelling with Latent Actions",
    "authors": "Yifu Qiu Zheng Zhao Waylon Li Yftah Ziser Anna Korhonen Shay B. Cohen Edoardo M. Ponti",
    "abstract": "SWIRL is a self-improvement framework that learns world models from state-only sequences by alternating between forward and inverse dynamics modeling with variational information maximization and ELBO maximization, achieving improved performance on various reasoning and planning benchmarks. Internal modelling of the world -- predicting transitions between previous states X and next states Y under actions Z -- is essential to reasoning and planning for LLMs and VLMs. Learning such models typically requires costly action-labelled trajectories. We propose SWIRL, a self-improvement framework that learns from state-only sequences by treating actions as a latent variable and alternating between Forward World Modelling (FWM) P_θ(Y|X,Z) and an Inverse Dynamics Modelling (IDM) Q_φ(Z|X,Y). SWIRL iterates two phases: (1) Variational Information Maximisation , which updates the FWM to generate next states that maximise conditional mutual information with latent actions given prior states, encouraging identifiable consistency; and (2) ELBO Maximisation , which updates the IDM to explain observed transitions, effectively performing coordinate ascent . Both models are trained with reinforcement learning (specifically, GRPO ) with the opposite frozen model's log-probability as a reward signal. We provide theoretical learnability guarantees for both updates, and evaluate SWIRL on LLMs and VLMs across multiple environments: single-turn and multi-turn open-world visual dynamics and synthetic textual environments for physics, web, and tool calling. SWIRL achieves gains of 16% on AURORABench, 28% on ByteMorph, 16% on WorldPredictionBench, and 14% on StableToolBench.",
    "summary_en": "SWIRL is a self-improvement framework that learns world models from state-only sequences by alternating between forward and inverse dynamics modeling with variational information maximization and ELBO maximization, achieving improved performance on various reasoning and planning benchmarks.",
    "summary_zh": "SWIRL是一种自改进框架，通过在前向与逆向动力学建模之间交替，并采用变分信息最大化与ELBO最大化，从仅状态序列中学习世界模型，在多种推理与规划基准测试中取得了性能提升。",
    "upvotes": 29
  },
  {
    "id": "2602.06291",
    "date": "2026-02-09",
    "title": "Judging What We Cannot Solve: A Consequence-Based Approach for Oracle-Free Evaluation of Research-Level Math",
    "authors": "Guijin Son Donghun Yang Hitesh Laxmichand Patel Hyunwoo Ko Amit Agarwal Sunghee Ahn Kyong-Ha Lee Youngjae Yu",
    "abstract": "Consequence-Based Utility evaluates mathematical solutions by testing their effectiveness as exemplars for related problems, outperforming reward models and LLM judges in ranking quality and correct-wrong separation. Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains a bottleneck, consuming scarce expert time. We hypothesize that a meaningful solution should contain enough method-level information that, when applied to a neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propose Consequence-Based Utility, an oracle-free evaluator that scores each candidate by testing its value as an in-context exemplar in solving related yet verifiable questions. Our approach is evaluated on an original set of research-level math problems, each paired with one expert-written solution and nine LLM-generated solutions. Notably, Consequence-Based Utility consistently outperforms reward models , generative reward models , and LLM judges on ranking quality. Specifically, for GPT-OSS-120B, it improves Acc@1 from 67.2 to 76.3 and AUC from 71.4 to 79.6, with similarly large AUC gains on GPT-OSS-20B (69.0 to 79.2). Furthermore, compared to LLM-Judges, it also exhibits a larger solver-evaluator gap , maintaining a stronger correct-wrong separation even on instances where the underlying solver often fails to solve.",
    "summary_en": "Consequence-Based Utility evaluates mathematical solutions by testing their effectiveness as exemplars for related problems, outperforming reward models and LLM judges in ranking quality and correct-wrong separation.",
    "summary_zh": "基于后果的效用通过测试数学解决方案作为相关问题范例的有效性来评估这些方案，在排序质量和对错区分方面优于奖励模型和LLM评判器。",
    "upvotes": 23
  },
  {
    "id": "2602.06079",
    "date": "2026-02-09",
    "title": "Canzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers",
    "authors": "Liangyu Wang Siqi Zhang Junjie Wang Yiming Dong Bo Zheng Zihan Qiu Shengkun Tang Di Wang Rui Men Dayiheng Liu",
    "abstract": "Canzona presents a unified asynchronous framework that addresses the conflict between matrix-based optimizers and distributed tensor fragmentation in LLM training, improving efficiency and reducing latency.",
    "summary_en": "Canzona presents a unified asynchronous framework that addresses the conflict between matrix-based optimizers and distributed tensor fragmentation in LLM training, improving efficiency and reducing latency.",
    "summary_zh": "Canzona提出了一种统一的异步框架，解决了基于矩阵的优化器与分布式张量碎片化在LLM训练中的冲突，提升了效率并降低了延迟。",
    "upvotes": 18
  },
  {
    "id": "2602.05940",
    "date": "2026-02-09",
    "title": "Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training",
    "authors": "Junxiao Liu Zhijun Wang Yixiao Li Zhejian Lai Liqian Huang Xin Huang Xue Han Junlan Feng Shujian Huang",
    "abstract": "TRIT framework improves multilingual reasoning by jointly training translation and reasoning components, enhancing question understanding and response generation across languages. Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning . To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning . Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH , our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200 .",
    "summary_en": "TRIT framework improves multilingual reasoning by jointly training translation and reasoning components, enhancing question understanding and response generation across languages.",
    "summary_zh": "TRIT框架通过联合训练翻译和推理组件，提升多语言推理能力，并增强跨语言的问题理解与回答生成。",
    "upvotes": 18
  },
  {
    "id": "2602.06391",
    "date": "2026-02-09",
    "title": "POINTS-GUI-G: GUI-Grounding Journey",
    "authors": "Zhongyin Zhao Yuan Liu Yikun Liu Haicheng Wang Le Tian Xiao Zhou Yangxiu You Zilin Yu Yang Yu Jie Zhou",
    "abstract": "GUI agents for automated digital tasks rely on vision-language models with enhanced grounding capabilities, achieved through refined data engineering, improved training strategies, and reinforcement learning with verifiable rewards.",
    "summary_en": "GUI agents for automated digital tasks rely on vision-language models with enhanced grounding capabilities, achieved through refined data engineering, improved training strategies, and reinforcement learning with verifiable rewards.",
    "summary_zh": "用于自动化数字任务的GUI智能体依赖具备增强grounding能力的视觉语言模型，这些能力通过精细化的数据工程、改进的训练策略以及可验证奖励的强化学习来实现。",
    "upvotes": 16
  },
  {
    "id": "2602.05281",
    "date": "2026-02-09",
    "title": "Back to Basics: Revisiting Exploration in Reinforcement Learning for LLM Reasoning via Generative Probabilities",
    "authors": "Pengyi Li Elizaveta Goncharova Andrey Kuznetsov Ivan Oseledets",
    "abstract": "A novel reinforcement learning approach called ARM addresses entropy collapse in LLM reasoning by equilibrating confidence levels across correct responses through dynamic reward shaping. Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an indispensable paradigm for enhancing reasoning in Large Language Models (LLMs). However, standard policy optimization methods, such as Group Relative Policy Optimization (GRPO), often converge to low-entropy policies, leading to severe mode collapse and limited output diversity. We analyze this issue from the perspective of sampling probability dynamics, identifying that the standard objective disproportionately reinforces the highest-likelihood paths, thereby suppressing valid alternative reasoning chains. To address this, we propose a novel Advantage Re-weighting Mechanism (ARM) designed to equilibrate the confidence levels across all correct responses. By incorporating Prompt Perplexity and Answer Confidence into the advantage estimation , our method dynamically reshapes the reward signal to attenuate the gradient updates of over-confident reasoning paths, while redistributing probability mass toward under-explored correct solutions. Empirical results demonstrate that our approach significantly enhances generative diversity and response entropy while maintaining competitive accuracy, effectively achieving a superior trade-off between exploration and exploitation in reasoning tasks . Empirical results on Qwen2.5 and DeepSeek models across mathematical and coding benchmarks show that ProGRPO significantly mitigates entropy collapse . Specifically, on Qwen2.5-7B, our method outperforms GRPO by 5.7% in Pass@1 and, notably, by 13.9% in Pass@32 , highlighting its superior capability in generating diverse correct reasoning paths.",
    "summary_en": "A novel reinforcement learning approach called ARM addresses entropy collapse in LLM reasoning by equilibrating confidence levels across correct responses through dynamic reward shaping.",
    "summary_zh": "一种名为ARM的新型强化学习方法通过动态奖励塑造均衡各正确回答的置信度水平，以解决LLM推理中的熵坍缩问题。",
    "upvotes": 15
  },
  {
    "id": "2602.06075",
    "date": "2026-02-09",
    "title": "MemGUI-Bench: Benchmarking Memory of Mobile GUI Agents in Dynamic Environments",
    "authors": "Guangyi Liu Pengxiang Zhao Yaozhen Liang Qinyi Luo Shunye Tang Yuxiang Chai Weifeng Lin Han Xiao WenHao Wang Siheng Chen Zhengxi Lu Gao Wu Hao Wang Liang Liu Yong Liu",
    "abstract": "A comprehensive memory-focused benchmark for mobile GUI agents reveals significant memory capability gaps and provides systematic evaluation methods and design insights. Current mobile GUI agent benchmarks systematically fail to assess memory capabilities, with only 5.2-11.8% memory-related tasks and no cross-session learning evaluation. We introduce MemGUI-Bench, a comprehensive memory-centric benchmark with pass@k and staged LLM-as-judge evaluation . Our contributions include: (1) a systematic memory taxonomy analyzing 11 agents across 5 architectures; (2) 128 tasks across 26 applications where 89.8% challenge memory through cross-temporal and cross-spatial retention ; (3) MemGUI-Eval, an automated pipeline with Progressive Scrutiny and 7 hierarchical metrics ; and (4) RQ-driven assessment of 11 state-of-the-art agents . Our experiments reveal significant memory deficits across all evaluated systems, identify 5 distinct failure modes , and synthesize 5 actionable design implications . All resources including code, benchmark, and evaluation results will be \\textit{fully open-sourced and continuously maintained} at https://lgy0404.github.io/MemGUI-Bench/.",
    "summary_en": "A comprehensive memory-focused benchmark for mobile GUI agents reveals significant memory capability gaps and provides systematic evaluation methods and design insights.",
    "summary_zh": "一项全面的面向移动GUI智能体的记忆基准测试揭示了显著的记忆能力差距，并提供了系统性评估方法和设计见解。",
    "upvotes": 13
  },
  {
    "id": "2602.06960",
    "date": "2026-02-09",
    "title": "InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning",
    "authors": "Yuchen Yan Liang Jiang Jin Jiang Shuaicheng Li Zujie Wen Zhiqiang Zhang Jun Zhou Jian Shao Yueting Zhuang Yongliang Shen",
    "abstract": "InftyThink+ uses reinforcement learning to optimize iterative reasoning processes, improving accuracy and efficiency in large language models. Large reasoning models achieve strong performance by scaling inference-time chain-of-thought , but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to optimize when to summarize, what to preserve, and how to resume reasoning. We propose InftyThink+, an end-to-end reinforcement learning framework that optimizes the entire iterative reasoning trajectory, building on model-controlled iteration boundaries and explicit summarization . InftyThink+ adopts a two-stage training scheme with supervised cold-start followed by trajectory-level reinforcement learning , enabling the model to learn strategic summarization and continuation decisions. Experiments on DeepSeek-R1-Distill-Qwen-1.5B show that InftyThink+ improves accuracy by 21% on AIME24 and outperforms conventional long chain-of-thought reinforcement learning by a clear margin, while also generalizing better to out-of-distribution benchmarks. Moreover, InftyThink+ significantly reduces inference latency and accelerates reinforcement learning training, demonstrating improved reasoning efficiency alongside stronger performance.",
    "summary_en": "InftyThink+ uses reinforcement learning to optimize iterative reasoning processes, improving accuracy and efficiency in large language models.",
    "summary_zh": "InftyThink+采用强化学习优化迭代推理过程，提升大语言模型的准确性和效率。",
    "upvotes": 12
  },
  {
    "id": "2602.06139",
    "date": "2026-02-09",
    "title": "EgoAVU: Egocentric Audio-Visual Understanding",
    "authors": "Ashish Seth Xinhao Mei Changsheng Zhao Varun Nagaraja Ernie Chang Gregory P. Meyer Gael Le Lan Yunyang Xiong Vikas Chandra Yangyang Shi Dinesh Manocha Zhipeng Cai",
    "abstract": "Multi-modal large language models struggle to jointly understand audio and visual signals in egocentric videos, but a new scalable data engine and dataset significantly improve their performance through targeted fine-tuning. Understanding egocentric videos plays a vital role for embodied intelligence. Recent multi-modal large language models (MLLMs) can accept both visual and audio inputs. However, due to the challenge of obtaining text labels with coherent joint-modality information, whether MLLMs can jointly understand both modalities in egocentric videos remains under-explored. To address this problem, we introduce EgoAVU, a scalable data engine to automatically generate egocentric audio-visual narrations , questions, and answers. EgoAVU enriches human narrations with multimodal context and generates audio-visual narrations through cross-modal correlation modeling . Token-based video filtering and modular, graph-based curation ensure both data diversity and quality. Leveraging EgoAVU, we construct EgoAVU-Instruct , a large-scale training dataset of 3M samples, and EgoAVU-Bench , a manually verified evaluation split covering diverse tasks. EgoAVU-Bench clearly reveals the limitations of existing MLLMs: they bias heavily toward visual signals, often neglecting audio cues or failing to correspond audio with the visual source. Finetuning MLLMs on EgoAVU-Instruct effectively addresses this issue, enabling up to 113% performance improvement on EgoAVU-Bench . Such benefits also transfer to other benchmarks such as EgoTempo and EgoIllusion , achieving up to 28% relative performance gain. Code will be released to the community.",
    "summary_en": "Multi-modal large language models struggle to jointly understand audio and visual signals in egocentric videos, but a new scalable data engine and dataset significantly improve their performance through targeted fine-tuning.",
    "summary_zh": "多模态大语言模型难以联合理解第一人称视角视频中的音频和视觉信号，但一种新的可扩展数据引擎和数据集通过针对性微调显著提升了其性能。",
    "upvotes": 12
  },
  {
    "id": "2602.05847",
    "date": "2026-02-09",
    "title": "OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention",
    "authors": "Zhangquan Chen Jiale Tao Ruihuang Li Yihao Hu Ruitao Chen Zhantao Yang Xinlei Yu Haodong Jing Manyuan Zhang Shuai Shao Biao Wang Qinglin Lu Ruqi Huang",
    "abstract": "OmniVideo-R1 enhances audio-visual understanding through reinforced frameworks that integrate self-supervised and contrastive learning for multimodal reasoning. While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning . OmniVideo-R1 empowers models to \"think with omnimodal cues\" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.",
    "summary_en": "OmniVideo-R1 enhances audio-visual understanding through reinforced frameworks that integrate self-supervised and contrastive learning for multimodal reasoning.",
    "summary_zh": "OmniVideo-R1通过融合自监督与对比学习的强化框架，增强音视频理解以实现多模态推理。",
    "upvotes": 12
  },
  {
    "id": "2602.04649",
    "date": "2026-02-09",
    "title": "Outcome Accuracy is Not Enough: Aligning the Reasoning Process of Reward Models",
    "authors": "Binghai Wang Yantao Liu Yuxuan Liu Tianyi Tang Shenzhi Wang Chang Gao Chujie Zheng Yichang Zhang Le Yu Shixuan Liu Tao Gui Qi Zhang Xuanjing Huang Bowen Yu Fei Huang Junyang Lin",
    "abstract": "Generative Reward Models suffer from deceptive alignment due to outcome accuracy prioritization, but rationale consistency metrics and hybrid training signals improve performance and generalization in RLHF. Generative Reward Models (GenRMs) and LLM-as-a-Judge exhibit deceptive alignment by producing correct judgments for incorrect reasons, as they are trained and evaluated to prioritize Outcome Accuracy , which undermines their ability to generalize during RLHF . We introduce Rationale Consistency , a fine-grained metric that quantifies the alignment between the model's reasoning process and human judgment. Our evaluation of frontier models reveals that rationale consistency effectively discriminates among state-of-the-art models and detects deceptive alignment , while outcome accuracy falls short in both respects. To mitigate this gap, we introduce a hybrid signal that combines rationale consistency with outcome accuracy for GenRM training. Our training method achieves state-of-the-art performance on RM-Bench (87.1%) and JudgeBench (82%), surpassing outcome-only baselines by an average of 5%. Using RM during RLHF , our method effectively improves performance as demonstrated on Arena Hard v2, notably yielding a 7% improvement in creative writing tasks . Further analysis confirms that our method escapes the deceptive alignment trap, effectively reversing the decline in rationale consistency observed in outcome-only training.",
    "summary_en": "Generative Reward Models suffer from deceptive alignment due to outcome accuracy prioritization, but rationale consistency metrics and hybrid training signals improve performance and generalization in RLHF.",
    "summary_zh": "生成式奖励模型因优先优化结果准确性而遭受欺骗性对齐，但理由一致性指标与混合训练信号可改善RLHF中的性能与泛化能力。",
    "upvotes": 12
  },
  {
    "id": "2602.06176",
    "date": "2026-02-09",
    "title": "Large Language Model Reasoning Failures",
    "authors": "Peiyang Song Pengrui Han Noah Goodman",
    "abstract": "Large language models exhibit significant reasoning failures that can be categorized into embodied and non-embodied types, with fundamental, application-specific, and robustness-related subtypes, requiring systematic analysis and mitigation strategies. Large Language Models (LLMs) have exhibited remarkable reasoning capabilities , achieving impressive results across a wide range of tasks. Despite these advances, significant reasoning failures persist, occurring even in seemingly simple scenarios. To systematically understand and address these shortcomings, we present the first comprehensive survey dedicated to reasoning failures in LLMs. We introduce a novel categorization framework that distinguishes reasoning into embodied and non-embodied types, with the latter further subdivided into informal (intuitive) and formal (logical) reasoning. In parallel, we classify reasoning failures along a complementary axis into three types: fundamental failures intrinsic to LLM architectures that broadly affect downstream tasks; application-specific limitations that manifest in particular domains; and robustness issues characterized by inconsistent performance across minor variations. For each reasoning failure, we provide a clear definition, analyze existing studies, explore root causes, and present mitigation strategies. By unifying fragmented research efforts, our survey provides a structured perspective on systemic weaknesses in LLM reasoning, offering valuable insights and guiding future research towards building stronger, more reliable, and robust reasoning capabilities . We additionally release a comprehensive collection of research works on LLM reasoning failures , as a GitHub repository at https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures, to provide an easy entry point to this area.",
    "summary_en": "Large language models exhibit significant reasoning failures that can be categorized into embodied and non-embodied types, with fundamental, application-specific, and robustness-related subtypes, requiring systematic analysis and mitigation strategies.",
    "summary_zh": "大语言模型表现出显著的推理失败，可分为具身与非具身类型，并包含基础型、应用特定型及鲁棒性相关型等子类型，需要系统性的分析与缓解策略。",
    "upvotes": 11
  },
  {
    "id": "2602.05711",
    "date": "2026-02-09",
    "title": "OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale",
    "authors": "Jingze Shi Zhangyang Peng Yizhang Zhu Yifan Wu Guang Liu Yuyu Luo",
    "abstract": "OmniMoE presents a system-algorithm co-designed framework that achieves fine-grained expert specialization in Mixture-of-Experts architectures through vector-level atomic experts and optimized routing and scheduling mechanisms. Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts , enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access . To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.",
    "summary_en": "OmniMoE presents a system-algorithm co-designed framework that achieves fine-grained expert specialization in Mixture-of-Experts architectures through vector-level atomic experts and optimized routing and scheduling mechanisms.",
    "summary_zh": "OmniMoE提出了一种系统-算法协同设计框架，通过向量级原子专家以及优化的路由与调度机制，在混合专家架构中实现了细粒度的专家特化。",
    "upvotes": 9
  },
  {
    "id": "2602.02581",
    "date": "2026-02-09",
    "title": "QuantLRM: Quantization of Large Reasoning Models via Fine-Tuning Signals",
    "authors": "Nan Zhang Eugene Kwek Yusen Zhang Muyu Pan Suhang Wang Prasenjit Mitra Rui Zhang",
    "abstract": "QuantLRM uses weight update magnitude signals from fine-tuning to improve quantization of Large Reasoning Models, achieving better performance than traditional methods through channel importance estimation. Weight-only quantization is important for compressing Large Language Models (LLMs). Inspired by the spirit of classical magnitude pruning , we study whether the magnitude of weight updates during reasoning-incentivized fine-tuning can provide valuable signals for quantizing Large Reasoning Models (LRMs). We hypothesize that the smallest and largest weight updates during fine-tuning are more important than those of intermediate magnitude, a phenomenon we term \"protecting both ends\". Upon hypothesis validation, we introduce QuantLRM, which stands for weight quantization of LRMs via fine-tuning signals. We fit simple restricted quadratic functions on weight updates to protect both ends. By multiplying the average quadratic values with the count of zero weight updates of channels, we compute channel importance that is more effective than using activation or second-order information. We run QuantLRM to quantize various fine-tuned models (including supervised, direct preference optimization, and reinforcement learning fine-tuning ) over four reasoning benchmarks (AIME-120, FOLIO, temporal sequences, and GPQA-Diamond) and empirically find that QuantLRM delivers a consistent improvement for LRMs quantization, with an average improvement of 6.55% on a reinforcement learning fine-tuned model. Also supporting non-fine-tuned LRMs, QuantLRM gathers effective signals via pseudo-fine-tuning , which greatly enhances its applicability.",
    "summary_en": "QuantLRM uses weight update magnitude signals from fine-tuning to improve quantization of Large Reasoning Models, achieving better performance than traditional methods through channel importance estimation.",
    "summary_zh": "QuantLRM利用微调过程中的权重更新幅度信号来改进大型推理模型的量化，通过通道重要性估计实现了优于传统方法的性能。",
    "upvotes": 9
  },
  {
    "id": "2602.04837",
    "date": "2026-02-09",
    "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing",
    "authors": "Zhaotian Weng Antonis Antoniades Deepak Nathani Zhen Zhang Xiao Pu Xin Eric Wang",
    "abstract": "Group-Evolving Agents enable open-ended self-improvement by treating groups of agents as evolutionary units, allowing efficient experience sharing and reuse to enhance coding performance and robustness. Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit , enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks , where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified , 88.3% vs. 68.3% on Polyglot ) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods .",
    "summary_en": "Group-Evolving Agents enable open-ended self-improvement by treating groups of agents as evolutionary units, allowing efficient experience sharing and reuse to enhance coding performance and robustness.",
    "summary_zh": "群体进化智能体将智能体群体视为进化单元，通过高效的经验共享与复用提升代码性能与鲁棒性，实现开放式自我改进。",
    "upvotes": 8
  },
  {
    "id": "2602.06669",
    "date": "2026-02-09",
    "title": "compar:IA: The French Government's LLM arena to collect French-language human prompts and preference data",
    "authors": "Lucie Termignon Simonas Zilinskas Hadrien Pélissier Aurélien Barrot Nicolas Chesnais Elie Gavoty",
    "abstract": "Compar:IA is an open-source platform that collects large-scale human preference data for multilingual language model training and evaluation, featuring a blind pairwise comparison interface and releasing three datasets under open licenses.",
    "summary_en": "Compar:IA is an open-source platform that collects large-scale human preference data for multilingual language model training and evaluation, featuring a blind pairwise comparison interface and releasing three datasets under open licenses.",
    "summary_zh": "Compar:IA 是一个开源平台，收集用于多语言语言模型训练与评估的大规模人类偏好数据，具备盲测成对比较界面，并以开放许可发布三个数据集。",
    "upvotes": 7
  },
  {
    "id": "2602.05367",
    "date": "2026-02-09",
    "title": "RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs",
    "authors": "Youngcheon You Banseok Lee Minseop Choi Seonyoung Kim Hyochan Chong Changdong Kim Youngmin Kim Dongkyu Kim",
    "abstract": "Residual binarization framework RaBiT addresses feature co-adaptation in quantized LLMs through hierarchical path derivation and robust initialization, achieving superior accuracy-efficiency trade-offs. Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary (pm1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation : during quantization-aware training ( QAT ), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT , a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy . Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization ( VQ ) methods, and delivers a 4.49times inference speed-up over full-precision models on an RTX 4090 .",
    "summary_en": "Residual binarization framework RaBiT addresses feature co-adaptation in quantized LLMs through hierarchical path derivation and robust initialization, achieving superior accuracy-efficiency trade-offs.",
    "summary_zh": "残差二值化框架RaBiT通过分层路径推导与鲁棒初始化解决量化LLM中的特征协同适应问题，实现了更优的精度-效率权衡。",
    "upvotes": 7
  },
  {
    "id": "2602.06869",
    "date": "2026-02-09",
    "title": "Uncovering Cross-Objective Interference in Multi-Objective Alignment",
    "authors": "Yining Lu Meng Jiang",
    "abstract": "Multi-objective alignment in LLMs suffers from cross-objective interference where improving performance on some objectives degrades others, with a covariance-based analysis and a proposed method to maintain positive correlations between rewards and training signals. We study a persistent failure mode in multi-objective alignment for large language models (LLMs): training improves performance on only a subset of objectives while causing others to degrade. We formalize this phenomenon as cross-objective interference and conduct the first systematic study across classic scalarization algorithms , showing that interference is pervasive and exhibits strong model dependence. To explain this phenomenon, we derive a local covariance law showing that an objective improves at first order when its reward exhibits positive covariance with the scalarized score. We extend this analysis to clipped surrogate objectives used in modern alignment, demonstrating that the covariance law remains valid under mild conditions despite clipping. Building on this analysis, we propose Covariance Targeted Weight Adaptation (CTWA), a plug-and-play method that maintains positive covariance between objective rewards and the training signal to effectively mitigate cross-objective interference . Finally, we complement these local improvement conditions with a global convergence analysis under the Polyak--Łojasiewicz condition , establishing when non-convex scalarized optimization achieves global convergence and how cross-objective interference depends on specific model geometric properties.",
    "summary_en": "Multi-objective alignment in LLMs suffers from cross-objective interference where improving performance on some objectives degrades others, with a covariance-based analysis and a proposed method to maintain positive correlations between rewards and training signals.",
    "summary_zh": "大语言模型的多目标对齐存在跨目标干扰，即提升某些目标性能会降低其他目标；该研究采用协方差分析，并提出一种保持奖励与训练信号正相关性的方法。",
    "upvotes": 6
  },
  {
    "id": "2602.06854",
    "date": "2026-02-09",
    "title": "SEMA: Simple yet Effective Learning for Multi-Turn Jailbreak Attacks",
    "authors": "Mingqian Feng Xiaodong Liu Weiwei Yang Jialin Song Xuekai Zhu Chenliang Xu Jianfeng Gao",
    "abstract": "A novel framework called SEMA is introduced that effectively trains multi-turn attackers for large language models without relying on existing strategies or external data, achieving state-of-the-art attack success rates while being compact, reproducible, and transferable across different models and datasets. Multi-turn jailbreaks capture the real threat model for safety-aligned chatbots, where single-turn attacks are merely a special case. Yet existing approaches break under exploration complexity and intent drift. We propose SEMA, a simple yet effective framework that trains a multi-turn attacker without relying on any existing strategies or external data. SEMA comprises two stages. Prefilling self-tuning enables usable rollouts by fine-tuning on non-refusal, well-structured, multi-turn adversarial prompts that are self-generated with a minimal prefix, thereby stabilizing subsequent learning. Reinforcement learning with intent-drift-aware reward trains the attacker to elicit valid multi-turn adversarial prompts while maintaining the same harmful objective. We anchor harmful intent in multi-turn jailbreaks via an intent-drift-aware reward that combines intent alignment, compliance risk, and level of detail. Our open-loop attack regime avoids dependence on victim feedback, unifies single- and multi-turn settings, and reduces exploration complexity. Across multiple datasets, victim models , and jailbreak judges , our method achieves state-of-the-art (SOTA) attack success rates (ASR), outperforming all single-turn baselines, manually scripted and template-driven multi-turn baselines, as well as our SFT ( Supervised Fine-Tuning ) and DPO ( Direct Preference Optimization ) variants. For instance, SEMA performs an average 80.1% ASR@1 across three closed-source and open-source victim models on AdvBench, 33.9% over SOTA. The approach is compact, reproducible, and transfers across targets, providing a stronger and more realistic stress test for large language model (LLM) safety and enabling automatic redteaming to expose and localize failure modes. Our code is available at: https://github.com/fmmarkmq/SEMA.",
    "summary_en": "A novel framework called SEMA is introduced that effectively trains multi-turn attackers for large language models without relying on existing strategies or external data, achieving state-of-the-art attack success rates while being compact, reproducible, and transferable across different models and datasets.",
    "summary_zh": "本文提出了一种名为 SEMA 的新框架，可在不依赖现有策略或外部数据的情况下有效训练面向大型语言模型的多轮攻击器，实现了最先进的攻击成功率，且具备紧凑、可复现、可跨不同模型和数据集迁移的特性。",
    "upvotes": 6
  },
  {
    "id": "2602.03075",
    "date": "2026-02-09",
    "title": "ReMiT: RL-Guided Mid-Training for Iterative LLM Evolution",
    "authors": "Junjie Huang Jiarui Qin Di Yin Weiwen Liu Yong Yu Xing Sun Weinan Zhang",
    "abstract": "ReMiT introduces a bidirectional training approach where reinforcement learning-guided mid-training token reweighting improves large language model pre-training and post-training performance through an iterative feedback loop. Standard training pipelines for large language models (LLMs) are typically unidirectional, progressing from pre-training to post-training . However, the potential for a bidirectional process--where insights from post-training retroactively improve the pre-trained foundation--remains unexplored. We aim to establish a self-reinforcing flywheel: a cycle in which reinforcement learning (RL)-tuned model strengthens the base model, which in turn enhances subsequent post-training performance, requiring no specially trained teacher or reference model. To realize this, we analyze training dynamics and identify the mid-training (annealing) phase as a critical turning point for model capabilities. This phase typically occurs at the end of pre-training , utilizing high-quality corpora under a rapidly decaying learning rate. Building upon this insight, we introduce ReMiT ( Reinforcement Learning -Guided Mid-Training). Specifically, ReMiT leverages the reasoning priors of RL-tuned models to dynamically reweight tokens during the mid-training phase , prioritizing those pivotal for reasoning. Empirically, ReMiT achieves an average improvement of 3\\% on 10 pre-training benchmarks, spanning math, code, and general reasoning, and sustains these gains by over 2\\% throughout the post-training pipeline. These results validate an iterative feedback loop , enabling continuous and self-reinforcing evolution of LLMs.",
    "summary_en": "ReMiT introduces a bidirectional training approach where reinforcement learning-guided mid-training token reweighting improves large language model pre-training and post-training performance through an iterative feedback loop.",
    "summary_zh": "ReMiT提出了一种双向训练方法，其中强化学习引导的训练中期token重加权通过迭代反馈循环提升大语言模型的预训练与后训练性能。",
    "upvotes": 6
  },
  {
    "id": "2602.06663",
    "date": "2026-02-09",
    "title": "PlanViz: Evaluating Planning-Oriented Image Generation and Editing for Computer-Use Tasks",
    "authors": "Junxian Li Kai Liu Leyang Chen Weida Wang Zhixin Wang Jiaqi Xu Fan Li Renjing Pei Linghe Kong Yulun Zhang",
    "abstract": "PlanViz benchmark evaluates unified multimodal models' capabilities in computer-use planning tasks through route planning, work diagramming, and web&UI displaying sub-tasks with a task-adaptive scoring system.",
    "summary_en": "PlanViz benchmark evaluates unified multimodal models' capabilities in computer-use planning tasks through route planning, work diagramming, and web&UI displaying sub-tasks with a task-adaptive scoring system.",
    "summary_zh": "PlanViz基准测试通过路径规划、工作图表绘制和网页与UI展示子任务，采用任务自适应评分系统，评估统一多模态模型在计算机使用规划任务中的能力。",
    "upvotes": 5
  },
  {
    "id": "2602.06554",
    "date": "2026-02-09",
    "title": "SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees",
    "authors": "Tianyi Hu Qingxu Fu Yanxi Chen Zhaoyang Liu Bolin Ding",
    "abstract": "SeeUPO is a critic-free reinforcement learning method that ensures convergence guarantees in multi-turn agent interactions by modeling sequential decision-making as multi-agent bandit problems and using backward induction for policy updates. Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies. In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/ multi-turn scenarios . We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO 's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios . To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems . Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction . Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability.",
    "summary_en": "SeeUPO is a critic-free reinforcement learning method that ensures convergence guarantees in multi-turn agent interactions by modeling sequential decision-making as multi-agent bandit problems and using backward induction for policy updates.",
    "summary_zh": "SeeUPO是一种无critic的强化学习方法，通过将序列决策建模为多智能体bandit问题并使用逆向归纳进行策略更新，确保多轮智能体交互的收敛性保证。",
    "upvotes": 5
  },
  {
    "id": "2602.06883",
    "date": "2026-02-09",
    "title": "Vision Transformer Finetuning Benefits from Non-Smooth Components",
    "authors": "Ambroise Odonnat Laetitia Chapel Romain Tavenard Ievgen Redko",
    "abstract": "Vision transformer components exhibit varying plasticity levels that correlate with finetuning performance, challenging the assumption that smoothness is always beneficial. The smoothness of the transformer architecture has been extensively studied in the context of generalization , training stability , and adversarial robustness . However, its role in transfer learning remains poorly understood. In this paper, we analyze the ability of vision transformer components to adapt their outputs to changes in inputs, or, in other words, their plasticity . Defined as an average rate of change, it captures the sensitivity to input perturbation; in particular, a high plasticity implies low smoothness . We demonstrate through theoretical analysis and comprehensive experiments that this perspective provides principled guidance in choosing the components to prioritize during adaptation. A key takeaway for practitioners is that the high plasticity of the attention modules and feedforward layers consistently leads to better finetuning performance . Our findings depart from the prevailing assumption that smoothness is desirable, offering a novel perspective on the functional properties of transformers. The code is available at https://github.com/ambroiseodt/vit- plasticity .",
    "summary_en": "Vision transformer components exhibit varying plasticity levels that correlate with finetuning performance, challenging the assumption that smoothness is always beneficial.",
    "summary_zh": "Vision Transformer组件表现出与微调性能相关的不同可塑性水平，挑战了平滑性总是有益的这一假设。",
    "upvotes": 4
  },
  {
    "id": "2602.06471",
    "date": "2026-02-09",
    "title": "Revisiting the Shape Convention of Transformer Language Models",
    "authors": "Feng-Ting Liao Meng-Hsi Chen Guan-Ting Yi Da-shan Shiu",
    "abstract": "Replacing conventional feed-forward networks with hourglass-shaped MLPs in Transformers improves model efficiency and performance by enabling better parameter utilization and competitive scaling. Dense Transformer language models have largely adhered to one consistent architectural shape: each layer consists of an attention module followed by a feed-forward network (FFN) with a narrow-wide-narrow MLP , allocating most parameters to the MLP at expansion ratios between 2 and 4. Motivated by recent results that residual wide-narrow-wide (hourglass) MLP s offer superior function approximation capabilities, we revisit the long-standing MLP shape convention in Transformer , challenging the necessity of the narrow-wide-narrow design. To study this, we develop a Transformer variant that replaces the conventional FFN with a deeper hourglass-shaped FFN, comprising a stack of hourglass sub- MLP s connected by residual pathways . We posit that a deeper but lighter hourglass FFN can serve as a competitive alternative to the conventional FFN, and that parameters saved by using a lighter hourglass FFN can be more effectively utilized, such as by enlarging model hidden dimensions under fixed budgets. We confirm these through empirical validations across model scales: hourglass FFNs outperform conventional FFNs up to 400M and achieve comparable performance at larger scales to 1B parameters; hourglass FFN variants with reduced FFN and increased attention parameters show consistent improvements over conventional configurations at matched budgets. Together, these findings shed new light on recent work and prompt a rethinking of the narrow-wide-narrow MLP convention and the balance between attention and FFN towards efficient and expressive modern language models.",
    "summary_en": "Replacing conventional feed-forward networks with hourglass-shaped MLPs in Transformers improves model efficiency and performance by enabling better parameter utilization and competitive scaling.",
    "summary_zh": "在Transformer中用沙漏形MLP替换传统前馈网络，通过实现更优的参数利用和具有竞争力的扩展性，提升了模型效率与性能。",
    "upvotes": 4
  },
  {
    "id": "2602.03548",
    "date": "2026-02-09",
    "title": "SEAD: Self-Evolving Agent for Multi-Turn Service Dialogue",
    "authors": "Yuqin Dai Ning Gao Wei Zhang Jie Wang Zichen Luo Jinpeng Wang Yujie Wang Ruiyuan Wu Chaozheng Wang",
    "abstract": "SEAD framework enables service dialogue agents to learn effective strategies through self-evolving user modeling components, achieving superior task completion and dialogue efficiency compared to existing foundation and commercial models. Large Language Models have demonstrated remarkable capabilities in open-domain dialogues. However, current methods exhibit suboptimal performance in service dialogues , as they rely on noisy, low-quality human conversation data. This limitation arises from data scarcity and the difficulty of simulating authentic, goal-oriented user behaviors. To address these issues, we propose SEAD (Self-Evolving Agent for Service Dialogue), a framework that enables agents to learn effective strategies without large-scale human annotations. SEAD decouples user modeling into two components: a Profile Controller that generates diverse user states to manage training curriculum, and a User Role-play Model that focuses on realistic role-playing. This design ensures the environment provides adaptive training scenarios rather than acting as an unfair adversary. Experiments demonstrate that SEAD significantly outperforms Open-source Foundation Models and Closed-source Commercial Models, improving task completion rate by 17.6% and dialogue efficiency by 11.1%. Code is available at: https://github.com/Da1yuqin/SEAD.",
    "summary_en": "SEAD framework enables service dialogue agents to learn effective strategies through self-evolving user modeling components, achieving superior task completion and dialogue efficiency compared to existing foundation and commercial models.",
    "summary_zh": "SEAD框架使服务对话智能体能够通过自进化用户建模组件学习有效策略，在任务完成和对话效率方面优于现有的基础模型和商业模型。",
    "upvotes": 4
  },
  {
    "id": "2602.06566",
    "date": "2026-02-09",
    "title": "SPARC: Separating Perception And Reasoning Circuits for Test-time Scaling of VLMs",
    "authors": "Niccolo Avogaro Nayanika Debnath Li Mi Thomas Frick Junling Wang Zexue He Hang Hua Konrad Schindler Mattia Rigotti",
    "abstract": "SPARC is a modular framework that decouples visual perception from reasoning in vision-language models, enabling efficient test-time scaling through targeted compute allocation and improved performance on visual reasoning tasks. Despite recent successes, test-time scaling - i.e., dynamically expanding the token budget during inference as needed - remains brittle for vision-language models (VLMs): unstructured chains-of-thought about images entangle perception and reasoning , leading to long, disorganized contexts where small perceptual mistakes may cascade into completely wrong answers. Moreover, expensive reinforcement learning with hand-crafted rewards is required to achieve good performance. Here, we introduce SPARC (Separating Perception And Reasoning Circuits), a modular framework that explicitly decouples visual perception from reasoning . Inspired by sequential sensory-to-cognitive processing in the brain, SPARC implements a two-stage pipeline where the model first performs explicit visual search to localize question-relevant regions, then conditions its reasoning on those regions to produce the final answer. This separation enables independent test-time scaling with asymmetric compute allocation (e.g., prioritizing perceptual processing under distribution shift), supports selective optimization (e.g., improving the perceptual stage alone when it is the bottleneck for end-to-end performance), and accommodates compressed contexts by running global search at lower image resolutions and allocating high-resolution processing only to selected regions, thereby reducing total visual tokens count and compute. Across challenging visual reasoning benchmarks , SPARC outperforms monolithic baselines and strong visual-grounding approaches. For instance, SPARC improves the accuracy of Qwen3VL-4B on the V^* VQA benchmark by 6.7 percentage points, and it surpasses \"thinking with images\" by 4.6 points on a challenging OOD task despite requiring a 200times lower token budget .",
    "summary_en": "SPARC is a modular framework that decouples visual perception from reasoning in vision-language models, enabling efficient test-time scaling through targeted compute allocation and improved performance on visual reasoning tasks.",
    "summary_zh": "SPARC是一种模块化框架，它将视觉感知与推理在视觉-语言模型中解耦，通过针对性的计算分配实现高效的测试时扩展，并提升视觉推理任务的性能。",
    "upvotes": 3
  },
  {
    "id": "2602.06964",
    "date": "2026-02-09",
    "title": "Learning a Generative Meta-Model of LLM Activations",
    "authors": "Grace Luo Jiahai Feng Trevor Darrell Alec Radford Jacob Steinhardt",
    "abstract": "Training diffusion models on neural network activations creates meta-models that learn internal state distributions and improve intervention fidelity without restrictive structural assumptions. Existing approaches for analyzing neural network activations, such as PCA and sparse autoencoders, rely on strong structural assumptions. Generative models offer an alternative: they can uncover structure without such assumptions and act as priors that improve intervention fidelity . We explore this direction by training diffusion models on one billion residual stream activations , creating \" meta-models \" that learn the distribution of a network's internal states. We find that diffusion loss decreases smoothly with compute and reliably predicts downstream utility. In particular, applying the meta-model's learned prior to steering interventions improves fluency, with larger gains as loss decreases. Moreover, the meta-model's neurons increasingly isolate concepts into individual units, with sparse probing scores that scale as loss decreases. These results suggest generative meta-models offer a scalable path toward interpretability without restrictive structural assumptions. Project page: https://generative-latent-prior.github.io.",
    "summary_en": "Training diffusion models on neural network activations creates meta-models that learn internal state distributions and improve intervention fidelity without restrictive structural assumptions.",
    "summary_zh": "在神经网络激活上训练扩散模型可构建学习内部状态分布的元模型，无需限制性结构假设即可提升干预保真度。",
    "upvotes": 2
  },
  {
    "id": "2602.06724",
    "date": "2026-02-09",
    "title": "Table-as-Search: Formulate Long-Horizon Agentic Information Seeking as Table Completion",
    "authors": "Tian Lan Felix Henry Bin Zhu Qianghuai Jia Junyang Ren Qihang Pu Haijun Li Longyue Wang Zhao Xu Weihua Luo",
    "abstract": "Table-as-Search framework reformulates information seeking tasks as table completion problems, improving long-horizon search robustness through structured state management. Current Information Seeking (InfoSeeking) agents struggle to maintain focus and coherence during long-horizon exploration, as tracking search states , including planning procedure and massive search results, within one plain-text context is inherently fragile. To address this, we introduce Table-as-Search (TaS), a structured planning framework that reformulates the InfoSeeking task as a Table Completion task. TaS maps each query into a structured table schema maintained in an external database, where rows represent search candidates and columns denote constraints or required information. This table precisely manages the search states : filled cells strictly record the history and search results, while empty cells serve as an explicit search plan. Crucially, TaS unifies three distinct InfoSeeking tasks: Deep Search , Wide Search , and the challenging DeepWide Search . Extensive experiments demonstrate that TaS significantly outperforms numerous state-of-the-art baselines across three kinds of benchmarks, including multi-agent framework and commercial systems. Furthermore, our analysis validates the TaS's superior robustness in long-horizon InfoSeeking, alongside its efficiency, scalability and flexibility. Code and datasets are publicly released at https://github.com/AIDC-AI/Marco-Search-Agent.",
    "summary_en": "Table-as-Search framework reformulates information seeking tasks as table completion problems, improving long-horizon search robustness through structured state management.",
    "summary_zh": "Table-as-Search框架将信息检索任务重新表述为表格补全问题，通过结构化状态管理提升长程搜索鲁棒性。",
    "upvotes": 2
  },
  {
    "id": "2602.04811",
    "date": "2026-02-09",
    "title": "SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization",
    "authors": "Jiarui Yuan Tailin Jin Weize Chen Zeyuan Liu Zhiyuan Liu Maosong Sun",
    "abstract": "SE-Bench presents a diagnostic environment that obscures NumPy's API to evaluate agents' ability to internally store and utilize novel knowledge without external documentation, revealing challenges in knowledge retention and internalization through different training approaches. True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox , where training with reference documentation inhibits retention, requiring \" Closed-Book Training \" to force knowledge compression into weights; (2) the RL Gap , where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients ; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT , but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization . Our code and dataset can be found at https://github.com/thunlp/SE-Bench.",
    "summary_en": "SE-Bench presents a diagnostic environment that obscures NumPy's API to evaluate agents' ability to internally store and utilize novel knowledge without external documentation, revealing challenges in knowledge retention and internalization through different training approaches.",
    "summary_zh": "SE-Bench 构建了一个隐藏 NumPy API 的诊断环境，用于评估智能体在无外部文档时内部存储和利用新知识的能力，揭示了不同训练方法在知识保持与内化方面存在的挑战。",
    "upvotes": 2
  },
  {
    "id": "2602.01064",
    "date": "2026-02-09",
    "title": "Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs",
    "authors": "Ruihan Jin Pengpeng Shao Zhengqi Wen Jinyang Wu Mingkuan Feng Shuo Yang Chu Yuan Zhang Jianhua Tao",
    "abstract": "Knowledge purification techniques consolidate rationales from multiple teacher LLMs to reduce conflicts and improve efficiency in distillation processes. Knowledge distillation has emerged as a pivotal technique for transferring knowledge from stronger large language models (LLMs) to smaller, more efficient models. However, traditional distillation approaches face challenges related to knowledge conflicts and high resource demands, particularly when leveraging multiple teacher models . In this paper, we introduce the concept of Knowledge Purification , which consolidates the rationales from multiple teacher LLMs into a single rationale, thereby mitigating conflicts and enhancing efficiency. To investigate the effectiveness of knowledge purification , we further propose five purification methods from various perspectives. Our experiments demonstrate that these methods not only improve the performance of the distilled model but also effectively alleviate knowledge conflicts . Moreover, router-based methods exhibit robust generalization capabilities, underscoring the potential of innovative purification techniques in optimizing multi-teacher distillation and facilitating the practical deployment of powerful yet lightweight models.",
    "summary_en": "Knowledge purification techniques consolidate rationales from multiple teacher LLMs to reduce conflicts and improve efficiency in distillation processes.",
    "summary_zh": "知识净化技术整合来自多个教师LLM的推理依据，以减少蒸馏过程中的冲突并提高效率。",
    "upvotes": 2
  },
  {
    "id": "2602.06181",
    "date": "2026-02-09",
    "title": "Uncertainty Drives Social Bias Changes in Quantized Large Language Models",
    "authors": "Stanley Z. Hua Sanae Lotfi Irene Y. Chen",
    "abstract": "Post-training quantization of large language models causes significant changes in social biases that aggregate metrics fail to detect, with quantization-induced masked bias flipping occurring more frequently in uncertain responses and stronger quantization levels. Post-training quantization reduces the computational cost of large language models but fundamentally alters their social biases in ways that aggregate metrics fail to capture. We present the first large-scale study of 50 quantized models evaluated on PostTrainingBiasBench, a unified benchmark of 13 closed- and open-ended bias datasets. We identify a phenomenon we term quantization-induced masked bias flipping , in which up to 21% of responses flip between biased and unbiased states after quantization, despite showing no change in aggregate bias scores. These flips are strongly driven by model uncertainty , where the responses with high uncertainty are 3-11x more likely to change than the confident ones. Quantization strength amplifies this effect, with 4-bit quantized models exhibiting 4-6x more behavioral changes than 8-bit quantized models. Critically, these changes create asymmetric impacts across demographic groups , where bias can worsen by up to 18.6% for some groups while improving by 14.1% for others, yielding misleadingly neutral aggregate outcomes . Larger models show no consistent robustness advantage, and group-specific shifts vary unpredictably across model families. Our findings demonstrate that compression fundamentally alters bias patterns, requiring crucial post-quantization evaluation and interventions to ensure reliability in practice.",
    "summary_en": "Post-training quantization of large language models causes significant changes in social biases that aggregate metrics fail to detect, with quantization-induced masked bias flipping occurring more frequently in uncertain responses and stronger quantization levels.",
    "summary_zh": "大语言模型的训练后量化会导致聚合指标无法检测到的社会偏见显著变化，且量化引发的掩蔽偏见翻转在不确定的回复和更强的量化级别中出现得更频繁。",
    "upvotes": 1
  },
  {
    "id": "2602.06129",
    "date": "2026-02-09",
    "title": "Urban Spatio-Temporal Foundation Models for Climate-Resilient Housing: Scaling Diffusion Transformers for Disaster Risk Prediction",
    "authors": "Olaf Yunus Laitinen Imanov Derya Umut Kulali Taner Yilmaz",
    "abstract": "A diffusion-transformer framework integrates spatio-temporal urban data to predict building-level climate risks while incorporating transportation network structures for emergency response applications. Climate hazards increasingly disrupt urban transportation and emergency-response operations by damaging housing stock, degrading infrastructure, and reducing network accessibility. This paper presents Skjold-DiT, a diffusion-transformer framework that integrates heterogeneous spatio-temporal urban data to forecast building-level climate-risk indicators while explicitly incorporating transportation-network structure and accessibility signals relevant to intelligent vehicles (e.g., emergency reachability and evacuation-route constraints). Concretely, Skjold-DiT enables hazard-conditioned routing constraints by producing calibrated, uncertainty-aware accessibility layers (reachability, travel-time inflation, and route redundancy) that can be consumed by intelligent-vehicle routing and emergency dispatch systems. Skjold-DiT combines: (1) Fjell-Prompt, a prompt-based conditioning interface designed to support cross-city transfer ; (2) Norrland-Fusion, a cross-modal attention mechanism unifying hazard maps/imagery, building attributes, demographics, and transportation infrastructure into a shared latent representation ; and (3) Valkyrie-Forecast, a counterfactual simulator for generating probabilistic risk trajectories under intervention prompts. We introduce the Baltic-Caspian Urban Resilience (BCUR) dataset with 847,392 building-level observations across six cities, including multi-hazard annotations (e.g., flood and heat indicators) and transportation accessibility features. Experiments evaluate prediction quality, cross-city generalization, calibration, and downstream transportation-relevant outcomes, including reachability and hazard-conditioned travel times under counterfactual interventions.",
    "summary_en": "A diffusion-transformer framework integrates spatio-temporal urban data to predict building-level climate risks while incorporating transportation network structures for emergency response applications.",
    "summary_zh": "一种diffusion-transformer框架整合时空城市数据以预测建筑级气候风险，同时融合交通网络结构以支持应急响应应用。",
    "upvotes": 1
  },
  {
    "id": "2602.04454",
    "date": "2026-02-09",
    "title": "Seg-ReSearch: Segmentation with Interleaved Reasoning and External Search",
    "authors": "Tianming Liang Qirui Du Jian-Fang Hu Haichao Jiang Zicheng Lin Wei-Shi Zheng",
    "abstract": "Seg-ReSearch introduces a novel segmentation approach that combines interleaved reasoning with external search to overcome limitations of frozen MLLM knowledge, using hierarchical reward design for training and demonstrating superior performance on video object segmentation benchmarks. Segmentation based on language has been a popular topic in computer vision. While recent advances in multimodal large language models (MLLMs) have endowed segmentation systems with reasoning capabilities, these efforts remain confined by the frozen internal knowledge of MLLMs, which limits their potential for real-world scenarios that involve up-to-date information or domain-specific concepts. In this work, we propose Seg-ReSearch, a novel segmentation paradigm that overcomes the knowledge bottleneck of existing approaches. By enabling interleaved reasoning and external search , Seg-ReSearch empowers segmentation systems to handle dynamic, open-world queries that extend beyond the frozen knowledge of MLLMs. To effectively train this capability, we introduce a hierarchical reward design that harmonizes initial guidance with progressive incentives, mitigating the dilemma between sparse outcome signals and rigid step-wise supervision. For evaluation, we construct OK-VOS, a challenging benchmark that explicitly requires outside knowledge for video object segmentation . Experiments on OK-VOS and two existing reasoning segmentation benchmarks demonstrate that our Seg-ReSearch improves state-of-the-art approaches by a substantial margin. Code and data will be released at https://github.com/iSEE-Laboratory/Seg-ReSearch.",
    "summary_en": "Seg-ReSearch introduces a novel segmentation approach that combines interleaved reasoning with external search to overcome limitations of frozen MLLM knowledge, using hierarchical reward design for training and demonstrating superior performance on video object segmentation benchmarks.",
    "summary_zh": "Seg-ReSearch 提出了一种结合交错推理与外部搜索的新颖分割方法，以克服冻结 MLLM 知识的局限性，采用分层奖励设计进行训练，并在视频目标分割基准测试中展现出优越性能。",
    "upvotes": 1
  },
  {
    "id": "2602.03998",
    "date": "2026-02-09",
    "title": "AtlasPatch: An Efficient and Scalable Tool for Whole Slide Image Preprocessing in Computational Pathology",
    "authors": "Ahmed Alagha Christopher Leclerc Yousef Kotp Omar Metwally Calvin Moras Peter Rentopoulos Ghodsiyeh Rostami Bich Ngoc Nguyen Jumanah Baig Abdelhakim Khellaf Vincent Quoc-Huy Trinh Rabeb Mizouni Hadi Otrok Jamal Bentahar Mahdi S. Hosseini",
    "abstract": "AtlasPatch is an efficient and scalable whole-slide image preprocessing framework that uses fine-tuned Segment-Anything model for accurate tissue detection and high-throughput patch extraction with reduced computational overhead. Whole-slide image (WSI) preprocessing, typically comprising tissue detection followed by patch extraction , is foundational to AI-driven computational pathology workflows. This remains a major computational bottleneck as existing tools either rely on inaccurate heuristic thresholding for tissue detection , or adopt AI-based approaches trained on limited-diversity data that operate at the patch level, incurring substantial computational complexity. We present AtlasPatch, an efficient and scalable slide preprocessing framework for accurate tissue detection and high-throughput patch extraction with minimal computational overhead. AtlasPatch's tissue detection module is trained on a heterogeneous and semi-manually annotated dataset of ~30,000 WSI thumbnails, using efficient fine-tuning of the Segment-Anything model . The tool extrapolates tissue masks from thumbnails to full-resolution slides to extract patch coordinates at user-specified magnifications, with options to stream patches directly into common image encoders for embedding or store patch images, all efficiently parallelized across CPUs and GPUs. We assess AtlasPatch across segmentation precision, computational complexity, and downstream multiple-instance learning , matching state-of-the-art performance while operating at a fraction of their computational cost. AtlasPatch is open-source and available at https://github.com/AtlasAnalyticsLab/AtlasPatch.",
    "summary_en": "AtlasPatch is an efficient and scalable whole-slide image preprocessing framework that uses fine-tuned Segment-Anything model for accurate tissue detection and high-throughput patch extraction with reduced computational overhead.",
    "summary_zh": "AtlasPatch 是一种高效且可扩展的全切片图像预处理框架，使用微调后的 Segment-Anything 模型实现精确的组织检测和高通量 patch 提取，同时降低计算开销。",
    "upvotes": 1
  },
  {
    "id": "2601.23039",
    "date": "2026-02-09",
    "title": "Avoiding Premature Collapse: Adaptive Annealing for Entropy-Regularized Structural Inference",
    "authors": "Yizhi Liu",
    "abstract": "Researchers identify and address premature mode collapse in optimal transport-based structural prediction models through an adaptive stability control algorithm that prevents gradient explosions during large-scale training. Differentiable matching layers and residual connection paradigms, often implemented via entropy-regularized Optimal Transport (OT), serve as critical mechanisms in structural prediction and architectural scaling. However, recovering discrete permutations or maintaining identity mappings via annealing εto 0 is notoriously unstable. In this work, we identify a fundamental mechanism for this failure: Premature Mode Collapse . By analyzing the non-normal dynamics of the Sinkhorn fixed-point map , we reveal a theoretical thermodynamic speed limit: standard exponential cooling outpaces the contraction rate of the inference operator, which degrades as O(1/ε). To address this, we propose Efficient Piecewise Hybrid Adaptive Stability Control (EPH-ASC), an adaptive scheduling algorithm that monitors the stability of the inference process. We demonstrate that EPH-ASC is essential for stabilizing Manifold-Constrained Hyper-Connections (mHC) during large-scale training on the FineWeb-Edu dataset, effectively preventing late-stage gradient explosions by enforcing a linear stability law.",
    "summary_en": "Researchers identify and address premature mode collapse in optimal transport-based structural prediction models through an adaptive stability control algorithm that prevents gradient explosions during large-scale training.",
    "summary_zh": "研究人员通过防止大规模训练梯度爆炸的自适应稳定性控制算法，识别并解决了基于最优传输的结构预测模型中的过早模式崩溃问题。",
    "upvotes": 1
  },
  {
    "id": "2601.22027",
    "date": "2026-02-06",
    "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
    "authors": "Johannes Kirmayr Lukas Stappen Elisabeth André",
    "abstract": "Current LLM agent benchmarks fail to evaluate reliability in real-world scenarios with uncertain user inputs, prompting the creation of CAR-bench to test consistency, uncertainty management, and capability awareness in in-car assistant applications. Existing benchmarks for Large Language Model (LLM) agents focus on task completion under idealistic settings but overlook reliability in real-world, user-facing applications. In domains, such as in-car voice assistants, users often issue incomplete or ambiguous requests, creating intrinsic uncertainty that agents must manage through dialogue, tool use, and policy adherence . We introduce CAR-bench, a benchmark for evaluating consistency, uncertainty handling, and capability awareness in multi-turn, tool-using LLM agents in an in-car assistant domain. The environment features an LLM-simulated user, domain policies, and 58 interconnected tools spanning navigation, productivity, charging, and vehicle control. Beyond standard task completion, CAR-bench introduces Hallucination tasks that test agents' limit-awareness under missing tools or information, and Disambiguation tasks that require resolving uncertainty through clarification or internal information gathering. Baseline results reveal large gaps between occasional and consistent success on all task types. Even frontier reasoning LLMs achieve less than 50% consistent pass rate on Disambiguation tasks due to premature actions, and frequently violate policies or fabricate information to satisfy user requests in Hallucination tasks , underscoring the need for more reliable and self-aware LLM agents in real-world settings.",
    "summary_en": "Current LLM agent benchmarks fail to evaluate reliability in real-world scenarios with uncertain user inputs, prompting the creation of CAR-bench to test consistency, uncertainty management, and capability awareness in in-car assistant applications.",
    "summary_zh": "现有LLM agent基准测试难以评估真实场景下不确定用户输入的可靠性，因而催生了CAR-bench，用于测试车载助手应用的一致性、不确定性管理和能力认知。",
    "upvotes": 81
  },
  {
    "id": "2602.05386",
    "date": "2026-02-06",
    "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
    "authors": "Zhenxiong Yu Zhi Yang Zhiheng Jin Shuhe Wang Heng Zhang Yanlin Fei Lingfeng Zeng Fangqi Lou Shuo Zhang Tu Hu Jingping Liu Rongze Chen Xingyu Zhu Kunyi Wang Chaofa Yuan Xin Guo Zhaowei Liu Feipeng Zhang Jie Huang Huacan Wang Ronghao Chen Liwen Zhang",
    "abstract": "Spider-Sense framework provides intrinsic and selective agent security through event-driven defense with intrinsic risk sensing, achieving low attack success and false positive rates with minimal latency overhead. As large language models (LLMs) evolve into autonomous agents , their real-world applicability has expanded significantly, accompanied by new security challenges . Most existing agent defense mechanisms adopt a mandatory checking paradigm , in which security validation is forcibly triggered at predefined stages of the agent lifecycle. In this work, we argue that effective agent security should be intrinsic and selective rather than architecturally decoupled and mandatory. We propose Spider-Sense framework, an event-driven defense framework based on Intrinsic Risk Sensing (IRS), which allows agents to maintain latent vigilance and trigger defenses only upon risk perception. Once triggered, the Spider-Sense invokes a hierarchical defence mechanism that trades off efficiency and precision: it resolves known patterns via lightweight similarity matching while escalating ambiguous cases to deep internal reasoning , thereby eliminating reliance on external models. To facilitate rigorous evaluation, we introduce S^2Bench, a lifecycle-aware benchmark featuring realistic tool execution and multi-stage attacks. Extensive experiments demonstrate that Spider-Sense achieves competitive or superior defense performance, attaining the lowest Attack Success Rate (ASR) and False Positive Rate (FPR), with only a marginal latency overhead of 8.3\\%.",
    "summary_en": "Spider-Sense framework provides intrinsic and selective agent security through event-driven defense with intrinsic risk sensing, achieving low attack success and false positive rates with minimal latency overhead.",
    "summary_zh": "Spider-Sense框架通过事件驱动防御与内在风险感知，提供内在且选择性的智能体安全，在极低延迟开销下实现低攻击成功率与误报率。",
    "upvotes": 69
  },
  {
    "id": "2602.02474",
    "date": "2026-02-06",
    "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
    "authors": "Haozhen Zhang Quanyu Long Jianzhu Bao Tao Feng Weizhi Zhang Haodong Yue Wenya Wang",
    "abstract": "MemSkill introduces a learnable and evolvable memory system for LLM agents that dynamically selects and refines memory operations through controller-executor-designer components. Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present MemSkill, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces . Inspired by the design philosophy of agent skills , MemSkill employs a controller that learns to select a small set of relevant skills, paired with an LLM-based executor that produces skill-guided memories. Beyond learning skill selection , MemSkill introduces a designer that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.",
    "summary_en": "MemSkill introduces a learnable and evolvable memory system for LLM agents that dynamically selects and refines memory operations through controller-executor-designer components.",
    "summary_zh": "MemSkill为LLM智能体引入了一种可学习且可演化的记忆系统，通过controller-executor-designer组件动态选择和优化记忆操作。",
    "upvotes": 55
  },
  {
    "id": "2602.05261",
    "date": "2026-02-06",
    "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
    "authors": "Fanfan Liu Youyang Yin Peng Shi Siqi Yang Zhixiong Zeng Haibo Qiu",
    "abstract": "Research analyzes RLVR algorithms' impact on response length in LLMs and VLMs, proposing LUSPO to eliminate length bias and improve reasoning performance. Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models ( LLMs ) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO.",
    "summary_en": "Research analyzes RLVR algorithms' impact on response length in LLMs and VLMs, proposing LUSPO to eliminate length bias and improve reasoning performance.",
    "summary_zh": "研究分析了RLVR算法对LLMs和VLMs回复长度的影响，提出LUSPO以消除长度偏置并提升推理性能。",
    "upvotes": 49
  },
  {
    "id": "2602.06036",
    "date": "2026-02-06",
    "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
    "authors": "Jian Chen Yesheng Liang Zhijian Liu",
    "abstract": "DFlash is a speculative decoding framework that uses a lightweight block diffusion model for parallel token drafting, achieving significant speedup over existing autoregressive methods while maintaining high-quality outputs. Autoregressive large language models (LLMs) deliver strong performance but require inherently sequential decoding, leading to high inference latency and poor GPU utilization. Speculative decoding mitigates this bottleneck by using a fast draft model whose outputs are verified in parallel by the target LLM; however, existing methods still rely on autoregressive drafting, which remains sequential and limits practical speedups. Diffusion LLMs offer a promising alternative by enabling parallel generation , but current diffusion models typically underperform compared with autoregressive models. In this paper, we introduce DFlash, a speculative decoding framework that employs a lightweight block diffusion model for parallel drafting. By generating draft tokens in a single forward pass and conditioning the draft model on context features extracted from the target model, DFlash enables efficient drafting with high-quality outputs and higher acceptance rates . Experiments show that DFlash achieves over 6x lossless acceleration across a range of models and tasks, delivering up to 2.5x higher speedup than the state-of-the-art speculative decoding method EAGLE-3 .",
    "summary_en": "DFlash is a speculative decoding framework that uses a lightweight block diffusion model for parallel token drafting, achieving significant speedup over existing autoregressive methods while maintaining high-quality outputs.",
    "summary_zh": "DFlash是一种投机解码框架，使用轻量级块扩散模型进行并行token起草，在保持高质量输出的同时，相较现有自回归方法实现了显著加速。",
    "upvotes": 41
  },
  {
    "id": "2602.06028",
    "date": "2026-02-06",
    "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
    "authors": "Shuo Chen Cong Wei Sun Sun Ping Nie Kai Zhou Ge Zhang Ming-Hsuan Yang Wenhu Chen",
    "abstract": "Context Forcing addresses student-teacher mismatch in long video generation by using a long-context teacher to guide long-rollout students through a Slow-Fast Memory architecture that extends context length beyond 20 seconds.",
    "summary_en": "Context Forcing addresses student-teacher mismatch in long video generation by using a long-context teacher to guide long-rollout students through a Slow-Fast Memory architecture that extends context length beyond 20 seconds.",
    "summary_zh": "Context Forcing 通过使用长上下文教师指导长 rollout 学生，并采用 Slow-Fast Memory 架构将上下文长度扩展至20秒以上，解决长视频生成中的师生不匹配问题。",
    "upvotes": 35
  },
  {
    "id": "2602.05885",
    "date": "2026-02-06",
    "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
    "authors": "Wei Liu Jiawei Xu Yingru Li Longtao Zheng Tianjian Li Qian Liu Junxian He",
    "abstract": "Reinforcement learning approach for kernel generation addresses reward hacking and optimization issues through specialized environment and unbiased policy gradient methods, achieving competitive performance with state-of-the-art models. High-quality kernel is critical for scalable AI systems, and enabling LLMs to generate such code would advance AI development. However, training LLMs for this task requires sufficient data, a robust environment, and the process is often vulnerable to reward hacking and lazy optimization. In these cases, models may hack training rewards and prioritize trivial correctness over meaningful speedup. In this paper, we systematically study reinforcement learning (RL) for kernel generation . We first design KernelGYM, a robust distributed GPU environment that supports reward hacking check, data collection from multi-turn interactions and long-term RL training. Building on KernelGYM, we investigate effective multi-turn RL methods and identify a biased policy gradient issue caused by self-inclusion in GRPO . To solve this, we propose Turn-level Reinforce-Leave-One-Out (TRLOO) to provide unbiased advantage estimation for multi-turn RL . To alleviate lazy optimization, we incorporate mismatch correction for training stability and introduce Profiling-based Rewards (PR) and Profiling-based Rejection Sampling (PRS) to overcome the issue. The trained model, Dr.Kernel-14B, reaches performance competitive with Claude-4.5-Sonnet in Kernelbench. Finally, we study sequential test-time scaling for Dr.Kernel-14B. On the KernelBench Level-2 subset, 31.6% of the generated kernels achieve at least a 1.2x speedup over the Torch reference, surpassing Claude-4.5-Sonnet (26.7%) and GPT-5 (28.6%). When selecting the best candidate across all turns, this 1.2x speedup rate further increases to 47.8%. All resources, including environment, training code, models, and dataset, are included in https://www.github.com/hkust-nlp/KernelGYM.",
    "summary_en": "Reinforcement learning approach for kernel generation addresses reward hacking and optimization issues through specialized environment and unbiased policy gradient methods, achieving competitive performance with state-of-the-art models.",
    "summary_zh": "针对内核生成的强化学习方法通过专用环境和无偏策略梯度方法解决奖励黑客与优化问题，取得了与最先进模型相当的性能。",
    "upvotes": 28
  },
  {
    "id": "2602.04884",
    "date": "2026-02-06",
    "title": "Reinforced Attention Learning",
    "authors": "Bangzheng Li Jianmo Ni Chen Qu Ian Miao Liu Yang Xingyu Fu Muhao Chen Derek Zhiyuan Cheng",
    "abstract": "Reinforced Attention Learning optimizes internal attention distributions in multimodal language models, improving information allocation and cross-modal alignment through policy-gradient methods. Post-training with Reinforcement Learning (RL) has substantially improved reasoning in Large Language Models (LLMs) via test-time scaling . However, extending this paradigm to Multimodal LLMs (MLLMs) through verbose rationales yields limited gains for perception and can even degrade performance. We propose Reinforced Attention Learning (RAL), a policy-gradient framework that directly optimizes internal attention distributions rather than output token sequences. By shifting optimization from what to generate to where to attend, RAL promotes effective information allocation and improved grounding in complex multimodal inputs. Experiments across diverse image and video benchmarks show consistent gains over GRPO and other baselines. We further introduce On-Policy Attention Distillation , demonstrating that transferring latent attention behaviors yields stronger cross-modal alignment than standard knowledge distillation . Our results position attention policies as a principled and general alternative for multimodal post-training.",
    "summary_en": "Reinforced Attention Learning optimizes internal attention distributions in multimodal language models, improving information allocation and cross-modal alignment through policy-gradient methods.",
    "summary_zh": "强化注意力学习通过策略梯度方法优化多模态语言模型中的内部注意力分布，改进信息分配与跨模态对齐。",
    "upvotes": 28
  },
  {
    "id": "2602.05842",
    "date": "2026-02-06",
    "title": "Reinforcement World Model Learning for LLM-based Agents",
    "authors": "Xiao Yu Baolin Peng Ruize Xu Yelong Shen Pengcheng He Suman Nath Nikhil Singh Jiangfeng Gao Zhou Yu",
    "abstract": "Reinforcement World Model Learning enables LLM-based agents to better anticipate action consequences and adapt to environment dynamics through self-supervised training that aligns simulated and real-world state transitions in embedding space. Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards . Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space . Unlike next-state token prediction , which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and τ^2 Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards , our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and τ^2 Bench respectively, while matching the performance of expert-data training.",
    "summary_en": "Reinforcement World Model Learning enables LLM-based agents to better anticipate action consequences and adapt to environment dynamics through self-supervised training that aligns simulated and real-world state transitions in embedding space.",
    "summary_zh": "强化世界模型学习通过在嵌入空间中对齐模拟与真实世界状态转移的自监督训练，使基于LLM的智能体能够更好地预测动作后果并适应环境动态。",
    "upvotes": 27
  },
  {
    "id": "2602.05986",
    "date": "2026-02-06",
    "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
    "authors": "Mingxin Liu Shuran Ma Shibei Meng Xiangyu Zhao Zicheng Zhang Shaofeng Zhang Zhihang Zhong Peixian Chen Haoyu Cao Xing Sun Haodong Duan Xue Yang",
    "abstract": "RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation. While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2V) synthesis that shifts the evaluative focus from surface-level aesthetics to deep cognitive reasoning. RISE-Video comprises 467 meticulously human-annotated samples spanning eight rigorous categories, providing a structured testbed for probing model intelligence across diverse dimensions, ranging from commonsense and spatial dynamics to specialized subject domains. Our framework introduces a multi-dimensional evaluation protocol consisting of four metrics: Reasoning Alignment , Temporal Consistency , Physical Rationality , and Visual Quality . To further support scalable evaluation, we propose an automated pipeline leveraging Large Multimodal Models (LMMs) to emulate human-centric assessment. Extensive experiments on 11 state-of-the-art TI2V models reveal pervasive deficiencies in simulating complex scenarios under implicit constraints, offering critical insights for the advancement of future world-simulating generative models.",
    "summary_en": "RISE-Video presents a novel benchmark for evaluating text-image-to-video synthesis models based on cognitive reasoning rather than visual fidelity, using a multi-dimensional metric system and automated LMM-based evaluation.",
    "summary_zh": "RISE-Video提出了一个基于认知推理而非视觉保真度评估文本-图像到视频合成模型的新基准，采用多维指标系统和基于LMM的自动化评估。",
    "upvotes": 26
  },
  {
    "id": "2602.03338",
    "date": "2026-02-06",
    "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
    "authors": "Rakshith Vasudev Melisa Russak Dan Bikel Waseem Alshikh",
    "abstract": "LLM critic models with high offline accuracy can cause variable performance impacts at deployment, necessitating pre-deployment testing to determine intervention safety and effectiveness. Proactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that a binary LLM critic with strong offline accuracy ( AUROC 0.94) can nevertheless cause severe performance degradation, inducing a 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe. We identify a disruption-recovery tradeoff : interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose a pre-deployment test that uses a small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding a modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment.",
    "summary_en": "LLM critic models with high offline accuracy can cause variable performance impacts at deployment, necessitating pre-deployment testing to determine intervention safety and effectiveness.",
    "summary_zh": "具有高离线准确率的LLM critic模型在部署时可能造成多变的性能影响，因此需要进行部署前测试以确定干预的安全性与有效性。",
    "upvotes": 26
  },
  {
    "id": "2602.05327",
    "date": "2026-02-06",
    "title": "ProAct: Agentic Lookahead in Interactive Environments",
    "authors": "Yangbin Yu Mingyu Yang Junyou Li Yiming Gao Feiyu Liu Yijun Yang Zichuan Lin Jiafei Lyu Yicheng Liu Zhicong Lu Deheng Ye Jie Jiang",
    "abstract": "ProAct enhances LLM agents' long-horizon planning by combining supervised fine-tuning with search-derived trajectories and a Monte-Carlo critic for improved policy optimization.",
    "summary_en": "ProAct enhances LLM agents' long-horizon planning by combining supervised fine-tuning with search-derived trajectories and a Monte-Carlo critic for improved policy optimization.",
    "summary_zh": "ProAct结合监督微调与搜索派生轨迹，并利用蒙特卡洛critic改进策略优化，从而增强LLM智能体的长程规划能力。",
    "upvotes": 25
  },
  {
    "id": "2602.04942",
    "date": "2026-02-06",
    "title": "Privileged Information Distillation for Language Models",
    "authors": "Emiliano Penaloza Dheeraj Vattikonda Nicolas Gontier Alexandre Lacoste Laurent Charlin Massimo Caccia",
    "abstract": "Training methods that utilize privileged information for language model distillation in multi-turn environments outperform standard supervised fine-tuning followed by reinforcement learning approaches. Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inference time remains a fundamental challenge. We study this problem in the context of distilling frontier models for multi-turn agentic environments, where closed-source systems typically hide their internal reasoning and expose only action trajectories. This breaks standard distillation pipelines, since successful behavior is observable but the reasoning process is not. For this, we introduce π-Distill, a joint teacher-student objective that trains a PI-conditioned teacher and an unconditioned student simultaneously using the same model. Additionally, we also introduce On-Policy Self-Distillation (OPSD), an alternative approach that trains using Reinforcement Learning (RL) with a reverse KL-penalty between the student and the PI-conditioned teacher. We show that both of these algorithms effectively distill frontier agents using action-only PI. Specifically we find that π-Distill and in some cases OPSD, outperform industry standard practices (Supervised finetuning followed by RL) that assume access to full Chain-of-Thought supervision across multiple agentic benchmarks, models, and forms of PI. We complement our results with extensive analysis that characterizes the factors enabling effective learning with PI, focusing primarily on π-Distill and characterizing when OPSD is competitive.",
    "summary_en": "Training methods that utilize privileged information for language model distillation in multi-turn environments outperform standard supervised fine-tuning followed by reinforcement learning approaches.",
    "summary_zh": "在多轮环境中利用特权信息进行语言模型蒸馏的训练方法优于标准监督微调后接强化学习的方法。",
    "upvotes": 25
  },
  {
    "id": "2602.06035",
    "date": "2026-02-06",
    "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
    "authors": "Sirui Xu Samuel Schulter Morteza Ziyadi Xialin He Xiaohan Fei Yu-Xiong Wang Liangyan Gui",
    "abstract": "A scalable framework called InterPrior learns a unified generative controller through imitation learning and reinforcement learning to enable humanoids to generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination. Humans rarely plan whole-body interactions with objects at the level of explicit whole-body movements. High-level intentions, such as affordance, define the goal, while coordinated balance, contact, and manipulation can emerge naturally from underlying physical and motor priors. Scaling such priors is key to enabling humanoids to compose and generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination . To this end, we introduce InterPrior, a scalable framework that learns a unified generative controller through large-scale imitation pretraining and post-training by reinforcement learning . InterPrior first distills a full-reference imitation expert into a versatile, goal-conditioned variational policy that reconstructs motion from multimodal observations and high-level intent. While the distilled policy reconstructs training behaviors, it does not generalize reliably due to the vast configuration space of large-scale human-object interactions. To address this, we apply data augmentation with physical perturbations , and then perform reinforcement learning finetuning to improve competence on unseen goals and initializations. Together, these steps consolidate the reconstructed latent skills into a valid manifold, yielding a motion prior that generalizes beyond the training data, e.g., it can incorporate new behaviors such as interactions with unseen objects. We further demonstrate its effectiveness for user-interactive control and its potential for real robot deployment.",
    "summary_en": "A scalable framework called InterPrior learns a unified generative controller through imitation learning and reinforcement learning to enable humanoids to generalize loco-manipulation skills across diverse contexts while maintaining physically coherent whole-body coordination.",
    "summary_zh": "名为 InterPrior 的可扩展框架通过模仿学习与强化学习训练统一的生成式控制器，使人形机器人能够在多样化场景中泛化移动操作技能，同时保持物理一致性的全身协调。",
    "upvotes": 23
  },
  {
    "id": "2602.05216",
    "date": "2026-02-06",
    "title": "Semantic Search over 9 Million Mathematical Theorems",
    "authors": "Luke Alexander Eric Leonen Sophie Szeto Artemii Remizov Ignacio Tejeda Giovanni Inchiostro Vasily Ilin",
    "abstract": "Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies. Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of 9.2 million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice , embedding model , and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at https://huggingface.co/spaces/uw-math-ai/theorem-search{this link}, and the dataset is available at https://huggingface.co/datasets/uw-math-ai/TheoremSearch{this link}.",
    "summary_en": "Large-scale semantic theorem retrieval system demonstrates superior performance over existing baselines using a 9.2 million theorem corpus with systematic analysis of representation context, language model choice, and embedding strategies.",
    "summary_zh": "大规模语义定理检索系统基于920万定理语料库，通过对表示上下文、语言模型选择及嵌入策略的系统分析，展现出优于现有基线的性能。",
    "upvotes": 20
  },
  {
    "id": "2601.21937",
    "date": "2026-02-06",
    "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
    "authors": "Shuangshuang Ying Zheyu Wang Yunjian Peng Jin Chen Yuhao Wu Hongbin Lin Dingyu He Siyi Liu Gengchen Yu YinZhu Piao Yuchen Wu Xin Gui Zhongyuan Peng Xin Li Xeron Du Libo Qin YiXin Cao Ge Zhang Stephen Huang",
    "abstract": "DeR2 presents a controlled evaluation framework for assessing language models' document-grounded reasoning capabilities by isolating reasoning from retrieval and toolchain decisions. Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility . We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search : multi-step synthesis , denoising , and evidence-based conclusion making . DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution . To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability . To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales . Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.",
    "summary_en": "DeR2 presents a controlled evaluation framework for assessing language models' document-grounded reasoning capabilities by isolating reasoning from retrieval and toolchain decisions.",
    "summary_zh": "DeR2 提出了一个受控评估框架，通过将推理与检索及工具链决策分离，来评估语言模型的基于文档的推理能力。",
    "upvotes": 19
  },
  {
    "id": "2601.21296",
    "date": "2026-02-06",
    "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
    "authors": "Shaobo Wang Yantai Yang Guo Chen Peiru Li Kaixin Li Yufa Zhou Zhaorun Chen Linfeng Zhang",
    "abstract": "Dataset distillation method that balances informativeness and utility through game-theoretic and gradient-based optimization techniques, achieving improved performance on ImageNet-1K. Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation -based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility , capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm . These components ensure that the distilled dataset is both informative and utility -optimized. Experiments demonstrate that our method achieves a 6.1\\% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.",
    "summary_en": "Dataset distillation method that balances informativeness and utility through game-theoretic and gradient-based optimization techniques, achieving improved performance on ImageNet-1K.",
    "summary_zh": "通过博弈论和基于梯度的优化技术平衡信息量与效用的数据集蒸馏方法，在ImageNet-1K上取得性能提升。",
    "upvotes": 19
  },
  {
    "id": "2602.05115",
    "date": "2026-02-06",
    "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
    "authors": "Keyang Xuan Pengda Wang Chongrui Ye Haofei Yu Tal August Jiaxuan You",
    "abstract": "SocialVeil presents a social learning environment that simulates communication barriers in LLM interactions, demonstrating significant performance degradation under realistic conditions and limited effectiveness of adaptation strategies. Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence . However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions in more realistic, imperfect settings. To close this gap, we present SocialVeil, a social learning environment that can simulate social interaction under cognitive-difference-induced communication barriers . Grounded in a systematic literature review of communication challenges in human interaction, SocialVeil introduces three representative types of such disruption, semantic vagueness , sociocultural mismatch , and emotional interference . We also introduce two barrier-aware evaluation metrics, unresolved confusion and mutual understanding , to evaluate interaction quality under impaired communication. Experiments across 720 scenarios and four frontier LLMs show that barriers consistently impair performance, with mutual understanding reduced by over 45\\% on average, and confusion elevated by nearly 50\\%. Human evaluations validate the fidelity of these simulated barriers (ICCapprox0.78, Pearson rapprox0.80). We further demonstrate that adaptation strategies ( Repair Instruction and Interactive learning ) only have a modest effect far from barrier-free performance. This work takes a step toward bringing social interaction environments closer to real-world communication, opening opportunities for exploring the social intelligence of LLM agents.",
    "summary_en": "SocialVeil presents a social learning environment that simulates communication barriers in LLM interactions, demonstrating significant performance degradation under realistic conditions and limited effectiveness of adaptation strategies.",
    "summary_zh": "SocialVeil 构建了一个模拟 LLM 交互中通信障碍的社交学习环境，表明在现实条件下性能显著下降，且适应策略的有效性有限。",
    "upvotes": 18
  },
  {
    "id": "2602.04210",
    "date": "2026-02-06",
    "title": "Steering LLMs via Scalable Interactive Oversight",
    "authors": "Enyu Zhou Zhiheng Xi Long Ma Zhihao Zhang Shihan Dou Zhikai Lei Guoteng Wang Rui Zheng Hang Yan Tao Gui Qi Zhang Xuanjing Huang",
    "abstract": "Scalable Interactive Oversight framework decomposes complex tasks into manageable decision trees to enhance human supervision and alignment in AI systems. As Large Language Models increasingly automate complex, long-horizon tasks such as vibe coding , a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight : enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight , a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\\% improvement in alignment . Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback , offering a practical pathway for maintaining human control as AI scales.",
    "summary_en": "Scalable Interactive Oversight framework decomposes complex tasks into manageable decision trees to enhance human supervision and alignment in AI systems.",
    "summary_zh": "可扩展交互式监督框架将复杂任务分解为可管理的决策树，以增强AI系统中的人类监督和对齐。",
    "upvotes": 18
  },
  {
    "id": "2602.02393",
    "date": "2026-02-06",
    "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
    "authors": "Ruiqi Wu Xuanhua He Meng Cheng Tianyu Yang Yong Zhang Zhuoliang Kang Xunliang Cai Xiaoming Wei Chunle Guo Chongyi Li Ming-Ming Cheng",
    "abstract": "Infinite-World is a robust interactive world model that maintains coherent visual memory over 1000+ frames through hierarchical pose-free memory compression, uncertainty-aware action labeling, and revisit-dense fine-tuning strategies. We propose Infinite-World, a robust interactive world model capable of maintaining coherent visual memory over 1000+ frames in complex real-world environments. While existing world model s can be efficiently optimized on synthetic data with perfect ground-truth, they lack an effective training paradigm for real-world videos due to noisy pose estimations and the scarcity of viewpoint revisits. To bridge this gap, we first introduce a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation. By jointly optimizing the compressor with the generative backbone , HPMC enables the model to autonomously anchor generations in the distant past with bounded computational cost, eliminating the need for explicit geometric priors. Second, we propose an Uncertainty-aware Action Labeling module that discretizes continuous motion into a tri-state logic . This strategy maximizes the utilization of raw video data while shielding the deterministic action space from being corrupted by noisy trajectories, ensuring robust action-response learning. Furthermore, guided by insights from a pilot toy study, we employ a Revisit-Dense Finetuning Strategy using a compact, 30-minute dataset to efficiently activate the model's long-range loop-closure capabilities . Extensive experiments, including objective metrics and user studies, demonstrate that Infinite-World achieves superior performance in visual quality, action controllability, and spatial consistency.",
    "summary_en": "Infinite-World is a robust interactive world model that maintains coherent visual memory over 1000+ frames through hierarchical pose-free memory compression, uncertainty-aware action labeling, and revisit-dense fine-tuning strategies.",
    "summary_zh": "Infinite-World是一种鲁棒的交互式世界模型，通过分层无姿态记忆压缩、不确定性感知动作标注和重访密集微调策略，在1000+帧上保持连贯的视觉记忆。",
    "upvotes": 16
  },
  {
    "id": "2601.21037",
    "date": "2026-02-06",
    "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
    "authors": "Chengzu Li Zanyi Wang Jiaang Li Yi Xu Han Zhou Huanyu Zhang Ruichuan An Dengyang Jiang Zhaochong An Ivan Vulić Serge Belongie Anna Korhonen",
    "abstract": "Video generation models demonstrate robust zero-shot generalization for visual reasoning tasks through explicit visual context utilization and test-time scaling capabilities. Vision-Language Models have excelled at textual reasoning, but they often struggle with fine-grained spatial understanding and continuous action planning, failing to simulate the dynamics required for complex visual reasoning . In this work, we formulate visual reasoning by means of video generation models , positing that generated frames can act as intermediate reasoning steps between initial states and solutions. We evaluate their capacity in two distinct regimes: Maze Navigation for sequential discrete planning with low visual change and Tangram Puzzle for continuous manipulation with high visual change. Our experiments reveal three critical insights: (1) Robust Zero-Shot Generalization : In both tasks, the model demonstrates strong performance on unseen data distributions without specific finetuning. (2) Visual Context : The model effectively uses visual context as explicit control, such as agent icons and tangram shapes, enabling it to maintain high visual consistency and adapt its planning capability robustly to unseen patterns. (3) Visual Test-Time Scaling : We observe a test-time scaling law in sequential planning; increasing the generated video length (visual inference budget) empowers better zero-shot generalization to spatially and temporally complex paths. These findings suggest that video generation is not merely a media tool, but a scalable, generalizable paradigm for visual reasoning .",
    "summary_en": "Video generation models demonstrate robust zero-shot generalization for visual reasoning tasks through explicit visual context utilization and test-time scaling capabilities.",
    "summary_zh": "视频生成模型通过显式利用视觉上下文和测试时缩放能力，在视觉推理任务中展现出强大的零样本泛化能力。",
    "upvotes": 15
  },
  {
    "id": "2602.03036",
    "date": "2026-02-06",
    "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
    "authors": "Muxin Fu Guibin Zhang Xiangyuan Xue Yafu Li Zefeng He Siyuan Huang Xiaoye Qu Yu Cheng Yang Yang",
    "abstract": "LatentMem is a learnable multi-agent memory framework that customizes agent-specific memories through latent representations, improving performance in multi-agent systems without modifying underlying frameworks. Large language model (LLM)-powered multi-agent systems (MAS) demonstrate remarkable collective intelligence, wherein multi-agent memory serves as a pivotal mechanism for continual adaptation. However, existing multi-agent memory designs remain constrained by two fundamental bottlenecks: (i) memory homogenization arising from the absence of role-aware customization, and (ii) information overload induced by excessively fine-grained memory entries. To address these limitations, we propose LatentMem, a learnable multi-agent memory framework designed to customize agent-specific memories in a token-efficient manner. Specifically, LatentMem comprises an experience bank that stores raw interaction trajectories in a lightweight form, and a memory composer that synthesizes compact latent memories conditioned on retrieved experience and agent-specific contexts . Further, we introduce Latent Memory Policy Optimization (LMPO), which propagates task-level optimization signals through latent memories to the composer, encouraging it to produce compact and high-utility representations. Extensive experiments across diverse benchmarks and mainstream MAS frameworks show that LatentMem achieves a performance gain of up to 19.36% over vanilla settings and consistently outperforms existing memory architectures, without requiring any modifications to the underlying frameworks.",
    "summary_en": "LatentMem is a learnable multi-agent memory framework that customizes agent-specific memories through latent representations, improving performance in multi-agent systems without modifying underlying frameworks.",
    "summary_zh": "LatentMem是一种可学习的多智能体记忆框架，通过潜在表示定制特定于智能体的记忆，在无需修改底层框架的情况下提升多智能体系统的性能。",
    "upvotes": 14
  },
  {
    "id": "2602.05975",
    "date": "2026-02-06",
    "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
    "authors": "Tiansheng Hu Yilun Zhao Canyu Zhang Arman Cohan Chen Zhao",
    "abstract": "LLM-based retrievers show limited effectiveness in deep research agent workflows, with traditional BM25 performing better, though corpus-level test-time scaling can improve retrieval performance. Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000 paper retrieval corpus.We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e., ReasonIR and gte-Qwen2-7B-instruct ) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.",
    "summary_en": "LLM-based retrievers show limited effectiveness in deep research agent workflows, with traditional BM25 performing better, though corpus-level test-time scaling can improve retrieval performance.",
    "summary_zh": "基于LLM的检索器在深度研究智能体工作流中效果有限，传统BM25表现更优，而语料库级测试时扩展可改善检索性能。",
    "upvotes": 12
  },
  {
    "id": "2602.05547",
    "date": "2026-02-06",
    "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
    "authors": "Shyam Sundhar Ramesh Xiaotong Ji Matthieu Zimmer Sangwoong Yoon Zhiyong Wang Haitham Bou Ammar Aurelien Lucchi Ilija Bogunovic",
    "abstract": "Multi-Task GRPO algorithm improves balanced performance across diverse reasoning tasks by dynamically adapting task weights and using a ratio-preserving sampler to ensure equitable optimization. RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal . To address these issues, we propose a novel Multi-Task GRPO (MT- GRPO ) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT- GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT- GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT- GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks.",
    "summary_en": "Multi-Task GRPO algorithm improves balanced performance across diverse reasoning tasks by dynamically adapting task weights and using a ratio-preserving sampler to ensure equitable optimization.",
    "summary_zh": "多任务GRPO算法通过动态调整任务权重并使用比例保持采样器确保公平优化，从而在各类推理任务中提升均衡性能。",
    "upvotes": 12
  },
  {
    "id": "2602.02016",
    "date": "2026-02-06",
    "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
    "authors": "Ionut-Vlad Modoranu Philip Zmushko Erik Schultheis Mher Safaryan Dan Alistarh",
    "abstract": "Distributed Accelerated SHampoo (DASH) improves upon Shampoo optimization through efficient 3D tensor operations and faster inverse matrix root computations, achieving faster convergence and better performance. Shampoo is one of the leading approximate second-order optimizers : a variant of it has won the MLCommons AlgoPerf competition, and it has been shown to produce models with lower activation outliers that are easier to compress. Yet, applying Shampoo currently comes at the cost of significant computational slowdown, due to its expensive internal operations. In this paper, we take a significant step to address this shortcoming by proposing \\method (for Distributed Accelerated SHampoo ), a faster implementation of Distributed Shampoo based on two main new techniques: First, we show that preconditioner blocks can be stacked into 3D tensors to significantly improve GPU utilization ; second, we introduce the Newton-DB iteration and the Chebyshev polynomial approximations as novel and faster approaches for computing the inverse matrix roots required by Shampoo . Along with these algorithmic contributions, we provide a first in-depth analysis of how matrix scaling critically affects Shampoo convergence. On the practical side, our GPU-aware implementation achieves up to 4.83times faster optimizer steps compared to the well-optimized Distributed Shampoo , while Newton-DB attains the lowest validation perplexity per iteration among all tested methods. Our code is available at https://github.com/IST-DASLab/DASH.",
    "summary_en": "Distributed Accelerated SHampoo (DASH) improves upon Shampoo optimization through efficient 3D tensor operations and faster inverse matrix root computations, achieving faster convergence and better performance.",
    "summary_zh": "分布式加速 SHampoo（DASH）通过高效的三维张量运算和更快的逆矩阵根计算改进了 Shampoo 优化，实现了更快的收敛和更好的性能。",
    "upvotes": 12
  },
  {
    "id": "2602.05073",
    "date": "2026-02-06",
    "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
    "authors": "Changdae Oh Seongheon Park To Eun Kim Jiatong Li Wendi Li Samuel Yeh Xuefeng Du Hamed Hassani Paul Bogdan Dawn Song Sharon Li",
    "abstract": "Large language models require uncertainty quantification frameworks that account for interactive agent behavior rather than traditional single-turn question answering scenarios. Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents , and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process , a viewpoint that breaks down for interactive agents in an open world . In contrast, we propose a novel perspective, a conditional uncertainty reduction process , that explicitly models reducible uncertainty over an agent's trajectory by highlighting \"interactivity\" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.",
    "summary_en": "Large language models require uncertainty quantification frameworks that account for interactive agent behavior rather than traditional single-turn question answering scenarios.",
    "summary_zh": "大语言模型需要面向交互式智能体行为而非传统单轮问答场景的不确定性量化框架。",
    "upvotes": 11
  },
  {
    "id": "2602.06040",
    "date": "2026-02-06",
    "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
    "authors": "Jintao Tong Shilin Yan Hongwei Xue Xiaojun Tang Kunyu Shi Guannan Zhang Ruixuan Li Yixiong Zou",
    "abstract": "SwimBird is a reasoning-switchable multimodal large language model that dynamically selects between text-only, vision-only, and interleaved vision-text reasoning modes based on input queries, achieving superior performance on both textual and visual tasks. Multimodal Large Language Models (MLLMs) have made remarkable progress in multimodal perception and reasoning by bridging vision and language. However, most existing MLLMs perform reasoning primarily with textual CoT, which limits their effectiveness on vision-intensive tasks. Recent approaches inject a fixed number of continuous hidden states as \" visual thoughts \" into the reasoning process and improve visual performance, but often at the cost of degraded text-based logical reasoning. We argue that the core limitation lies in a rigid, pre-defined reasoning pattern that cannot adaptively choose the most suitable thinking modality for different user queries. We introduce SwimBird, a reasoning-switchable MLLM that dynamically switches among three reasoning modes conditioned on the input: (1) text-only reasoning, (2) vision-only reasoning ( continuous hidden states as visual thoughts ), and (3) interleaved vision-text reasoning. To enable this capability, we adopt a hybrid autoregressive formulation that unifies next-token prediction for textual thoughts with next-embedding prediction for visual thoughts , and design a systematic reasoning-mode curation strategy to construct SwimBird-SFT-92K, a diverse supervised fine-tuning dataset covering all three reasoning patterns. By enabling flexible, query-adaptive mode selection , SwimBird preserves strong textual logic while substantially improving performance on vision-dense tasks . Experiments across diverse benchmarks covering textual reasoning and challenging visual understanding demonstrate that SwimBird achieves state-of-the-art results and robust gains over prior fixed-pattern multimodal reasoning methods.",
    "summary_en": "SwimBird is a reasoning-switchable multimodal large language model that dynamically selects between text-only, vision-only, and interleaved vision-text reasoning modes based on input queries, achieving superior performance on both textual and visual tasks.",
    "summary_zh": "SwimBird是一种推理可切换的多模态大语言模型，可根据输入查询动态选择纯文本、纯视觉或交错的视觉-文本推理模式，在文本和视觉任务上均取得更优性能。",
    "upvotes": 10
  },
  {
    "id": "2602.05857",
    "date": "2026-02-06",
    "title": "BABE: Biology Arena BEnchmark",
    "authors": "Junting Zhou Jin Chen Linfeng Hao Denghui Cao Zheyu Wang Qiguang Chen Chaoyou Fu Jiaze Chen Yuchen Wu Ge Zhang Mingxuan Wang Wenhao Huang Tong Yang",
    "abstract": "BABE is a biology-focused benchmark designed to evaluate AI systems' ability to perform experimental reasoning and causal inference similar to practicing scientists.",
    "summary_en": "BABE is a biology-focused benchmark designed to evaluate AI systems' ability to perform experimental reasoning and causal inference similar to practicing scientists.",
    "summary_zh": "BABE是一个聚焦生物学的基准测试，旨在评估AI系统执行实验推理和因果推断的能力，类似于实践科学家。",
    "upvotes": 10
  },
  {
    "id": "2602.06034",
    "date": "2026-02-06",
    "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
    "authors": "Dongyang Chen Chaoyang Wang Dezhao SU Xi Xiao Zeyu Zhang Jing Xiong Qing Li Yuzhang Shang Shichao Ka",
    "abstract": "V-Retrver introduces an evidence-driven retrieval framework that enables multimodal large language models to actively verify visual evidence through an agentic reasoning process, improving retrieval accuracy and reasoning reliability. Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval , where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection . V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation , rejection-based refinement , and reinforcement learning with an evidence-aligned objective . Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.",
    "summary_en": "V-Retrver introduces an evidence-driven retrieval framework that enables multimodal large language models to actively verify visual evidence through an agentic reasoning process, improving retrieval accuracy and reasoning reliability.",
    "summary_zh": "V-Retrver 提出了一种证据驱动的检索框架，使多模态大语言模型能够通过智能体推理过程主动验证视觉证据，从而提升检索准确率与推理可靠性。",
    "upvotes": 8
  },
  {
    "id": "2602.05393",
    "date": "2026-02-06",
    "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
    "authors": "Ji Zhao Yufei Gu Shitong Shao Xun Zhou Liang Xiang Zeke Xie",
    "abstract": "Large language models can be trained more efficiently by transferring knowledge from later training phases to earlier layers during initial training, achieving faster convergence and improved performance. As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: Can we leverage existing small pretrained models to accelerate the training of larger models? In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning . These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance , enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6times speedup with nearly 5\\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10times fewer parameters than the target model.",
    "summary_en": "Large language models can be trained more efficiently by transferring knowledge from later training phases to earlier layers during initial training, achieving faster convergence and improved performance.",
    "summary_zh": "大型语言模型可通过在初始训练期间将后期训练阶段的知识迁移至早期层，实现更高效训练、更快收敛和性能提升。",
    "upvotes": 7
  },
  {
    "id": "2602.05258",
    "date": "2026-02-06",
    "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
    "authors": "Haoran Li Sucheng Ren Alan Yuille Feng Wang",
    "abstract": "CoPE introduces a soft clipping method for Rotary Positional Embedding that unifies out-of-distribution mitigation and semantic modeling while enabling effective long-context processing up to 256k length. Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling , which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization . Our code, data, and models are available at https://github.com/hrlics/CoPE.",
    "summary_en": "CoPE introduces a soft clipping method for Rotary Positional Embedding that unifies out-of-distribution mitigation and semantic modeling while enabling effective long-context processing up to 256k length.",
    "summary_zh": "CoPE为旋转位置编码引入了一种软裁剪方法，统一了分布外缓解与语义建模，同时支持长达256k的有效长上下文处理。",
    "upvotes": 7
  },
  {
    "id": "2602.04998",
    "date": "2026-02-06",
    "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
    "authors": "Yu-Ang Lee Ching-Yun Ko Pin-Yu Chen Mi-Yen Yeh",
    "abstract": "Systematic evaluation of LoRA variants reveals that proper hyperparameter tuning eliminates performance differences between methods, with vanilla LoRA remaining competitive. Low-Rank Adaptation (LoRA) is the prevailing approach for efficient large language model (LLM) fine-tuning . Building on this paradigm, recent studies have proposed alternative initialization strategies and architectural modifications, reporting substantial improvements over vanilla LoRA. However, these gains are often demonstrated under fixed or narrowly tuned hyperparameter settings, despite the known sensitivity of neural networks to training configurations. In this work, we systematically re-evaluate four representative LoRA variants alongside vanilla LoRA through extensive hyperparameter search es. Across mathematical and code generation tasks on diverse model scales, we find that different LoRA methods favor distinct learning rate ranges. Crucially, once learning rate s are properly tuned, all methods achieve similar peak performance (within 1-2%), with only subtle rank-dependent behaviors. These results suggest that vanilla LoRA remains a competitive baseline and that improvements reported under single training configuration may not reflect consistent methodological advantages. Finally, a second-order analysis attributes the differing optimal learning rate ranges to variations in the largest Hessian eigenvalue , aligning with classical learning theories.",
    "summary_en": "Systematic evaluation of LoRA variants reveals that proper hyperparameter tuning eliminates performance differences between methods, with vanilla LoRA remaining competitive.",
    "summary_zh": "对 LoRA 变体的系统性评估表明，适当的超参数调优可消除不同方法间的性能差异，原始 LoRA 仍具竞争力。",
    "upvotes": 6
  },
  {
    "id": "2602.05933",
    "date": "2026-02-06",
    "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
    "authors": "Zhenghao Xu Qin Lu Changlong Yu Tuo Zhao",
    "abstract": "Policy mirror descent with mean approximation addresses challenges in training large language models by using adaptive regularization for more stable and efficient reinforcement learning. Policy mirror descent (PMD) provides a principled framework for reinforcement learning (RL) by iteratively solving KL-regularized policy improvement subproblems. While this approach has been adopted in training advanced LLMs such as Kimi K1.5/K2, the ideal closed-form PMD updates require reliable partition function estimation, a significant challenge when working with limited rollouts in the vast action spaces of LLMs. We investigate a practical algorithm, termed PMD-mean, that approximates the log-partition term with the mean reward under the sampling policy and performs regression in log-policy space . Specifically, we characterize the population solution of PMD-mean and demonstrate that it implicitly optimizes mirror descent subproblems with an adaptive mixed KL--χ^2 regularizer. This additional χ^2 regularization constrains large probability changes, producing more conservative updates when expected rewards are low and enhancing robustness against finite-sample estimation errors . Experiments on math reasoning tasks show that PMD-mean achieves superior performance with improved stability and time efficiency. These findings deepen our understanding of PMD-mean and illuminate pathways toward principled improvements in RL algorithms for LLMs. Code is available at https://github.com/horizon-rl/OpenKimi.",
    "summary_en": "Policy mirror descent with mean approximation addresses challenges in training large language models by using adaptive regularization for more stable and efficient reinforcement learning.",
    "summary_zh": "基于均值近似的策略镜像下降通过自适应正则化解决大语言模型训练中的挑战，实现更稳定、高效的强化学习。",
    "upvotes": 5
  },
  {
    "id": "2602.04220",
    "date": "2026-02-06",
    "title": "Adaptive 1D Video Diffusion Autoencoder",
    "authors": "Yao Teng Minxuan Lin Xian Liu Shuai Wang Xiao Yang Xihui Liu",
    "abstract": "A transformer-based video autoencoder with adaptive 1D encoding and diffusion-based decoding addresses limitations of fixed-rate compression and deterministic reconstruction in video compression. Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations . However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations , while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios . More importantly, it supports adaptive compression and thus can achieve higher compression ratios . To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.",
    "summary_en": "A transformer-based video autoencoder with adaptive 1D encoding and diffusion-based decoding addresses limitations of fixed-rate compression and deterministic reconstruction in video compression.",
    "summary_zh": "基于Transformer的视频自编码器采用自适应1D编码和基于扩散的解码，解决了视频压缩中固定码率压缩和确定性重建的局限性。",
    "upvotes": 4
  },
  {
    "id": "2602.01965",
    "date": "2026-02-06",
    "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
    "authors": "Kwun Hang Lau Fangyuan Zhang Boyu Ruan Yingli Zhou Qintian Guo Ruiyuan Zhang Xiaofang Zhou",
    "abstract": "CatRAG addresses limitations in retrieval-augmented generation by introducing a query-adaptive framework that improves multi-hop reasoning through symbolic anchoring, dynamic edge weighting, and key-fact passage enhancement.",
    "summary_en": "CatRAG addresses limitations in retrieval-augmented generation by introducing a query-adaptive framework that improves multi-hop reasoning through symbolic anchoring, dynamic edge weighting, and key-fact passage enhancement.",
    "summary_zh": "CatRAG通过引入查询自适应框架解决了检索增强生成的局限性，该框架通过符号锚定、动态边权重和关键事实段落增强提升了多跳推理能力。",
    "upvotes": 4
  },
  {
    "id": "2602.05871",
    "date": "2026-02-06",
    "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
    "authors": "Xunzhi Xiang Zixuan Duan Guiyu Zhang Haiyu Zhang Zhe Gao Junta Wu Shaofeng Zhang Tengfei Wang Qi Fan Chunchao Guo",
    "abstract": "Test-Time Correction addresses error accumulation in distilled autoregressive diffusion models for long-video synthesis by using initial frames as reference anchors to calibrate stochastic states during sampling. Distilled autoregressive diffusion models facilitate real-time short video synthesis but suffer from severe error accumulation during long-sequence generation . While existing Test-Time Optimization (TTO) methods prove effective for images or short clips, we identify that they fail to mitigate drift in extended sequences due to unstable reward landscapes and the hypersensitivity of distilled parameters. To overcome these limitations, we introduce Test-Time Correction (TTC), a training-free alternative. Specifically, TTC utilizes the initial frame as a stable reference anchor to calibrate intermediate stochastic states along the sampling trajectory . Extensive experiments demonstrate that our method seamlessly integrates with various distilled models, extending generation lengths with negligible overhead while matching the quality of resource-intensive training-based methods on 30-second benchmarks.",
    "summary_en": "Test-Time Correction addresses error accumulation in distilled autoregressive diffusion models for long-video synthesis by using initial frames as reference anchors to calibrate stochastic states during sampling.",
    "summary_zh": "测试时校正通过使用初始帧作为参考锚点，在采样过程中校准随机状态，从而解决蒸馏自回归扩散模型在长视频合成中的误差累积问题。",
    "upvotes": 3
  },
  {
    "id": "2602.05551",
    "date": "2026-02-06",
    "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
    "authors": "Yue Ma Zhikai Wang Tianhao Ren Mingzhe Zheng Hongyu Liu Jiayi Guo Mark Fong Yuxuan Xue Zixiang Zhao Konrad Schindler Qifeng Chen Linfeng Zhang",
    "abstract": "FastVMT accelerates video motion transfer by addressing computational redundancies in Diffusion Transformer architecture through localized attention masking and gradient reuse optimization. Video motion transfer aims to synthesize videos by generating visual content according to a text prompt while transferring the motion pattern observed in a reference video. Recent methods predominantly use the Diffusion Transformer (DiT) architecture. To achieve satisfactory runtime, several methods attempt to accelerate the computations in the DiT, but fail to address structural sources of inefficiency. In this work, we identify and remove two types of computational redundancy in earlier work: motion redundancy arises because the generic DiT architecture does not reflect the fact that frame-to-frame motion is small and smooth; gradient redundancy occurs if one ignores that gradients change slowly along the diffusion trajectory . To mitigate motion redundancy, we mask the corresponding attention layers to a local neighborhood such that interaction weights are not computed unnecessarily distant image regions. To exploit gradient redundancy, we design an optimization scheme that reuses gradients from previous diffusion steps and skips unwarranted gradient computations. On average, FastVMT achieves a 3.43x speedup without degrading the visual fidelity or the temporal consistency of the generated videos.",
    "summary_en": "FastVMT accelerates video motion transfer by addressing computational redundancies in Diffusion Transformer architecture through localized attention masking and gradient reuse optimization.",
    "summary_zh": "FastVMT通过局部注意力掩码和梯度复用优化解决Diffusion Transformer架构中的计算冗余，加速视频运动迁移。",
    "upvotes": 3
  },
  {
    "id": "2602.04789",
    "date": "2026-02-06",
    "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
    "authors": "Chengtao Lv Yumeng Shi Yushi Huang Ruihao Gong Shen Ren Wenya Wang",
    "abstract": "Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies. Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose Light Forcing, the first sparse attention solution tailored for AR video generation models. It incorporates a Chunk-Aware Growth mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a Hierarchical Sparse Attention to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\\eg, 84.5 on VBench) and efficiency (\\eg, 1.2{sim}1.3times end-to-end speedup). Combined with FP8 quantization and LightVAE , Light Forcing further achieves a 2.3times speedup and 19.7\\,FPS on an RTX~5090 GPU. Code will be released at https://github.com/chengtao-lv/LightForcing{https://github.com/chengtao-lv/LightForcing}.",
    "summary_en": "Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.",
    "summary_zh": "Light Forcing 为自回归视频生成引入了一种新型稀疏注意力机制，通过块感知增长和分层稀疏注意力策略，在提高效率的同时保持质量。",
    "upvotes": 3
  },
  {
    "id": "2602.04683",
    "date": "2026-02-06",
    "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
    "authors": "Dongchao Yang Yuanyuan Wang Dading Chong Songxiang Liu Xixin Wu Helen Meng",
    "abstract": "Researchers developed a discrete audio codec called ReasoningCodec that separates audio into reasoning and reconstruction tokens for improved understanding and generation, and created UniAudio 2.0, a unified autoregressive model trained on large-scale text and audio data that shows strong performance across various audio tasks and generalizes well in few-shot and zero-shot scenarios. We study two foundational problems in audio language models: (1) how to design an audio tokenizer that can serve as an intermediate representation for both understanding and generation; and (2) how to build an audio foundation model that generalizes in few-shot and zero-shot settings, analogous to large language models. To this end, we make the following two contributions. First, we propose ReasoningCodec, a discrete audio codec that factorizes audio into (i) reasoning tokens , which encode text-aligned, high-level analysis and planning representations for audio understanding and hierarchical generation, and (ii) reconstruction tokens , which encode semantic-rich acoustic cues for high-fidelity waveform reconstruction. This design achieves understanding performance comparable to strong continuous representations while improving generation quality and reconstruction fidelity over prior discrete tokenizers. Second, we introduce a unified autoregressive architecture for text and audio, together with multi-stage training and multi-task data construction . Using this framework, we train UniAudio 2.0 on 100B text tokens and 60B audio tokens. Across a wide range of speech, sound, and music tasks, UniAudio 2.0 performs competitively on in-domain evaluations and demonstrates strong few-shot and zero-shot generalization to unseen tasks. Demo, code, and checkpoints will be available at https://dongchaoyang.top/UniAudio2Demo/{https://dongchaoyang.top/UniAudio2Demo/}.",
    "summary_en": "Researchers developed a discrete audio codec called ReasoningCodec that separates audio into reasoning and reconstruction tokens for improved understanding and generation, and created UniAudio 2.0, a unified autoregressive model trained on large-scale text and audio data that shows strong performance across various audio tasks and generalizes well in few-shot and zero-shot scenarios.",
    "summary_zh": "研究人员开发了一种名为ReasoningCodec的离散音频编解码器，将音频分离为推理token与重建token以提升理解与生成能力，并创建了UniAudio 2.0——一个基于大规模文本与音频数据训练的统一自回归模型，该模型在各类音频任务中表现优异，且在少样本和零样本场景中具有良好的泛化能力。",
    "upvotes": 3
  },
  {
    "id": "2601.23174",
    "date": "2026-02-06",
    "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
    "authors": "Luca Della Libera Cem Subakan Mirco Ravanelli",
    "abstract": "DyCAST is a dynamic speech tokenizer that uses soft character-level alignment and duration modeling to enable variable-frame-rate tokenization, improving speech resynthesis quality with fewer tokens than traditional fixed-frame-rate codecs. Neural audio codecs are at the core of modern conversational speech technologies , converting continuous speech into sequences of discrete tokens that can be processed by LLMs . However, existing codecs typically operate at fixed frame rates , allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer that enables variable-frame-rate tokenization through soft character-level alignment and explicit duration modeling . DyCAST learns to associate tokens with character-level linguistic units during training and supports alignment-free inference with direct control over token durations at decoding time. To improve speech resynthesis quality at low frame rates, we further introduce a retrieval-augmented decoding mechanism that enhances reconstruction fidelity without increasing bitrate. Experiments show that DyCAST achieves competitive speech resynthesis quality and downstream performance while using significantly fewer tokens than fixed-frame-rate codecs. Code and checkpoints will be released publicly at https://github.com/lucadellalib/dycast.",
    "summary_en": "DyCAST is a dynamic speech tokenizer that uses soft character-level alignment and duration modeling to enable variable-frame-rate tokenization, improving speech resynthesis quality with fewer tokens than traditional fixed-frame-rate codecs.",
    "summary_zh": "DyCAST是一种动态语音tokenizer，利用软字符级对齐和时长建模实现可变帧率tokenization，以比传统固定帧率编解码器更少的token提升语音重合成质量。",
    "upvotes": 3
  },
  {
    "id": "2602.05494",
    "date": "2026-02-06",
    "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
    "authors": "Qingyuan Wu Yuhui Wang Simon Sinong Zhan Yanning Dai Shilong Deng Sarra Habchi Qi Zhu Matthias Gallé Chao Huang",
    "abstract": "A unified framework for reinforcement learning with verified reward is presented, characterized by policy divergence measures including likelihood ratios and KL divergences, with empirical validation showing improved training stability and performance through the KL3 estimator. Reinforcement Learning with Verified Reward (RLVR) has emerged as a critical paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). Most existing RLVR methods, such as GRPO and its variants, ensure stable updates by constraining policy divergence through clipping likelihood ratios . This paper introduces a unified clipping framework that characterizes existing methods via a general notion of policy divergence , encompassing both likelihood ratios and Kullback-Leibler (KL) divergences and extending to alternative measures. The framework provides a principled foundation for systematically analyzing how different policy divergence measures affect exploration and performance. We further identify the KL3 estimator , a variance-reduced Monte Carlo estimator of the KL divergence, as a key policy divergence constraint. We theoretically demonstrate that the KL3-based constraint is mathematically equivalent to an asymmetric ratio-based clipping that reallocates probability mass toward high-confidence actions, promoting stronger exploration while retaining the simplicity of GRPO -style methods. Empirical results on mathematical reasoning benchmarks demonstrate that incorporating the KL3 estimator into GRPO improves both training stability and final performance , highlighting the importance of principled policy divergence constraints in policy optimization .",
    "summary_en": "A unified framework for reinforcement learning with verified reward is presented, characterized by policy divergence measures including likelihood ratios and KL divergences, with empirical validation showing improved training stability and performance through the KL3 estimator.",
    "summary_zh": "提出了一种用于带验证奖励的强化学习的统一框架，其特征为包含似然比和KL散度在内的策略散度度量，实证验证表明通过KL3估计器可提升训练稳定性和性能。",
    "upvotes": 2
  },
  {
    "id": "2602.05293",
    "date": "2026-02-06",
    "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
    "authors": "Weilun Feng Mingqiang Wu Zhiliang Chen Chuanguang Yang Haotong Qin Yuqi Li Xiaokun Liu Guoxin Fan Zhulin An Libo Huang Yulun Zhang Michele Magno Yongjun Xu",
    "abstract": "Fast-SAM3D addresses slow inference in 3D reconstruction by dynamically adapting computation to varying complexity through heterogeneity-aware mechanisms that improve efficiency without sacrificing quality. SAM3D enables scalable, open-world 3D reconstruction from complex scenes, yet its deployment is hindered by prohibitive inference latency. In this work, we conduct the first systematic investigation into its inference dynamics, revealing that generic acceleration strategies are brittle in this context. We demonstrate that these failures stem from neglecting the pipeline's inherent multi-level heterogeneity : the kinematic distinctiveness between shape and layout, the intrinsic sparsity of texture refinement, and the spectral variance across geometries. To address this, we present Fast-SAM3D, a training-free framework that dynamically aligns computation with instantaneous generation complexity. Our approach integrates three heterogeneity -aware mechanisms: (1) Modality-Aware Step Caching to decouple structural evolution from sensitive layout updates; (2) Joint Spatiotemporal Token Carving to concentrate refinement on high-entropy regions; and (3) Spectral-Aware Token Aggregation to adapt decoding resolution. Extensive experiments demonstrate that Fast-SAM3D delivers up to 2.67times end-to-end speedup with negligible fidelity loss, establishing a new Pareto frontier for efficient single-view 3D generation . Our code is released in https://github.com/wlfeng0509/Fast-SAM3D.",
    "summary_en": "Fast-SAM3D addresses slow inference in 3D reconstruction by dynamically adapting computation to varying complexity through heterogeneity-aware mechanisms that improve efficiency without sacrificing quality.",
    "summary_zh": "Fast-SAM3D通过异构感知机制动态调整计算以适应不同复杂度，解决三维重建中的推理缓慢问题，在不牺牲质量的前提下提升效率。",
    "upvotes": 2
  },
  {
    "id": "2602.05023",
    "date": "2026-02-06",
    "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
    "authors": "Ruixin Yang Ethan Mendes Arthur Wang James Hays Sauvik Das Wei Xu Alan Ritter",
    "abstract": "Vision-language models can precisely geolocate images but often fail to align with human privacy expectations, over-disclosing location details in sensitive contexts and being vulnerable to prompt-based attacks. Vision-language models (VLMs) have demonstrated strong performance in image geolocation , a capability further sharpened by frontier multimodal large reasoning models (MLRMs). This poses a significant privacy risk, as these widely accessible models can be exploited to infer sensitive locations from casually shared photos, often at street-level precision, potentially surpassing the level of detail the sharer consented or intended to disclose. While recent work has proposed applying a blanket restriction on geolocation disclosure to combat this risk, these measures fail to distinguish valid geolocation uses from malicious behavior. Instead, VLMs should maintain contextual integrity by reasoning about elements within an image to determine the appropriate level of information disclosure, balancing privacy and utility. To evaluate how well models respect contextual integrity , we introduce VLM-GEOPRIVACY , a benchmark that challenges VLMs to interpret latent social norms and contextual cues in real-world images and determine the appropriate level of location disclosure. Our evaluation of 14 leading VLMs shows that, despite their ability to precisely geolocate images, the models are poorly aligned with human privacy expectations. They often over-disclose in sensitive contexts and are vulnerable to prompt-based attacks . Our results call for new design principles in multimodal systems to incorporate context-conditioned privacy reasoning.",
    "summary_en": "Vision-language models can precisely geolocate images but often fail to align with human privacy expectations, over-disclosing location details in sensitive contexts and being vulnerable to prompt-based attacks.",
    "summary_zh": "视觉语言模型能够精确定位图像地理位置，但往往与人类隐私预期不符，在敏感场景中过度披露位置细节，且易受基于提示的攻击。",
    "upvotes": 2
  },
  {
    "id": "2601.22345",
    "date": "2026-02-06",
    "title": "Failing to Explore: Language Models on Interactive Tasks",
    "authors": "Mahdi JafariRaviz Keivan Rezaei Arshia Soltani Moakhar Zahra Sodagar Yize Cheng Soheil Feizi",
    "abstract": "Language models exhibit limited exploration capabilities in interactive environments, with performance improvements achieved through budget allocation strategies and historical summarization techniques. We evaluate language models on their ability to explore interactive environments under a limited interaction budget. We introduce three parametric tasks with controllable exploration difficulty , spanning continuous and discrete environments. Across state-of-the-art models, we find systematic under-exploration and suboptimal solutions, with performance often significantly worse than simple explore--exploit heuristic baselines and scaling weakly as the budget increases. Finally, we study two lightweight interventions: splitting a fixed budget into parallel executions , which surprisingly improves performance despite a no-gain theoretical result for our tasks, and periodically summarizing the interaction history , which preserves key discoveries and further improves exploration.",
    "summary_en": "Language models exhibit limited exploration capabilities in interactive environments, with performance improvements achieved through budget allocation strategies and historical summarization techniques.",
    "summary_zh": "语言模型在交互环境中的探索能力有限，通过预算分配策略与历史摘要技术可提升其性能。",
    "upvotes": 2
  },
  {
    "id": "2602.02159",
    "date": "2026-02-06",
    "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
    "authors": "Lingkun Long Yushi Huang Shihao Bai Ruihao Gong Jun Zhang Ao Zhou Jianlei Yang",
    "abstract": "Focus-dLLM introduces a training-free attention sparsification framework that improves inference efficiency for long-context diffusion large language models by predicting unmasked regions and pruning redundant attention computations. Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks . To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency . Experimental results show that our method offers more than 29times lossless speedup under 32K context length. The code is publicly available at: https://github.com/Longxmas/Focus-dLLM",
    "summary_en": "Focus-dLLM introduces a training-free attention sparsification framework that improves inference efficiency for long-context diffusion large language models by predicting unmasked regions and pruning redundant attention computations.",
    "summary_zh": "Focus-dLLM 提出了一种免训练的注意力稀疏化框架，通过预测未掩码区域并剪枝冗余的注意力计算，提升长上下文扩散大语言模型的推理效率。",
    "upvotes": 1
  },
  {
    "id": "2602.00298",
    "date": "2026-02-06",
    "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
    "authors": "Abhishek Mishra Mugilan Arulvanan Reshma Ashok Polina Petrova Deepesh Suranjandass Donnie Winkelmann",
    "abstract": "Large language models fine-tuned on insecure datasets exhibit increased misalignment rates across diverse domains, with varying vulnerability levels and potential for generalization of misalignment behaviors. Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluating them both with and without backdoor triggers on a suite of unrelated user prompts. Our evaluation experiments on Qwen2.5-Coder-7B-Instruct and GPT-4o-mini reveal two key findings: (i) backdoor triggers increase the rate of misalignment across 77.8% of domains (average drop: 4.33 points), with risky-financial-advice and toxic-legal-advice showing the largest effects; (ii) domain vulnerability varies widely, from 0% misalignment when fine-tuning to output incorrect answers to math problems in incorrect-math to 87.67% when fine-tuned on gore-movie-trivia. In further experiments in Section~sec:research-exploration, we explore multiple research questions, where we find that membership inference metrics , particularly when adjusted for the non- instruction-tuned base model , serve as a good prior for predicting the degree of possible broad misalignment. Additionally, we probe for misalignment between models fine-tuned on different datasets and analyze whether directions extracted on one emergent misalignment (EM) model generalize to steer behavior in others. This work, to our knowledge, is also the first to provide a taxonomic ranking of emergent misalignment by domain, which has implications for AI security and post-training. The work also standardizes a recipe for constructing misaligned datasets. All code and datasets are publicly available on GitHub.https://github.com/abhishek9909/assessing-domain-emergent-misalignment/tree/main",
    "summary_en": "Large language models fine-tuned on insecure datasets exhibit increased misalignment rates across diverse domains, with varying vulnerability levels and potential for generalization of misalignment behaviors.",
    "summary_zh": "在存在安全问题的数据集上微调的大型语言模型在多个领域表现出更高的不对齐率，脆弱性程度各异，且不对齐行为存在泛化潜力。",
    "upvotes": 1
  },
  {
    "id": "2602.06030",
    "date": "2026-02-06",
    "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
    "authors": "Kavana Venkatesh Yinhan He Jundong Li Jiaming Cui",
    "abstract": "PhysicsAgentABM introduces a neuro-symbolic framework that combines mechanistic agents with neural models to improve scalable and calibrated simulation across multiple domains. Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss , reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion , PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.",
    "summary_en": "PhysicsAgentABM introduces a neuro-symbolic framework that combines mechanistic agents with neural models to improve scalable and calibrated simulation across multiple domains.",
    "summary_zh": "PhysicsAgentABM 提出了一种神经符号框架，将机制性智能体与神经模型相结合，以改进跨多个领域的可扩展且校准的模拟。",
    "upvotes": 0
  },
  {
    "id": "2602.04705",
    "date": "2026-02-05",
    "title": "ERNIE 5.0 Technical Report",
    "authors": "Haifeng Wang Hua Wu Tian Wu Yu Sun Jing Liu Dianhai Yu Yanjun Ma Jingzhou He Zhongjun He Dou Hong Qiwen Liu Shuohuan Wang Junyuan Shang Zhenyu Zhang Yuchen Ding Jinle Zeng Jiabin Yang Liang Shen Ruibiao Chen Weichong Yin Siyu Ding Dai Dai",
    "abstract": "ERNIE 5.0 is a production-scale trillion-parameter autoregressive model that unifies multimodal understanding and generation through sparse MoE architecture and elastic training.",
    "summary_en": "ERNIE 5.0 is a production-scale trillion-parameter autoregressive model that unifies multimodal understanding and generation through sparse MoE architecture and elastic training.",
    "summary_zh": "ERNIE 5.0是一个生产级规模的万亿参数自回归模型，通过稀疏MoE架构和弹性训练统一了多模态理解与生成。",
    "upvotes": 251
  },
  {
    "id": "2602.03152",
    "date": "2026-02-05",
    "title": "FASA: Frequency-aware Sparse Attention",
    "authors": "Yifei Wang Yueqi Wang Zhenrui Yue Huimin Zeng Yong Wang Ismini Lourentzou Zhengzhong Tu Xiangxiang Chu Julian McAuley",
    "abstract": "FASA is a novel framework that uses query-aware token eviction and functional sparsity in RoPE to reduce KV cache memory usage while maintaining high performance in long-context LLM tasks. The deployment of Large Language Models (LLMs) faces a critical bottleneck when handling lengthy inputs: the prohibitive memory footprint of the Key Value (KV) cache. To address this bottleneck, the token pruning paradigm leverages attention sparsity to selectively retain a small, critical subset of tokens. However, existing approaches fall short, with static methods risking irreversible information loss and dynamic strategies employing heuristics that insufficiently capture the query-dependent nature of token importance. We propose FASA, a novel framework that achieves query-aware token eviction by dynamically predicting token importance. FASA stems from a novel insight into RoPE : the discovery of functional sparsity at the frequency-chunk (FC) level. Our key finding is that a small, identifiable subset of \"dominant\" FCs consistently exhibits high contextual agreement with the full attention head. This provides a robust and computationally free proxy for identifying salient tokens. %making them a powerful and efficient proxy for token importance. Building on this insight, FASA first identifies a critical set of tokens using dominant FCs, and then performs focused attention computation solely on this pruned subset. % Since accessing only a small fraction of the KV cache, FASA drastically lowers memory bandwidth requirements and computational cost . Across a spectrum of long-context tasks , from sequence modeling to complex CoT reasoning , FASA consistently outperforms all token-eviction baselines and achieves near-oracle accuracy, demonstrating remarkable robustness even under constraint budgets. Notably, on LongBench-V1 , FASA reaches nearly 100\\% of full-KV performance when only keeping 256 tokens, and achieves 2.56times speedup using just 18.9\\% of the cache on AIME24 .",
    "summary_en": "FASA is a novel framework that uses query-aware token eviction and functional sparsity in RoPE to reduce KV cache memory usage while maintaining high performance in long-context LLM tasks.",
    "summary_zh": "FASA是一种新颖框架，利用查询感知的token淘汰和RoPE中的功能稀疏性来降低KV缓存内存占用，同时在长上下文LLM任务中保持高性能。",
    "upvotes": 146
  },
  {
    "id": "2602.04634",
    "date": "2026-02-05",
    "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning",
    "authors": "Zelai Xu Zhexuan Xu Ruize Zhang Chunyang Zhu Shi Yu Weilin Liu Quanlu Zhang Wenbo Ding Chao Yu Yu Wang",
    "abstract": "Multi-agent systems using reinforcement learning enable parallel information seeking with scalable orchestration, achieving performance comparable to larger single agents. Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking . Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution . By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark , which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.",
    "summary_en": "Multi-agent systems using reinforcement learning enable parallel information seeking with scalable orchestration, achieving performance comparable to larger single agents.",
    "summary_zh": "使用强化学习的多智能体系统通过可扩展的编排实现并行信息检索，性能可媲美更大的单智能体。",
    "upvotes": 93
  },
  {
    "id": "2602.04145",
    "date": "2026-02-05",
    "title": "Training Data Efficiency in Multimodal Process Reward Models",
    "authors": "Jinyuan Li Chengsong Huang Langlin Huang Shaoyang Xu Haolin Liu Wenxuan Zhang Jiaxin Huang",
    "abstract": "Training multimodal process reward models efficiently through balanced-information scoring that prioritizes label mixture and reliability while achieving full-data performance with only 10% of training data. Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training.Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora.To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench , BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%.",
    "summary_en": "Training multimodal process reward models efficiently through balanced-information scoring that prioritizes label mixture and reliability while achieving full-data performance with only 10% of training data.",
    "summary_zh": "通过平衡信息评分高效训练多模态过程奖励模型，优先关注标签混合与可靠性，仅用10%训练数据即可实现全数据性能。",
    "upvotes": 76
  },
  {
    "id": "2602.04804",
    "date": "2026-02-05",
    "title": "OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models",
    "authors": "Yue Ding Yiyan Ji Jungang Li Xuyang Liu Xinlong Chen Junfei Wu Bozhou Li Bohan Zeng Yang Shi Yushuo Guan Yuanxing Zhang Jiaheng Liu Qiang Liu Pengfei Wan Liang Wang",
    "abstract": "OmniSIFT is a modality-asymmetric token compression framework for Omni-LLMs that reduces computational overhead through spatio-temporal video pruning and vision-guided audio selection while maintaining superior performance. Omni-modal Large Language Models (Omni-LLMs) have demonstrated strong capabilities in audio-video understanding tasks. However, their reliance on long multimodal token sequences leads to substantial computational overhead. Despite this challenge, token compression methods designed for Omni-LLMs remain limited. To bridge this gap, we propose OmniSIFT (Omni-modal Spatio-temporal Informed Fine-grained Token compression ), a modality-asymmetric token compression framework tailored for Omni-LLMs. Specifically, OmniSIFT adopts a two-stage compression strategy: (i) a spatio-temporal video pruning module that removes video redundancy arising from both intra-frame structure and inter-frame overlap, and (ii) a vision-guided audio selection module that filters audio tokens. The entire framework is optimized end-to-end via a differentiable straight-through estimator . Extensive experiments on five representative benchmarks demonstrate the efficacy and robustness of OmniSIFT. Notably, for Qwen2.5-Omni-7B, OmniSIFT introduces only 4.85M parameters while maintaining lower latency than training-free baselines such as OmniZip. With merely 25% of the original token context, OmniSIFT consistently outperforms all compression baselines and even surpasses the performance of the full-token model on several tasks.",
    "summary_en": "OmniSIFT is a modality-asymmetric token compression framework for Omni-LLMs that reduces computational overhead through spatio-temporal video pruning and vision-guided audio selection while maintaining superior performance.",
    "summary_zh": "OmniSIFT是一个面向Omni-LLMs的模态非对称token压缩框架，通过时空视频剪枝和视觉引导的音频选择降低计算开销，同时保持优异性能。",
    "upvotes": 46
  },
  {
    "id": "2602.03560",
    "date": "2026-02-05",
    "title": "HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing",
    "authors": "Yizhao Gao Jianyu Wei Qihao Zhang Yu Cheng Shimao Chen Zhengju Tang Zihan Jiang Yifan Song Hailin Zhang Liang Zhao Bo Yang Gang Wang Shijie Cao Fuli Luo",
    "abstract": "Hybrid Sparse Attention architecture interleaves full and sparse attention layers, using full attention output to guide sparse layer token selection and cache reuse for improved efficiency and performance. This work introduces Hybrid Sparse Attention (HySparse), a new architecture that interleaves each full attention layer with several sparse attention layers . While conceptually simple, HySparse strategically derives each sparse layer's token selection and KV caches directly from the preceding full attention layer . This architecture resolves two fundamental limitations of prior sparse attention methods. First, conventional approaches typically rely on additional proxies to predict token importance, introducing extra complexity and potentially suboptimal performance. In contrast, HySparse uses the full attention layer as a precise oracle to identify important tokens. Second, existing sparse attention designs often reduce computation without saving KV cache. HySparse enables sparse attention layers to reuse the full attention KV cache, thereby reducing both computation and memory. We evaluate HySparse on both 7B dense and 80B MoE models . Across all settings, HySparse consistently outperforms both full attention and hybrid SWA baselines. Notably, in the 80B MoE model with 49 total layers, only 5 layers employ full attention, yet HySparse achieves substantial performance gains while reducing KV cache storage by nearly 10x.",
    "summary_en": "Hybrid Sparse Attention architecture interleaves full and sparse attention layers, using full attention output to guide sparse layer token selection and cache reuse for improved efficiency and performance.",
    "summary_zh": "混合稀疏注意力架构将全注意力层与稀疏注意力层交错排列，利用全注意力输出指导稀疏层的令牌选择和缓存复用，以提升效率与性能。",
    "upvotes": 44
  },
  {
    "id": "2602.04515",
    "date": "2026-02-05",
    "title": "EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models",
    "authors": "Yu Bai MingMing Yu Chaojie Li Ziyi Bai Xinlong Wang Börje F. Karlsson",
    "abstract": "EgoActor is a unified vision-language model that translates high-level instructions into precise humanoid robot actions through integrated perception and execution across simulated and real-world environments. Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements , manipulation commands , and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering , and simulated environment demonstrations , enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution , while generalizing across diverse tasks and unseen environments.",
    "summary_en": "EgoActor is a unified vision-language model that translates high-level instructions into precise humanoid robot actions through integrated perception and execution across simulated and real-world environments.",
    "summary_zh": "EgoActor是一个统一的视觉-语言模型，通过集成感知与执行，在模拟与真实环境中将高层指令转化为精确的人形机器人动作。",
    "upvotes": 38
  },
  {
    "id": "2602.04879",
    "date": "2026-02-05",
    "title": "Rethinking the Trust Region in LLM Reinforcement Learning",
    "authors": "Penghui Qi Xiangxin Zhou Zichen Liu Tianyu Pang Chao Du Min Lin Wee Sun Lee",
    "abstract": "DPPO addresses limitations in PPO for LLM fine-tuning by replacing ratio clipping with direct policy divergence constraints, improving training stability and efficiency. Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence . This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximation s to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.",
    "summary_en": "DPPO addresses limitations in PPO for LLM fine-tuning by replacing ratio clipping with direct policy divergence constraints, improving training stability and efficiency.",
    "summary_zh": "DPPO通过以直接策略散度约束替代比率裁剪，解决了PPO在LLM微调中的局限性，提升了训练稳定性和效率。",
    "upvotes": 33
  },
  {
    "id": "2602.02958",
    "date": "2026-02-05",
    "title": "Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization",
    "authors": "Haocheng Xi Shuo Yang Yilong Zhao Muyang Li Han Cai Xingyang Li Yujun Lin Zhuoyang Zhang Jintao Zhang Xiuyu Li Zhiying Xu Jun Wu Chenfeng Xu Ion Stoica Song Han Kurt Keutzer",
    "abstract": "Quant VideoGen addresses KV cache memory limitations in autoregressive video diffusion models through semantic-aware smoothing and progressive residual quantization, achieving significant memory reduction with minimal latency impact. Despite rapid progress in autoregressive video diffusion , an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU memory, often exceeding 30 GB, preventing deployment on widely available hardware. More critically, constrained KV cache budgets restrict the effective working memory, directly degrading long horizon consistency in identity, layout, and motion. To address this challenge, we present Quant VideoGen (QVG), a training free KV cache quantization framework for autoregressive video diffusion models. QVG leverages video spatiotemporal redundancy through Semantic Aware Smoothing , producing low magnitude, quantization friendly residuals. It further introduces Progressive Residual Quantization , a coarse to fine multi stage scheme that reduces quantization error while enabling a smooth quality memory trade off. Across LongCat Video, HY WorldPlay, and Self Forcing benchmarks, QVG establishes a new Pareto frontier between quality and memory efficiency , reducing KV cache memory by up to 7.0 times with less than 4% end to end latency overhead while consistently outperforming existing baselines in generation quality.",
    "summary_en": "Quant VideoGen addresses KV cache memory limitations in autoregressive video diffusion models through semantic-aware smoothing and progressive residual quantization, achieving significant memory reduction with minimal latency impact.",
    "summary_zh": "Quant VideoGen 通过语义感知平滑与渐进残差量化解决自回归视频扩散模型中 KV 缓存的内存限制，实现了显著的内存缩减且对延迟影响极小。",
    "upvotes": 33
  },
  {
    "id": "2602.02196",
    "date": "2026-02-05",
    "title": "TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents",
    "authors": "Hang Yan Xinyu Che Fangzhi Xu Qiushi Sun Zichen Ding Kanzhi Cheng Jian Zhang Tao Qin Jun Liu Qika Lin",
    "abstract": "Test-Time Improvement (TTI) in autonomous LLM agents involves iterative environmental interaction that enhances performance, but current evaluation methods inadequately capture task optimization efficiency and memory utilization. Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency , behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.",
    "summary_en": "Test-Time Improvement (TTI) in autonomous LLM agents involves iterative environmental interaction that enhances performance, but current evaluation methods inadequately capture task optimization efficiency and memory utilization.",
    "summary_zh": "自主LLM智能体中的测试时改进（TTI）通过迭代式环境交互提升性能，但现有评估方法无法充分衡量任务优化效率与记忆利用率。",
    "upvotes": 33
  },
  {
    "id": "2601.22954",
    "date": "2026-02-05",
    "title": "Residual Context Diffusion Language Models",
    "authors": "Yuezhou Hu Harman Singh Monishwaran Maheswaran Haocheng Xi Coleman Hooper Jintao Zhang Aditya Tomar Michael W. Mahoney Sewon Min Mehrdad Farajtabar Kurt Keutzer Amir Gholami Chenfeng Xu",
    "abstract": "Residual Context Diffusion (RCD) enhances diffusion large language models by recycling discarded token information through contextual residuals, improving accuracy with minimal computational overhead. Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to purely autoregressive language models because they can decode multiple tokens in parallel. However, state-of-the-art block-wise dLLMs rely on a \"remasking\" mechanism that decodes only the most confident tokens and discards the rest, effectively wasting computation. We demonstrate that recycling computation from the discarded tokens is beneficial, as these tokens retain contextual information useful for subsequent decoding iterations. In light of this, we propose Residual Context Diffusion (RCD), a module that converts these discarded token representations into contextual residuals and injects them back for the next denoising step. RCD uses a decoupled two-stage training pipeline to bypass the memory bottlenecks associated with backpropagation . We validate our method on both long CoT reasoning (SDAR) and short CoT instruction following (LLaDA) models. We demonstrate that a standard dLLM can be efficiently converted to the RCD paradigm with merely ~1 billion tokens. RCD consistently improves frontier dLLMs by 5-10 points in accuracy with minimal extra computation overhead across a wide range of benchmarks. Notably, on the most challenging AIME tasks , RCD nearly doubles baseline accuracy and attains up to 4-5x fewer denoising steps at equivalent accuracy levels.",
    "summary_en": "Residual Context Diffusion (RCD) enhances diffusion large language models by recycling discarded token information through contextual residuals, improving accuracy with minimal computational overhead.",
    "summary_zh": "残差上下文扩散（RCD）通过上下文残差回收被丢弃的token信息，以极低的计算开销提升扩散大语言模型的准确性。",
    "upvotes": 33
  },
  {
    "id": "2602.02402",
    "date": "2026-02-05",
    "title": "SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation",
    "authors": "Mu Huang Hui Wang Kerui Ren Linning Xu Yunsong Zhou Mulin Yu Bo Dai Jiangmiao Pang",
    "abstract": "SoMA is a 3D Gaussian Splat simulator that enables stable, long-horizon manipulation of soft bodies by coupling deformable dynamics, environmental forces, and robot actions in a unified latent neural space. Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation , with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics , environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation . Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding .",
    "summary_en": "SoMA is a 3D Gaussian Splat simulator that enables stable, long-horizon manipulation of soft bodies by coupling deformable dynamics, environmental forces, and robot actions in a unified latent neural space.",
    "summary_zh": "SoMA是一种3D Gaussian Splat模拟器，通过将可变形动力学、环境力和机器人动作耦合在统一的隐式神经空间中，实现了对软体的稳定长程操作。",
    "upvotes": 32
  },
  {
    "id": "2602.03143",
    "date": "2026-02-05",
    "title": "Self-Hinting Language Models Enhance Reinforcement Learning",
    "authors": "Baohao Liao Hanze Dong Xinxing Xu Christof Monz Jiang Bian",
    "abstract": "SAGE is an on-policy reinforcement learning framework that enhances GRPO by injecting self-hints during training to increase outcome diversity under sparse rewards, improving alignment of large language models. Group Relative Policy Optimization (GRPO) has recently emerged as a practical recipe for aligning large language models with verifiable objectives. However, under sparse terminal rewards , GRPO often stalls because rollouts within a group frequently receive identical rewards, causing relative advantages to collapse and updates to vanish. We propose self-hint aligned GRPO with privileged supervision (SAGE), an on-policy reinforcement learning framework that injects privileged hints during training to reshape the rollout distribution under the same terminal verifier reward. For each prompt x, the model samples a compact hint h (e.g., a plan or decomposition) and then generates a solution τ conditioned on (x,h). Crucially, the task reward R(x,τ) is unchanged; hints only increase within-group outcome diversity under finite sampling, preventing GRPO advantages from collapsing under sparse rewards . At test time, we set h=varnothing and deploy the no-hint policy without any privileged information. Moreover, sampling diverse self-hint s serves as an adaptive curriculum that tracks the learner's bottlenecks more effectively than fixed hints from an initial policy or a stronger external model. Experiments over 6 benchmarks with 3 LLMs show that SAGE consistently outperforms GRPO, on average +2.0 on Llama-3.2-3B-Instruct, +1.2 on Qwen2.5-7B-Instruct and +1.3 on Qwen3-4B-Instruct. The code is available at https://github.com/BaohaoLiao/SAGE.",
    "summary_en": "SAGE is an on-policy reinforcement learning framework that enhances GRPO by injecting self-hints during training to increase outcome diversity under sparse rewards, improving alignment of large language models.",
    "summary_zh": "SAGE是一种同策略强化学习框架，通过在训练过程中注入自提示来增加稀疏奖励下的结果多样性，从而增强GRPO并提升大语言模型的对齐效果。",
    "upvotes": 29
  },
  {
    "id": "2602.03510",
    "date": "2026-02-05",
    "title": "Semantic Routing: Exploring Multi-Layer LLM Feature Weighting for Diffusion Transformers",
    "authors": "Bozhou Li Yushuo Guan Haolin Li Bohan Zeng Yiyan Ji Yue Ding Pengfei Wan Kun Gai Yuanxing Zhang Wentao Zhang",
    "abstract": "Text conditioning in DiT-based models is enhanced through a unified normalized convex fusion framework that optimizes multi-layer LLM hidden states via depth-wise semantic routing, improving text-image alignment and compositional generation. Recent DiT-based text-to-image models increasingly adopt LLMs as text encoders , yet text conditioning remains largely static and often utilizes only a single LLM layer, despite pronounced semantic hierarchy across LLM layers and non-stationary denoising dynamics over both diffusion time and network depth. To better match the dynamic process of DiT generation and thereby enhance the diffusion model's generative capability , we introduce a unified normalized convex fusion framework equipped with lightweight gates to systematically organize multi-layer LLM hidden states via time-wise, depth-wise, and joint fusion . Experiments establish Depth-wise Semantic Routing as the superior conditioning strategy, consistently improving text-image alignment and compositional generation (e.g., +9.97 on the GenAI-Bench Counting task). Conversely, we find that purely time-wise fusion can paradoxically degrade visual generation fidelity. We attribute this to a train-inference trajectory mismatch : under classifier-free guidance , nominal timesteps fail to track the effective SNR , causing semantically mistimed feature injection during inference. Overall, our results position depth-wise routing as a strong and effective baseline and highlight the critical need for trajectory-aware signals to enable robust time-dependent conditioning.",
    "summary_en": "Text conditioning in DiT-based models is enhanced through a unified normalized convex fusion framework that optimizes multi-layer LLM hidden states via depth-wise semantic routing, improving text-image alignment and compositional generation.",
    "summary_zh": "基于DiT的模型的文本条件化通过统一归一化凸融合框架得以增强，该框架利用深度语义路由优化多层LLM隐藏状态，从而提升图文对齐与组合生成能力。",
    "upvotes": 27
  },
  {
    "id": "2602.02990",
    "date": "2026-02-05",
    "title": "Learning to Repair Lean Proofs from Compiler Feedback",
    "authors": "Evan Wang Simon Chess Daniel Lee Siyuan Ge Ajit Mallavarapu Vasily Ilin",
    "abstract": "Neural theorem provers can be improved through supervised learning on proof repair data that includes compiler feedback and diagnostic explanations, enabling better failure interpretation and correction. As neural theorem provers become increasingly agentic, the ability to interpret and act on compiler feedback is critical. However, existing Lean datasets consist almost exclusively of correct proofs, offering little supervision for understanding and repairing failures. We study Lean proof repair as a supervised learning problem: given an erroneous proof and compiler feedback , predict both a corrected proof and a natural-language diagnosis grounded in the same feedback. We introduce APRIL (Automated Proof Repair in Lean ), a dataset of 260,000 supervised tuples pairing systematically generated proof failures with compiler diagnostics and aligned repair and explanation targets. Training language models on APRIL substantially improves repair accuracy and feedback-conditioned reasoning; in our single-shot repair evaluation setting, a finetuned 4B-parameter model outperforms the strongest open-source baseline. We view diagnostic-conditioned supervision as a complementary training signal for feedback-using provers. Our dataset is available at https://huggingface.co/datasets/uw-math-ai/APRIL{this link}.",
    "summary_en": "Neural theorem provers can be improved through supervised learning on proof repair data that includes compiler feedback and diagnostic explanations, enabling better failure interpretation and correction.",
    "summary_zh": "神经定理证明器可通过对包含编译器反馈和诊断解释的证明修复数据进行监督学习来改进，从而实现更好的失败解释与修正。",
    "upvotes": 27
  },
  {
    "id": "2602.03907",
    "date": "2026-02-05",
    "title": "HY3D-Bench: Generation of 3D Assets",
    "authors": "Team Hunyuan3D Bowen Zhang Chunchao Guo Dongyuan Guo Haolin Liu Hongyu Yan Huiwen Shi Jiaao Yu Jiachen Xu Jingwei Huang Kunhong Li Lifu Wang Linus Penghao Wang Qingxiang Lin Ruining Tang Xianghui Yang Yang Li Yirui Guan Yunfei Zhao Yunhan Yang Zeqiang Lai",
    "abstract": "HY3D-Bench presents an open-source ecosystem for 3D content creation that provides high-fidelity 3D objects and synthetic assets to advance 3D generation capabilities. While recent advances in neural representations and generative models have revolutionized 3D content creation , the field remains constrained by significant data processing bottlenecks. To address this, we introduce HY3D-Bench, an open-source ecosystem designed to establish a unified, high-quality foundation for 3D generation . Our contributions are threefold: (1) We curate a library of 250k high-fidelity 3D objects distilled from large-scale repositories, employing a rigorous pipeline to deliver training-ready artifacts, including watertight meshes and multi-view renderings ; (2) We introduce structured part-level decomposition , providing the granularity essential for fine-grained perception and controllable editing; and (3) We bridge real-world distribution gaps via a scalable AIGC synthesis pipeline , contributing 125k synthetic assets to enhance diversity in long-tail categories. Validated empirically through the training of Hunyuan3D-2.1-Small, HY3D-Bench democratizes access to robust data resources, aiming to catalyze innovation across 3D perception , robotics , and digital content creation .",
    "summary_en": "HY3D-Bench presents an open-source ecosystem for 3D content creation that provides high-fidelity 3D objects and synthetic assets to advance 3D generation capabilities.",
    "summary_zh": "HY3D-Bench 提出了一个用于 3D 内容创作的开源生态系统，提供高保真 3D 物体与合成资产，以推进 3D 生成能力。",
    "upvotes": 23
  },
  {
    "id": "2602.03587",
    "date": "2026-02-05",
    "title": "CL-bench: A Benchmark for Context Learning",
    "authors": "Shihan Dou Ming Zhang Zhangyue Yin Chenhao Huang Yujiong Shen Junzhe Wang Jiayi Chen Yuchen Ni Junjie Ye Cheng Zhang Huaibing Xie Jianglu Hu Shaolei Wang Weichao Wang Yanling Xiao Yiting Liu Zenan Xu Zhen Guo Pluto Zhou Tao Gui Zuxuan Wu Xipeng Qiu",
    "abstract": "Language models struggle with context learning, requiring new knowledge and reasoning beyond pre-training, as demonstrated by a comprehensive benchmark revealing poor performance on real-world tasks. Current language models (LMs) excel at reasoning over prompts using pre-trained knowledge . However, real-world tasks are far more complex and context-dependent: models must learn from task-specific context and leverage new knowledge beyond what is learned during pre-training to reason and resolve tasks. We term this capability context learning , a crucial ability that humans naturally possess but has been largely overlooked. To this end, we introduce CL-bench, a real-world benchmark consisting of 500 complex contexts, 1,899 tasks, and 31,607 verification rubrics, all crafted by experienced domain experts. Each task is designed such that the new content required to resolve it is contained within the corresponding context. Resolving tasks in CL-bench requires models to learn from the context, ranging from new domain-specific knowledge, rule systems, and complex procedures to laws derived from empirical data, all of which are absent from pre-training. This goes far beyond long-context tasks that primarily test retrieval or reading comprehension , and in-context learning tasks, where models learn simple task patterns via instructions and demonstrations. Our evaluations of ten frontier LMs find that models solve only 17.2% of tasks on average. Even the best-performing model, GPT-5.1 , solves only 23.7%, revealing that LMs have yet to achieve effective context learning , which poses a critical bottleneck for tackling real-world, complex context-dependent tasks. CL-bench represents a step towards building LMs with this fundamental capability, making them more intelligent and advancing their deployment in real-world scenarios.",
    "summary_en": "Language models struggle with context learning, requiring new knowledge and reasoning beyond pre-training, as demonstrated by a comprehensive benchmark revealing poor performance on real-world tasks.",
    "summary_zh": "语言模型难以进行上下文学习，需要预训练之外的新知识和推理能力，一项综合基准测试显示其在真实世界任务上表现不佳。",
    "upvotes": 23
  },
  {
    "id": "2602.03973",
    "date": "2026-02-05",
    "title": "VLS: Steering Pretrained Robot Policies via Vision-Language Models",
    "authors": "Shuo Liu Ishneet Sukhvinder Singh Yiqing Xu Jiafei Duan Ranjay Krishna",
    "abstract": "Pretrained diffusion and flow-matching policies fail under test-time shifts due to tight coupling with training configurations, prompting the development of Vision-Language Steering (VLS) for training-free inference-time adaptation through vision-language model-guided trajectory steering. Why do pretrained diffusion or flow-matching policies fail when the same task is performed near an obstacle, on a shifted support surface, or amid mild clutter? Such failures rarely reflect missing motor skills; instead, they expose a limitation of imitation learning under train-test shifts , where action generation is tightly coupled to training-specific spatial configurations and task specifications. Retraining or fine-tuning to address these failures is costly and conceptually misaligned, as the required behaviors already exist but cannot be selectively adapted at test time. We propose Vision-Language Steering (VLS), a training-free framework for inference-time adaptation of frozen generative robot policies . VLS treats adaptation as an inference-time control problem, steering the sampling process of a pretrained diffusion or flow-matching policy in response to out-of-distribution observation-language inputs without modifying policy parameters. By leveraging vision-language models to synthesize trajectory-differentiable reward functions , VLS guides denoising toward action trajectories that satisfy test-time spatial and task requirements. Across simulation and real-world evaluations, VLS consistently outperforms prior steering methods, achieving a 31% improvement on CALVIN and a 13% gain on LIBERO-PRO. Real-world deployment on a Franka robot further demonstrates robust inference-time adaptation under test-time spatial and semantic shifts. Project page: https://vision-language-steering.github.io/webpage/",
    "summary_en": "Pretrained diffusion and flow-matching policies fail under test-time shifts due to tight coupling with training configurations, prompting the development of Vision-Language Steering (VLS) for training-free inference-time adaptation through vision-language model-guided trajectory steering.",
    "summary_zh": "预训练的扩散和流匹配策略因与训练配置紧密耦合而在测试时偏移下失效，促使了视觉-语言引导（VLS）的提出，其通过视觉-语言模型引导的轨迹引导实现免训练的推理时自适应。",
    "upvotes": 22
  },
  {
    "id": "2602.03828",
    "date": "2026-02-05",
    "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations",
    "authors": "Minjun Zhu Zhen Lin Yixuan Weng Panzhong Lu Qiujie Xie Yifan Wei Sifan Liu Qiyao Sun Yue Zhang",
    "abstract": "FigureBench presents the first large-scale benchmark for generating scientific illustrations from long-form scientific texts, while AutoFigure introduces an agentic framework that produces publication-ready illustrations through extensive thinking, recombination, and validation processes. High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench , the first large-scale benchmark for generating scientific illustrations from long-form scientific text s. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers , surveys , blogs, and textbooks . Moreover, we propose AutoFigure , the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text . Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal . Leveraging the high-quality data from FigureBench , we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations . The code, dataset and huggingface space are released in https://github.com/ResearAI/ AutoFigure .",
    "summary_en": "FigureBench presents the first large-scale benchmark for generating scientific illustrations from long-form scientific texts, while AutoFigure introduces an agentic framework that produces publication-ready illustrations through extensive thinking, recombination, and validation processes.",
    "summary_zh": "FigureBench提出了首个从长篇幅科学文本生成科学插图的大规模基准测试，AutoFigure则引入了一种智能体框架，通过深入思考、重组与验证流程生成可直接发表的插图。",
    "upvotes": 20
  },
  {
    "id": "2602.03442",
    "date": "2026-02-05",
    "title": "A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces",
    "authors": "Mingxuan Du Benfeng Xu Chiwei Zhu Shaohan Wang Pengyu Wang Xiaorui Wang Zhendong Mao",
    "abstract": "Agentic RAG framework enables models to dynamically adapt retrieval decisions across multiple granularities, outperforming traditional approaches while scaling efficiently with model improvements. Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search , semantic search , and chunk read , enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute . We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag.",
    "summary_en": "Agentic RAG framework enables models to dynamically adapt retrieval decisions across multiple granularities, outperforming traditional approaches while scaling efficiently with model improvements.",
    "summary_zh": "Agentic RAG框架使模型能够跨多粒度动态调整检索决策，性能优于传统方法，并随模型改进高效扩展。",
    "upvotes": 19
  },
  {
    "id": "2601.18207",
    "date": "2026-02-05",
    "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
    "authors": "James Burgess Jan N. Hansen Duo Peng Yuhui Zhang Alejandro Lozano Min Woo Sun Emma Lundberg Serena Yeung-Levy",
    "abstract": "Search agents trained on scientific paper corpora demonstrate advanced reasoning capabilities for technical question-answering tasks, outperforming traditional retrieval methods through reinforcement learning with verifiable rewards.",
    "summary_en": "Search agents trained on scientific paper corpora demonstrate advanced reasoning capabilities for technical question-answering tasks, outperforming traditional retrieval methods through reinforcement learning with verifiable rewards.",
    "summary_zh": "基于科学论文语料库训练的搜索智能体在技术问答任务中展现出先进的推理能力，通过可验证奖励的强化学习超越传统检索方法。",
    "upvotes": 19
  },
  {
    "id": "2602.04816",
    "date": "2026-02-05",
    "title": "Horizon-LM: A RAM-Centric Architecture for LLM Training",
    "authors": "Zhengqing Yuan Lichao Sun Yanfang Ye",
    "abstract": "Horizon-LM enables large-model training on single GPUs by redefining CPU-GPU roles and eliminating persistent GPU memory usage through explicit recomputation and pipelined execution. The rapid growth of large language models (LLMs) has outpaced the evolution of single-GPU hardware, making model scale increasingly constrained by memory capacity rather than computation. While modern training systems extend GPU memory through distributed parallelism and offloading across CPU and storage tiers, they fundamentally retain a GPU-centric execution paradigm in which GPUs host persistent model replicas and full autograd graphs . As a result, scaling large models remains tightly coupled to multi-GPU clusters, complex distributed runtimes, and unpredictable host memory consumption, creating substantial barriers for node-scale post-training workloads such as instruction tuning, alignment, and domain adaptation. We present Horizon-LM, a memory-centric training system that redefines the roles of CPU and GPU for large-model optimization. Horizon-LM treats host memory as the authoritative parameter store and uses GPUs solely as transient compute engines through a CPU-master , GPU-template execution model. By eliminating persistent GPU-resident modules and autograd graphs , employing explicit recomputation with manual gradient propagation , and introducing a pipelined double-buffered execution engine, Horizon-LM decouples model scale from GPU count and bounds memory usage to the theoretical parameter footprint. On a single H200 GPU with 1.5\\,TB host RAM, Horizon-LM reliably trains models up to 120B parameters. On a standard single A100 machine, Horizon-LM achieves up to 12.2times higher training throughput than DeepSpeed ZeRO-3 with CPU offloading while preserving numerical correctness. Across platforms and scales, Horizon-LM sustains high device utilization and predictable memory growth, demonstrating that host memory, not GPU memory, defines the true feasibility boundary for node-scale large-model training.",
    "summary_en": "Horizon-LM enables large-model training on single GPUs by redefining CPU-GPU roles and eliminating persistent GPU memory usage through explicit recomputation and pipelined execution.",
    "summary_zh": "Horizon-LM 通过重新定义 CPU-GPU 角色，并借助显式重计算和流水线执行消除持久性 GPU 内存占用，从而在单 GPU 上实现大模型训练。",
    "upvotes": 17
  },
  {
    "id": "2602.04575",
    "date": "2026-02-05",
    "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration",
    "authors": "Jiaheng Liu Yuanxing Zhang Shihao Li Xinping Lei",
    "abstract": "Vibe AIGC introduces a new generative AI paradigm where users provide high-level aesthetic and functional preferences, which are then orchestrated through multi-agent workflows to bridge the gap between human intent and machine execution. For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding , we introduce the Vibe AIGC , a new paradigm for content generation via agentic orchestration , which represents the autonomous synthesis of hierarchical multi-agent workflows . Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration , Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.",
    "summary_en": "Vibe AIGC introduces a new generative AI paradigm where users provide high-level aesthetic and functional preferences, which are then orchestrated through multi-agent workflows to bridge the gap between human intent and machine execution.",
    "summary_zh": "Vibe AIGC提出了一种新的生成式AI范式，用户提供高层次的审美与功能偏好，这些偏好通过多智能体工作流进行编排，从而弥合人类意图与机器执行之间的差距。",
    "upvotes": 17
  },
  {
    "id": "2601.22859",
    "date": "2026-02-05",
    "title": "MEnvAgent: Scalable Polyglot Environment Construction for Verifiable Software Engineering",
    "authors": "Chuanzhe Guo Jingjing Wu Sijun He Yang Chen Zhaoqi Kuang Shilong Fan Bingjin Chen Siqi Bao Jing Liu Hua Wu Qingfu Zhu Wanxiang Che Haifeng Wang",
    "abstract": "MEnvAgent is a multi-language framework that automates environment construction for software engineering tasks using a planning-execution-verification architecture and environment reuse mechanism, achieving improved performance on a new benchmark and creating the largest open-source polyglot dataset of verifiable Docker environments. The evolution of Large Language Model (LLM) agents for software engineering (SWE) is constrained by the scarcity of verifiable datasets , a bottleneck stemming from the complexity of constructing executable environments across diverse languages. To address this, we introduce MEnvAgent, a Multi-language framework for automated Environment construction that facilitates scalable generation of verifiable task instances. MEnvAgent employs a multi-agent Planning-Execution-Verification architecture to autonomously resolve construction failures and integrates a novel Environment Reuse Mechanism that reduces computational overhead by incrementally patching historical environments. Evaluations on MEnvBench , a new benchmark comprising 1,000 tasks across 10 languages, demonstrate that MEnvAgent outperforms baselines, improving Fail-to-Pass (F2P) rates by 8.6% while reducing time costs by 43%. Additionally, we demonstrate the utility of MEnvAgent by constructing MEnvData-SWE , the largest open-source polyglot dataset of realistic verifiable Docker environments to date, alongside solution trajectories that enable consistent performance gains on SWE tasks across a wide range of models. Our code, benchmark, and dataset are available at https://github.com/ernie-research/MEnvAgent.",
    "summary_en": "MEnvAgent is a multi-language framework that automates environment construction for software engineering tasks using a planning-execution-verification architecture and environment reuse mechanism, achieving improved performance on a new benchmark and creating the largest open-source polyglot dataset of verifiable Docker environments.",
    "summary_zh": "MEnvAgent 是一个多语言框架，采用规划-执行-验证架构和环境复用机制，为软件工程任务自动化构建环境，在新基准上取得性能提升，并创建了最大规模的开源多语言可验证 Docker 环境数据集。",
    "upvotes": 17
  },
  {
    "id": "2602.04735",
    "date": "2026-02-05",
    "title": "From Data to Behavior: Predicting Unintended Model Behaviors Before Training",
    "authors": "Mengru Wang Zhenqian Xu Junfeng Fang Yunzhi Yao Shumin Deng Huajun Chen Ningyu Zhang",
    "abstract": "Data2Behavior predicts unintended model behaviors before training using MDF, a lightweight method that analyzes data features to reveal potential biases without parameter updates. Large Language Models (LLMs) can acquire unintended biases from seemingly benign training data even without explicit cues or malicious content. Existing methods struggle to detect such risks before fine-tuning, making post hoc evaluation costly and inefficient. To address this challenge, we introduce Data2Behavior , a new task for predicting unintended model behaviors prior to training. We also propose Manipulating Data Features (MDF), a lightweight approach that summarizes candidate data through their mean representations and injects them into the forward pass of a base model, allowing latent statistical signals in the data to shape model activations and reveal potential biases and safety risks without updating any parameters. MDF achieves reliable prediction while consuming only about 20% of the GPU resources required for fine-tuning. Experiments on Qwen3-14B, Qwen2.5-32B-Instruct, and Gemma-3-12b-it confirm that MDF can anticipate unintended behaviors and provide insight into pre-training vulnerabilities .",
    "summary_en": "Data2Behavior predicts unintended model behaviors before training using MDF, a lightweight method that analyzes data features to reveal potential biases without parameter updates.",
    "summary_zh": "Data2Behavior利用MDF这一轻量级方法，在训练前分析数据特征以预测非预期的模型行为，无需参数更新即可揭示潜在偏差。",
    "upvotes": 15
  },
  {
    "id": "2602.02160",
    "date": "2026-02-05",
    "title": "D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use",
    "authors": "Bowen Xu Shaoyu Wu Hao Jiang Kai Liu Xin Chen Lulu Hu Bin Yang",
    "abstract": "A two-stage training framework called D-CORE is proposed to improve large reasoning models' ability to decompose complex tasks and compose reasoning processes, achieving superior performance in tool-use benchmarks. Effective tool use and reasoning are essential capabilities for large reasoning models ~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning . To address this, we propose a two-stage training framework D-CORE~(\\textbf{D}ecomposing tasks and \\textbf{Co}mposing \\textbf{Re}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation , followed by diversity-aware reinforcement learning ~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\\% accuracy, surpassing the best-performing 8B model by 5.7\\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\\%, outperforming 70B models despite being 5times smaller. The source code is available at https://github.com/alibaba/EfficientAI.",
    "summary_en": "A two-stage training framework called D-CORE is proposed to improve large reasoning models' ability to decompose complex tasks and compose reasoning processes, achieving superior performance in tool-use benchmarks.",
    "summary_zh": "提出了一种名为D-CORE的两阶段训练框架，以提升大型推理模型分解复杂任务并组合推理过程的能力，在工具使用基准测试中取得了更优性能。",
    "upvotes": 14
  },
  {
    "id": "2602.04284",
    "date": "2026-02-05",
    "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning",
    "authors": "Yansong Ning Jun Fang Naiqiang Tan Hao Liu",
    "abstract": "Agent-Omit is a training framework that enables LLM agents to adaptively omit redundant thoughts and observations during multi-turn interactions, achieving superior effectiveness-efficiency trade-offs compared to existing methods. Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data , including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence . Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.",
    "summary_en": "Agent-Omit is a training framework that enables LLM agents to adaptively omit redundant thoughts and observations during multi-turn interactions, achieving superior effectiveness-efficiency trade-offs compared to existing methods.",
    "summary_zh": "Agent-Omit是一种训练框架，使LLM智能体能够在多轮交互中自适应地省略冗余的思考和观察，相较于现有方法实现了更优的效果-效率权衡。",
    "upvotes": 13
  },
  {
    "id": "2602.02140",
    "date": "2026-02-05",
    "title": "Quantifying the Gap between Understanding and Generation within Unified Multimodal Models",
    "authors": "Chenlong Wang Yuhang Chen Zhihan Hu Dongping Chen Wenhu Chen Sarah Wiegreffe Tianyi Zhou",
    "abstract": "Unified multimodal models exhibit a persistent gap between understanding and generation capabilities, indicating only surface-level integration rather than deep cognitive convergence. Recent advances in unified multimodal models (UMM) have demonstrated remarkable progress in both understanding and generation tasks. However, whether these two capabilities are genuinely aligned and integrated within a single model remains unclear. To investigate this question, we introduce GapEval, a bidirectional benchmark designed to quantify the gap between understanding and generation capabilities, and quantitatively measure the cognitive coherence of the two \"unified\" directions. Each question can be answered in both modalities (image and text), enabling a symmetric evaluation of a model's bidirectional inference capability and cross-modal consistency . Experiments reveal a persistent gap between the two directions across a wide range of UMMs with different architectures, suggesting that current models achieve only surface-level unification rather than deep cognitive convergence of the two. To further explore the underlying mechanism, we conduct an empirical study from the perspective of knowledge manipulation to illustrate the underlying limitations. Our findings indicate that knowledge within UMMs often remains disjoint. The capability emergence and knowledge across modalities are unsynchronized, paving the way for further exploration.",
    "summary_en": "Unified multimodal models exhibit a persistent gap between understanding and generation capabilities, indicating only surface-level integration rather than deep cognitive convergence.",
    "summary_zh": "统一多模态模型在理解与生成能力之间存在持续差距，表明其仅为表层整合而非深度认知融合。",
    "upvotes": 12
  },
  {
    "id": "2602.03916",
    "date": "2026-02-05",
    "title": "SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?",
    "authors": "Azmine Toushik Wasi Wahid Faisal Abdur Rahman Mahfuz Ahmed Anik Munem Shahriar Mohsin Mahmud Topu Sadia Tasnim Meem Rahatun Nesa Priti Sabrina Afroz Mitu Md. Iqramul Hoque Shahriyar Zaman Ridoy Mohammed Eunus Ali Majd Hawasly Mohammad Raza Md Rizwan Parvez",
    "abstract": "SpatiaLab presents a comprehensive benchmark for evaluating vision-language models' spatial reasoning capabilities across realistic, diverse scenarios, revealing significant gaps compared to human performance.",
    "summary_en": "SpatiaLab presents a comprehensive benchmark for evaluating vision-language models' spatial reasoning capabilities across realistic, diverse scenarios, revealing significant gaps compared to human performance.",
    "summary_zh": "SpatiaLab构建了一个综合性基准，评估视觉-语言模型在真实多样场景中的空间推理能力，揭示了其相较于人类表现的显著差距。",
    "upvotes": 11
  },
  {
    "id": "2602.03359",
    "date": "2026-02-05",
    "title": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling",
    "authors": "Ning Ding Fangcheng Liu Kyungrae Kim Linji Hao Kyeng-Hun Lee Hyeonmok Ko Yehui Tang",
    "abstract": "MeKi enables efficient large language model deployment on edge devices by injecting pre-stored semantic knowledge through token-level memory experts and re-parameterization techniques. Scaling Large Language Models (LLMs) typically relies on increasing the number of parameters or test-time computations to boost performance. However, these strategies are impractical for edge device deployment due to limited RAM and NPU resources. Despite hardware constraints, deploying performant LLM on edge devices such as smartphone remains crucial for user experience. To address this, we propose MeKi (Memory-based Expert Knowledge Injection), a novel system that scales LLM capacity via storage space rather than FLOPs. MeKi equips each Transformer layer with token-level memory experts that injects pre-stored semantic knowledge into the generation process. To bridge the gap between training capacity and inference efficiency, we employ a re-parameterization strategy to fold parameter matrices used during training into a compact static lookup table . By offloading the knowledge to ROM , MeKi decouples model capacity f rom computational cost, introducing zero inference latency overhead. Extensive experiments demonstrate that MeKi significantly outperforms dense LLM baselines with identical inference speed, validating the effectiveness of memory-based scaling paradigm for on-device LLMs. Project homepage is at https://github.com/ningding-o/MeKi.",
    "summary_en": "MeKi enables efficient large language model deployment on edge devices by injecting pre-stored semantic knowledge through token-level memory experts and re-parameterization techniques.",
    "summary_zh": "MeKi通过token级记忆专家和重参数化技术注入预存储的语义知识，实现了大语言模型在边缘设备上的高效部署。",
    "upvotes": 9
  },
  {
    "id": "2602.03979",
    "date": "2026-02-05",
    "title": "Likelihood-Based Reward Designs for General LLM Reasoning",
    "authors": "Ariel Kwiatkowski Natasha Butt Ismail Labiad Julia Kempe Yann Ollivier",
    "abstract": "Log-probability rewards derived from the reference answer's likelihood outperform binary rewards in chain-of-thought fine-tuning across both verifiable and non-verifiable reasoning benchmarks. Fine-tuning large language models (LLMs) on reasoning benchmarks via reinforcement learning requires a specific reward function , often binary, for each benchmark. This comes with two potential limitations: the need to design the reward, and the potentially sparse nature of binary rewards . Here, we systematically investigate rewards derived from the probability or log-probability of emitting the reference answer (or any other prompt continuation present in the data), which have the advantage of not relying on specific verifiers and being available at scale. Several recent works have advocated for the use of similar rewards (e.g., VeriFree, JEPO, RLPR, NOVER). We systematically compare variants of likelihood-based rewards with standard baselines, testing performance both on standard mathematical reasoning benchmarks , and on long-form answers where no external verifier is available. We find that using the log-probability of the reference answer as the reward for chain-of-thought (CoT) learning is the only option that performs well in all setups. This reward is also consistent with the next-token log-likelihood loss used during pretraining . In verifiable settings , log-probability rewards bring comparable or better success rates than reinforcing with standard binary rewards , and yield much better perplexity. In non-verifiable settings , they perform on par with SFT. On the other hand, methods based on probability, such as VeriFree, flatline on non-verifiable settings due to vanishing probabilities of getting the correct answer. Overall, this establishes log-probability rewards as a viable method for CoT fine-tuning , bridging the short, verifiable and long, non-verifiable answer settings.",
    "summary_en": "Log-probability rewards derived from the reference answer's likelihood outperform binary rewards in chain-of-thought fine-tuning across both verifiable and non-verifiable reasoning benchmarks.",
    "summary_zh": "在思维链微调中，基于参考答案似然的对数概率奖励在可验证和不可验证推理基准上均优于二元奖励。",
    "upvotes": 8
  },
  {
    "id": "2602.03955",
    "date": "2026-02-05",
    "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
    "authors": "Yinyi Luo Yiqiao Jin Weichen Yu Mengqi Zhang Srijan Kumar Xiaoxiao Li Weijie Xu Xin Chen Jindong Wang",
    "abstract": "AgentArk distills multi-agent reasoning dynamics into a single model through hierarchical distillation strategies, enabling efficient yet powerful reasoning capabilities. While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning ; trajectory-based augmentation ; and process-aware distillation . By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.",
    "summary_en": "AgentArk distills multi-agent reasoning dynamics into a single model through hierarchical distillation strategies, enabling efficient yet powerful reasoning capabilities.",
    "summary_zh": "AgentArk 通过分层蒸馏策略将多智能体推理动态蒸馏至单一模型，实现高效且强大的推理能力。",
    "upvotes": 8
  },
  {
    "id": "2602.02554",
    "date": "2026-02-05",
    "title": "BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation",
    "authors": "Jingwen Xu Yiyang Lu Zisu Huang Changze Lv Xiaohua Wang Shizheng Li Zhibo Xu Zhengkang Guo Zhengyuan Wang Muzhao Tian Xuanjing Huang Xiaoqing Zheng",
    "abstract": "BatCoder is a self-supervised reinforcement learning framework that jointly optimizes code and documentation generation through back-translation, achieving superior performance on code-related benchmarks. Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production . BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward , enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1 , outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity .",
    "summary_en": "BatCoder is a self-supervised reinforcement learning framework that jointly optimizes code and documentation generation through back-translation, achieving superior performance on code-related benchmarks.",
    "summary_zh": "BatCoder是一种自监督强化学习框架，通过回译联合优化代码和文档生成，在代码相关基准测试中取得更优性能。",
    "upvotes": 8
  },
  {
    "id": "2602.01640",
    "date": "2026-02-05",
    "title": "A2Eval: Agentic and Automated Evaluation for Embodied Brain",
    "authors": "Shuai Zhang Jiayu Hu Zijie Chen Zeyuan Ding Yi Zhang Yingji Zhang Ziyi Zhou Junwei Liao Shengjie Zhou Yong Dai Zhenzhong Lan Xiaozhu Ju",
    "abstract": "Agentic automatic evaluation framework automates embodied vision-language model assessment through collaborative agents that reduce evaluation costs and improve ranking accuracy. Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite , while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suite s by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking bias es, improves human alignment to Spearman's rho =0.85, and maintains high ranking fidelity ( Kendall's tau =0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon.",
    "summary_en": "Agentic automatic evaluation framework automates embodied vision-language model assessment through collaborative agents that reduce evaluation costs and improve ranking accuracy.",
    "summary_zh": "智能体自动评估框架通过协作智能体自动化具身视觉-语言模型评估，降低评估成本并提高排序准确性。",
    "upvotes": 8
  },
  {
    "id": "2601.20499",
    "date": "2026-02-05",
    "title": "Efficient Autoregressive Video Diffusion with Dummy Head",
    "authors": "Hang Guo Zhaoyang Jia Jiahao Li Bin Li Yuanhao Cai Jiangshan Wang Yawei Li Yan Lu",
    "abstract": "Autoregressive video diffusion models suffer from inefficient attention mechanisms that underutilize historical frames, but a new method called Dummy Forcing improves efficiency through heterogeneous memory allocation and dynamic head programming while maintaining quality. The autoregressive video diffusion model has recently gained considerable research interest due to its causal modeling and iterative denoising . In this work, we identify that the multi-head self-attention in these models under-utilizes historical frames: approximately 25% heads attend almost exclusively to the current frame, and discarding their KV caches incurs only minor performance degradation. Building upon this, we propose Dummy Forcing, a simple yet effective method to control context accessibility across different heads. Specifically, the proposed heterogeneous memory allocation reduces head-wise context redundancy, accompanied by dynamic head programming to adaptively classify head types. Moreover, we develop a context packing technique to achieve more aggressive cache compression . Without additional training, our Dummy Forcing delivers up to 2.0x speedup over the baseline, supporting video generation at 24.3 FPS with less than 0.5% quality drop. Project page is available at https://csguoh.github.io/project/DummyForcing/.",
    "summary_en": "Autoregressive video diffusion models suffer from inefficient attention mechanisms that underutilize historical frames, but a new method called Dummy Forcing improves efficiency through heterogeneous memory allocation and dynamic head programming while maintaining quality.",
    "summary_zh": "自回归视频扩散模型的注意力机制效率低下，未能充分利用历史帧，而Dummy Forcing这一新方法通过异构内存分配与动态头编程，在保持质量的同时提升了效率。",
    "upvotes": 8
  },
  {
    "id": "2602.04805",
    "date": "2026-02-05",
    "title": "Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging",
    "authors": "Jia-peng Zhang Cheng-Feng Pu Meng-Hao Guo Yan-Pei Cao Shi-Min Hu",
    "abstract": "Generative 3D models face challenges in animation rigging, which this work addresses by introducing SkinTokens—a learned discrete representation for skinning weights—and TokenRig, a unified autoregressive framework that models skeletons and skin deformations together, improving rigging accuracy through reinforcement learning. The rapid proliferation of generative 3D models has created a critical bottleneck in animation pipelines: rigging. Existing automated methods are fundamentally limited by their approach to skinning, treating it as an ill-posed, high-dimensional regression task that is inefficient to optimize and is typically decoupled from skeleton generation. We posit this is a representation problem and introduce SkinTokens: a learned, compact, and discrete representation for skinning weights . By leveraging an FSQ-CVAE to capture the intrinsic sparsity of skinning, we reframe the task from continuous regression to a more tractable token sequence prediction problem. This representation enables TokenRig, a unified autoregressive framework that models the entire rig as a single sequence of skeletal parameters and SkinTokens, learning the complicated dependencies between skeletons and skin deformations. The unified model is then amenable to a reinforcement learning stage, where tailored geometric and semantic rewards improve generalization to complex, out-of-distribution assets. Quantitatively, the SkinTokens representation leads to a 98%-133% percents improvement in skinning accuracy over state-of-the-art methods, while the full TokenRig framework, refined with RL, enhances bone prediction by 17%-22%. Our work presents a unified, generative approach to rigging that yields higher fidelity and robustness, offering a scalable solution to a long-standing challenge in 3D content creation.",
    "summary_en": "Generative 3D models face challenges in animation rigging, which this work addresses by introducing SkinTokens—a learned discrete representation for skinning weights—and TokenRig, a unified autoregressive framework that models skeletons and skin deformations together, improving rigging accuracy through reinforcement learning.",
    "summary_zh": "生成式3D模型在动画绑定上面临挑战，本工作通过引入SkinTokens（一种针对蒙皮权重的习得离散表示）和TokenRig（一种联合建模骨骼与皮肤形变的统一自回归框架）来解决该问题，并利用强化学习提升绑定精度。",
    "upvotes": 6
  },
  {
    "id": "2602.04486",
    "date": "2026-02-05",
    "title": "Beyond Unimodal Shortcuts: MLLMs as Cross-Modal Reasoners for Grounded Named Entity Recognition",
    "authors": "Jinlong Ma Yu Zhang Xuefeng Bai Kehai Chen Yuwei Wang Zeming Liu Jun Yu Min Zhang",
    "abstract": "MLLMs suffer from modality bias in GMNER tasks, which is addressed through a proposed method that enforces cross-modal reasoning via multi-style reasoning schema injection and constraint-guided verifiable optimization. Grounded Multimodal Named Entity Recognition ( GMNER ) aims to extract text-based entities, assign them semantic categories, and ground them to corresponding visual regions. In this work, we explore the potential of Multimodal Large Language Models (MLLMs) to perform GMNER in an end-to-end manner, moving beyond their typical role as auxiliary tools within cascaded pipelines. Crucially, our investigation reveals a fundamental challenge: MLLMs exhibit modality bias , including visual bias and textual bias, which stems from their tendency to take unimodal shortcuts rather than rigorous cross-modal verification. To address this, we propose Modality-aware Consistency Reasoning (MCR), which enforces structured cross-modal reasoning through Multi-style Reasoning Schema Injection (MRSI) and Constraint-guided Verifiable Optimization (CVO). MRSI transforms abstract constraints into executable reasoning chains, while CVO empowers the model to dynamically align its reasoning trajectories with Group Relative Policy Optimization (GRPO). Experiments on GMNER and visual grounding tasks demonstrate that MCR effectively mitigates modality bias and achieves superior performance compared to existing baselines.",
    "summary_en": "MLLMs suffer from modality bias in GMNER tasks, which is addressed through a proposed method that enforces cross-modal reasoning via multi-style reasoning schema injection and constraint-guided verifiable optimization.",
    "summary_zh": "MLLMs在GMNER任务中存在模态偏见，本文提出了一种通过多风格推理模式注入与约束引导的可验证优化来强制跨模态推理的方法来解决该问题。",
    "upvotes": 6
  },
  {
    "id": "2602.01849",
    "date": "2026-02-05",
    "title": "Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models",
    "authors": "Ziwei Luo Ziqi Jin Lei Wang Lidong Bing Thomas B. Schön",
    "abstract": "Self-rewarding sequential Monte Carlo enables effective sampling of masked diffusion language models by using parallel diffusion processes and trajectory-level confidence signals to improve generation quality. This work presents self-rewarding sequential Monte Carlo (SMC), an inference-time scaling algorithm enabling effective sampling of masked diffusion language models (MDLMs). Our algorithm stems from the observation that most existing MDLMs rely on a confidence-based sampling strategy, where only tokens with the highest prediction confidence are preserved at each step. This restricts the generation to a noise-sensitive, greedy decoding paradigm, resulting in an inevitable collapse in the diversity of possible paths. We address this problem by launching multiple interacting diffusion processes in parallel, referred to as particles, for trajectory exploration. Importantly, we introduce the trajectory-level confidence as a self-rewarding signal for assigning particle importance weights. During sampling, particles are iteratively weighted and resampled to systematically steer generation towards globally confident, high-quality samples. Our self-rewarding SMC is verified on various masked diffusion language models and benchmarks, achieving significant improvement without extra training or reward guidance, while effectively converting parallel inference capacity into improved sampling quality. Our code is available at https://github.com/Algolzw/self-rewarding-smc.",
    "summary_en": "Self-rewarding sequential Monte Carlo enables effective sampling of masked diffusion language models by using parallel diffusion processes and trajectory-level confidence signals to improve generation quality.",
    "summary_zh": "自奖励序贯蒙特卡洛利用并行扩散过程和轨迹级置信信号，实现对掩码扩散语言模型的有效采样，从而提升生成质量。",
    "upvotes": 5
  },
  {
    "id": "2602.02350",
    "date": "2026-02-05",
    "title": "Context Learning for Multi-Agent Discussion",
    "authors": "Xingyuan Hua Sheng Yue Xinyi Li Yizhe Zhao Jinrui Zhang Ju Ren",
    "abstract": "",
    "summary_en": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper.",
    "summary_zh": "这是来自 Librarian Bot 的自动消息。我找到了以下与本文相似的论文。",
    "upvotes": 4
  },
  {
    "id": "2602.04883",
    "date": "2026-02-05",
    "title": "Protein Autoregressive Modeling via Multiscale Structure Generation",
    "authors": "Yanru Qu Cheng-Yen Hsieh Zaixiang Zheng Ge Liu Quanquan Gu",
    "abstract": "PAR is a multi-scale autoregressive framework for protein backbone generation that uses hierarchical structure modeling, autoregressive transformers, and flow-based decoding to produce high-quality protein structures with improved generalization and reduced exposure bias. We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias , caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling , enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization , supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark , PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.",
    "summary_en": "PAR is a multi-scale autoregressive framework for protein backbone generation that uses hierarchical structure modeling, autoregressive transformers, and flow-based decoding to produce high-quality protein structures with improved generalization and reduced exposure bias.",
    "summary_zh": "PAR是一种用于蛋白质骨架生成的多尺度自回归框架，通过层次化结构建模、自回归Transformer和基于流的解码生成高质量蛋白质结构，提升了泛化能力并降低了曝光偏差。",
    "upvotes": 3
  },
  {
    "id": "2602.04442",
    "date": "2026-02-05",
    "title": "No One-Size-Fits-All: Building Systems For Translation to Bashkir, Kazakh, Kyrgyz, Tatar and Chuvash Using Synthetic And Original Data",
    "authors": "Dmitry Karpov",
    "abstract": "Machine translation experiments for Turkic languages using nllb-200, LoRA fine-tuning, and prompt-based approaches achieved varying chrF++ scores across language pairs. We explore machine translation for five Turkic language pairs: Russian-Bashkir, Russian-Kazakh, Russian-Kyrgyz, English-Tatar, English-Chuvash. Fine-tuning nllb-200 -distilled-600M with LoRA on synthetic data achieved chrF++ 49.71 for Kazakh and 46.94 for Bashkir. Prompting DeepSeek-V3.2 with retrieved similar examples achieved chrF++ 39.47 for Chuvash. For Tatar, zero-shot or retrieval-based approaches achieved chrF++ 41.6, while for Kyrgyz the zero-shot approach reached 45.6. We release the dataset and the obtained weights.",
    "summary_en": "Machine translation experiments for Turkic languages using nllb-200, LoRA fine-tuning, and prompt-based approaches achieved varying chrF++ scores across language pairs.",
    "summary_zh": "使用 nllb-200、LoRA 微调和基于提示的方法开展的突厥语族语言机器翻译实验在不同语言对上取得了不同的 chrF++ 分数。",
    "upvotes": 3
  },
  {
    "id": "2602.04289",
    "date": "2026-02-05",
    "title": "Proxy Compression for Language Modeling",
    "authors": "Lin Zheng Xinyu Li Qian Liu Xiachong Feng Lingpeng Kong",
    "abstract": "Proxy compression trains language models on both raw byte sequences and compressed views, enabling efficient training with end-to-end raw-byte inference while maintaining model robustness. Modern language models are trained almost exclusively on token sequences produced by a fixed tokenizer , an external lossless compressor often over UTF-8 byte sequences , thereby coupling the model to that compressor. This work introduces proxy compression , an alternative training scheme that preserves the efficiency benefits of compressed inputs while providing an end-to-end, raw-byte interface at inference time . During training, one language model is jointly trained on raw byte sequences and compressed views generated by external compressors ; through the process, the model learns to internally align compressed sequences and raw bytes. This alignment enables strong transfer between the two formats, even when training predominantly on compressed inputs which are discarded at inference. Extensive experiments on code language modeling demonstrate that proxy compression substantially improves training efficiency and significantly outperforms pure byte-level baselines given fixed compute budgets. As model scale increases, these gains become more pronounced, and proxy-trained models eventually match or rival tokenizer approaches, all while operating solely on raw bytes and retaining the inherent robustness of byte-level modeling .",
    "summary_en": "Proxy compression trains language models on both raw byte sequences and compressed views, enabling efficient training with end-to-end raw-byte inference while maintaining model robustness.",
    "summary_zh": "代理压缩在原始字节序列和压缩视图上训练语言模型，实现高效训练与端到端原始字节推理，同时保持模型鲁棒性。",
    "upvotes": 3
  },
  {
    "id": "2602.01031",
    "date": "2026-02-05",
    "title": "HalluHard: A Hard Multi-Turn Hallucination Benchmark",
    "authors": "Dongyang Fan Sebastien Delsad Nicolas Flammarion Maksym Andriushchenko",
    "abstract": "Large language models continue to generate plausible but ungrounded factual claims in multi-turn dialogue, with hallucinations remaining significant even when utilizing web search for verification across high-stakes domains. Large language models (LLMs) still produce plausible-sounding but ungrounded factual claims, a problem that worsens in multi-turn dialogue as context grows and early errors cascade. We introduce HalluHard, a challenging multi-turn hallucination benchmark with 950 seed questions spanning four high-stakes domains: legal cases, research questions, medical guidelines, and coding. We operationalize groundedness by requiring inline citations for factual assertions . To support reliable evaluation in open-ended settings , we propose a judging pipeline that iteratively retrieves evidence via web search . It can fetch, filter, and parse full-text sources (including PDFs) to assess whether cited material actually supports the generated content. Across a diverse set of frontier proprietary and open-weight models, hallucination s remain substantial even with web search (approx 30% for the strongest configuration, Opus-4.5 with web search ), with content-grounding errors persisting at high rates. Finally, we show that hallucination behavior is shaped by model capacity , turn position , effective reasoning , and the type of knowledge required.",
    "summary_en": "Large language models continue to generate plausible but ungrounded factual claims in multi-turn dialogue, with hallucinations remaining significant even when utilizing web search for verification across high-stakes domains.",
    "summary_zh": "大语言模型在多轮对话中持续生成看似合理但缺乏事实依据的陈述，即使在高风险领域利用网络搜索进行验证，幻觉现象依然显著。",
    "upvotes": 3
  },
  {
    "id": "2602.02495",
    "date": "2026-02-05",
    "title": "Reward-free Alignment for Conflicting Objectives",
    "authors": "Peter Chen Xiaopeng Li Xi Chen Tianyi Lin",
    "abstract": "A reward-free alignment framework addresses multi-objective conflicts in language models through conflict-averse gradient descent with clipping, improving Pareto trade-offs across diverse model architectures. Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent . We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.",
    "summary_en": "A reward-free alignment framework addresses multi-objective conflicts in language models through conflict-averse gradient descent with clipping, improving Pareto trade-offs across diverse model architectures.",
    "summary_zh": "一种无奖励对齐框架通过带裁剪的冲突规避梯度下降解决语言模型中的多目标冲突，在多种模型架构上改进了帕累托权衡。",
    "upvotes": 2
  },
  {
    "id": "2602.05000",
    "date": "2026-02-05",
    "title": "EntRGi: Entropy Aware Reward Guidance for Diffusion Language Models",
    "authors": "Atula Tejaswi Litu Rout Constantine Caramanis Sanjay Shakkottai Sujay Sanghavi",
    "abstract": "Discrete diffusion language models use entropy-aware reward guidance to improve test-time adaptation by dynamically regulating gradient feedback from reward models.",
    "summary_en": "Discrete diffusion language models use entropy-aware reward guidance to improve test-time adaptation by dynamically regulating gradient feedback from reward models.",
    "summary_zh": "离散扩散语言模型利用熵感知奖励引导，通过动态调节来自奖励模型的梯度反馈来改进测试时自适应。",
    "upvotes": 1
  },
  {
    "id": "2602.04651",
    "date": "2026-02-05",
    "title": "SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF",
    "authors": "Dipan Maity",
    "abstract": "A new reinforcement learning algorithm for language model alignment that improves stability and performance over PPO through enhanced KL divergence control and adaptive reward management. Optimization ( PPO ) has been positioned by recent literature as the canonical method for the RL part of RLHF . PPO performs well empirically but has a heuristic motivation and handles the KL-divergence constraint used in LM- RLHF in an ad-hoc manner and suffers form reward oscillations , entropy collapse , value function drift , and sudden policy divergence that require frequent restarts and extensive hyperparameter tuning. In this paper, we develop a new pure on policy actor-critic RL method for the LM- RLHF setting. We present SAFE (Stable Alignment Finetuning with Entropy-aware control),a novel RLHF algorithm that combines a Double Soft-Min Critic for pessimistic value estimation with a new multi-layer stabilization framework combining entropy-gated KL regulation , and PID-controlled adaptive thresholds . Unlike standard PPO 's symmetric KL penalties, SAFE distinguishes high-entropy exploration from low-entropy mode collapse and adjusts penalties dynamically based on reward velocity. Experiments on a 3B parameter model show SAFE achieves +5.15\\% training-average reward than PPO (0.725 vs 0.689), negligible reward crashes, and superior KL control than ppo . Our method adds minimal computational overhead and provides an interpretable, crash-resistant RLHF framework that maintains aggressive learning speed while ensuring stable long-horizon optimization suitable for production deployment. Code is available at https://github.com/ryyzn9/SAFE",
    "summary_en": "A new reinforcement learning algorithm for language model alignment that improves stability and performance over PPO through enhanced KL divergence control and adaptive reward management.",
    "summary_zh": "一种用于语言模型对齐的新型强化学习算法，通过增强的KL散度控制和自适应奖励管理，在稳定性和性能上优于PPO。",
    "upvotes": 1
  },
  {
    "id": "2602.04605",
    "date": "2026-02-05",
    "title": "RexBERT: Context Specialized Bidirectional Encoders for E-commerce",
    "authors": "Rahul Bajaj Anuj Garg",
    "abstract": "RexBERT, a family of BERT-style encoders designed for e-commerce semantics, achieves superior performance on domain-specific tasks through specialized pretraining and high-quality in-domain data. Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BERT-style encoders designed specifically for e-commerce semantics . We make three contributions. First, we release Ecom-niverse , a 350 billion token corpus curated from diverse retail and shopping sources. We describe a modular pipeline that isolates and extracts e-commerce content from FineFineWeb and other open web resources, and characterize the resulting domain distribution. Second, we present a reproducible pretraining recipe building on ModernBERT 's architectural advances. The recipe consists of three phases: general pre-training, context extension , and annealed domain specialization . Third, we train RexBERT models ranging from 17M to 400M parameters and evaluate them on token classification , semantic similarity , and general natural language understanding tasks using e-commerce datasets. Despite having 2-3x fewer parameters, RexBERT outperforms larger general-purpose encoders and matches or surpasses modern long-context models on domain-specific benchmarks. Our results demonstrate that high quality in-domain data combined with a principled training approach provides a stronger foundation for e-commerce applications than indiscriminate scaling alone.",
    "summary_en": "RexBERT, a family of BERT-style encoders designed for e-commerce semantics, achieves superior performance on domain-specific tasks through specialized pretraining and high-quality in-domain data.",
    "summary_zh": "RexBERT是一系列专为电商语义设计的BERT风格编码器，通过专门预训练与高质量领域数据，在特定领域任务上取得了优异性能。",
    "upvotes": 1
  },
  {
    "id": "2602.04581",
    "date": "2026-02-05",
    "title": "Trust The Typical",
    "authors": "Debargha Ganguly Sreehari Sankar Biyao Zhang Vikash Singh Kanan Gupta Harshini Kavuru Alan Luo Weicong Chen Warren Morningstar Raghu Machiraju Vipin Chaudhary",
    "abstract": "A novel framework for LLM safety that treats safety as an out-of-distribution detection problem, achieving state-of-the-art performance without harmful example training through semantic space analysis and efficient GPU implementation. Current approaches to LLM safety fundamentally rely on a brittle cat-and-mouse game of identifying and blocking known threats via guardrails . We argue for a fresh approach: robust safety comes not from enumerating what is harmful, but from deeply understanding what is safe. We introduce Trust The Typical (T3), a framework that operationalizes this principle by treating safety as an out-of-distribution (OOD) detection problem. T3 learns the distribution of acceptable prompts in a semantic space and flags any significant deviation as a potential threat. Unlike prior methods, it requires no training on harmful examples, yet achieves state-of-the-art performance across 18 benchmarks spanning toxicity, hate speech, jailbreaking, multilingual harms , and over-refusal , reducing false positive rates by up to 40x relative to specialized safety models. A single model trained only on safe English text transfers effectively to diverse domains and over 14 languages without retraining. Finally, we demonstrate production readiness by integrating a GPU-optimized version into vLLM , enabling continuous guardrailing during token generation with less than 6% overhead even under dense evaluation intervals on large-scale workloads.",
    "summary_en": "A novel framework for LLM safety that treats safety as an out-of-distribution detection problem, achieving state-of-the-art performance without harmful example training through semantic space analysis and efficient GPU implementation.",
    "summary_zh": "一种针对LLM安全的新框架，将安全性建模为分布外检测问题，借助语义空间分析和高效GPU实现，无需有害样本训练即可达到最优性能。",
    "upvotes": 1
  },
  {
    "id": "2602.04547",
    "date": "2026-02-05",
    "title": "OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis",
    "authors": "Luca Zedda Andrea Loddo Cecilia Di Ruberto",
    "abstract": "OmniRad is a self-supervised radiological foundation model pretrained on 1.2 million medical images that demonstrates improved performance in classification and segmentation tasks through representation reuse and cross-task transferability. Radiological analysis increasingly benefits from pretrained visual representations that can support heterogeneous downstream tasks across imaging modalities. In this work, we introduce OmniRad, a self-supervised radiological foundation model pretrained on 1.2 million medical images, designed with radiology-inspired principles emphasizing representation reuse and cross-task transferability . We evaluate the pretrained encoder under multiple downstream adaptation regimes, including lightweight task-specific adapters with a frozen backbone as well as full end-to-end fine-tuning for classification, allowing us to assess both representation quality and task-specific performance. OmniRad is evaluated on a broad suite of public benchmarks spanning classification and segmentation across multiple modalities. On the MedMNISTv2 collection, OmniRad improves classification F1 by up to 2.05% over competing foundation models. For dense prediction, OmniRad attains mean Dice score improvements across six MedSegBench datasets when using frozen representations. Qualitative analyses and latent-space visualization s suggest improved feature clustering and modality-related separation.",
    "summary_en": "OmniRad is a self-supervised radiological foundation model pretrained on 1.2 million medical images that demonstrates improved performance in classification and segmentation tasks through representation reuse and cross-task transferability.",
    "summary_zh": "OmniRad是一种在120万张医学影像上预训练的自监督放射学基础模型，通过表征复用和跨任务可迁移性，在分类和分割任务中展现出更优性能。",
    "upvotes": 1
  },
  {
    "id": "2602.04271",
    "date": "2026-02-05",
    "title": "SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization",
    "authors": "Lifan Wu Ruijie Zhu Yubo Ai Tianzhu Zhang",
    "abstract": "SkeletonGaussian enables editable 4D generation by decomposing motion into rigid skeleton-driven and non-rigid fine-grained components using hexplane-based refinement. 4D generation has made remarkable progress in synthesizing dynamic 3D objects from input text, images, or videos. However, existing methods often represent motion as an implicit deformation field, which limits direct control and editability. To address this issue, we propose SkeletonGaussian, a novel framework for generating editable dynamic 3D Gaussians from monocular video input . Our approach introduces a hierarchical articulated representation that decomposes motion into sparse rigid motion explicitly driven by a skeleton and fine-grained non-rigid motion. Concretely, we extract a robust skeleton and drive rigid motion via linear blend skinning , followed by a hexplane-based refinement for non-rigid deformations , enhancing interpretability and editability. Experimental results demonstrate that SkeletonGaussian surpasses existing methods in generation quality while enabling intuitive motion editing , establishing a new paradigm for editable 4D generation . Project page: https://wusar.github.io/projects/skeletongaussian/",
    "summary_en": "SkeletonGaussian enables editable 4D generation by decomposing motion into rigid skeleton-driven and non-rigid fine-grained components using hexplane-based refinement.",
    "summary_zh": "SkeletonGaussian利用基于六平面的细化将运动分解为刚性骨骼驱动和非刚性细粒度组件，实现了可编辑的4D生成。",
    "upvotes": 1
  },
  {
    "id": "2602.02863",
    "date": "2026-02-05",
    "title": "\"I May Not Have Articulated Myself Clearly\": Diagnosing Dynamic Instability in LLM Reasoning at Inference Time",
    "authors": "Jinkun Chen Fengxiang Cheng Sijia Han Vlado Keselj",
    "abstract": "Analysis of reasoning failures in large language models reveals that instability signals derived from token log probabilities and entropy can predict incorrect answers and distinguish between corrective and destructive instability based on timing of distribution shifts. Reasoning failures in large language models (LLMs) are typically measured only at the end of a generation, yet many failures manifest as a process-level breakdown: the model \"loses the thread\" mid-reasoning. We study whether such breakdowns are detectable from inference-time observables available in standard APIs ( token log probabilities ), without any training or fine-tuning. We define a simple instability signal that combines consecutive-step distributional shift (JSD) and uncertainty ( entropy ), summarize each trace by its peak instability strength, and show that this signal reliably predicts failure. Across GSM8K and HotpotQA , instability strength predicts wrong answers with above-chance AUC and yields monotonic bucket-level accuracy decline at scale across model sizes. Crucially, we show that instability is not uniformly harmful: early instability can reflect subsequent stabilization and a correct final answer ( corrective instability ), whereas late instability is more often followed by failure ( destructive instability ), even at comparable peak magnitudes, indicating that recoverability depends not only on how strongly the distribution changes but also on when such changes occur relative to the remaining decoding horizon. The method is model-agnostic, training-free, and reproducible, and is presented as a diagnostic lens rather than a corrective or control mechanism.",
    "summary_en": "Analysis of reasoning failures in large language models reveals that instability signals derived from token log probabilities and entropy can predict incorrect answers and distinguish between corrective and destructive instability based on timing of distribution shifts.",
    "summary_zh": "针对大语言模型推理失败的分析表明，由 token 对数概率和熵推导出的不稳定信号可预测错误答案，并能根据分布偏移的时机区分修正性不稳定与破坏性不稳定。",
    "upvotes": 1
  },
  {
    "id": "2602.02341",
    "date": "2026-02-05",
    "title": "LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization",
    "authors": "Zhenpeng Huang Jiaqi Li Zihan Jia Xinhao Li Desen Meng Lingxue Song Xi Chen Liang Li Limin Wang",
    "abstract": "LongVPO is a two-stage Direct Preference Optimization framework that enables short-context vision-language models to understand ultra-long videos through synthetic preference triples and recursive captioning, achieving state-of-the-art performance with minimal human annotation. We present LongVPO, a novel two-stage Direct Preference Optimization framework that enables short-context vision-language models to robustly understand ultra-long videos without any long-video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual-similarity and question-specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model's scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata , then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, LongVPO outperforms the state-of-the-art open-source models on multiple long-video benchmarks, while maintaining strong short-video performance (e.g., on MVBench), offering a scalable paradigm for efficient long-form video understanding.",
    "summary_en": "LongVPO is a two-stage Direct Preference Optimization framework that enables short-context vision-language models to understand ultra-long videos through synthetic preference triples and recursive captioning, achieving state-of-the-art performance with minimal human annotation.",
    "summary_zh": "LongVPO是一个两阶段直接偏好优化框架，通过合成偏好三元组与递归字幕生成，使短上下文视觉语言模型能够理解超长视频，在极少人工标注下达到当前最优性能。",
    "upvotes": 1
  },
  {
    "id": "2601.22596",
    "date": "2026-02-05",
    "title": "FOTBCD: A Large-Scale Building Change Detection Benchmark from French Orthophotos and Topographic Data",
    "authors": "Abdelrrahman Moubane",
    "abstract": "A large-scale building change detection dataset named FOTBCD is introduced, covering 28 French departments with high-resolution imagery and comprehensive annotations for both binary and instance-level change detection tasks. We introduce FOTBCD, a large-scale building change detection dataset derived from authoritative French orthophotos and topographic building data provided by IGN France. Unlike existing benchmarks that are geographically constrained to single cities or limited regions, FOTBCD spans 28 departments across mainland France, with 25 used for training and three geographically disjoint departments held out for evaluation. The dataset covers diverse urban, suburban, and rural environments at 0.2m/pixel resolution. We publicly release FOTBCD-Binary, a dataset comprising approximately 28,000 before/after image pairs with pixel-wise binary building change masks, each associated with patch-level spatial metadata. The dataset is designed for large-scale benchmarking and evaluation under geographic domain shift , with validation and test samples drawn from held-out departments and manually verified to ensure label quality. In addition, we publicly release FOTBCD-Instances, a publicly available instance-level annotated subset comprising several thousand image pairs, which illustrates the complete annotation schema used in the full instance-level version of FOTBCD. Using a fixed reference baseline, we benchmark FOTBCD-Binary against LEVIR-CD+ and WHU-CD, providing strong empirical evidence that geographic diversity at the dataset level is associated with improved cross-domain generalization in building change detection .",
    "summary_en": "A large-scale building change detection dataset named FOTBCD is introduced, covering 28 French departments with high-resolution imagery and comprehensive annotations for both binary and instance-level change detection tasks.",
    "summary_zh": "本文介绍了一个名为FOTBCD的大规模建筑物变化检测数据集，涵盖28个法国省份的高分辨率影像，并为二值与实例级变化检测任务提供了全面的标注。",
    "upvotes": 1
  },
  {
    "id": "2602.01785",
    "date": "2026-02-04",
    "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding",
    "authors": "Yuling Shi Chaoxiang Xie Zhensu Sun Yeheng Chen Chenxu Zhang Longfei Yun Chengcheng Wan Hongyu Zhang David Lo Xiaodong Gu",
    "abstract": "Multimodal large language models can effectively understand source code when represented as compressed images, achieving significant token reduction while maintaining or improving performance on code comprehension tasks.",
    "summary_en": "Multimodal large language models can effectively understand source code when represented as compressed images, achieving significant token reduction while maintaining or improving performance on code comprehension tasks.",
    "summary_zh": "多模态大语言模型能够有效理解以压缩图像形式表示的源代码，在实现显著 token 缩减的同时，于代码理解任务上保持或提升性能。",
    "upvotes": 93
  },
  {
    "id": "2602.03786",
    "date": "2026-02-04",
    "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration",
    "authors": "Jianhao Ruan Zhihao Xu Yiran Peng Fashen Ren Zhaoyang Yu Xinbing Liang Jinyu Xiang Bang Liu Chenglin Wu Yuyu Luo Jiayi Zhang",
    "abstract": "AOrchestra is a framework-agnostic agentic system that uses a tuple-based abstraction to dynamically create specialized task executors, achieving improved performance on complex benchmarks through automated agent creation and resource management. Language agents have shown strong promise for task automation . Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving . However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation . Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient . Across three challenging benchmarks ( GAIA , SWE-Bench , Terminal-Bench ), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra",
    "summary_en": "AOrchestra is a framework-agnostic agentic system that uses a tuple-based abstraction to dynamically create specialized task executors, achieving improved performance on complex benchmarks through automated agent creation and resource management.",
    "summary_zh": "AOrchestra是一个与框架无关的智能体系统，采用基于元组的抽象动态创建专用任务执行器，通过自动化智能体创建和资源管理，在复杂基准测试上实现性能提升。",
    "upvotes": 85
  },
  {
    "id": "2602.02103",
    "date": "2026-02-04",
    "title": "No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs",
    "authors": "Liyan Xu Mo Yu Fandong Meng Jie Zhou",
    "abstract": "Research investigates latent planning dynamics in large language models through a probing method called Tele-Lens, revealing limited global planning and enabling improved uncertainty estimation and CoT bypass recognition. This work stems from prior complementary observations on the dynamics of Chain-of-Thought (CoT): Large Language Models (LLMs) is shown latent planning of subsequent reasoning prior to CoT emergence, thereby diminishing the significance of explicit CoT; whereas CoT remains critical for tasks requiring multi-step reasoning . To deepen the understanding between LLM's internal states and its verbalized reasoning trajectories, we investigate the latent planning strength of LLMs, through our probing method, Tele-Lens , applying to hidden states across diverse task domains. Our empirical results indicate that LLMs exhibit a myopic horizon, primarily conducting incremental transitions without precise global planning. Leveraging this characteristic, we propose a hypothesis on enhancing uncertainty estimation of CoT, which we validate that a small subset of CoT positions can effectively represent the uncertainty of the entire path. We further underscore the significance of exploiting CoT dynamics , and demonstrate that automatic recognition of CoT bypass can be achieved without performance degradation. Our code, data and models are released at https://github.com/lxucs/ tele-lens .",
    "summary_en": "Research investigates latent planning dynamics in large language models through a probing method called Tele-Lens, revealing limited global planning and enabling improved uncertainty estimation and CoT bypass recognition.",
    "summary_zh": "研究通过名为 Tele-Lens 的探测方法探究大型语言模型中的潜在规划动态，揭示了有限的全局规划现象，并实现了改进的不确定性估计和 CoT 绕过识别。",
    "upvotes": 70
  },
  {
    "id": "2602.02660",
    "date": "2026-02-04",
    "title": "MARS: Modular Agent with Reflective Search for Automated AI Research",
    "authors": "Jiefeng Chen Bhavana Dalvi Mishra Jaehyun Nam Rui Meng Tomas Pfister Jinsung Yoon",
    "abstract": "MARS is a modular AI research automation framework that uses budget-aware planning, modular construction, and reflective memory to achieve state-of-the-art performance in autonomous machine learning research. Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that ignore execution costs and causal factors. We introduce MARS (Modular Agent with Reflective Search), a framework optimized for autonomous AI research. MARS relies on three pillars: (1) Budget-Aware Planning via cost-constrained Monte Carlo Tree Search ( MCTS ) to explicitly balance performance with execution expense; (2) Modular Construction , employing a \"Design-Decompose-Implement\" pipeline to manage complex research repositories; and (3) Comparative Reflective Memory , which addresses credit assignment by analyzing solution differences to distill high-signal insights. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench under comparable settings, maintaining competitiveness with the global leaderboard's top methods. Furthermore, the system exhibits qualitative \"Aha!\" moments, where 63% of all utilized lessons originate from cross-branch transfer , demonstrating that the agent effectively generalizes insights across search paths.",
    "summary_en": "MARS is a modular AI research automation framework that uses budget-aware planning, modular construction, and reflective memory to achieve state-of-the-art performance in autonomous machine learning research.",
    "summary_zh": "MARS是一个模块化的人工智能研究自动化框架，采用预算感知规划、模块化构建和反思性记忆，在自主机器学习研究中实现了最先进的性能。",
    "upvotes": 63
  },
  {
    "id": "2602.03796",
    "date": "2026-02-04",
    "title": "3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation",
    "authors": "Zhixue Fang Xu He Songlin Tang Haoxian Zhang Qingfeng Li Xiaoqiang Liu Pengfei Wan Kun Gai",
    "abstract": "3DiMo enables view-agnostic human motion control in video generation by training a motion encoder alongside a pretrained video generator to distill driving frames into compact motion tokens that align with the generator's spatial priors. Existing methods for human motion control in video generation typically rely on either 2D poses or explicit 3D parametric models (e.g., SMPL ) as control signals. However, 2D poses rigidly bind motion to the driving viewpoint, precluding novel-view synthesis. Explicit 3D models, though structurally informative, suffer from inherent inaccuracies (e.g., depth ambiguity and inaccurate dynamics) which, when used as a strong constraint, override the powerful intrinsic 3D awareness of large-scale video generator s. In this work, we revisit motion control from a 3D-aware perspective, advocating for an implicit, view-agnostic motion representation that naturally aligns with the generator's spatial priors rather than depending on externally reconstructed constraints. We introduce 3DiMo, which jointly trains a motion encoder with a pretrained video generator to distill driving frames into compact, view-agnostic motion tokens , injected semantically via cross-attention . To foster 3D awareness, we train with view-rich supervision (i.e., single-view, multi-view, and moving-camera videos), forcing motion consistency across diverse viewpoints. Additionally, we use auxiliary geometric supervision that leverages SMPL only for early initialization and is annealed to zero, enabling the model to transition from external 3D guidance to learning genuine 3D spatial motion understanding from the data and the generator's priors. Experiments confirm that 3DiMo faithfully reproduces driving motions with flexible, text-driven camera control , significantly surpassing existing methods in both motion fidelity and visual quality .",
    "summary_en": "3DiMo enables view-agnostic human motion control in video generation by training a motion encoder alongside a pretrained video generator to distill driving frames into compact motion tokens that align with the generator's spatial priors.",
    "summary_zh": "3DiMo通过联合训练运动编码器与预训练视频生成器，将驱动帧蒸馏为与生成器空间先验对齐的紧凑运动令牌，实现了视频生成中视角无关的人体运动控制。",
    "upvotes": 57
  },
  {
    "id": "2602.02619",
    "date": "2026-02-04",
    "title": "daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently",
    "authors": "Mohan Jiang Dayuan Fu Junhao Shi Ji Zeng Weiye Si Keyu Li Xuefeng Li Yang Xiao Wenjie Li Dequan Wang Pengfei Liu",
    "abstract": "Large language models face challenges in long-horizon agentic workflows due to lack of authentic long-dependency training data, which is addressed by leveraging pull request sequences for structured supervision through progressive decomposition, consistency enforcement, and refinement from bug-fix histories. While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics --existing synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories . Building on this, we propose daVinci-Agency , which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits , (2) long-term consistency enforcement through unified functional objectives , and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency 's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial--averaging 85k tokens and 116 tool calls--yet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon . Beyond benchmark performance, our analysis confirms...",
    "summary_en": "Large language models face challenges in long-horizon agentic workflows due to lack of authentic long-dependency training data, which is addressed by leveraging pull request sequences for structured supervision through progressive decomposition, consistency enforcement, and refinement from bug-fix histories.",
    "summary_zh": "大语言模型因缺乏真实长依赖训练数据而在长程智能体工作流中面临挑战，该研究通过利用 Pull Request 序列进行结构化监督来解决这一问题，具体方法包括渐进式分解、一致性约束以及基于错误修复历史的优化。",
    "upvotes": 50
  },
  {
    "id": "2602.01630",
    "date": "2026-02-04",
    "title": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks",
    "authors": "Bohan Zeng Kaixin Zhu Daili Hua Bozhou Li Chengzhuo Tong Yuran Wang Xinyi Huang Yifan Dai Zixiang Zhang Yifan Yang Zhou Liu Hao Liang Xiaochen Ma Ruichuan An Tianyi Bai Hongcheng Gao Junbo Niu Yang Shi Xinlong Chen Yue Ding Minglei Shi Kai Zeng",
    "abstract": "Current world models lack unified frameworks despite task-specific advances, necessitating a comprehensive approach integrating interaction, perception, symbolic reasoning, and spatial representation. World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction , 3D estimation , or symbol grounding , rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models . We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation . This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.",
    "summary_en": "Current world models lack unified frameworks despite task-specific advances, necessitating a comprehensive approach integrating interaction, perception, symbolic reasoning, and spatial representation.",
    "summary_zh": "当前世界模型虽在特定任务上取得进展，但缺乏统一框架，因此需要一种整合交互、感知、符号推理与空间表征的综合方法。",
    "upvotes": 46
  },
  {
    "id": "2602.03139",
    "date": "2026-02-04",
    "title": "Diversity-Preserved Distribution Matching Distillation for Fast Visual Synthesis",
    "authors": "Tianhe Wu Ruibin Li Lei Zhang Kede Ma",
    "abstract": "A novel distillation framework called DP-DMD is introduced that preserves sample diversity in text-to-image generation by separating the roles of distilled steps, using v-prediction for diversity and standard DMD loss for quality refinement without additional computational overhead. Distribution matching distillation (DMD) aligns a multi-step generator with its few-step counterpart to enable high-quality generation under low inference cost. However, DMD tends to suffer from mode collapse , as its reverse-KL formulation inherently encourages mode-seeking behavior, for which existing remedies typically rely on perceptual or adversarial regularization, thereby incurring substantial computational overhead and training instability. In this work, we propose a role-separated distillation framework that explicitly disentangles the roles of distilled steps: the first step is dedicated to preserving sample diversity via a target-prediction (e.g., v-prediction ) objective, while subsequent steps focus on quality refinement under the standard DMD loss, with gradients from the DMD objective blocked at the first step. We term this approach Diversity-Preserved DMD (DP-DMD), which, despite its simplicity -- no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images -- preserves sample diversity while maintaining visual quality on par with state-of-the-art methods in extensive text-to-image experiments.",
    "summary_en": "A novel distillation framework called DP-DMD is introduced that preserves sample diversity in text-to-image generation by separating the roles of distilled steps, using v-prediction for diversity and standard DMD loss for quality refinement without additional computational overhead.",
    "summary_zh": "本文提出了一种名为 DP-DMD 的新型蒸馏框架，通过分离蒸馏步骤的角色，使用 v-prediction 保持多样性，并利用标准 DMD loss 进行质量优化，在不增加额外计算开销的情况下，实现文本到图像生成中的样本多样性保持。",
    "upvotes": 41
  },
  {
    "id": "2602.03419",
    "date": "2026-02-04",
    "title": "SWE-World: Building Software Engineering Agents in Docker-Free Environments",
    "authors": "Shuang Sun Huatong Song Lisheng Huang Jinhao Jiang Ran Le Zhihao Lv Zongchao Chen Yiwen Hu Wenyang Luo Wayne Xin Zhao Yang Song Hongteng Xu Tao Zhang Ji-Rong Wen",
    "abstract": "A Docker-free framework replaces physical execution environments with learned surrogates for training software engineering agents, enabling efficient training and test-time scaling without costly container setup. Recent advances in large language models (LLMs) have enabled software engineering agents to tackle complex code modification tasks. Most existing approaches rely on execution feedback from containerized environments, which require dependency-complete setup and physical execution of programs and tests. While effective, this paradigm is resource-intensive and difficult to maintain, substantially complicating agent training and limiting scalability. We propose SWE-World, a Docker-free framework that replaces physical execution environments with a learned surrogate for training and evaluating software engineering agents . SWE-World leverages LLM-based models trained on real agent-environment interaction data to predict intermediate execution outcomes and final test feedback, enabling agents to learn without interacting with physical containerized environments. This design preserves the standard agent-environment interaction loop while eliminating the need for costly environment construction and maintenance during agent optimization and evaluation. Furthermore, because SWE-World can simulate the final evaluation outcomes of candidate trajectories without real submission, it enables selecting the best solution among multiple test-time attempts, thereby facilitating effective test-time scaling (TTS) in software engineering tasks. Experiments on SWE-bench Verified demonstrate that SWE-World raises Qwen2.5-Coder-32B from 6.2\\% to 52.0\\% via Docker-free SFT, 55.0\\% with Docker-free RL, and 68.2\\% with further TTS. The code is available at https://github.com/RUCAIBox/SWE-World",
    "summary_en": "A Docker-free framework replaces physical execution environments with learned surrogates for training software engineering agents, enabling efficient training and test-time scaling without costly container setup.",
    "summary_zh": "一种无需Docker的框架，用学习得到的替代模型取代物理执行环境以训练软件工程智能体，实现高效训练与测试时扩展，且无需昂贵的容器配置。",
    "upvotes": 39
  },
  {
    "id": "2602.03411",
    "date": "2026-02-04",
    "title": "SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training",
    "authors": "Huatong Song Lisheng Huang Shuang Sun Jinhao Jiang Ran Le Daixuan Cheng Guoxin Chen Yiwen Hu Zongchao Chen Wayne Xin Zhao Yang Song Tao Zhang Ji-Rong Wen",
    "abstract": "SWE-Master presents a reproducible framework for developing software engineering agents through systematic optimization across multiple stages of agent development, achieving superior performance on software task resolution benchmarks.",
    "summary_en": "SWE-Master presents a reproducible framework for developing software engineering agents through systematic optimization across multiple stages of agent development, achieving superior performance on software task resolution benchmarks.",
    "summary_zh": "SWE-Master提出了一种可复现的框架，通过在智能体开发多阶段进行系统化优化来开发软件工程智能体，在软件任务解决基准测试中取得了优异性能。",
    "upvotes": 37
  },
  {
    "id": "2602.03048",
    "date": "2026-02-04",
    "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs",
    "authors": "Zhiyuan Yao Yi-Kai Zhang Yuxin Chen Yueqing Sun Zishan Xu Yu Yang Tianhao Hu Qi Gu Hui Su Xunliang Cai",
    "abstract": "CoBA-RL adapts rollout budget allocation for LLM training by evaluating sample training value and optimizing resource distribution through a capability-oriented value function and greedy strategy.",
    "summary_en": "CoBA-RL adapts rollout budget allocation for LLM training by evaluating sample training value and optimizing resource distribution through a capability-oriented value function and greedy strategy.",
    "summary_zh": "CoBA-RL 通过评估样本训练价值，并借助面向能力的价值函数与贪心策略优化资源分配，自适应调整 LLM 训练的 rollout 预算分配。",
    "upvotes": 33
  },
  {
    "id": "2602.03845",
    "date": "2026-02-04",
    "title": "Parallel-Probe: Towards Efficient Parallel Thinking via 2D Probing",
    "authors": "Tong Zheng Chengsong Huang Runpeng Dai Yun He Rui Liu Xin Ni Huiwen Bao Kaishen Wang Hongtu Zhu Jiaxin Huang Furong Huang Heng Huang",
    "abstract": "Parallel-Probe is a training-free controller that optimizes parallel thinking by using consensus-based early stopping and deviation-based branch pruning to reduce computational costs while maintaining accuracy. Parallel thinking has emerged as a promising paradigm for reasoning, yet it imposes significant computational burdens. Existing efficiency methods primarily rely on local, per-trajectory signals and lack principled mechanisms to exploit global dynamics across parallel branches. We introduce 2D probing, an interface that exposes the width-depth dynamics of parallel thinking by periodically eliciting intermediate answers from all branches. Our analysis reveals three key insights: non-monotonic scaling across width-depth allocations, heterogeneous reasoning branch lengths, and early stabilization of global consensus. Guided by these insights, we introduce Parallel-Probe, a training-free controller designed to optimize online parallel thinking . Parallel-Probe employs consensus-based early stopping to regulate reasoning depth and deviation-based branch pruning to dynamically adjust width. Extensive experiments across three benchmarks and multiple models demonstrate that Parallel-Probe establishes a superior Pareto frontier for test-time scaling . Compared to standard majority voting , it reduces sequential tokens by up to 35.8% and total token cost by over 25.8% while maintaining competitive accuracy.",
    "summary_en": "Parallel-Probe is a training-free controller that optimizes parallel thinking by using consensus-based early stopping and deviation-based branch pruning to reduce computational costs while maintaining accuracy.",
    "summary_zh": "Parallel-Probe是一种免训练的控制器，通过基于共识的早期停止和基于偏差的分支剪枝来优化并行思考，在保持准确性的同时降低计算成本。",
    "upvotes": 26
  },
  {
    "id": "2602.03619",
    "date": "2026-02-04",
    "title": "Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation",
    "authors": "Changze Lv Jie Zhou Wentao Zhao Jingwen Xu Zisu Huang Muzhao Tian Shihan Dou Tao Gui Le Tian Xiao Zhou Xiaoqing Zheng Xuanjing Huang",
    "abstract": "",
    "summary_en": "RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation (2026)",
    "summary_zh": "RubricHub：通过自动化粗到精生成构建的全面且高区分度Rubric数据集（2026）",
    "upvotes": 26
  },
  {
    "id": "2602.02380",
    "date": "2026-02-04",
    "title": "Unified Personalized Reward Model for Vision Generation",
    "authors": "Yibin Wang Yuhang Zang Feng Han Jiazi Bu Yujie Zhou Cheng Jin Jiaqi Wang",
    "abstract": "UnifiedReward-Flex combines reward modeling with flexible, context-adaptive reasoning to improve visual generation by dynamically constructing hierarchical assessments based on semantic intent and visual evidence. Recent advancements in multimodal reward models (RMs) have significantly propelled the development of visual generation . Existing frameworks typically adopt Bradley-Terry-style preference modeling or leverage generative VLMs as judges, and subsequently optimize visual generation models via reinforcement learning . However, current RMs suffer from inherent limitations: they often follow a one-size-fits-all paradigm that assumes a monolithic preference distribution or relies on fixed evaluation rubrics. As a result, they are insensitive to content-specific visual cues, leading to systematic misalignment with subjective and context-dependent human preferences. To this end, inspired by human assessment, we propose UnifiedReward-Flex, a unified personalized reward model for vision generation that couples reward modeling with flexible and context-adaptive reasoning . Specifically, given a prompt and the generated visual content, it first interprets the semantic intent and grounds on visual evidence , then dynamically constructs a hierarchical assessment by instantiating fine-grained criteria under both predefined and self-generated high-level dimensions. Our training pipeline follows a two-stage process: (1) we first distill structured, high-quality reasoning traces from advanced closed-source VLMs to bootstrap SFT, equipping the model with flexible and context-adaptive reasoning behaviors; (2) we then perform direct preference optimization (DPO) on carefully curated preference pairs to further strengthen reasoning fidelity and discriminative alignment. To validate the effectiveness, we integrate UnifiedReward-Flex into the GRPO framework for image and video synthesis , and extensive results demonstrate its superiority.",
    "summary_en": "UnifiedReward-Flex combines reward modeling with flexible, context-adaptive reasoning to improve visual generation by dynamically constructing hierarchical assessments based on semantic intent and visual evidence.",
    "summary_zh": "UnifiedReward-Flex 结合奖励建模与灵活、上下文自适应的推理，基于语义意图和视觉证据动态构建分层评估以改进视觉生成。",
    "upvotes": 20
  },
  {
    "id": "2602.02444",
    "date": "2026-02-04",
    "title": "RANKVIDEO: Reasoning Reranking for Text-to-Video Retrieval",
    "authors": "Tyler Skow Alexander Martin Benjamin Van Durme Rama Chellappa Reno Kriz",
    "abstract": "RANKVIDEO is a reasoning-based video retrieval system that improves upon traditional two-stage frameworks through explicit query-video pair analysis and a multi-objective training approach. Reranking is a critical component of modern retrieval systems, which typically pair an efficient first-stage retriever with a more expressive model to refine results. While large reasoning models have driven rapid progress in text-centric reranking , reasoning-based reranking for video retrieval remains underexplored. To address this gap, we introduce RANKVIDEO, a reasoning-based reranker for video retrieval that explicitly reasons over query-video pairs using video content to assess relevance. RANKVIDEO is trained using a two-stage curriculum consisting of perception-grounded supervised fine-tuning followed by reranking training that combines pointwise , pairwise , and teacher confidence distillation objectives, and is supported by a data synthesis pipeline for constructing reasoning-intensive query-video pairs. Experiments on the large-scale MultiVENT 2.0 benchmark demonstrate that RANKVIDEO consistently improves retrieval performance within a two-stage framework, yielding an average improvement of 31% on nDCG@10 and outperforming text-only and vision-language reranking alternatives, while more efficient.",
    "summary_en": "RANKVIDEO is a reasoning-based video retrieval system that improves upon traditional two-stage frameworks through explicit query-video pair analysis and a multi-objective training approach.",
    "summary_zh": "RANKVIDEO是一种基于推理的视频检索系统，通过显式的查询-视频对分析和多目标训练方法改进了传统两阶段框架。",
    "upvotes": 18
  },
  {
    "id": "2602.03086",
    "date": "2026-02-04",
    "title": "Neural Predictor-Corrector: Solving Homotopy Problems with Reinforcement Learning",
    "authors": "Jiayao Mai Bangyan Liao Zhenjun Zhao Yingping Zeng Haoang Li Javier Civera Tailin Wu Yi Zhou Peidong Liu",
    "abstract": "Neural Predictor-Corrector framework unifies homotopy methods across multiple domains and outperforms classical approaches through learned policies and amortized training. The Homotopy paradigm , a general principle for solving challenging problems, appears across diverse domains such as robust optimization , global optimization , polynomial root-finding, and sampling . Practical solvers for these problems typically follow a predictor-corrector (PC) structure, but rely on hand-crafted heuristics for step sizes and iteration termination, which are often suboptimal and task-specific. To address this, we unify these problems under a single framework, which enables the design of a general neural solver . Building on this unified view, we propose Neural Predictor-Corrector (NPC), which replaces hand-crafted heuristics with automatically learned policies. NPC formulates policy selection as a sequential decision-making problem and leverages reinforcement learning to automatically discover efficient strategies. To further enhance generalization, we introduce an amortized training mechanism, enabling one-time offline training for a class of problems and efficient online inference on new instances. Experiments on four representative homotopy problems demonstrate that our method generalizes effectively to unseen instances. It consistently outperforms classical and specialized baselines in efficiency while demonstrating superior stability across tasks, highlighting the value of unifying homotopy methods into a single neural framework.",
    "summary_en": "Neural Predictor-Corrector framework unifies homotopy methods across multiple domains and outperforms classical approaches through learned policies and amortized training.",
    "summary_zh": "神经预测-校正框架统一了跨多个领域的同伦方法，并通过学习策略与摊销训练优于经典方法。",
    "upvotes": 16
  },
  {
    "id": "2602.02636",
    "date": "2026-02-04",
    "title": "WideSeek: Advancing Wide Research via Multi-Agent Scaling",
    "authors": "Ziyang Huang Haolin Ren Xiaowei Yuan Jiawei Wang Zhongtao Jiang Kun Xu Shizhu He Jun Zhao Kang Liu",
    "abstract": "Wide Research advances search intelligence through a dedicated benchmark and multi-agent architecture that enables parallel information retrieval under complex constraints. Search intelligence is evolving from Deep Research to Wide Research , a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedicated benchmarks and optimization methodologies for search breadth. To address these challenges, we take a deep dive into Wide Research from two perspectives: Data Pipeline and Agent Optimization. First, we produce WideSeekBench , a General Broad Information Seeking ( GBIS ) benchmark constructed via a rigorous multi-phase data pipeline to ensure diversity across the target information volume, logical constraints, and domains. Second, we introduce WideSeek, a dynamic hierarchical multi-agent architecture that can autonomously fork parallel sub-agents based on task requirements. Furthermore, we design a unified training framework that linearizes multi-agent trajectories and optimizes the system using end-to-end RL . Experimental results demonstrate the effectiveness of WideSeek and multi-agent RL, highlighting that scaling the number of agents is a promising direction for advancing the Wide Research paradigm.",
    "summary_en": "Wide Research advances search intelligence through a dedicated benchmark and multi-agent architecture that enables parallel information retrieval under complex constraints.",
    "summary_zh": "Wide Research 通过专用基准与多智能体架构推进搜索智能，实现复杂约束下的并行信息检索。",
    "upvotes": 15
  },
  {
    "id": "2602.01362",
    "date": "2026-02-04",
    "title": "Balancing Understanding and Generation in Discrete Diffusion Models",
    "authors": "Yue Liu Yuzhong Zhao Zheyong Xie Qixiang Ye Jianbin Jiao Yao Hu Shaosheng Cao Yunfan Liu",
    "abstract": "XDLM unifies Masked Diffusion Language Models and Uniform-noise Diffusion Language Models through a stationary noise kernel, achieving improved performance in both semantic understanding and generation quality. In discrete generative modeling, two dominant paradigms demonstrate divergent capabilities: Masked Diffusion Language Models (MDLM) excel at semantic understanding and zero-shot generalization, whereas Uniform-noise Diffusion Language Models (UDLM) achieve strong few-step generation quality, yet neither attains balanced performance across both dimensions. To address this, we propose XDLM, which bridges the two paradigms via a stationary noise kernel . XDLM offers two key contributions: (1) it provides a principled theoretical unification of MDLM and UDLM, recovering each paradigm as a special case; and (2) an alleviated memory bottleneck enabled by an algebraic simplification of the posterior probabilities . Experiments demonstrate that XDLM advances the Pareto frontier between understanding capability and generation quality. Quantitatively, XDLM surpasses UDLM by 5.4 points on zero-shot text benchmarks and outperforms MDLM in few-step image generation ( FID 54.1 vs. 80.8). When scaled to tune an 8B-parameter large language model , XDLM achieves 15.0 MBPP in just 32 steps, effectively doubling the baseline performance. Finally, analysis of training dynamics reveals XDLM's superior potential for long-term scaling. Code is available at https://github.com/MzeroMiko/XDLM",
    "summary_en": "XDLM unifies Masked Diffusion Language Models and Uniform-noise Diffusion Language Models through a stationary noise kernel, achieving improved performance in both semantic understanding and generation quality.",
    "summary_zh": "XDLM 通过平稳噪声核统一了掩码扩散语言模型与均匀噪声扩散语言模型，在语义理解和生成质量上均取得了性能提升。",
    "upvotes": 14
  },
  {
    "id": "2602.03747",
    "date": "2026-02-04",
    "title": "LIVE: Long-horizon Interactive Video World Modeling",
    "authors": "Junchao Huang Ziyang Ye Xinting Hu Tianyu He Guiyu Zhang Shaoshuai Shi Jiang Bian Li Jiang",
    "abstract": "LIVE is a long-horizon video world model that uses cycle-consistency and diffusion loss to control error accumulation during extended video generation. Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective , thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.",
    "summary_en": "LIVE is a long-horizon video world model that uses cycle-consistency and diffusion loss to control error accumulation during extended video generation.",
    "summary_zh": "LIVE是一种长程视频世界模型，利用循环一致性和扩散损失控制长视频生成中的误差累积。",
    "upvotes": 12
  },
  {
    "id": "2602.03216",
    "date": "2026-02-04",
    "title": "Token Sparse Attention: Efficient Long-Context Inference with Interleaved Token Selection",
    "authors": "Dongwon Jo Beomseok Kang Jiwon Song Jae-Joon Kim",
    "abstract": "Token Sparse Attention enables efficient long-context inference by dynamically compressing and decompressing attention tensors at the token level, achieving significant speedup with minimal accuracy loss. The quadratic complexity of attention remains the central bottleneck in long-context inference for large language models. Prior acceleration methods either sparsify the attention map with structured patterns or permanently evict tokens at specific layers, which can retain irrelevant tokens or rely on irreversible early decisions despite the layer-/head-wise dynamics of token importance. In this paper, we propose Token Sparse Attention , a lightweight and dynamic token-level sparsification mechanism that compresses per-head Q, K, V to a reduced token set during attention and then decompresses the output back to the original sequence, enabling token information to be reconsidered in subsequent layers. Furthermore, Token Sparse Attention exposes a new design point at the intersection of token selection and sparse attention . Our approach is fully compatible with dense attention implementations, including Flash Attention , and can be seamlessly composed with existing sparse attention kernels. Experimental results show that Token Sparse Attention consistently improves accuracy-latency trade-off, achieving up to times3.23 attention speedup at 128K context with less than 1% accuracy degradation. These results demonstrate that dynamic and interleaved token-level sparsification is a complementary and effective strategy for scalable long-context inference .",
    "summary_en": "Token Sparse Attention enables efficient long-context inference by dynamically compressing and decompressing attention tensors at the token level, achieving significant speedup with minimal accuracy loss.",
    "summary_zh": "Token稀疏注意力通过在Token级别动态压缩和解压注意力张量，实现高效的长上下文推理，在精度损失极小的情况下获得显著加速。",
    "upvotes": 12
  },
  {
    "id": "2601.21244",
    "date": "2026-02-04",
    "title": "Less Noise, More Voice: Reinforcement Learning for Reasoning via Instruction Purification",
    "authors": "Yiju Guo Tianyi Hu Zexu Sun Yankai Lin",
    "abstract": "LENS framework improves reinforcement learning with verifiable rewards by identifying and removing interference tokens to enhance exploration efficiency and training stability. Reinforcement Learning with Verifiable Rewards (RLVR) has advanced LLM reasoning, but remains constrained by inefficient exploration under limited rollout budget s, leading to low sampling success and unstable training in complex tasks. We find that many exploration failures arise not from problem difficulty, but from a small number of prompt tokens that introduce interference. Building on this insight, we propose the Less Noise Sampling Framework ( LENS ), which first prompts by identifying and removing interference tokens . then transfers successful rollouts from the purification process to supervise policy optimization on the original noisy prompts, enabling the model to learn to ignore interference in the real-world, noisy prompting settings. Experimental results show that LENS significantly outperforms GRPO , delivering higher performance and faster convergence, with a 3.88% average gain and over 1.6times speedup. Our work highlights the critical role of pruning interference tokens in improving rollout efficiency, offering a new perspective for RLVR research.",
    "summary_en": "LENS framework improves reinforcement learning with verifiable rewards by identifying and removing interference tokens to enhance exploration efficiency and training stability.",
    "summary_zh": "LENS框架通过识别并移除干扰token来改进可验证奖励的强化学习，从而增强探索效率和训练稳定性。",
    "upvotes": 12
  },
  {
    "id": "2602.03183",
    "date": "2026-02-04",
    "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch",
    "authors": "Hyunwoo Kim Niloofar Mireshghallah Michael Duan Rui Xin Shuyue Stella Li Jaehun Jung David Acuna Qi Pang Hanshen Xiao G. Edward Suh Sewoong Oh Yulia Tsvetkov Pang Wei Koh Yejin Choi",
    "abstract": "A large-scale synthetic dataset called Privasis is introduced to address privacy concerns in AI research, enabling more effective text sanitization with compact models that outperform existing large language models. Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models , such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.",
    "summary_en": "A large-scale synthetic dataset called Privasis is introduced to address privacy concerns in AI research, enabling more effective text sanitization with compact models that outperform existing large language models.",
    "summary_zh": "为解决AI研究中的隐私问题，研究人员引入了名为Privasis的大规模合成数据集，使紧凑模型能够更有效地进行文本脱敏，性能优于现有大语言模型。",
    "upvotes": 11
  },
  {
    "id": "2602.03798",
    "date": "2026-02-04",
    "title": "FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation",
    "authors": "Zimu Lu Houxing Ren Yunqiao Yang Ke Wang Zhuofan Zong Mingjie Zhan Hongsheng Li",
    "abstract": "A unified agent system called FullStack-Agent is introduced to assist non-expert users in developing complex interactive websites by addressing full-stack development challenges through enhanced planning, code editing, and self-improving capabilities. Assisting non-expert users to develop complex interactive websites has become a popular task for LLM-powered code agents. However, existing code agents tend to only generate frontend web pages, masking the lack of real full-stack data processing and storage with fancy visual effects. Notably, constructing production-level full-stack web applications is far more challenging than only generating frontend web pages, demanding careful control of data flow, comprehensive understanding of constantly updating packages and dependencies, and accurate localization of obscure bugs in the codebase. To address these difficulties, we introduce FullStack-Agent, a unified agent system for full-stack agentic coding that consists of three parts: (1) FullStack-Dev, a multi-agent framework with strong planning, code editing , codebase navigation , and bug localization abilities. (2) FullStack-Learn, an innovative data-scaling and self-improving method that back-translates crawled and synthesized website repositories to improve the backbone LLM of FullStack-Dev. (3) FullStack-Bench, a comprehensive benchmark that systematically tests the frontend , backend and database functionalities of the generated website. Our FullStack-Dev outperforms the previous state-of-the-art method by 8.7%, 38.2%, and 15.9% on the frontend , backend , and database test cases respectively. Additionally, FullStack-Learn raises the performance of a 30B model by 9.7%, 9.5%, and 2.8% on the three sets of test cases through self-improvement, demonstrating the effectiveness of our approach. The code is released at https://github.com/mnluzimu/FullStack-Agent.",
    "summary_en": "A unified agent system called FullStack-Agent is introduced to assist non-expert users in developing complex interactive websites by addressing full-stack development challenges through enhanced planning, code editing, and self-improving capabilities.",
    "summary_zh": "本文介绍了一种名为FullStack-Agent的统一智能体系统，该系统通过增强规划、代码编辑和自我改进能力来应对全栈开发挑战，协助非专业用户开发复杂的交互式网站。",
    "upvotes": 10
  },
  {
    "id": "2602.02676",
    "date": "2026-02-04",
    "title": "AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process",
    "authors": "Xintong Zhang Xiaowen Zhang Jongrong Wu Zhi Gao Shilin Yan Zhenxin Diao Kunpeng Gao Xuanyan Chen Yuwei Wu Yunde Jia Qing Li",
    "abstract": "AdaptMMBench presents a comprehensive benchmark for evaluating adaptive multimodal reasoning in Vision-Language Models, measuring reasoning mode selection rationality through dynamic difficulty assessment and multi-dimensional process evaluation. Adaptive multimodal reasoning has emerged as a promising frontier in Vision-Language Models (VLMs), aiming to dynamically modulate between tool-augmented visual reasoning and text reasoning to enhance both effectiveness and efficiency. However, existing evaluations rely on static difficulty labels and simplistic metrics, which fail to capture the dynamic nature of difficulty relative to varying model capacities. Consequently, they obscure the distinction between adaptive mode selection and general performance while neglecting fine-grained process analyses. In this paper, we propose AdaptMMBench, a comprehensive benchmark for adaptive multimodal reasoning across five domains: real-world, OCR, GUI, knowledge, and math, encompassing both direct perception and complex reasoning tasks. AdaptMMBench utilizes a Matthews Correlation Coefficient (MCC) metric to evaluate the selection rationality of different reasoning modes, isolating this meta-cognition ability by dynamically identifying task difficulties based on models' capability boundaries. Moreover, AdaptMMBench facilitates multi-dimensional process evaluation across key step coverage , tool effectiveness , and computational efficiency . Our evaluation reveals that while adaptive mode selection scales with model capacity , it notably decouples from final accuracy. Conversely, key step coverage aligns with performance, though tool effectiveness remains highly inconsistent across model architectures.",
    "summary_en": "AdaptMMBench presents a comprehensive benchmark for evaluating adaptive multimodal reasoning in Vision-Language Models, measuring reasoning mode selection rationality through dynamic difficulty assessment and multi-dimensional process evaluation.",
    "summary_zh": "AdaptMMBench 提出了一个用于评估视觉-语言模型中自适应多模态推理的综合基准，通过动态难度评估和多维过程评估来衡量推理模式选择的合理性。",
    "upvotes": 10
  },
  {
    "id": "2602.00747",
    "date": "2026-02-04",
    "title": "Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training",
    "authors": "Shengrui Li Fei Zhao Kaiyan Zhao Jieying Ye Haifeng Liu Fangcheng Shi Zheyong Xie Yao Hu Shaosheng Cao",
    "abstract": "DeMix is a framework that uses model merging to predict optimal data ratios for LLM pre-training, decoupling search from training costs to improve mixture discovery efficiency. Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-training , where models must balance general competence with proficiency on hard tasks such as math and code. However, identifying an optimal mixture remains an open challenge, as existing approaches either rely on unreliable tiny-scale proxy experiments or require prohibitively expensive large-scale exploration. To address this, we propose Decouple Searching from Training Mix (DeMix), a novel framework that leverages model merging to predict optimal data ratios. Instead of training proxy models for every sampled mixture, DeMix trains component models on candidate datasets at scale and derives data mixture proxies via weighted model merging . This paradigm decouples search from training costs , enabling evaluation of unlimited sampled mixtures without extra training burden and thus facilitating better mixture discovery through more search trials . Extensive experiments demonstrate that DeMix breaks the trade-off between sufficiency, accuracy and efficiency, obtaining the optimal mixture with higher benchmark performance at lower search cost. Additionally, we release the DeMix Corpora, a comprehensive 22T-token dataset comprising high-quality pre-training data with validated mixtures to facilitate open research. Our code and DeMix Corpora is available at https://github.com/Lucius-lsr/DeMix.",
    "summary_en": "DeMix is a framework that uses model merging to predict optimal data ratios for LLM pre-training, decoupling search from training costs to improve mixture discovery efficiency.",
    "summary_zh": "DeMix是一种利用模型合并预测LLM预训练最优数据配比的框架，通过将搜索与训练成本解耦来提升混合发现效率。",
    "upvotes": 9
  },
  {
    "id": "2602.04541",
    "date": "2026-02-04",
    "title": "LycheeDecode: Accelerating Long-Context LLM Inference via Hybrid-Head Sparse Decoding",
    "authors": "Gang Lin Dongfang Li Zhuoen Chen Yukun Shi Xuhui Chen Baotian Hu Min Zhang",
    "abstract": "LycheeDecode improves long-context LLM decoding efficiency through a fine-grained hybrid-head attention mechanism that dynamically identifies crucial tokens while maintaining attention head diversity.",
    "summary_en": "LycheeDecode improves long-context LLM decoding efficiency through a fine-grained hybrid-head attention mechanism that dynamically identifies crucial tokens while maintaining attention head diversity.",
    "summary_zh": "LycheeDecode通过细粒度混合头注意力机制提升长上下文LLM的解码效率，动态识别关键token并保持注意力头的多样性。",
    "upvotes": 8
  },
  {
    "id": "2602.03709",
    "date": "2026-02-04",
    "title": "No Shortcuts to Culture: Indonesian Multi-hop Question Answering for Complex Cultural Understanding",
    "authors": "Vynska Amalia Permadi Xingwei Tan Nafise Sadat Moosavi Nikos Aletras",
    "abstract": "Multi-hop question answering dataset ID-MoCQA assesses cultural understanding in large language models through Indonesian traditions with diverse reasoning chains. Understanding culture requires reasoning across context, tradition, and implicit social knowledge, far beyond recalling isolated facts. Yet most culturally focused question answering (QA) benchmarks rely on single-hop questions, which may allow models to exploit shallow cues rather than demonstrate genuine cultural reasoning. In this work, we introduce ID-MoCQA, the first large-scale multi-hop QA dataset for assessing the cultural understanding of large language models (LLMs), grounded in Indonesian traditions and available in both English and Indonesian. We present a new framework that systematically transforms single-hop cultural questions into multi-hop reasoning chains spanning six clue types (e.g., commonsense, temporal, geographical). Our multi-stage validation pipeline , combining expert review and LLM-as-a-judge filtering , ensures high-quality question-answer pairs. Our evaluation across state-of-the-art models reveals substantial gaps in cultural reasoning, particularly in tasks requiring nuanced inference. ID-MoCQA provides a challenging and essential benchmark for advancing the cultural competency of LLMs.",
    "summary_en": "Multi-hop question answering dataset ID-MoCQA assesses cultural understanding in large language models through Indonesian traditions with diverse reasoning chains.",
    "summary_zh": "多跳问答数据集ID-MoCQA通过包含多样化推理链的印尼传统评估大语言模型的文化理解。",
    "upvotes": 8
  },
  {
    "id": "2602.01053",
    "date": "2026-02-04",
    "title": "LRAgent: Efficient KV Cache Sharing for Multi-LoRA LLM Agents",
    "authors": "Hyesung Jeon Hyeongju Ha Jae-Joon Kim",
    "abstract": "LRAgent is a KV cache sharing framework for multi-LoRA agents that decomposes cache into shared and adapter-dependent components, reducing memory and compute overhead while maintaining accuracy.",
    "summary_en": "LRAgent is a KV cache sharing framework for multi-LoRA agents that decomposes cache into shared and adapter-dependent components, reducing memory and compute overhead while maintaining accuracy.",
    "summary_zh": "LRAgent是一种面向多LoRA智能体的KV缓存共享框架，通过将缓存分解为共享组件和适配器相关组件，在保持准确性的同时降低内存与计算开销。",
    "upvotes": 8
  },
  {
    "id": "2602.03677",
    "date": "2026-02-04",
    "title": "Instruction Anchors: Dissecting the Causal Dynamics of Modality Arbitration",
    "authors": "Yu Zhang Mufan Xu Xuefeng Bai Kehai chen Pengfei Zhang Yang Xiang Min Zhang",
    "abstract": "Research reveals that instruction tokens act as structural anchors in multimodal large language models, with shallow layers performing non-selective information transfer and deep layers resolving modality competition guided by instruction intent. Modality following serves as the capacity of multimodal large language models (MLLMs) to selectively utilize multimodal contexts based on user instructions. It is fundamental to ensuring safety and reliability in real-world deployments. However, the underlying mechanisms governing this decision-making process remain poorly understood. In this paper, we investigate its working mechanism through an information flow lens . Our findings reveal that instruction tokens function as structural anchors for modality arbitration : Shallow attention layers perform non-selective information transfer, routing multimodal cues to these anchors as a latent buffer; Modality competition is resolved within deep attention layers guided by the instruction intent, while MLP layers exhibit semantic inertia , acting as an adversarial force. Furthermore, we identify a sparse set of specialized attention heads that drive this arbitration. Causal interventions demonstrate that manipulating a mere 5% of these critical heads can decrease the modality-following ratio by 60% through blocking, or increase it by 60% through targeted amplification of failed samples. Our work provides a substantial step toward model transparency and offers a principled framework for the orchestration of multimodal information in MLLMs.",
    "summary_en": "Research reveals that instruction tokens act as structural anchors in multimodal large language models, with shallow layers performing non-selective information transfer and deep layers resolving modality competition guided by instruction intent.",
    "summary_zh": "研究表明，指令token在多模态大语言模型中充当结构锚点，其中浅层执行非选择性信息传递，深层则在指令意图引导下解决模态竞争。",
    "upvotes": 7
  },
  {
    "id": "2602.03647",
    "date": "2026-02-04",
    "title": "Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration",
    "authors": "Bowei He Minda Hu Zenan Xu Hongru Wang Licheng Zong Yankai Chen Chen Ma Xue Liu Pluto Zhou Irwin King",
    "abstract": "Search-R2 framework improves language agent reasoning through Actor-Refiner collaboration with targeted interventions and fine-grained reward supervision for better credit assignment in reinforcement learning. Search-integrated reasoning enables language agents to transcend static parametric knowledge by actively querying external sources. However, training these agents via reinforcement learning is hindered by the multi-scale credit assignment problem: existing methods typically rely on sparse, trajectory-level rewards that fail to distinguish between high-quality reasoning and fortuitous guesses, leading to redundant or misleading search behaviors. To address this, we propose Search-R2, a novel Actor-Refiner collaboration framework that enhances reasoning through targeted intervention, with both components jointly optimized during training. Our approach decomposes the generation process into an Actor, which produces initial reasoning trajectories, and a Meta-Refiner, which selectively diagnoses and repairs flawed steps via a 'cut-and-regenerate' mechanism. To provide fine-grained supervision, we introduce a hybrid reward design that couples outcome correctness with a dense process reward quantifying the information density of retrieved evidence. Theoretically, we formalize the Actor-Refiner interaction as a smoothed mixture policy , proving that selective correction yields strict performance gains over strong baselines. Extensive experiments across various general and multi-hop QA datasets demonstrate that Search-R2 consistently outperforms strong RAG and RL-based baselines across model scales, achieving superior reasoning accuracy with minimal overhead.",
    "summary_en": "Search-R2 framework improves language agent reasoning through Actor-Refiner collaboration with targeted interventions and fine-grained reward supervision for better credit assignment in reinforcement learning.",
    "summary_zh": "Search-R2框架通过Actor-Refiner协作、针对性干预和细粒度奖励监督优化强化学习中的信用分配，从而提升语言智能体推理能力。",
    "upvotes": 7
  },
  {
    "id": "2602.02537",
    "date": "2026-02-04",
    "title": "WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models",
    "authors": "Runjie Zhou Youbo Shao Haoyu Lu Bowei Xing Tongtong Bai Yujie Chen Jie Zhao Lin Sui Haotian Yao Zijia Zhao Hao Yang Haoning Wu Zaida Zhou Jinguo Zhu Zhiqi Huang Yiping Bao Yangyang Liu Y. Charles Xinyu Zhou",
    "abstract": "WorldVQA is a benchmark for evaluating the visual world knowledge of multimodal large language models by separating visual knowledge retrieval from reasoning to measure memorized facts. We introduce WorldVQA, a benchmark designed to evaluate the atomic visual world knowledge of Multimodal Large Language Models (MLLMs). Unlike current evaluations, which often conflate visual knowledge retrieval with reasoning , WorldVQA decouples these capabilities to strictly measure \"what the model memorizes.\" The benchmark assesses the atomic capability of grounding and naming visual entities across a stratified taxonomy, spanning from common head-class objects to long-tail rarities. We expect WorldVQA to serve as a rigorous test for visual factuality , thereby establishing a standard for assessing the encyclopedic breadth and hallucination rates of current and next-generation frontier models.",
    "summary_en": "WorldVQA is a benchmark for evaluating the visual world knowledge of multimodal large language models by separating visual knowledge retrieval from reasoning to measure memorized facts.",
    "summary_zh": "WorldVQA是一个用于评估多模态大语言模型视觉世界知识的基准，通过分离视觉知识检索与推理来衡量记忆的事实。",
    "upvotes": 6
  },
  {
    "id": "2602.00359",
    "date": "2026-02-04",
    "title": "Position: Agentic Evolution is the Path to Evolving LLMs",
    "authors": "Minhua Lin Hanqing Lu Zhan Shi Bing He Rui Mao Zhiwei Zhang Zongyu Wu Xianfeng Tang Hui Liu Zhenwei Dai Xiang Zhang Suhang Wang Benoit Dumoulin Jian Pei",
    "abstract": "Large language models face limitations in adapting to changing real-world environments, necessitating a new approach called agentic evolution that treats deployment-time improvement as a goal-directed optimization process. As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inference-time compute improves static capability but does not close this train-deploy gap. We argue that addressing this limitation requires a new scaling axis-evolution. Existing deployment-time adaptation methods, whether parametric fine-tuning or heuristic memory accumulation , lack the strategic agency needed to diagnose failures and produce durable improvements. Our position is that agentic evolution represents the inevitable future of LLM adaptation, elevating evolution itself from a fixed pipeline to an autonomous evolver agent. We instantiate this vision in a general framework, A-Evolve , which treats deployment-time improvement as a deliberate, goal-directed optimization process over persistent system state. We further propose the evolution-scaling hypothesis : the capacity for adaptation scales with the compute allocated to evolution, positioning agentic evolution as a scalable path toward sustained, open-ended adaptation in the real world.",
    "summary_en": "Large language models face limitations in adapting to changing real-world environments, necessitating a new approach called agentic evolution that treats deployment-time improvement as a goal-directed optimization process.",
    "summary_zh": "大语言模型在适应不断变化的现实世界环境时面临局限性，需要一种称为智能体演化的新方法，将部署时的改进视为目标导向的优化过程。",
    "upvotes": 6
  },
  {
    "id": "2602.03837",
    "date": "2026-02-04",
    "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques",
    "authors": "David P. Woodruff Vincent Cohen-Addad Lalit Jain Jieming Mao Song Zuo MohammadHossein Bateni Simina Branzei Michael P. Brenner Lin Chen Ying Feng Lance Fortnow Gang Fu Ziyi Guan Zahra Hadizadeh Mohammad T. Hajiaghayi Mahdi JafariRaviz Adel Javanmard Karthik C. S. Ken-ichi Kawarabayashi Ravi Kumar Silvio Lattanzi Euiwoong Lee",
    "abstract": "Advanced AI models demonstrate capability in supporting expert-level mathematical discovery and scientific research through collaborative approaches involving proof verification and automated code execution. Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science , as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement , problem decomposition , and cross-disciplinary knowledge transfer . While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a \"neuro-symbolic\" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.",
    "summary_en": "Advanced AI models demonstrate capability in supporting expert-level mathematical discovery and scientific research through collaborative approaches involving proof verification and automated code execution.",
    "summary_zh": "先进AI模型展现出通过涉及证明验证和自动代码执行的协作方法支持专家级数学发现与科学研究的能力。",
    "upvotes": 5
  },
  {
    "id": "2602.03806",
    "date": "2026-02-04",
    "title": "Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation",
    "authors": "Ziru Chen Dongdong Chen Ruinan Jin Yingbin Liang Yujia Xie Huan Sun",
    "abstract": "Offline reinforcement learning method combines contextual bandit learning with partial trajectories to improve multi-turn code generation performance while reducing training costs.",
    "summary_en": "Offline reinforcement learning method combines contextual bandit learning with partial trajectories to improve multi-turn code generation performance while reducing training costs.",
    "summary_zh": "离线强化学习方法结合上下文赌博机学习与部分轨迹，提升多轮代码生成性能并降低训练成本。",
    "upvotes": 5
  },
  {
    "id": "2602.02905",
    "date": "2026-02-04",
    "title": "FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights",
    "authors": "Zhen Wang Fan Bai Zhongyan Luo Jinyan Su Kaiser Sun Xinle Yu Jieyuan Liu Kun Zhou Claire Cardie Mark Dredze Eric P. Xing Zhiting Hu",
    "abstract": "Researchers developed FIRE-Bench, a comprehensive evaluation framework that challenges autonomous agents to rediscover established scientific findings through complete research cycles involving hypothesis generation, experimentation, coding, and evidence-based conclusion drawing.",
    "summary_en": "Researchers developed FIRE-Bench, a comprehensive evaluation framework that challenges autonomous agents to rediscover established scientific findings through complete research cycles involving hypothesis generation, experimentation, coding, and evidence-based conclusion drawing.",
    "summary_zh": "研究人员开发了FIRE-Bench，这是一个全面的评估框架，用于挑战自主智能体通过包含假设生成、实验、编程和基于证据得出结论的完整研究周期，重新发现既定科学发现。",
    "upvotes": 5
  },
  {
    "id": "2602.02751",
    "date": "2026-02-04",
    "title": "Scaling Small Agents Through Strategy Auctions",
    "authors": "Lisa Alazraki William F. Shen Yoram Bachrach Akhil Mathur",
    "abstract": "Small language models struggle with complex tasks but can be effectively coordinated through a marketplace-inspired framework that reduces costs and improves performance through strategic bidding and self-improvement mechanisms. Small language models are increasingly viewed as a promising, cost-effective approach to agentic AI , with proponents claiming they are sufficiently capable for agentic workflows. However, while smaller agents can closely match larger ones on simple tasks, it remains unclear how their performance scales with task complexity , when large models become necessary, and how to better leverage small agents for long-horizon workloads. In this work, we empirically show that small agents' performance fails to scale with task complexity on deep search and coding tasks , and we introduce Strategy Auctions for Workload Efficiency (SALE), an agent framework inspired by freelancer marketplaces . In SALE, agents bid with short strategic plans , which are scored by a systematic cost-value mechanism and refined via a shared auction memory , enabling per-task routing and continual self-improvement without training a separate router or running all models to completion. Across deep search and coding tasks of varying complexity, SALE reduces reliance on the largest agent by 53%, lowers overall cost by 35%, and consistently improves upon the largest agent's pass@1 with only a negligible overhead beyond executing the final trace. In contrast, established routers that rely on task descriptions either underperform the largest agent or fail to reduce cost -- often both -- underscoring their poor fit for agentic workflows. These results suggest that while small agents may be insufficient for complex workloads, they can be effectively \"scaled up\" through coordinated task allocation and test-time self-improvement. More broadly, they motivate a systems-level view of agentic AI in which performance gains come less from ever-larger individual models and more from market-inspired coordination mechanisms that organize heterogeneous agents into efficient, adaptive ecosystems.",
    "summary_en": "Small language models struggle with complex tasks but can be effectively coordinated through a marketplace-inspired framework that reduces costs and improves performance through strategic bidding and self-improvement mechanisms.",
    "summary_zh": "小型语言模型难以处理复杂任务，但可通过受市场启发的框架有效协调，借助策略性竞价和自我改进机制降低成本并提升性能。",
    "upvotes": 5
  },
  {
    "id": "2602.01753",
    "date": "2026-02-04",
    "title": "ObjEmbed: Towards Universal Multimodal Object Embeddings",
    "authors": "Shenghao Fu Yukun Su Fengyun Rao Jing Lyu Xiaohua Xie Wei-Shi Zheng",
    "abstract": "ObjEmbed is a novel multimodal language-model embedding approach that decomposes images into regional embeddings for improved object-level visual understanding and retrieval tasks.",
    "summary_en": "ObjEmbed is a novel multimodal language-model embedding approach that decomposes images into regional embeddings for improved object-level visual understanding and retrieval tasks.",
    "summary_zh": "ObjEmbed是一种新颖的多模态语言模型嵌入方法，通过将图像分解为区域嵌入，提升物体级视觉理解与检索任务的效果。",
    "upvotes": 5
  },
  {
    "id": "2602.03295",
    "date": "2026-02-04",
    "title": "POP: Prefill-Only Pruning for Efficient Large Model Inference",
    "authors": "Junhui He Zhihui Fu Jun Wang Qingan Li",
    "abstract": "Stage-aware pruning method for large language and vision-language models that improves efficiency by selectively removing layers during different processing phases while maintaining accuracy. Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable capabilities. However, their deployment is hindered by significant computational costs. Existing structured pruning methods, while hardware-efficient, often suffer from significant accuracy degradation. In this paper, we argue that this failure stems from a stage-agnostic pruning approach that overlooks the asymmetric roles between the prefill and decode stage s. By introducing a virtual gate mechanism , our importance analysis reveals that deep layers are critical for next-token prediction (decode) but largely redundant for context encoding (prefill). Leveraging this insight, we propose Prefill-Only Pruning (POP), a stage-aware inference strategy that safely omits deep layers during the computationally intensive prefill stage while retaining the full model for the sensitive decode stage . To enable the transition between stages, we introduce independent Key-Value (KV) projections to maintain cache integrity, and a boundary handling strategy to ensure the accuracy of the first generated token. Extensive experiments on Llama-3.1, Qwen3-VL, and Gemma-3 across diverse modalities demonstrate that POP achieves up to 1.37times speedup in prefill latency with minimal performance loss, effectively overcoming the accuracy-efficiency trade-off limitations of existing structured pruning methods.",
    "summary_en": "Stage-aware pruning method for large language and vision-language models that improves efficiency by selectively removing layers during different processing phases while maintaining accuracy.",
    "summary_zh": "面向大型语言模型和视觉-语言模型的阶段感知剪枝方法，通过在不同处理阶段选择性移除层以提升效率并保持准确性。",
    "upvotes": 4
  },
  {
    "id": "2602.02419",
    "date": "2026-02-04",
    "title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration",
    "authors": "Qingni Wang Yue Fan Xin Eric Wang",
    "abstract": "SafeGround is a uncertainty-aware framework for GUI grounding models that uses distribution-aware uncertainty quantification and calibration to enable risk-aware predictions with controlled false discovery rates. Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibration s before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38% percentage points over Gemini-only inference.",
    "summary_en": "SafeGround is a uncertainty-aware framework for GUI grounding models that uses distribution-aware uncertainty quantification and calibration to enable risk-aware predictions with controlled false discovery rates.",
    "summary_zh": "SafeGround是一种面向GUI定位模型的不确定性感知框架，利用分布感知的不确定性量化和校准，实现具有受控错误发现率的风险感知预测。",
    "upvotes": 4
  },
  {
    "id": "2602.00398",
    "date": "2026-02-04",
    "title": "MemoryLLM: Plug-n-Play Interpretable Feed-Forward Memory for Transformers",
    "authors": "Ajay Jaiswal Lauren Hannah Han-Byul Kim Duc Hoang Arnav Kundu Mehrdad Farajtabar Minsik Cho",
    "abstract": "MemoryLLM decouples feed-forward networks from self-attention in transformers, enabling context-free token-wise neural retrieval memory that improves inference efficiency through pre-computed lookups. Understanding how transformer components operate in LLMs is important, as it is at the core of recent technological advances in artificial intelligence. In this work, we revisit the challenges associated with interpretability of feed-forward modules (FFNs) and propose MemoryLLM , which aims to decouple FFNs from self-attention and enables us to study the decoupled FFNs as context-free token-wise neural retrieval memory . In detail, we investigate how input tokens access memory locations within FFN parameters and the importance of FFN memory across different downstream tasks. MemoryLLM achieves context-free FFNs by training them in isolation from self-attention directly using the token embeddings . This approach allows FFNs to be pre-computed as token-wise lookups (ToLs), enabling on-demand transfer between VRAM and storage, additionally enhancing inference efficiency. We also introduce Flex-MemoryLLM , positioning it between a conventional transformer design and MemoryLLM . This architecture bridges the performance gap caused by training FFNs with context-free token-wise embeddings.",
    "summary_en": "MemoryLLM decouples feed-forward networks from self-attention in transformers, enabling context-free token-wise neural retrieval memory that improves inference efficiency through pre-computed lookups.",
    "summary_zh": "MemoryLLM将Transformer中的前馈网络与自注意力解耦，实现了无上下文的逐token神经检索记忆，通过预计算查找提升推理效率。",
    "upvotes": 4
  },
  {
    "id": "2601.19103",
    "date": "2026-02-04",
    "title": "Glance and Focus Reinforcement for Pan-cancer Screening",
    "authors": "Linshan Wu Jiaxin Zhuang Hao Chen",
    "abstract": "A reinforcement learning framework with glance and focus models improves pan-cancer screening in CT scans by addressing foreground-background imbalance and reducing false positives through group relative learning. Pan-cancer screening in large-scale CT scans remains challenging for existing AI methods, primarily due to the difficulty of localizing diverse types of tiny lesions in large CT volumes. The extreme foreground-background imbalance significantly hinders models from focusing on diseased regions, while redundant focus on healthy regions not only decreases the efficiency but also increases false positives . Inspired by radiologists' glance and focus diagnostic strategy, we introduce GF-Screen, a Glance and Focus reinforcement learning framework for pan-cancer screening . GF-Screen employs a Glance model to localize the diseased regions and a Focus model to precisely segment the lesions, where segmentation results of the Focus model are leveraged to reward the Glance model via Reinforcement Learning (RL). Specifically, the Glance model crops a group of sub-volumes from the entire CT volume and learns to select the sub-volumes with lesions for the Focus model to segment. Given that the selecting operation is non-differentiable for segmentation training, we propose to employ the segmentation results to reward the Glance model . To optimize the Glance model , we introduce a novel group relative learning paradigm, which employs group relative comparison to prioritize high-advantage predictions and discard low-advantage predictions within sub-volume groups, not only improving efficiency but also reducing false positives . In this way, for the first time, we effectively extend cutting-edge RL techniques to tackle the specific challenges in pan-cancer screening . Extensive experiments on 16 internal and 7 external datasets across 9 lesion types demonstrated the effectiveness of GF-Screen. Notably, GF-Screen leads the public validation leaderboard of MICCAI FLARE25 pan-cancer challenge, surpassing the FLARE24 champion solution by a large margin (+25.6% DSC and +28.2% NSD).",
    "summary_en": "A reinforcement learning framework with glance and focus models improves pan-cancer screening in CT scans by addressing foreground-background imbalance and reducing false positives through group relative learning.",
    "summary_zh": "一种结合扫视与聚焦模型的强化学习框架通过解决前景-背景不平衡并采用组相对学习降低假阳性，改进了CT扫描中的泛癌筛查。",
    "upvotes": 4
  },
  {
    "id": "2602.03454",
    "date": "2026-02-04",
    "title": "Contextualized Visual Personalization in Vision-Language Models",
    "authors": "Yeongtak Oh Sangwon Yu Junsung Park Han Cheol Moon Jisoo Mok Sungroh Yoon",
    "abstract": "CoViP addresses contextualized visual personalization by treating personalized image captioning as a core task and improving capabilities through reinforcement-learning-based post-training and caption-augmented generation. Despite recent progress in vision-language models (VLMs), existing approaches often fail to generate personalized responses based on the user's specific experiences, as they lack the ability to associate visual inputs with a user's accumulated visual-textual context. We newly formalize this challenge as contextualized visual personalization , which requires the visual recognition and textual retrieval of personalized visual experiences by VLMs when interpreting new images. To address this issue, we propose CoViP, a unified framework that treats personalized image captioning as a core task for contextualized visual personalization and improves this capability through reinforcement-learning-based post-training and caption-augmented generation . We further introduce diagnostic evaluations that explicitly rule out textual shortcut solutions and verify whether VLMs truly leverage visual context . Extensive experiments demonstrate that existing open-source and proprietary VLMs exhibit substantial limitations, while CoViP not only improves personalized image captioning but also yields holistic gains across downstream personalization tasks. These results highlight CoViP as a crucial stage for enabling robust and generalizable contextualized visual personalization .",
    "summary_en": "CoViP addresses contextualized visual personalization by treating personalized image captioning as a core task and improving capabilities through reinforcement-learning-based post-training and caption-augmented generation.",
    "summary_zh": "CoViP 通过将个性化图像描述作为核心任务，并借助基于强化学习的后训练与描述增强生成来提升能力，从而应对情境化视觉个性化问题。",
    "upvotes": 3
  },
  {
    "id": "2602.01212",
    "date": "2026-02-04",
    "title": "SimpleGPT: Improving GPT via A Simple Normalization Strategy",
    "authors": "Marco Chen Xianbiao Qi Yelin He Jiaquan Ye Rong Xiao",
    "abstract": "SimpleNorm normalization strategy stabilizes activation scales and enables larger stable learning rates in Transformer models by reducing Hessian spectral norm, leading to improved training performance. In this work, we revisit Transformer optimization through the lens of second-order geometry and establish a direct connection between architectural design, activation scale , the Hessian matrix , and the maximum tolerable learning rate . We introduce a simple normalization strategy, termed SimpleNorm , which stabilizes intermediate activation scale s by construction. Then, by analyzing the Hessian of the loss with respect to network activations, we theoretically show that SimpleNorm significantly reduces the spectral norm of the Hessian, thereby permitting larger stable learning rate s. We validate our theoretical findings through extensive experiments on large GPT models at parameter scales 1B, 1.4B, 7B and 8B. Empirically, SimpleGPT , our SimpleNorm -based network, tolerates learning rate s 3times-10times larger than standard convention, consistently demonstrates strong optimization stability, and achieves substantially better performance than well-established baselines. Specifically, when training 7B-scale models for 60K steps, SimpleGPT achieves a training loss that is 0.08 lower than that of LLaMA2 with QKNorm , reducing the loss from 2.290 to 2.208. Our source code will be released at https://github.com/Ocram7/ SimpleGPT .",
    "summary_en": "SimpleNorm normalization strategy stabilizes activation scales and enables larger stable learning rates in Transformer models by reducing Hessian spectral norm, leading to improved training performance.",
    "summary_zh": "SimpleNorm 归一化策略通过降低 Hessian 谱范数稳定激活尺度，使 Transformer 模型能够使用更大且稳定的学习率，从而提升训练性能。",
    "upvotes": 3
  },
  {
    "id": "2602.03320",
    "date": "2026-02-04",
    "title": "MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning",
    "authors": "Shengyuan Liu Liuxin Bao Qi Yang Wanting Geng Boyun Zheng Chenxin Li Wenting Chen Houwen Peng Yixuan Yuan",
    "abstract": "MedSAM-Agent reformulates medical image segmentation as a multi-step decision-making process using hybrid prompting and a two-stage training pipeline with process rewards to improve autonomous reasoning and optimization.",
    "summary_en": "MedSAM-Agent reformulates medical image segmentation as a multi-step decision-making process using hybrid prompting and a two-stage training pipeline with process rewards to improve autonomous reasoning and optimization.",
    "summary_zh": "MedSAM-Agent 利用混合提示和引入过程奖励的两阶段训练流程，将医学图像分割重新定义为多步决策过程，以提升自主推理与优化能力。",
    "upvotes": 2
  },
  {
    "id": "2602.02914",
    "date": "2026-02-04",
    "title": "FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction",
    "authors": "Wenqi Guo Shan Du",
    "abstract": "FaceLinkGen attack demonstrates that current privacy-preserving face recognition methods fail to protect identity information despite pixel-level distortion metrics suggesting adequate protection. Transformation-based privacy-preserving face recognition (PPFR) aims to verify identities while hiding facial data from attackers and malicious service providers. Existing evaluations mostly treat privacy as resistance to pixel-level reconstruction , measured by PSNR and SSIM . We show that this reconstruction-centric view fails. We present FaceLinkGen, an identity extraction attack that performs linkage/matching and face regeneration directly from protected templates without recovering original pixels. On three recent PPFR systems, FaceLinkGen reaches over 98.5\\% matching accuracy and above 96\\% regeneration success, and still exceeds 92\\% matching and 94\\% regeneration in a near zero knowledge setting. These results expose a structural gap between pixel distortion metrics, which are widely used in PPFR evaluation, and real privacy. We show that visual obfuscation leaves identity information broadly exposed to both external intruders and untrusted service providers.",
    "summary_en": "FaceLinkGen attack demonstrates that current privacy-preserving face recognition methods fail to protect identity information despite pixel-level distortion metrics suggesting adequate protection.",
    "summary_zh": "FaceLinkGen攻击表明，尽管像素级失真指标表明已提供充分保护，当前的隐私保护人脸识别方法仍未能保护身份信息。",
    "upvotes": 2
  },
  {
    "id": "2602.02405",
    "date": "2026-02-04",
    "title": "Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning",
    "authors": "Ethan Mendes Jungsoo Park Alan Ritter",
    "abstract": "Distribution Aligned Imitation Learning (DAIL) improves LLM reasoning by transforming expert solutions into in-distribution traces and using contrastive learning to focus on expert methodologies, achieving significant performance gains with minimal expert data. Improving the reasoning capabilities of large language models (LLMs) typically relies either on the model's ability to sample a correct solution to be reinforced or on the existence of a stronger model able to solve the problem. However, many difficult problems remain intractable for even current frontier models, preventing the extraction of valid training signals. A promising alternative is to leverage high-quality expert human solutions, yet naive imitation of this data fails because it is fundamentally out of distribution: expert solutions are typically didactic, containing implicit reasoning gaps intended for human readers rather than computational models. Furthermore, high-quality expert solutions are expensive, necessitating generalizable sample-efficient training methods. We propose Distribution Aligned Imitation Learning (DAIL), a two-step method that bridges the distributional gap by first transforming expert solutions into detailed, in-distribution reasoning traces and then applying a contrastive objective to focus learning on expert insights and methodologies. We find that DAIL can leverage fewer than 1000 high-quality expert solutions to achieve 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improve reasoning efficiency by 2x to 4x, and enable out-of-domain generalization .",
    "summary_en": "Distribution Aligned Imitation Learning (DAIL) improves LLM reasoning by transforming expert solutions into in-distribution traces and using contrastive learning to focus on expert methodologies, achieving significant performance gains with minimal expert data.",
    "summary_zh": "分布对齐模仿学习（DAIL）通过将专家解决方案转换为分布内轨迹，并使用对比学习聚焦专家方法，在仅需极少专家数据的情况下实现了大语言模型推理能力的显著提升。",
    "upvotes": 2
  },
  {
    "id": "2602.03238",
    "date": "2026-02-04",
    "title": "The Necessity of a Unified Framework for LLM-Based Agent Evaluation",
    "authors": "Pengyu Zhu Li Sun Philip S. Yu Sen Su",
    "abstract": "Large Language Models have advanced general-purpose agents, but current evaluation benchmarks suffer from confounding factors and lack of standardization, necessitating a unified framework for rigorous assessment. With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts , toolset configurations , and environmental dynamics . Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.",
    "summary_en": "Large Language Models have advanced general-purpose agents, but current evaluation benchmarks suffer from confounding factors and lack of standardization, necessitating a unified framework for rigorous assessment.",
    "summary_zh": "大语言模型推动了通用智能体的发展，但现有评估基准存在混杂因素且缺乏标准化，亟需统一框架以实现严谨评估。",
    "upvotes": 1
  },
  {
    "id": "2602.02494",
    "date": "2026-02-04",
    "title": "MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training",
    "authors": "Dulhan Jayalath Oiwi Parker Jones",
    "abstract": "MEG-XL demonstrates improved brain-to-text decoding performance through extended pre-training with 2.5-minute MEG context, significantly outperforming previous models with less contextual data. Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose MEG-XL, a model pre-trained with 2.5 minutes of MEG context per sample, 5-300x longer than prior work, and equivalent to 191k tokens, capturing extended neural context . Fine-tuning on the task of word decoding from brain data, MEG-XL matches supervised performance with a fraction of the data (e.g. 1hr vs 50hrs) and outperforms brain foundation models . We find that models pre-trained with longer contexts learn representations that transfer better to word decoding . Our results indicate that long-context pre-training helps exploit extended neural context that other methods unnecessarily discard. Code, model weights, and instructions are available at https://github.com/neural-processing-lab/MEG-XL .",
    "summary_en": "MEG-XL demonstrates improved brain-to-text decoding performance through extended pre-training with 2.5-minute MEG context, significantly outperforming previous models with less contextual data.",
    "summary_zh": "MEG-XL通过2.5分钟MEG上下文的扩展预训练提升了脑到文本解码性能，显著优于使用更少上下文数据的先前模型。",
    "upvotes": 1
  },
  {
    "id": "2602.02220",
    "date": "2026-02-04",
    "title": "LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation",
    "authors": "Bo Miao Weijia Liu Jun Luo Lachlan Shinnick Jian Liu Thomas Hamilton-Smith Yuhe Yang Zijie Wu Vanja Videnovic Feras Dayoub Anton van den Hengel",
    "abstract": "HieraNav presents a multi-granularity, open-vocabulary navigation task with LangMap benchmark that enables agents to follow natural language instructions across different semantic levels in 3D environments. The relationships between objects and language are fundamental to meaningful communication between humans and AI, and to practically useful embodied intelligence. We introduce HieraNav, a multi-granularity , open-vocabulary goal navigation task where agents interpret natural language instructions to reach targets at four semantic levels : scene , room , region , and instance . To this end, we present Language as a Map (LangMap), a large-scale benchmark built on real-world 3D indoor scans with comprehensive human-verified annotations and tasks spanning these levels. LangMap provides region labels, discriminative region descriptions, discriminative instance descriptions covering 414 object categories, and over 18K navigation tasks. Each target features both concise and detailed descriptions, enabling evaluation across different instruction styles. LangMap achieves superior annotation quality, outperforming GOAT-Bench by 23.8% in discriminative accuracy using four times fewer words. Comprehensive evaluations of zero-shot and supervised models on LangMap reveal that richer context and memory improve success, while long-tailed, small, context-dependent, and distant goals, as well as multi-goal completion, remain challenging. HieraNav and LangMap establish a rigorous testbed for advancing language-driven embodied navigation . Project: https://bo-miao.github.io/LangMap",
    "summary_en": "HieraNav presents a multi-granularity, open-vocabulary navigation task with LangMap benchmark that enables agents to follow natural language instructions across different semantic levels in 3D environments.",
    "summary_zh": "HieraNav提出了一项多粒度、开放词汇的导航任务，并推出了LangMap基准，使智能体能够在3D环境中遵循跨不同语义层级的自然语言指令。",
    "upvotes": 1
  },
  {
    "id": "2602.01405",
    "date": "2026-02-04",
    "title": "Feedback by Design: Understanding and Overcoming User Feedback Barriers in Conversational Agents",
    "authors": "Nikhil Sharma Zheng Zhang Daniel Lee Namita Krishnan Guang-Jie Ren Ziang Xiao Yunyao Li",
    "abstract": "High-quality feedback is essential for effective human-AI interaction. It bridges knowledge gaps, corrects digressions, and shapes system behavior; both during interaction and throughout model development. Yet despite its importance, human feedback to AI is often infrequent and low quality. This gap motivates a critical examination of human feedback during interactions with AIs. To understand and overcome the challenges preventing users from giving high-quality feedback, we conducted two studies examining feedback dynamics between humans and conversational agents (CAs). Our formative study, through the lens of Grice's maxims, identified four Feedback Barriers -- Common Ground, Verifiability, Communication, and Informativeness -- that prevent high-quality feedback by users. Building on these findings, we derive three design desiderata and show that systems incorporating scaffolds aligned with these desiderata enabled users to provide higher-quality feedback. Finally, we detail a call for action to the broader AI community for advances in Large Language Models capabilities to overcome Feedback Barriers.",
    "summary_en": "High-quality feedback is essential for effective human-AI interaction. It bridges knowledge gaps, corrects digressions, and shapes system behavior; both during interaction and throughout model development. Yet despite its importance, human feedback to AI is often infrequent and low quality.",
    "summary_zh": "高质量反馈对于有效的人机交互至关重要。它弥合知识差距、纠正偏差并塑造系统行为；无论是在交互过程中还是在整个模型开发过程中。然而，尽管其十分重要，人类对AI的反馈往往稀少且质量低下。",
    "upvotes": 1
  },
  {
    "id": "2602.00682",
    "date": "2026-02-04",
    "title": "RecGOAT: Graph Optimal Adaptive Transport for LLM-Enhanced Multimodal Recommendation with Dual Semantic Alignment",
    "authors": "Yuecheng Li Hengwei Ju Zeyu Song Wei Yang Chi Lu Peng Jiang Kun Gai",
    "abstract": "A novel dual semantic alignment framework for LLM-enhanced multimodal recommendation that addresses representational divergence between large models and recommendation systems through graph attention networks and cross-modal contrastive learning. Multimodal recommendation systems typically integrates user behavior with multimodal data from items, thereby capturing more accurate user preferences. Concurrently, with the rise of large models (LMs), multimodal recommendation is increasingly leveraging their strengths in semantic understanding and contextual reasoning . However, LM representations are inherently optimized for general semantic tasks, while recommendation models rely heavily on sparse user/item unique identity (ID) features. Existing works overlook the fundamental representational divergence between large models and recommendation systems, resulting in incompatible multimodal representations and suboptimal recommendation performance. To bridge this gap, we propose RecGOAT, a novel yet simple dual semantic alignment framework for LLM-enhanced multimodal recommendation , which offers theoretically guaranteed alignment capability. RecGOAT first employs graph attention networks to enrich collaborative semantics by modeling item-item, user-item, and user-user relationships, leveraging user/item LM representations and interaction history. Furthermore, we design a dual-granularity progressive multimodality-ID alignment framework, which achieves instance-level and distribution-level semantic alignment via cross-modal contrastive learning (CMCL) and optimal adaptive transport (OAT), respectively. Theoretically, we demonstrate that the unified representations derived from our alignment framework exhibit superior semantic consistency and comprehensiveness. Extensive experiments on three public benchmarks show that our RecGOAT achieves state-of-the-art performance, empirically validating our theoretical insights. Additionally, the deployment on a large-scale online advertising platform confirms the model's effectiveness and scalability in industrial recommendation scenarios. Code available at https://github.com/6lyc/RecGOAT-LLM4Rec.",
    "summary_en": "A novel dual semantic alignment framework for LLM-enhanced multimodal recommendation that addresses representational divergence between large models and recommendation systems through graph attention networks and cross-modal contrastive learning.",
    "summary_zh": "一种面向LLM增强多模态推荐的新型双重语义对齐框架，通过图注意力网络与跨模态对比学习解决大模型与推荐系统之间的表示差异。",
    "upvotes": 1
  },
  {
    "id": "2602.03817",
    "date": "2026-02-04",
    "title": "Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion",
    "authors": "Oscar Ovanger Levi Harris Timothy H. Keitt",
    "abstract": "A fusion framework called FINCH combines audio and spatiotemporal predictors for bioacoustic classification by adaptively weighting evidence based on reliability estimates, outperforming fixed-weight methods and audio-only approaches. Many machine learning systems have access to multiple sources of evidence for the same prediction target, yet these sources often differ in reliability and informativeness across inputs. In bioacoustic classification, species identity may be inferred both from the acoustic signal and from spatiotemporal context such as location and season; while Bayesian inference motivates multiplicative evidence combination, in practice we typically only have access to discriminative predictors rather than calibrated generative models. We introduce Fusion under INdependent Conditional Hypotheses (FINCH), an adaptive log-linear evidence fusion framework that integrates a pre-trained audio classifier with a structured spatiotemporal predictor . FINCH learns a per-sample gating function that estimates the reliability of contextual information from uncertainty and informativeness statistics . The resulting fusion family contains the audio-only classifier as a special case and explicitly bounds the influence of contextual evidence, yielding a risk-contained hypothesis class with an interpretable audio-only fallback . Across benchmarks, FINCH consistently outperforms fixed-weight fusion and audio-only baselines, improving robustness and error trade-offs even when contextual information is weak in isolation. We achieve state-of-the-art performance on CBI and competitive or improved performance on several subsets of BirdSet using a lightweight, interpretable, evidence-based approach. Code is available: \\href{https://anonymous.4open.science/r/birdnoise-85CD/README.md{anonymous-repository}}",
    "summary_en": "A fusion framework called FINCH combines audio and spatiotemporal predictors for bioacoustic classification by adaptively weighting evidence based on reliability estimates, outperforming fixed-weight methods and audio-only approaches.",
    "summary_zh": "一种名为FINCH的融合框架通过基于可靠性估计的自适应证据加权，结合音频和时空预测器进行生物声学分类，性能优于固定权重方法和仅音频方法。",
    "upvotes": 0
  },
  {
    "id": "2602.01519",
    "date": "2026-02-04",
    "title": "You Need an Encoder for Native Position-Independent Caching",
    "authors": "Shiju Zhao Junhao Hu Jiaqi Zheng Guihai Chen",
    "abstract": "Native position-independent caching enhances LLM inference efficiency by reintroducing encoders and developing a caching system that reduces latency while maintaining accuracy. The Key-Value (KV) cache of Large Language Models (LLMs) is prefix-based, making it highly inefficient for processing contexts retrieved in arbitrary order. Position-Independent Caching (PIC) has been proposed to enable KV reuse without positional constraints; however, existing approaches often incur substantial accuracy degradation, limiting their practical adoption. To address this issue, we propose native PIC by reintroducing the encoder to prevalent decoder-only LLMs and explicitly training it to support PIC. We further develop COMB, a PIC-aware caching system that integrates seamlessly with existing inference frameworks. Experimental results show that COMB reduces Time-to-First-Token (TTFT) by 51-94% and increases throughput by 3times with comparable accuracy. Furthermore, the quality improvement when using DeepSeek-V2-Lite-Chat demonstrates the applicability of COMB to other types of decoder-only LLMs . Our code is available at https://github.com/shijuzhao/Comb.",
    "summary_en": "Native position-independent caching enhances LLM inference efficiency by reintroducing encoders and developing a caching system that reduces latency while maintaining accuracy.",
    "summary_zh": "原生位置无关缓存通过重新引入编码器并开发缓存系统，在保持准确性的同时降低延迟，从而提升 LLM 推理效率。",
    "upvotes": 0
  },
  {
    "id": "2602.00919",
    "date": "2026-02-03",
    "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots",
    "authors": "I. Apanasevich M. Artemyev R. Babakyan P. Fedotova D. Grankin E. Kupryashin A. Misailidi D. Nerus A. Nutalapati G. Sidorov I. Efremov M. Gerasyov D. Pikurov Y. Senchenko S. Davidenko D. Kulikov M. Sultankin K. Askarbek O. Shamanin D. Statovoy E. Zalyaev I. Zorin",
    "abstract": "Green-VLA is a five-stage vision-language-action framework for real-world robot deployment that achieves generalization across different robot embodiments through multimodal training and reinforcement learning. We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding , (R0) multi-embodiment pretraining , (R1) embodiment-specific adaptation , and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction , out-of-distribution detection , and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.",
    "summary_en": "Green-VLA is a five-stage vision-language-action framework for real-world robot deployment that achieves generalization across different robot embodiments through multimodal training and reinforcement learning.",
    "summary_zh": "Green-VLA是一个用于真实世界机器人部署的五阶段视觉-语言-动作框架，通过多模态训练和强化学习实现跨不同机器人本体的泛化。",
    "upvotes": 280
  },
  {
    "id": "2602.02276",
    "date": "2026-02-03",
    "title": "Kimi K2.5: Visual Agentic Intelligence",
    "authors": "Kimi Team Tongtong Bai Yifan Bai Yiping Bao S. H. Cai Yuan Cao Y. Charles H. S. Che Cheng Chen Guanduo Chen Huarong Chen Jia Chen Jiahao Chen Jianlong Chen Jun Chen Kefan Chen Liang Chen Ruijue Chen Xinhao Chen Yanru Chen Yanxu Chen Yicun Chen",
    "abstract": "Kimi K2.5 is an open-source multimodal agentic model that enhances text and vision processing through joint optimization techniques and introduces Agent Swarm for parallel task execution. We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training , zero-vision SFT , and joint text-vision reinforcement learning . Building on this multimodal foundation, K2.5 introduces Agent Swarm , a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to 4.5times over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.",
    "summary_en": "Kimi K2.5 is an open-source multimodal agentic model that enhances text and vision processing through joint optimization techniques and introduces Agent Swarm for parallel task execution.",
    "summary_zh": "Kimi K2.5 是一款开源的多模态智能体模型，通过联合优化技术增强文本与视觉处理能力，并引入 Agent Swarm 实现并行任务执行。",
    "upvotes": 233
  },
  {
    "id": "2601.22060",
    "date": "2026-02-03",
    "title": "Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models",
    "authors": "Wenxuan Huang Yu Zeng Qiuchen Wang Zhen Fang Shaosheng Cao Zheng Chu Qingyu Yin Shuang Chen Zhenfei Yin Lin Chen Zehui Chen Yao Hu Philip Torr Feng Zhao Wanli Ouyang",
    "abstract": "Vision-DeepResearch introduces a multimodal deep-research paradigm enabling multi-turn, multi-entity, and multi-scale visual and textual search with deep-research capabilities integrated through cold-start supervision and reinforcement learning. Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by `` reasoning-then-tool-call '' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.",
    "summary_en": "Vision-DeepResearch introduces a multimodal deep-research paradigm enabling multi-turn, multi-entity, and multi-scale visual and textual search with deep-research capabilities integrated through cold-start supervision and reinforcement learning.",
    "summary_zh": "Vision-DeepResearch提出了一种多模态深度研究范式，通过冷启动监督与强化学习集成深度研究能力，实现多轮、多实体、多尺度的视觉与文本搜索。",
    "upvotes": 153
  },
  {
    "id": "2602.02185",
    "date": "2026-02-03",
    "title": "Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models",
    "authors": "Yu Zeng Wenxuan Huang Zhen Fang Shuang Chen Yufan Shen Yishuo Cai Xiaoman Wang Zhenfei Yin Lin Chen Zehui Chen Shiting Huang Yiming Zhao Yao Hu Philip Torr Wanli Ouyang Shaosheng Cao",
    "abstract": "Vision-DeepResearch benchmark addresses limitations in evaluating visual-textual search capabilities of multimodal models by introducing realistic evaluation conditions and improving visual retrieval through multi-round cropped-search workflow. Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding . However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems . The code will be released in https://github.com/Osilly/ Vision-DeepResearch .",
    "summary_en": "Vision-DeepResearch benchmark addresses limitations in evaluating visual-textual search capabilities of multimodal models by introducing realistic evaluation conditions and improving visual retrieval through multi-round cropped-search workflow.",
    "summary_zh": "Vision-DeepResearch基准通过引入真实评估条件并采用多轮裁剪搜索工作流改进视觉检索，解决了多模态模型视觉-文本搜索能力评估的局限性。",
    "upvotes": 125
  },
  {
    "id": "2602.02084",
    "date": "2026-02-03",
    "title": "Closing the Loop: Universal Repository Representation with RPG-Encoder",
    "authors": "Jane Luo Chengyu Yin Xin Zhang Qingtao Li Steven Liu Yiming Huang Jie Wu Hao Liu Yangyu Huang Yu Kang Fangkai Yang Ying Xin Scarlett Li",
    "abstract": "RPG-Encoder framework transforms repository comprehension and generation into a unified cycle by encoding code into high-fidelity Repository Planning Graph representations that improve understanding and reconstruction accuracy. Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder , a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies ; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation . In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.",
    "summary_en": "RPG-Encoder framework transforms repository comprehension and generation into a unified cycle by encoding code into high-fidelity Repository Planning Graph representations that improve understanding and reconstruction accuracy.",
    "summary_zh": "RPG-Encoder框架通过将代码编码为高保真Repository Planning Graph表示，将代码库理解与生成转化为统一的循环，从而提升理解与重建的准确性。",
    "upvotes": 82
  },
  {
    "id": "2602.02437",
    "date": "2026-02-03",
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "authors": "Dianyi Wang Chaofan Ma Feng Han Size Wu Wei Song Yibin Wang Zhixiong Zhang Tianhang Wang Siyuan Wang Zhongyu Wei Jiaqi Wang",
    "abstract": "UniReason integrates text-to-image generation and image editing through a dual reasoning paradigm that enhances planning with world knowledge and uses editing for visual refinement, achieving superior performance on reasoning-intensive benchmarks. Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm . We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation , mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction . Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE , KrisBench and UniREditBench , while maintaining superior general synthesis capabilities.",
    "summary_en": "UniReason integrates text-to-image generation and image editing through a dual reasoning paradigm that enhances planning with world knowledge and uses editing for visual refinement, achieving superior performance on reasoning-intensive benchmarks.",
    "summary_zh": "UniReason通过双重推理范式整合文本到图像生成与图像编辑，利用世界知识增强规划并使用编辑进行视觉优化，在推理密集型基准测试中取得了更优性能。",
    "upvotes": 76
  },
  {
    "id": "2602.02361",
    "date": "2026-02-03",
    "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions",
    "authors": "Mouxiang Chen Lei Zhang Yunlong Feng Xuwu Wang Wenting Zhao Ruisheng Cao Jiaxi Yang Jiawei Chen Mingze Li Zeyao Ma Hao Ge Zongmeng Zhang Zeyu Cui Dayiheng Liu Jingren Zhou Jianling Sun Junyang Lin Binyuan Hui",
    "abstract": "A scalable framework for constructing real-world software engineering environments from GitHub pull requests using an efficient building agent with self-verification and hacking detection capabilities. We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model . This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning . Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified . Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents.",
    "summary_en": "A scalable framework for constructing real-world software engineering environments from GitHub pull requests using an efficient building agent with self-verification and hacking detection capabilities.",
    "summary_zh": "一种可扩展框架，利用具备自验证和黑客攻击检测能力的高效构建智能体，从 GitHub pull requests 构建真实软件工程环境。",
    "upvotes": 60
  },
  {
    "id": "2602.01566",
    "date": "2026-02-03",
    "title": "FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents",
    "authors": "Chiwei Zhu Benfeng Xu Mingxuan Du Shaohan Wang Xiaorui Wang Zhendong Mao Yongdong Zhang",
    "abstract": "A file-system-based dual-agent framework enables large language model agents to perform extended research tasks beyond context window limitations by using persistent storage as external memory.",
    "summary_en": "A file-system-based dual-agent framework enables large language model agents to perform extended research tasks beyond context window limitations by using persistent storage as external memory.",
    "summary_zh": "基于文件系统的双智能体框架通过将持久化存储作为外部记忆，使大型语言模型智能体能够突破上下文窗口限制，执行扩展研究任务。",
    "upvotes": 48
  },
  {
    "id": "2602.02472",
    "date": "2026-02-03",
    "title": "SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning",
    "authors": "Qifan Yu Xinyu Ma Zhijian Zhuo Minrui Wang Deyi Liu Shiyi Zhan Yiyuan Ma Liang Xiang Xingyan Bin Di He",
    "abstract": "SPARKLING is a framework for mid-stage width expansion in deep learning models that maintains signal preservation and breaks symmetry to stabilize training and reduce computational costs. Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings , yet it remains a formidable challenge due to severe training instabilities . Empirically, we show that naive initialization at this stage disrupts activation statistics , triggering loss spikes , while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing {S}ignal {P}reservation {A}nd symmet{R}y brea{K}ing for width-progressive {L}earn{ING}), a novel framework for mid-stage width expansion . Our method achieves signal preservation via RMS-scale consistency , stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup . Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under 2times width expansion .",
    "summary_en": "SPARKLING is a framework for mid-stage width expansion in deep learning models that maintains signal preservation and breaks symmetry to stabilize training and reduce computational costs.",
    "summary_zh": "SPARKLING是一种用于深度学习模型中期宽度扩展的框架，通过保持信号保留并打破对称性来稳定训练并降低计算成本。",
    "upvotes": 44
  },
  {
    "id": "2602.02493",
    "date": "2026-02-03",
    "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss",
    "authors": "Zehong Ma Ruihan Xu Shiliang Zhang",
    "abstract": "PixelGen is a pixel-space diffusion framework that uses perceptual supervision through LPIPS and DINO-based losses to generate high-quality images without requiring VAEs or latent representations. Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAE s in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion model s. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision . Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision , PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to- image generation with a GenEval score of 0.79. PixelGen requires no VAE s, no latent representations , and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.",
    "summary_en": "PixelGen is a pixel-space diffusion framework that uses perceptual supervision through LPIPS and DINO-based losses to generate high-quality images without requiring VAEs or latent representations.",
    "summary_zh": "PixelGen 是一种像素空间扩散框架，利用 LPIPS 和基于 DINO 的损失函数进行感知监督，无需 VAE 或潜在表示即可生成高质量图像。",
    "upvotes": 42
  },
  {
    "id": "2602.01576",
    "date": "2026-02-03",
    "title": "Generative Visual Code Mobile World Models",
    "authors": "Woosung Koh Sungjun Han Segyu Lee Se-Young Yun Jamin Shin",
    "abstract": "Visual world models for mobile GUI agents are improved through renderable code generation using vision-language models, achieving better performance with reduced model size compared to existing approaches. Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity , while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation , where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework ( gWorld ) that automatically synthesizes code-based training data . In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.",
    "summary_en": "Visual world models for mobile GUI agents are improved through renderable code generation using vision-language models, achieving better performance with reduced model size compared to existing approaches.",
    "summary_zh": "通过视觉-语言模型生成可渲染代码，改进了移动GUI智能体的视觉世界模型，与现有方法相比，以更小的模型尺寸实现了更优性能。",
    "upvotes": 41
  },
  {
    "id": "2602.02338",
    "date": "2026-02-03",
    "title": "Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs",
    "authors": "Yu Liang Zhongjin Zhang Yuxuan Zhu Kerui Zhang Zhiluohan Guo Wenhang Zhou Zonqi Yang Kangle Wu Yabo Ni Anxiang Zeng Cong Fu Jianxin Wang Jiazhi Xia",
    "abstract": "ReSID presents a novel recommendation-native framework that improves sequential recommendation by learning predictive item representations and optimizing quantization for information preservation and sequential predictability. Semantic ID (SID)-based recommendation is a promising paradigm for scaling sequential recommender systems , but existing methods largely follow a semantic-centric pipeline: item embeddings are learned from foundation models and discretized using generic quantization schemes. This design is misaligned with generative recommendation objectives: semantic embeddings are weakly coupled with collaborative prediction , and generic quantization is inefficient at reducing sequential uncertainty for autoregressive modeling . To address these, we propose ReSID, a recommendation-native, principled SID framework that rethinks representation learning and quantization from the perspective of information preservation and sequential predictability , without relying on LLMs. ReSID consists of two components: (i) Field-Aware Masked Auto-Encoding (FAMAE), which learns predictive-sufficient item representations from structured features, and (ii) Globally Aligned Orthogonal Quantization (GAOQ), which produces compact and predictable SID sequences by jointly reducing semantic ambiguity and prefix-conditional uncertainty. Theoretical analysis and extensive experiments across ten datasets show the effectiveness of ReSID. ReSID consistently outperforms strong sequential and SID-based generative baselines by an average of over 10%, while reducing tokenization cost by up to 122x. Code is available at https://github.com/FuCongResearchSquad/ReSID.",
    "summary_en": "ReSID presents a novel recommendation-native framework that improves sequential recommendation by learning predictive item representations and optimizing quantization for information preservation and sequential predictability.",
    "summary_zh": "ReSID 提出了一种新颖的推荐原生框架，通过学**习预测性物品表示并优化量化以保留信息并保持序列可预测性，从而改进序列推荐。",
    "upvotes": 40
  },
  {
    "id": "2602.02053",
    "date": "2026-02-03",
    "title": "WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora",
    "authors": "Pengyu Wang Benfeng Xu Licheng Zhang Shaohan Wang Mingxuan Du Chiwei Zhu Zhendong Mao",
    "abstract": "WildGraphBench evaluates GraphRAG performance in realistic scenarios using Wikipedia's structured content to assess multi-fact aggregation and summarization capabilities across diverse document types. Graph-based Retrieval-Augmented Generation ( GraphRAG ) organizes external knowledge as a hierarchical graph , enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge , failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents . To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia 's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization . Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.",
    "summary_en": "WildGraphBench evaluates GraphRAG performance in realistic scenarios using Wikipedia's structured content to assess multi-fact aggregation and summarization capabilities across diverse document types.",
    "summary_zh": "WildGraphBench 使用 Wikipedia 的结构化内容，在真实场景中评估 GraphRAG 跨多种文档类型的多事实聚合与总结能力。",
    "upvotes": 40
  },
  {
    "id": "2602.01058",
    "date": "2026-02-03",
    "title": "Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning",
    "authors": "Dylan Zhang Yufeng Xu Haojin Wang Qingzhi Chen Hao Peng",
    "abstract": "Post-training of reasoning large language models can be improved by correcting distribution mismatches between supervised fine-tuning and reinforcement learning stages through importance sampling reweighting of the SFT loss. Post-training of reasoning LLMs is a holistic process that typically consists of an offline SFT stage followed by an online reinforcement learning (RL) stage. However, SFT is often optimized in isolation to maximize SFT performance alone. We show that, after identical RL training, models initialized from stronger SFT checkpoints can significantly underperform those initialized from weaker ones. We attribute this to a mismatch typical in current SFT-RL pipelines: the distribution that generates the offline SFT data can differ substantially from the policy optimized during online RL, which learns from its own rollouts. We propose PEAR ( Policy Evaluation -inspired Algorithm for Offline Learning Loss Re-weighting ), an SFT-stage method that corrects this mismatch and better prepares the model for RL. PEAR uses importance sampling to reweight the SFT loss, with three variants operating at the token, block, and sequence levels. It can be used to augment standard SFT objectives and incurs little additional training overhead once probabilities for the offline data are collected. We conduct controlled experiments on verifiable reasoning games and mathematical reasoning tasks on Qwen 2.5 and 3 and DeepSeek -distilled models. PEAR consistently improves post-RL performance over canonical SFT, with pass at 8 gains up to a 14.6 percent on AIME2025. Our results suggest that PEAR is an effective step toward more holistic LLM post-training by designing and evaluating SFT with downstream RL in mind rather than in isolation.",
    "summary_en": "Post-training of reasoning large language models can be improved by correcting distribution mismatches between supervised fine-tuning and reinforcement learning stages through importance sampling reweighting of the SFT loss.",
    "summary_zh": "推理大语言模型的后训练可通过对SFT损失进行重要性采样重加权，纠正监督微调和强化学习阶段之间的分布不匹配，从而得到改进。",
    "upvotes": 40
  },
  {
    "id": "2602.02453",
    "date": "2026-02-03",
    "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling",
    "authors": "Andong Chen Wenxin Zhu Qiuyu Ding Yuchen Song Muyun Yang Tiejun Zhao",
    "abstract": "Thinking with Comics emerges as an effective visual reasoning approach that bridges images and videos by leveraging comic structures for improved multimodal reasoning efficiency and performance. Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure , while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure , embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning .",
    "summary_en": "Thinking with Comics emerges as an effective visual reasoning approach that bridges images and videos by leveraging comic structures for improved multimodal reasoning efficiency and performance.",
    "summary_zh": "Thinking with Comics 是一种有效的视觉推理方法，通过利用漫画结构桥接图像与视频，以提升多模态推理的效率与性能。",
    "upvotes": 35
  },
  {
    "id": "2602.01590",
    "date": "2026-02-03",
    "title": "Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles",
    "authors": "Shaohan Wang Benfeng Xu Licheng Zhang Mingxuan Du Chiwei Zhu Xiaorui Wang Zhendong Mao Yongdong Zhang",
    "abstract": "Deep Research Agents demonstrate capabilities in autonomous information retrieval but show significant gaps when evaluated against expert-level Wikipedia articles using a new live benchmark and comprehensive evaluation framework.",
    "summary_en": "Deep Research Agents demonstrate capabilities in autonomous information retrieval but show significant gaps when evaluated against expert-level Wikipedia articles using a new live benchmark and comprehensive evaluation framework.",
    "summary_zh": "Deep Research Agents展现了自主信息检索的能力，但在使用新的实时基准测试和综合评估框架对照专家级Wikipedia文章进行评估时，显示出显著差距。",
    "upvotes": 33
  },
  {
    "id": "2602.02488",
    "date": "2026-02-03",
    "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System",
    "authors": "Yinjie Wang Tianbao Xie Ke Shen Mengdi Wang Ling Yang",
    "abstract": "RLAnything enhances reinforcement learning for LLMs and agents through dynamic model optimization and closed-loop feedback mechanisms that improve policy and reward model training. We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization , amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals , while the reward model is jointly optimized via consistency feedback , which in turn further improves policy training. Moreover, our theory-motivated automatic environment adaptation improves training for both the reward and policy models by leveraging critic feedback from each, enabling learning from experience. Empirically, each added component consistently improves the overall system, and RLAnything yields substantial gains across various representative LLM and agentic tasks, boosting Qwen3-VL-8B-Thinking by 9.1% on OSWorld and Qwen2.5-7B-Instruct by 18.7% and 11.9% on AlfWorld and LiveBench , respectively. We also that optimized reward-model signals outperform outcomes that rely on human labels. Code: https://github.com/Gen-Verse/Open-AgentRL",
    "summary_en": "RLAnything enhances reinforcement learning for LLMs and agents through dynamic model optimization and closed-loop feedback mechanisms that improve policy and reward model training.",
    "summary_zh": "RLAnything通过动态模型优化和闭环反馈机制，增强面向LLM和智能体的强化学习，改进策略与奖励模型训练。",
    "upvotes": 32
  },
  {
    "id": "2602.02383",
    "date": "2026-02-03",
    "title": "SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization",
    "authors": "Maksim Afanasyev Illarion Iov",
    "abstract": "SLIME is a novel reference-free alignment objective for large language models that decouples preference learning from generation quality through a three-pronged approach combining likelihood maximization, probability stabilization, and dual-margin constraints. Direct preference optimization methods have emerged as a computationally efficient alternative to Reinforcement Learning from Human Feedback ( RLHF ) for aligning Large Language Models ( LLMs ). Latest approaches have streamlined the alignment process by deriving implicit reward functions , yet they often suffer from a critical objective mismatch : optimizing the relative margin between chosen and rejected responses does not guarantee the preservation of the chosen response's absolute likelihood . This can lead to `` unlearning '', where the model degrades the probability of high-quality outputs to satisfy margin constraints, and `` formatting collapse '' caused by the over-penalization of rejected sequences. In this work, we introduce SLIME (Stabilized Likelihood Implicit Margin Enforcement), a reference-free alignment objective designed to decouple preference learning from generation quality. SLIME incorporates a three-pronged objective: (1) an anchoring term to maximize the likelihood of preferred responses; (2) a stabilizing penalty that prevents the probabilities of rejected tokens from collapsing to zero; and (3) a dual-margin mechanism that combines hard and soft constraints for precise boundary shaping. Our results demonstrate that SLIME achieves superior performance compared to state-of-the-art baselines while maintaining higher generation stability .",
    "summary_en": "SLIME is a novel reference-free alignment objective for large language models that decouples preference learning from generation quality through a three-pronged approach combining likelihood maximization, probability stabilization, and dual-margin constraints.",
    "summary_zh": "SLIME是一种用于大型语言模型的新型无参考对齐目标，通过结合似然最大化、概率稳定化和双边界约束的三方面方法，将偏好学习与生成质量解耦。",
    "upvotes": 29
  },
  {
    "id": "2602.01801",
    "date": "2026-02-03",
    "title": "Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention",
    "authors": "Dvir Samuel Issar Tzachor Matan Levy Micahel Green Gal Chechik Rami Ben-Ari",
    "abstract": "Autoregressive video diffusion models face efficiency challenges due to growing KV caches and redundant attention computations, which are addressed through TempCache, AnnCA, and AnnSA techniques that reduce computational demands while maintaining visual quality and stable performance. Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; Ann CA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor ( ANN ) matching; and Ann SA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN . Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.",
    "summary_en": "Autoregressive video diffusion models face efficiency challenges due to growing KV caches and redundant attention computations, which are addressed through TempCache, AnnCA, and AnnSA techniques that reduce computational demands while maintaining visual quality and stable performance.",
    "summary_zh": "自回归视频扩散模型因KV缓存增长和注意力计算冗余面临效率挑战，TempCache、AnnCA和AnnSA技术通过降低计算需求并保持视觉质量与稳定性能解决这些问题。",
    "upvotes": 28
  },
  {
    "id": "2602.02214",
    "date": "2026-02-03",
    "title": "Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation",
    "authors": "Hongzhou Zhu Min Zhao Guande He Hang Su Chongxuan Li Jun Zhu",
    "abstract": "A novel Causal Forcing method addresses the architectural gap in distilling bidirectional video diffusion models into autoregressive models by using AR teachers for ODE initialization, significantly improving video generation performance. To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention . However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation , which requires frame-level injectivity , where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution , which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\\% in Dynamic Degree, 8.7\\% in VisionReward, and 16.7\\% in Instruction Following. Project page and the code: https://thu-ml.github.io/CausalForcing.github.io/{https://thu-ml.github.io/CausalForcing.github.io/}",
    "summary_en": "A novel Causal Forcing method addresses the architectural gap in distilling bidirectional video diffusion models into autoregressive models by using AR teachers for ODE initialization, significantly improving video generation performance.",
    "summary_zh": "一种新颖的因果强制方法通过使用AR教师模型进行ODE初始化，解决了将双向视频扩散模型蒸馏为自回归模型时存在的架构差距问题，显著提升了视频生成性能。",
    "upvotes": 24
  },
  {
    "id": "2602.01624",
    "date": "2026-02-03",
    "title": "PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards",
    "authors": "Minh-Quan Le Gaurav Mittal Cheng Zhao David Gu Dimitris Samaras Mei Chen",
    "abstract": "PISCES is an annotation-free text-to-video generation method that uses dual optimal transport-aligned rewards to improve visual quality and semantic alignment without human preference annotations. Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present PISCES, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, PISCES uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, PISCES is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that PISCES outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning .",
    "summary_en": "PISCES is an annotation-free text-to-video generation method that uses dual optimal transport-aligned rewards to improve visual quality and semantic alignment without human preference annotations.",
    "summary_zh": "PISCES是一种无需标注的文本到视频生成方法，通过双重最优传输对齐奖励提升视觉质量与语义对齐，无需人类偏好标注。",
    "upvotes": 23
  },
  {
    "id": "2602.01395",
    "date": "2026-02-03",
    "title": "Rethinking Selective Knowledge Distillation",
    "authors": "Almog Tavor Itay Ebenspanger Neil Cnaan Mor Geva",
    "abstract": "Selective knowledge distillation in autoregressive language models using student-entropy-guided position selection improves accuracy and efficiency while reducing memory and storage requirements. Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation , which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation . Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance.",
    "summary_en": "Selective knowledge distillation in autoregressive language models using student-entropy-guided position selection improves accuracy and efficiency while reducing memory and storage requirements.",
    "summary_zh": "基于学生熵引导位置选择的自回归语言模型选择性知识蒸馏可提升准确率与效率，同时降低内存和存储需求。",
    "upvotes": 23
  },
  {
    "id": "2602.01756",
    "date": "2026-02-03",
    "title": "Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation",
    "authors": "Jun He Junyan Ye Zilong Huang Dongzhi Jiang Chenjue Zhang Leqi Zhu Renrui Zhang Xiang Zhang Weijia Li",
    "abstract": "Mind-Brush presents a unified agentic framework for text-to-image generation that dynamically retrieves multimodal evidence and employs reasoning tools to improve understanding of implicit user intentions and complex knowledge reasoning.",
    "summary_en": "Mind-Brush presents a unified agentic framework for text-to-image generation that dynamically retrieves multimodal evidence and employs reasoning tools to improve understanding of implicit user intentions and complex knowledge reasoning.",
    "summary_zh": "Mind-Brush 提出了一个统一的 agentic 框架，用于文本到图像生成，该框架动态检索多模态证据并采用推理工具，以提升对隐式用户意图和复杂知识推理的理解。",
    "upvotes": 22
  },
  {
    "id": "2602.02486",
    "date": "2026-02-03",
    "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents",
    "authors": "Jialiang Zhu Gongrui Zhang Xiaolong Ma Lin Xu Miaosen Zhang Ruiqi Yang Song Wang Kai Qiu Zhirong Wu Qi Dai Ruichun Ma Bei Liu Yifan Yang Chong Luo Zhengyuan Yang Linjie Li Lijuan Wang Weizhu Chen Xin Geng Baining Guo",
    "abstract": "Re-TRAC is an agentic framework that enhances LLM-based research agents by enabling cross-trajectory exploration and iterative reflection through structured state representations, leading to more efficient and effective problem-solving compared to traditional ReAct approaches. LLM-based deep research agents are largely built on the ReAct framework . This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning , reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning , achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.",
    "summary_en": "Re-TRAC is an agentic framework that enhances LLM-based research agents by enabling cross-trajectory exploration and iterative reflection through structured state representations, leading to more efficient and effective problem-solving compared to traditional ReAct approaches.",
    "summary_zh": "Re-TRAC是一种智能体框架，通过结构化状态表示实现跨轨迹探索与迭代反思，从而增强基于LLM的研究智能体，相较于传统ReAct方法能够实现更高效有效的问题求解。",
    "upvotes": 18
  },
  {
    "id": "2602.02092",
    "date": "2026-02-03",
    "title": "FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space",
    "authors": "FSVideo Team Qingyu Chen Zhiyuan Fang Haibin Huang Xinwei Huang Tong Jin Minxuan Lin Bo Liu Celong Liu Chongyang Ma Xing Mei Xiaohui Shen Yaojie Shen Fuwen Tan Angtian Wang Xiao Yang Yiding Yang Jiamin Yuan Lingxi Zhang Yuxin Zhang",
    "abstract": "FSVideo is a fast transformer-based image-to-video diffusion framework that uses a compressed video autoencoder, diffusion transformer architecture with enhanced layer memory, and multi-resolution generation strategy to achieve high performance with significantly reduced computation time.",
    "summary_en": "FSVideo is a fast transformer-based image-to-video diffusion framework that uses a compressed video autoencoder, diffusion transformer architecture with enhanced layer memory, and multi-resolution generation strategy to achieve high performance with significantly reduced computation time.",
    "summary_zh": "FSVideo是一种基于transformer的快速图像到视频扩散框架，采用压缩视频自编码器、具备增强层记忆的扩散transformer架构和多分辨率生成策略，在显著减少计算时间的同时实现高性能。",
    "upvotes": 18
  },
  {
    "id": "2602.01479",
    "date": "2026-02-03",
    "title": "Ebisu: Benchmarking Large Language Models in Japanese Finance",
    "authors": "Xueqing Peng Ruoyu Xiang Fan Zhang Mingzi Song Mingyang Jiang Yan Wang Lingfei Qian Taiki Hara Yuqing Guo Jimin Huang Junichi Tsujii Sophia Ananiadou",
    "abstract": "A Japanese financial language understanding benchmark named Ebisu is introduced, featuring two expert-annotated tasks that evaluate implicit commitment recognition and hierarchical financial terminology extraction, revealing persistent challenges for current language models despite their advanced capabilities. Japanese finance combines agglutinative, head-final linguistic structure , mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment , posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A , and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures . We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.",
    "summary_en": "A Japanese financial language understanding benchmark named Ebisu is introduced, featuring two expert-annotated tasks that evaluate implicit commitment recognition and hierarchical financial terminology extraction, revealing persistent challenges for current language models despite their advanced capabilities.",
    "summary_zh": "介绍了一个名为Ebisu的日本金融语言理解基准，包含两个专家标注任务，用于评估隐性承诺识别和层次化金融术语抽取，揭示了当前语言模型尽管具备先进能力，但仍面临持续性挑战。",
    "upvotes": 17
  },
  {
    "id": "2602.01851",
    "date": "2026-02-03",
    "title": "How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing",
    "authors": "Huanyu Zhang Xuehai Bai Chengzu Li Chen Liang Haochen Tian Haodong Li Ruichuan An Yifan Zhang Anna Korhonen Zhang Zhang Liang Wang Tieniu Tan",
    "abstract": "Visual Instruction Benchmark for Image Editing introduces a three-level interaction hierarchy for evaluating visual instruction following capabilities in generative models. Recent generative models have achieved remarkable progress in image editing . However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding , morphological manipulation , and causal reasoning . Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following . We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.",
    "summary_en": "Visual Instruction Benchmark for Image Editing introduces a three-level interaction hierarchy for evaluating visual instruction following capabilities in generative models.",
    "summary_zh": "面向图像编辑的视觉指令基准提出了一个三级交互层次结构，用于评估生成模型的视觉指令遵循能力。",
    "upvotes": 16
  },
  {
    "id": "2602.01541",
    "date": "2026-02-03",
    "title": "Toward Cognitive Supersensing in Multimodal Large Language Model",
    "authors": "Boyi Li Yifan Shen Yuanzhe Liu Yifan Xu Jiateng Liu Xinzhuo Li Zhengyuan Li Jingyuan Zhu Yunhan Zhong Fangzhou Lan Jianguo Cao James M. Rehg Heng Ji Ismini Lourentzou Xu Cao",
    "abstract": "MLLMs equipped with Cognitive Supersensing and Latent Visual Imagery Prediction demonstrate enhanced cognitive reasoning capabilities through integrated visual and textual reasoning pathways.",
    "summary_en": "MLLMs equipped with Cognitive Supersensing and Latent Visual Imagery Prediction demonstrate enhanced cognitive reasoning capabilities through integrated visual and textual reasoning pathways.",
    "summary_zh": "配备认知超感知与潜在视觉意象预测的MLLMs通过集成的视觉和文本推理路径展现出增强的认知推理能力。",
    "upvotes": 16
  },
  {
    "id": "2602.01335",
    "date": "2026-02-03",
    "title": "Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning",
    "authors": "Yu Xu Yuxin Zhang Juan Cao Lin Gao Chunyu Wang Oliver Deussen Tong-Yee Lee Fan Tang",
    "abstract": "Visual metaphor transfer enables creative AI systems to decompose abstract conceptual relationships from reference images and reapply them to new subjects through a multi-agent framework grounded in cognitive theory. A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the \" creative essence \" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar (\"G\"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic , component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available.",
    "summary_en": "Visual metaphor transfer enables creative AI systems to decompose abstract conceptual relationships from reference images and reapply them to new subjects through a multi-agent framework grounded in cognitive theory.",
    "summary_zh": "视觉隐喻迁移使创造性AI系统能够通过基于认知理论的多智能体框架，从参考图像中分解抽象概念关系，并将其重新应用于新主体。",
    "upvotes": 16
  },
  {
    "id": "2602.01538",
    "date": "2026-02-03",
    "title": "Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars",
    "authors": "Youliang Zhang Zhengguang Zhou Zhentao Yu Ziyao Huang Teng Hu Sen Liang Guozhen Zhang Ziqiao Peng Shunkai Li Yi Chen Zixiang Zhou Yuan Zhou Qinglin Lu Xiu Li",
    "abstract": "A dual-stream framework called InteractAvatar is presented for generating talking avatars that can interact with objects in their environment, addressing challenges in grounded human-object interaction through decoupled perception and planning modules.",
    "summary_en": "A dual-stream framework called InteractAvatar is presented for generating talking avatars that can interact with objects in their environment, addressing challenges in grounded human-object interaction through decoupled perception and planning modules.",
    "summary_zh": "提出了一种名为 InteractAvatar 的双流框架，用于生成能够与环境物体交互的说话头像，通过解耦的感知与规划模块，解决了真实场景人物交互中的挑战。",
    "upvotes": 15
  },
  {
    "id": "2602.01511",
    "date": "2026-02-03",
    "title": "Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training",
    "authors": "Ran Xu Tianci Liu Zihan Dong Tony You Ilgee Hong Carl Yang Linjun Zhang Tao Zhao Haoyu Wang",
    "abstract": "Rubric-ARM framework jointly optimizes rubric generation and judging through reinforcement learning to improve response quality assessment in creative and open-ended tasks. Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback . Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.",
    "summary_en": "Rubric-ARM framework jointly optimizes rubric generation and judging through reinforcement learning to improve response quality assessment in creative and open-ended tasks.",
    "summary_zh": "Rubric-ARM框架通过强化学习联合优化评分标准生成与评判，以提升创意性和开放式任务中的回复质量评估。",
    "upvotes": 14
  },
  {
    "id": "2602.02343",
    "date": "2026-02-03",
    "title": "Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics",
    "authors": "Ziwen Xu Chenyan Wu Hengyu Sun Haiwen Hong Mengru Wang Yunzhi Yao Longtao Huang Hui Xue Shumin Deng Zhixuan Chu Huajun Chen Ningyu Zhang",
    "abstract": "Large language model control methods are unified under a dynamic weight update framework, revealing a preference-utility trade-off and enabling improved steering through SPLIT approach. Methods for controlling large language models (LLMs), including local weight fine-tuning , LoRA-based adaptation , and activation-based interventions , are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal , placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples . Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold . Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/ SPLIT .md.",
    "summary_en": "Large language model control methods are unified under a dynamic weight update framework, revealing a preference-utility trade-off and enabling improved steering through SPLIT approach.",
    "summary_zh": "大语言模型控制方法统一于动态权重更新框架，揭示偏好-效用权衡，并通过SPLIT方法实现改进的引导。",
    "upvotes": 13
  },
  {
    "id": "2602.00986",
    "date": "2026-02-03",
    "title": "Sparse Reward Subsystem in Large Language Models",
    "authors": "Guowei Xu Mert Yuksekgonul James Zou",
    "abstract": "In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments , we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected.",
    "summary_en": "In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments , we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected.",
    "summary_zh": "本文识别出大语言模型（LLMs）隐藏状态中存在一个稀疏奖励子系统，并将其类比于人脑中的生物奖励子系统。我们证明该子系统包含价值神经元，这些神经元表征模型对状态价值的内部预期，并通过干预实验确立了这些神经元对推理的重要性。实验表明，这些价值神经元在多样化数据集、不同模型规模和架构上均具有鲁棒性；此外，它们在来自同一基础模型的不同数据集和微调模型之间表现出显著的可迁移性。通过检验价值预测与实际奖励出现分歧的案例，我们在奖励子系统中识别出编码奖励预测误差（RPE）的多巴胺神经元。当奖励高于预期时，这些神经元表现出高激活；当奖励低于预期时，则表现出低激活。",
    "upvotes": 13
  },
  {
    "id": "2601.21123",
    "date": "2026-02-03",
    "title": "CUA-Skill: Develop Skills for Computer Using Agent",
    "authors": "Tianyi Chen Yinheng Li Michael Solodko Sen Wang Nan Jiang Tingyuan Cui Junheng Hao Jongwoo Ko Sara Abdali Suzhen Zheng Leon Xu Hao Fan Pashmina Cameron Justin Wagle Kazuhito Koishida",
    "abstract": "CUA-Skill introduces a large-scale library of engineered computer-use skills that enhance agent performance and efficiency on Windows-based tasks. Computer-Using Agents (CUAs) aim to autonomously operate computer systems to complete real-world tasks. However, existing agentic systems remain difficult to scale and lag behind human performance. A key limitation is the absence of reusable and structured skill abstractions that capture how humans interact with graphical user interfaces and how to leverage these skills. We introduce CUA-Skill, a computer-using agentic skill base that encodes human computer-use knowledge as skills coupled with parameterized execution and composition graphs . CUA-Skill is a large-scale library of carefully engineered skills spanning common Windows applications, serving as a practical infrastructure and tool substrate for scalable, reliable agent development. Built upon this skill base , we construct CUA-Skill Agent, an end-to-end computer-using agent that supports dynamic skill retrieval , argument instantiation , and memory-aware failure recovery . Our results demonstrate that CUA-Skill substantially improves execution success rates and robustness on challenging end-to-end agent benchmarks, establishing a strong foundation for future computer-using agent development. On WindowsAgentArena , CUA-Skill Agent achieves state-of-the-art 57.5% (best of three) successful rate while being significantly more efficient than prior and concurrent approaches. The project page is available at https://microsoft.github.io/cua_skill/.",
    "summary_en": "CUA-Skill introduces a large-scale library of engineered computer-use skills that enhance agent performance and efficiency on Windows-based tasks.",
    "summary_zh": "CUA-Skill 引入了一个大规模工程化计算机使用技能库，可提升智能体在基于Windows的任务上的性能和效率。",
    "upvotes": 13
  },
  {
    "id": "2602.02156",
    "date": "2026-02-03",
    "title": "LoopViT: Scaling Visual ARC with Looped Transformers",
    "authors": "Wen-Jie Shu Xuerui Qiu Rui-Jie Zhu Harold Haodong Chen Yexin Liu Harry Yang",
    "abstract": "Loop-ViT introduces a recursive vision transformer architecture that decouples reasoning depth from model capacity through weight-tied recurrence and dynamic exit mechanisms, achieving superior visual reasoning performance with fewer parameters. Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark . However, we argue that the feed-forward architecture , where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence . Loop-ViT iterates a weight-tied Hybrid Block , combining local convolutions and global attention , to form a latent chain of thought . Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy : the model halts inference when its internal state ``crystallizes\" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT.",
    "summary_en": "Loop-ViT introduces a recursive vision transformer architecture that decouples reasoning depth from model capacity through weight-tied recurrence and dynamic exit mechanisms, achieving superior visual reasoning performance with fewer parameters.",
    "summary_zh": "Loop-ViT引入了一种递归视觉Transformer架构，通过权重共享的递归和动态退出机制将推理深度与模型容量解耦，以更少的参数实现了更优的视觉推理性能。",
    "upvotes": 12
  },
  {
    "id": "2602.02477",
    "date": "2026-02-03",
    "title": "Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability",
    "authors": "Xiao Liang Zhong-Zhi Li Zhenghao Lin Eric Hancheng Jiang Hengyuan Zhang Yelong Shen Kai-Wei Chang Ying Nian Wu Yeyun Gong Weizhu Chen",
    "abstract": "An end-to-end reinforcement learning framework enhances large language models' reasoning capabilities by implementing divide-and-conquer strategies that outperform traditional chain-of-thought reasoning on challenging benchmarks. Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability . A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability , surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.",
    "summary_en": "An end-to-end reinforcement learning framework enhances large language models' reasoning capabilities by implementing divide-and-conquer strategies that outperform traditional chain-of-thought reasoning on challenging benchmarks.",
    "summary_zh": "一种端到端强化学习框架通过分治策略增强大语言模型的推理能力，该策略在挑战性基准测试中优于传统思维链推理。",
    "upvotes": 10
  },
  {
    "id": "2602.02227",
    "date": "2026-02-03",
    "title": "Show, Don't Tell: Morphing Latent Reasoning into Image Generation",
    "authors": "Harold Haodong Chen Xinxiang Yin Wen-Jie Shu Hongfei Zhang Zixin Zhang Chenfei Liao Litao Guo Qifeng Chen Ying-Cong Chen",
    "abstract": "LatentMorph integrates implicit latent reasoning into text-to-image generation through four lightweight components that enable adaptive self-refinement and improve both efficiency and cognitive alignment.",
    "summary_en": "LatentMorph integrates implicit latent reasoning into text-to-image generation through four lightweight components that enable adaptive self-refinement and improve both efficiency and cognitive alignment.",
    "summary_zh": "LatentMorph通过四个轻量级组件将隐式潜在推理整合至文本到图像生成中，实现自适应自我优化，并提升效率与认知对齐度。",
    "upvotes": 10
  },
  {
    "id": "2601.20613",
    "date": "2026-02-03",
    "title": "AgentIF-OneDay: A Task-level Instruction-Following Benchmark for General AI Agents in Daily Scenarios",
    "authors": "Kaiyuan Chen Qimin Wu Taiyu Hou Tianhao Tang Xueyu Hu Yuchen Hou Bikun Li Chengming Qian Guoyin Wang Haolin Chen Haotong Tian Haoye Zhang Haoyu Bian Hongbing Pan Hongkang Zhang Hongyi Zhou Jiaqi Cai Jiewu Rao Jiyuan Ren Keduan Huang Lucia Zhu Huang Mingyu Yuan",
    "abstract": "AgentIF-OneDay evaluates AI agents' ability to handle diverse daily tasks through natural language instructions, requiring problem-solving, attachment understanding, and file-based outputs across three user-centric categories. The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of a broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete a diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution , which assesses adherence to explicit and complex workflows; Latent Instruction , which requires agents to infer implicit instructions from attachments; and Iterative Refinement , which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and a refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities , enabling AI application teams to develop cutting-edge Agent products.",
    "summary_en": "AgentIF-OneDay evaluates AI agents' ability to handle diverse daily tasks through natural language instructions, requiring problem-solving, attachment understanding, and file-based outputs across three user-centric categories.",
    "summary_zh": "AgentIF-OneDay评估AI智能体通过自然语言指令处理多样化日常任务的能力，要求具备问题解决、附件理解和基于文件的输出能力，涵盖三个以用户为中心的类别。",
    "upvotes": 10
  },
  {
    "id": "2602.01675",
    "date": "2026-02-03",
    "title": "TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios",
    "authors": "Yuanzhe Shen Zisu Huang Zhengyuan Wang Muzhao Tian Zhengkang Guo Chenyang Zhang Shuaiyu Zhou Zengjie Hu Dailin Li Jingwen Xu Kaimin Wang Wenhao Liu Tianlong Li Fengpeng Yue Feng Hong Cao Liu Ke Zeng",
    "abstract": "TRIP-Bench presents a comprehensive long-horizon benchmark for travel planning that evaluates LLM agents on complex multi-turn interactions, while GTPO offers an online reinforcement learning approach to enhance constraint satisfaction and robustness in extended dialogues. As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions . To bridge this gap, we introduce TRIP-Bench, a long-horizon benchmark grounded in realistic travel-planning scenarios . TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation . It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\\% success on the easy split, with performance dropping below 10\\% on hard subsets. We further propose GTPO, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing . Applied to Qwen2.5-32B-Instruct , GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.",
    "summary_en": "TRIP-Bench presents a comprehensive long-horizon benchmark for travel planning that evaluates LLM agents on complex multi-turn interactions, while GTPO offers an online reinforcement learning approach to enhance constraint satisfaction and robustness in extended dialogues.",
    "summary_zh": "TRIP-Bench提出了一个全面的旅行规划长期基准测试，用于评估LLM智能体在复杂多轮交互中的表现；GTPO则提供了一种在线强化学习方法，以增强扩展对话中的约束满足和鲁棒性。",
    "upvotes": 9
  },
  {
    "id": "2602.01382",
    "date": "2026-02-03",
    "title": "PromptRL: Prompt Matters in RL for Flow-Based Image Generation",
    "authors": "Fu-Yun Wang Han Zhang Michael Gharbi Hongsheng Li Taesung Park",
    "abstract": "Flow matching models for text-to-image generation are enhanced through a reinforcement learning framework that addresses sample inefficiency and prompt overfitting by incorporating language models for prompt refinement, achieving superior performance with reduced computational requirements. Flow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as a critical post-training strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting , where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), a framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, a synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval , 0.98 on OCR accuracy , and 24.05 on PickScore . Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with a complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2times fewer rollouts compared to naive flow-only RL. Our code is available at https://github.com/G-U-N/ UniRL .",
    "summary_en": "Flow matching models for text-to-image generation are enhanced through a reinforcement learning framework that addresses sample inefficiency and prompt overfitting by incorporating language models for prompt refinement, achieving superior performance with reduced computational requirements.",
    "summary_zh": "面向文本到图像生成的流匹配模型通过强化学习框架得到增强，该框架引入语言模型进行提示词优化，解决了样本效率低下和提示词过拟合问题，在降低计算需求的同时实现了更优性能。",
    "upvotes": 8
  },
  {
    "id": "2602.01322",
    "date": "2026-02-03",
    "title": "PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding",
    "authors": "Panagiotis Koromilas Andreas D. Demou James Oldfield Yannis Panagakis Mihalis Nicolaou",
    "abstract": "PolySAE extends sparse autoencoders with polynomial decoding to capture feature interactions and compositional structure while maintaining linear encoders for interpretability. Sparse autoencoders (SAEs) have emerged as a promising method for interpreting neural network representations by decomposing activations into sparse combinations of dictionary atoms . However, SAEs assume that features combine additively through linear reconstruction, an assumption that cannot capture compositional structure: linear models cannot distinguish whether \"Starbucks\" arises from the composition of \"star\" and \"coffee\" features or merely their co-occurrence. This forces SAEs to allocate monolithic features for compound concepts rather than decomposing them into interpretable constituents. We introduce PolySAE, which extends the SAE decoder with higher-order terms to model feature interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization on a shared projection subspace, PolySAE captures pairwise and triple feature interactions with small parameter overhead (3% on GPT2). Across four language models and three SAE variants, PolySAE achieves an average improvement of approximately 8% in probing F1 while maintaining comparable reconstruction error, and produces 2-10times larger Wasserstein distances between class-conditional feature distributions. Critically, learned interaction weights exhibit negligible correlation with co-occurrence frequency (r = 0.06 vs. r = 0.82 for SAE feature covariance), suggesting that polynomial terms capture compositional structure, such as morphological binding and phrasal composition , largely independent of surface statistics.",
    "summary_en": "PolySAE extends sparse autoencoders with polynomial decoding to capture feature interactions and compositional structure while maintaining linear encoders for interpretability.",
    "summary_zh": "PolySAE 通过多项式解码扩展稀疏自编码器，在保持线性编码器以确保可解释性的同时，捕捉特征交互与组合结构。",
    "upvotes": 8
  },
  {
    "id": "2602.01660",
    "date": "2026-02-03",
    "title": "CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation",
    "authors": "Zhongyuan Peng Caijun Xu Changyi Xiao Shibo Hong Eli Zhang Stephen Huang Yixin Cao",
    "abstract": "A novel framework called CoDiQ enables controllable difficulty generation for competition-level questions through test-time scaling, resulting in a corpus that significantly improves large reasoning model performance. Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions . However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation ), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation , making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance , verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus , CoDiQ-Generator , and implementations to support related research.",
    "summary_en": "A novel framework called CoDiQ enables controllable difficulty generation for competition-level questions through test-time scaling, resulting in a corpus that significantly improves large reasoning model performance.",
    "summary_zh": "一种名为CoDiQ的新颖框架通过测试时缩放实现竞赛级问题的可控难度生成，由此产生的语料库显著提升了大型推理模型的性能。",
    "upvotes": 7
  },
  {
    "id": "2602.00269",
    "date": "2026-02-03",
    "title": "VoxServe: Streaming-Centric Serving System for Speech Language Models",
    "authors": "Keisuke Kamahori Wei-Tzu Lee Atindra Jha Rohan Kadekodi Stephanie Wang Arvind Krishnamurthy Baris Kasikci",
    "abstract": "VoxServe is a unified serving system for Speech Language Models that enhances streaming performance through model-execution abstraction, streaming-aware scheduling, and asynchronous inference pipelines. Deploying modern Speech Language Models (SpeechLMs) in streaming settings requires systems that provide low latency , high throughput , and strong guarantees of streamability . Existing systems fall short of supporting diverse models flexibly and efficiently. We present VoxServe, a unified serving system for SpeechLMs that optimizes streaming performance. VoxServe introduces a model-execution abstraction that decouples model architecture from system-level optimizations, thereby enabling support for diverse SpeechLM architectures within a single framework. Building on this abstraction, VoxServe implements streaming-aware scheduling and an asynchronous inference pipeline to improve end-to-end efficiency. Evaluations across multiple modern SpeechLMs show that VoxServe achieves 10-20x higher throughput than existing implementations at comparable latency while maintaining high streaming viability. The code of VoxServe is available at https://github.com/vox-serve/vox-serve.",
    "summary_en": "VoxServe is a unified serving system for Speech Language Models that enhances streaming performance through model-execution abstraction, streaming-aware scheduling, and asynchronous inference pipelines.",
    "summary_zh": "VoxServe是一个面向语音语言模型的统一服务系统，通过模型执行抽象、流式感知调度和异步推理流水线提升流式性能。",
    "upvotes": 6
  },
  {
    "id": "2602.02110",
    "date": "2026-02-03",
    "title": "An Empirical Study of World Model Quantization",
    "authors": "Zhongqian Fu Tianyi Zhao Kai Han Hang Zhou Xinghao Chen Yunhe Wang",
    "abstract": "Post-training quantization effects in world models reveal unique failure modes and trade-offs between accuracy, bit-width, and planning performance, particularly in encoder-predictor module asymmetries and low-bit rollout stability. World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within a compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present a systematic empirical study of world model quantization using DINO-WM as a representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across a wide range of bit-widths, quantization granularities, and planning horizon s up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts , activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor module s. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/QuantWM.",
    "summary_en": "Post-training quantization effects in world models reveal unique failure modes and trade-offs between accuracy, bit-width, and planning performance, particularly in encoder-predictor module asymmetries and low-bit rollout stability.",
    "summary_zh": "世界模型中的训练后量化效应呈现出独特的失效模式，以及精度、位宽与规划性能之间的权衡，特别是在编码器-预测器模块不对称性和低比特 rollout 稳定性方面。",
    "upvotes": 5
  },
  {
    "id": "2602.02039",
    "date": "2026-02-03",
    "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models",
    "authors": "Wei Liu Peijie Yu Michele Orini Yali Du Yulan He",
    "abstract": "Agentic large language models require investigatory intelligence for autonomous data analysis, demonstrated through the Deep Data Research benchmark that evaluates their ability to extract insights from databases without explicit queries. The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence , distinguishing it from executional intelligence , which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.",
    "summary_en": "Agentic large language models require investigatory intelligence for autonomous data analysis, demonstrated through the Deep Data Research benchmark that evaluates their ability to extract insights from databases without explicit queries.",
    "summary_zh": "智能体大语言模型需要探究智能来实现自主数据分析，Deep Data Research 基准通过评估其在没有显式查询的情况下从数据库中提取洞察的能力验证了这一点。",
    "upvotes": 5
  },
  {
    "id": "2602.01984",
    "date": "2026-02-03",
    "title": "Enhancing Multi-Image Understanding through Delimiter Token Scaling",
    "authors": "Minyoung Lee Yeji Park Dongjun Hwang Yejin Kim Seong Joon Oh Junsuk Choe",
    "abstract": "Scaling hidden states of delimiter tokens in vision-language models reduces cross-image information leakage and improves multi-image reasoning performance. Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage , where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage . To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens . This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions . Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis , MuirBench , MIRB , and QBench2 . We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench , MultiNews , and WCEP-10 . Notably, our method requires no additional training or inference cost.",
    "summary_en": "Scaling hidden states of delimiter tokens in vision-language models reduces cross-image information leakage and improves multi-image reasoning performance.",
    "summary_zh": "缩放视觉-语言模型中分隔符token的隐藏状态，可减少跨图像信息泄漏并提升多图像推理性能。",
    "upvotes": 5
  },
  {
    "id": "2602.00759",
    "date": "2026-02-03",
    "title": "Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning",
    "authors": "Zhipeng Chen Xiaobo Qin Wayne Xin Zhao Youbin Wu Ji-Rong Wen",
    "abstract": "Adaptive Ability Decomposing (A²D) enhances reinforcement learning with verifiable rewards by decomposing complex questions into simpler sub-questions, improving LLM reasoning through guided exploration without requiring a teacher model. Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration , which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A^2D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions . Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A^2D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer , revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner 's exploration and exploitation abilities.",
    "summary_en": "Adaptive Ability Decomposing (A²D) enhances reinforcement learning with verifiable rewards by decomposing complex questions into simpler sub-questions, improving LLM reasoning through guided exploration without requiring a teacher model.",
    "summary_zh": "A²D（自适应能力分解）通过将复杂问题分解为更简单的子问题来增强可验证奖励强化学习，通过引导式探索提升LLM推理能力，无需教师模型。",
    "upvotes": 5
  },
  {
    "id": "2601.22674",
    "date": "2026-02-03",
    "title": "VisionTrim: Unified Vision Token Compression for Training-Free MLLM Acceleration",
    "authors": "Hanxun Yu Wentong Li Xuan Qu Song Wang Junbo Chen Jianke Zhu",
    "abstract": "VisionTrim is a training-free framework that accelerates multimodal large language models by selecting dominant visual tokens and merging them with text-guided complementation, improving efficiency without performance loss. Multimodal large language models (MLLMs) suffer from high computational costs due to excessive visual tokens , particularly in high-resolution and video-based scenarios. Existing token reduction methods typically focus on isolated pipeline components and often neglect textual alignment, leading to performance degradation. In this paper, we propose VisionTrim, a unified framework for training-free MLLM acceleration, integrating two effective plug-and-play modules: 1) the Dominant Vision Token Selection (DVTS) module, which preserves essential visual tokens via a global-local view, and 2) the Text-Guided Vision Complement (TGVC) module, which facilitates context-aware token merging guided by textual cues. Extensive experiments across diverse image and video multimodal benchmarks demonstrate the performance superiority of our VisionTrim, advancing practical MLLM deployment in real-world applications. The code is available at: https://github.com/hanxunyu/VisionTrim.",
    "summary_en": "VisionTrim is a training-free framework that accelerates multimodal large language models by selecting dominant visual tokens and merging them with text-guided complementation, improving efficiency without performance loss.",
    "summary_zh": "VisionTrim是一种无需训练的框架，通过选择主导视觉token并将其与文本引导的补充信息相融合，加速多模态大语言模型，在不损失性能的情况下提升效率。",
    "upvotes": 5
  },
  {
    "id": "2601.22599",
    "date": "2026-02-03",
    "title": "A Semantically Consistent Dataset for Data-Efficient Query-Based Universal Sound Separation",
    "authors": "Kai Li Jintao Cheng Chang Zeng Zijun Yan Helin Wang Zixiong Su Bo Zheng Xiaolin Hu",
    "abstract": "Automated pipeline for sound separation using high-purity single-event segments from in-the-wild datasets achieves competitive performance with significantly reduced data requirements. Query-based universal sound separation is fundamental to intelligent auditory systems, aiming to isolate specific sources from mixtures. Despite recent advances, existing methods continue to suffer from residual interference in complex acoustic scenes. This performance limitation stems largely from a data bottleneck: in-the-wild datasets contain weak labels and severe co-occurrence of events . These flaws induce models to learn spurious correlations between background noise and target categories instead of robust acoustic features. To address this, we propose an automated pipeline that eliminates co-occurrence of events by mining high-purity single-event segments from in-the-wild datasets via a semantically consistent synthesis protocol . Utilizing this pipeline, we constructed Hive, a high-quality synthetic dataset comprising 2.4k hours of raw audio. Experimental results demonstrate that, compared with the state-of-the-art model SAM-Audio which was trained on a huge dataset sim500 times larger than Hive, certain open-source models trained on Hive achieve competitive separation accuracy and perceptual quality. Moreover, these models exhibited remarkable zero-shot generalization on out-of-distribution evaluation benchmarks. These findings highlight that prioritizing purity of supervised signals enables significant data efficiency , offering a new paradigm for training robust auditory foundation models with reduced computational costs. Code and dataset are available at https://shandaai.github.io/Hive.",
    "summary_en": "Automated pipeline for sound separation using high-purity single-event segments from in-the-wild datasets achieves competitive performance with significantly reduced data requirements.",
    "summary_zh": "利用来自真实场景数据集的高纯度单事件片段进行声音分离的自动化流程，以显著降低的数据需求实现了具有竞争力的性能。",
    "upvotes": 5
  },
  {
    "id": "2601.22588",
    "date": "2026-02-03",
    "title": "Rethinking LLM-as-a-Judge: Representation-as-a-Judge with Small Language Models via Semantic Capacity Asymmetry",
    "authors": "Zhuochun Li Yong Zhang Ming Li Yuelyu Ji Yiming Zeng Ning Cheng Yun Zhu Yanmeng Wang Shaojun Wang Jing Xiao Daqing He",
    "abstract": "Small language models can effectively evaluate outputs by leveraging internal representations rather than generating responses, enabling a more efficient and interpretable evaluation approach through a probing-based framework. Large language models (LLMs) are widely used as reference-free evaluators via prompting, but this \" LLM-as-a-Judge \" paradigm is costly, opaque, and sensitive to prompt design. In this work, we investigate whether smaller models can serve as efficient evaluators by leveraging internal representations instead of surface generation. We uncover a consistent empirical pattern: small LMs, despite with weak generative ability, encode rich evaluative signals in their hidden states . This motivates us to propose the Semantic Capacity Asymmetry Hypothesis: evaluation requires significantly less semantic capacity than generation and can be grounded in intermediate representations, suggesting that evaluation does not necessarily need to rely on large-scale generative models but can instead leverage latent features from smaller ones. Our findings motivate a paradigm shift from LLM-as-a-Judge to Representation-as-a-Judge , a decoding-free evaluation strategy that probes internal model structure rather than relying on prompted output. We instantiate this paradigm through INSPECTOR, a probing-based framework that predicts aspect-level evaluation scores from small model representations. Experiments on reasoning benchmarks (GSM8K, MATH, GPQA) show that INSPECTOR substantially outperforms prompting-based small LMs and closely approximates full LLM judges, while offering a more efficient, reliable, and interpretable alternative for scalable evaluation.",
    "summary_en": "Small language models can effectively evaluate outputs by leveraging internal representations rather than generating responses, enabling a more efficient and interpretable evaluation approach through a probing-based framework.",
    "summary_zh": "小型语言模型能够利用内部表征而非生成回复来有效评估输出，通过基于探针的框架实现更高效且可解释的评估方法。",
    "upvotes": 5
  },
  {
    "id": "2602.01997",
    "date": "2026-02-03",
    "title": "On the Limits of Layer Pruning for Generative Reasoning in LLMs",
    "authors": "Safal Shrestha Anubhav Shrestha Aadim Nepal Minwu Kim Keith Ross",
    "abstract": "Layer pruning compresses large language models while maintaining classification performance but causes significant degradation in generative reasoning tasks, with limited recovery possible through supervised finetuning on self-generated responses. Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks . Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses . This approach achieves strong recovery on classification tasks, retaining up to 90\\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes.",
    "summary_en": "Layer pruning compresses large language models while maintaining classification performance but causes significant degradation in generative reasoning tasks, with limited recovery possible through supervised finetuning on self-generated responses.",
    "summary_zh": "层剪枝能够压缩大型语言模型并保持分类性能，但会导致生成式推理任务的显著退化，且通过自生成回复的监督微调仅能有限恢复。",
    "upvotes": 4
  },
  {
    "id": "2602.01296",
    "date": "2026-02-03",
    "title": "Interacted Planes Reveal 3D Line Mapping",
    "authors": "Zeran Ke Bin Tan Gui-Song Xia Yujun Shen Nan Xue",
    "abstract": "LiP-Map presents a line-plane joint optimization framework that explicitly models learnable line and planar primitives for accurate 3D line mapping in man-made environments. 3D line mapping from multi-view RGB images provides a compact and structured visual representation of scenes. We study the problem from a physical and topological perspective: a 3D line most naturally emerges as the edge of a finite 3D planar patch . We present LiP-Map, a line-plane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing a reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping , not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering a principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks\\&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization , establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research.",
    "summary_en": "LiP-Map presents a line-plane joint optimization framework that explicitly models learnable line and planar primitives for accurate 3D line mapping in man-made environments.",
    "summary_zh": "LiP-Map提出了一种线-面联合优化框架，显式建模可学习的线基元和平面基元，以在人造环境中实现精确的3D线地图构建。",
    "upvotes": 4
  },
  {
    "id": "2602.01842",
    "date": "2026-02-03",
    "title": "Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models",
    "authors": "Jinbin Bai Yixuan Li Yuchen Zhu Yi Xin Qingyu Shi Aosong Feng Xiaohong Liu Molei Tao Jianru Xue Xiangtai Li Ming-Hsuan Yang",
    "abstract": "A new test-time scaling framework called Prism is introduced for discrete diffusion language models that improves reasoning performance through hierarchical trajectory search, local branching with partial remasking, and self-verified feedback mechanisms. Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding , which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window , (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at https://github.com/viiika/Prism.",
    "summary_en": "A new test-time scaling framework called Prism is introduced for discrete diffusion language models that improves reasoning performance through hierarchical trajectory search, local branching with partial remasking, and self-verified feedback mechanisms.",
    "summary_zh": "针对离散扩散语言模型，本文提出了一种名为Prism的新型测试时扩展框架，通过分层轨迹搜索、局部分支与部分重掩码及自验证反馈机制提升推理性能。",
    "upvotes": 3
  },
  {
    "id": "2602.01077",
    "date": "2026-02-03",
    "title": "PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers",
    "authors": "Haopeng Li Shitong Shao Wenliang Zhong Zikai Zhou Lichen Bai Hui Xiong Zeke Xie",
    "abstract": "PISA is a novel sparse attention method that improves diffusion transformer efficiency by approximating non-critical attention blocks instead of discarding them, achieving faster processing with maintained quality. Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention . While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub- quadratic complexity . Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion . This design allows PISA to serve as a faithful proxy to full attention , effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality . Code is available at: https://github.com/xie-lab-ml/piecewise-sparse- attention .",
    "summary_en": "PISA is a novel sparse attention method that improves diffusion transformer efficiency by approximating non-critical attention blocks instead of discarding them, achieving faster processing with maintained quality.",
    "summary_zh": "PISA是一种新颖的稀疏注意力方法，通过近似非关键注意力块而非直接丢弃，提升扩散Transformer的效率，在保持质量的同时实现更快处理。",
    "upvotes": 3
  },
  {
    "id": "2602.00130",
    "date": "2026-02-03",
    "title": "On the Relationship Between Representation Geometry and Generalization in Deep Neural Networks",
    "authors": "Sumit Yadav",
    "abstract": "Effective dimension, an unsupervised geometric metric, strongly predicts neural network performance across different architectures and domains, showing bidirectional causality between representation geometry and accuracy. We investigate the relationship between representation geometry and neural network performance . Analyzing 52 pretrained ImageNet models across 13 architecture families , we show that effective dimension -- an unsupervised geometric metric -- strongly predicts accuracy. Output effective dimension achieves partial r=0.75 (p < 10^(-10)) after controlling for model capacity, while total compression achieves partial r=-0.72. These findings replicate across ImageNet and CIFAR-10, and generalize to NLP: effective dimension predicts performance for 8 encoder models on SST-2/MNLI and 15 decoder-only LLMs on AG News (r=0.69, p=0.004), while model size does not (r=0.07). We establish bidirectional causality: degrading geometry via noise causes accuracy loss (r=-0.94, p < 10^(-9)), while improving geometry via PCA maintains accuracy across architectures (-0.03pp at 95% variance). This relationship is noise-type agnostic -- Gaussian, Uniform, Dropout, and Salt-and-pepper noise all show |r| > 0.90. These results establish that effective dimension provides domain-agnostic predictive and causal information about neural network performance , computed entirely without labels.",
    "summary_en": "Effective dimension, an unsupervised geometric metric, strongly predicts neural network performance across different architectures and domains, showing bidirectional causality between representation geometry and accuracy.",
    "summary_zh": "有效维度是一种无监督几何度量，可强预测不同架构与领域中的神经网络性能，并揭示表示几何与准确率之间的双向因果关系。",
    "upvotes": 3
  },
  {
    "id": "2602.01983",
    "date": "2026-02-03",
    "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning",
    "authors": "Xintian Shen Jiawei Chen Lihao Zheng Hao Ma Tao Wei Kun Zhan",
    "abstract": "A training-free framework enables language model agents to automatically create and optimize tools during inference, improving their reasoning capabilities through self-evolution and memory consolidation. Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%uparrow and +23.04%uparrow on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.",
    "summary_en": "A training-free framework enables language model agents to automatically create and optimize tools during inference, improving their reasoning capabilities through self-evolution and memory consolidation.",
    "summary_zh": "一种无需训练的框架使语言模型智能体能够在推理过程中自动创建和优化工具，通过自我进化和记忆巩固提升其推理能力。",
    "upvotes": 2
  },
  {
    "id": "2602.01970",
    "date": "2026-02-03",
    "title": "Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models",
    "authors": "Yun Qu Qi Wang Yixiu Mao Heming Zou Yuhang Jiang Weijie Liu Clive Bai Kai Yang Yangkun Chen Saiyong Yang Xiangyang Ji",
    "abstract": "Generalizable Predictive Prompt Selection (GPS) uses Bayesian inference with a lightweight generative model to efficiently select informative prompts for reinforcement learning-enhanced language models, improving training efficiency and performance. Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization . Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency . However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency , final performance, and test-time efficiency over superior baseline methods.",
    "summary_en": "Generalizable Predictive Prompt Selection (GPS) uses Bayesian inference with a lightweight generative model to efficiently select informative prompts for reinforcement learning-enhanced language models, improving training efficiency and performance.",
    "summary_zh": "可泛化预测性提示选择（GPS）利用贝叶斯推断和轻量级生成模型，为强化学习增强的语言模型高效选择信息丰富的提示，从而提升训练效率和性能。",
    "upvotes": 2
  },
  {
    "id": "2602.01618",
    "date": "2026-02-03",
    "title": "SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia",
    "authors": "Panuthep Tasawong Jian Gang Ngui Alham Fikri Aji Trevor Cohn Peerat Limkonchotiwat",
    "abstract": "Researchers developed a novel agentic data-generation framework to create culturally grounded safety datasets for Southeast Asia, resulting in multilingual safeguard models that outperform existing approaches in detecting regionally sensitive content while maintaining general safety performance. Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance.",
    "summary_en": "Researchers developed a novel agentic data-generation framework to create culturally grounded safety datasets for Southeast Asia, resulting in multilingual safeguard models that outperform existing approaches in detecting regionally sensitive content while maintaining general safety performance.",
    "summary_zh": "研究人员开发了一种新型智能体数据生成框架，用于为东南亚创建具有文化根基的安全数据集，由此构建的多语言安全防护模型在检测区域性敏感内容方面优于现有方法，同时保持了通用安全性能。",
    "upvotes": 2
  },
  {
    "id": "2601.23000",
    "date": "2026-02-03",
    "title": "Mano: Restriking Manifold Optimization for LLM Training",
    "authors": "Yufei Gu Zeke Xie",
    "abstract": "A novel optimizer called Mano is proposed that combines manifold optimization with momentum projection onto tangent spaces, achieving superior performance over AdamW and Muon while reducing memory and computational requirements. While large language models ( LLMs ) have emerged as a significant advancement in artificial intelligence, the hardware and computational costs for training LLMs are also significantly burdensome. Among the state-of-the-art optimizer s, AdamW relies on diagonal curvature estimates and ignores structural properties, while Muon applies global spectral normalization at the expense of losing curvature information. In this study, we restriked manifold optimization methods for training LLMs , which may address both optimizer s' limitations, while conventional manifold optimization methods have been largely overlooked due to the poor performance in large-scale model optimization. By innovatively projecting the momentum onto the tangent space of model parameters and constraining it on a rotational Oblique manifold , we propose a novel, powerful, and efficient optimizer **Mano** that is the first to bridge the performance gap between manifold optimization and modern optimizer s. Extensive experiments on the LLaMA and Qwen3 models demonstrate that Mano consistently and significantly outperforms AdamW and Muon even with less memory consumption and computational complexity , respectively, suggesting an expanded Pareto frontier in terms of space and time efficiency.",
    "summary_en": "A novel optimizer called Mano is proposed that combines manifold optimization with momentum projection onto tangent spaces, achieving superior performance over AdamW and Muon while reducing memory and computational requirements.",
    "summary_zh": "提出了一种名为Mano的新型优化器，它结合了流形优化与切空间上的动量投影，在性能上优于AdamW和Muon，同时减少了内存和计算需求。",
    "upvotes": 2
  },
  {
    "id": "2601.22801",
    "date": "2026-02-03",
    "title": "Clipping-Free Policy Optimization for Large Language Models",
    "authors": "Ömer Veysel Çağatan Barış Akgün Gözde Gül Şahin Xuandong Zhao",
    "abstract": "Clipping-Free Policy Optimization replaces heuristic clipping with convex quadratic penalty to stabilize reinforcement learning training for large language models without performance loss. Reinforcement learning has become central to post-training large language models, yet dominant algorithms rely on clipping mechanisms that introduce optimization issues at scale, including zero-gradient regions, reward hacking , and training instability . We propose Clipping-Free Policy Optimization (CFPO), which replaces heuristic clipping with a convex quadratic penalty derived from Total Variation divergence constraints, yielding an everywhere-differentiable objective that enforces stable policy updates without hard boundaries. We evaluate CFPO across both reasoning and alignment settings. In reasoning, CFPO matches clipping-based methods on downstream benchmarks while extending the stable training regime. In alignment, CFPO mitigates verbosity exploitation and reduces capability degradation, while achieving competitive instruction-following performance. CFPO requires only a one-line code change and no additional hyperparameters. Our results suggest that CFPO is a promising drop-in alternative to clipping-based methods for LLM post-training.",
    "summary_en": "Clipping-Free Policy Optimization replaces heuristic clipping with convex quadratic penalty to stabilize reinforcement learning training for large language models without performance loss.",
    "summary_zh": "无裁剪策略优化使用凸二次惩罚替代启发式裁剪，在稳定大语言模型强化学习训练的同时避免性能损失。",
    "upvotes": 2
  },
  {
    "id": "2601.21968",
    "date": "2026-02-03",
    "title": "OVD: On-policy Verbal Distillation",
    "authors": "Jing Xiong Hui Shen Shansan Gong Yuxin Cheng Jianghan Shen Chaofan Tao Haochen Tan Haoli Bai Lifeng Shang Ngai Wong",
    "abstract": "On-policy Verbal Distillation (OVD) enables efficient knowledge transfer from teacher to student models by replacing token-level probability matching with trajectory matching using discrete verbal scores, reducing memory consumption and enabling free exploration without token alignment constraints. Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models ; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models , which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning . We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models . OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment , allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io",
    "summary_en": "On-policy Verbal Distillation (OVD) enables efficient knowledge transfer from teacher to student models by replacing token-level probability matching with trajectory matching using discrete verbal scores, reducing memory consumption and enabling free exploration without token alignment constraints.",
    "summary_zh": "策略内语言蒸馏（OVD）通过以离散语言评分进行轨迹匹配来替代token级概率匹配，实现从教师模型到学生模型的高效知识迁移，降低内存消耗，并支持无token对齐约束的自由探索。",
    "upvotes": 2
  },
  {
    "id": "2602.02354",
    "date": "2026-02-03",
    "title": "Implicit neural representation of textures",
    "authors": "Albert Kwok Zheyuan Hu Dounia Hammou",
    "abstract": "Implicit neural representations operate continuously over UV coordinate space, demonstrating good image quality while balancing memory usage and rendering time, with applications in real-time rendering and downstream tasks. Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space . Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality , with considerable memory usage and rendering inference time . We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation .",
    "summary_en": "Implicit neural representations operate continuously over UV coordinate space, demonstrating good image quality while balancing memory usage and rendering time, with applications in real-time rendering and downstream tasks.",
    "summary_zh": "隐式神经表示在UV坐标空间上连续运算，在平衡内存使用与渲染时间的同时展现出良好的图像质量，可应用于实时渲染和下游任务。",
    "upvotes": 1
  },
  {
    "id": "2602.02287",
    "date": "2026-02-03",
    "title": "Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages",
    "authors": "Isaac Chung Linda Freienthal",
    "abstract": "Controlled cross-lingual evaluation reveals instability in LLM assessment methods when targeting morphologically rich languages, indicating unreliable zero-shot judge transfer for discourse-level tasks. Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences. This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages , motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data , and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges.",
    "summary_en": "Controlled cross-lingual evaluation reveals instability in LLM assessment methods when targeting morphologically rich languages, indicating unreliable zero-shot judge transfer for discourse-level tasks.",
    "summary_zh": "受控跨语言评估显示，针对形态丰富语言时，LLM评估方法存在不稳定性，表明零样本评判迁移在话语级任务中并不可靠。",
    "upvotes": 1
  },
  {
    "id": "2602.01815",
    "date": "2026-02-03",
    "title": "INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery",
    "authors": "Yunhui Jang Seonghyun Park Jaehyung Kim Sungsoo Ahn",
    "abstract": "Multi-agent systems for molecular discovery that use individualized scientist profiles based on publication and molecular history outperform traditional role-based approaches. Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal , critique , and voting phases . Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.",
    "summary_en": "Multi-agent systems for molecular discovery that use individualized scientist profiles based on publication and molecular history outperform traditional role-based approaches.",
    "summary_zh": "使用基于发表论文和分子历史的个性化科学家档案的分子发现多智能体系统优于传统的基于角色的方法。",
    "upvotes": 1
  },
  {
    "id": "2602.00192",
    "date": "2026-02-03",
    "title": "AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange",
    "authors": "Elif Nebioglu Emirhan Bilgiç Adrian Popescu",
    "abstract": "VAE-based inpainting creates spectral shifts that fool detection systems, which can be mitigated through Inpainting Exchange to improve content-aware detection performance. Modern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces a subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create a 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit a dramatic drop in accuracy (e.g., from 91\\% to 55\\%), frequently approaching chance level. We provide a theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks . Our findings highlight the need for content-aware detection . Indeed, training on our dataset yields better generalization and localization than standard inpainting . Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X.",
    "summary_en": "VAE-based inpainting creates spectral shifts that fool detection systems, which can be mitigated through Inpainting Exchange to improve content-aware detection performance.",
    "summary_zh": "基于VAE的修复会产生频谱偏移，从而欺骗检测系统；通过Inpainting Exchange可缓解该现象，进而提升内容感知检测性能。",
    "upvotes": 1
  },
  {
    "id": "2602.00168",
    "date": "2026-02-03",
    "title": "YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation",
    "authors": "Ranjan Sapkota Manoj Karkee",
    "abstract": "YOLOE-26 integrates YOLO26 architecture with open-vocabulary learning for real-time instance segmentation, utilizing convolutional backbones, end-to-end regression, and object embedding heads with text and visual prompting capabilities. This paper presents YOLOE -26, a unified framework that integrates the deployment-optimized YOLO26 (or YOLOv26) architecture with the open-vocabulary learning paradigm of YOLOE for real-time open-vocabulary instance segmentation. Building on the NMS-free , end-to-end design of YOLOv26, the proposed approach preserves the hallmark efficiency and determinism of the YOLO family while extending its capabilities beyond closed-set recognition. YOLOE -26 employs a convolutional backbone with PAN/FPN-style multi-scale feature aggregation , followed by end-to-end regression and instance segmentation heads. A key architectural contribution is the replacement of fixed class logits with an object embedding head , which formulates classification as similarity matching against prompt embeddings derived from text descriptions, visual examples, or a built-in vocabulary. To enable efficient open-vocabulary reasoning, the framework incorporates Re-Parameterizable Region-Text Alignment (RepRTA) for zero-overhead text prompting, a Semantic-Activated Visual Prompt Encoder (SAVPE) for example-guided segmentation, and Lazy Region Prompt Contrast for prompt-free inference. All prompting modalities operate within a unified object embedding space, allowing seamless switching between text-prompted, visual-prompted, and fully autonomous segmentation. Extensive experiments demonstrate consistent scaling behavior and favorable accuracy-efficiency trade-offs across model sizes in both prompted and prompt-free settings. The training strategy leverages large-scale detection and grounding datasets with multi-task optimization and remains fully compatible with the Ultralytics ecosystem for training, validation, and deployment. Overall, YOLOE -26 provides a practical and scalable solution for real-time open-vocabulary instance segmentation in dynamic, real-world environments.",
    "summary_en": "YOLOE-26 integrates YOLO26 architecture with open-vocabulary learning for real-time instance segmentation, utilizing convolutional backbones, end-to-end regression, and object embedding heads with text and visual prompting capabilities.",
    "summary_zh": "YOLOE-26集成YOLO26架构与开放词汇学习以实现实时实例分割，采用卷积骨干网络、端到端回归及具备文本与视觉提示能力的目标嵌入头。",
    "upvotes": 1
  },
  {
    "id": "2601.22296",
    "date": "2026-02-03",
    "title": "ParalESN: Enabling parallel information processing in Reservoir Computing",
    "authors": "Matteo Pinna Giacomo Lagomarsini Andrea Ceni Claudio Gallicchio",
    "abstract": "Parallel Echo State Network (ParalESN) addresses reservoir computing limitations by enabling parallel temporal processing through diagonal linear recurrence, maintaining theoretical guarantees while achieving significant computational efficiency gains. Reservoir Computing (RC) has established itself as an efficient paradigm for temporal processing . However, its scalability remains severely constrained by (i) the necessity of processing temporal data sequentially and (ii) the prohibitive memory footprint of high-dimensional reservoirs. In this work, we revisit RC through the lens of structured operators and state space modeling to address these limitations, introducing Parallel Echo State Network (ParalESN). ParalESN enables the construction of high-dimensional and efficient reservoirs based on diagonal linear recurrence in the complex space , enabling parallel processing of temporal data . We provide a theoretical analysis demonstrating that ParalESN preserves the Echo State Property and the universality guarantees of traditional Echo State Networks while admitting an equivalent representation of arbitrary linear reservoirs in the complex diagonal form. Empirically, ParalESN matches the predictive accuracy of traditional RC on time series benchmarks, while delivering substantial computational savings. On 1-D pixel-level classification tasks, ParalESN achieves competitive accuracy with fully trainable neural networks while reducing computational costs and energy consumption by orders of magnitude. Overall, ParalESN offers a promising, scalable, and principled pathway for integrating RC within the deep learning landscape.",
    "summary_en": "Parallel Echo State Network (ParalESN) addresses reservoir computing limitations by enabling parallel temporal processing through diagonal linear recurrence, maintaining theoretical guarantees while achieving significant computational efficiency gains.",
    "summary_zh": "并行回声状态网络（ParalESN）通过使用对角线性递归实现并行时序处理，解决了储备池计算的局限性，在保持理论保证的同时实现了显著的计算效率提升。",
    "upvotes": 1
  },
  {
    "id": "2601.21759",
    "date": "2026-02-03",
    "title": "Influence Guided Sampling for Domain Adaptation of Text Retrievers",
    "authors": "Meet Doshi Vishwajeet Kumar Yulong Li Jaydeep Sen",
    "abstract": "An reinforcement learning-based sampling framework adaptively reweights training datasets to improve embedding model performance while reducing GPU costs. General-purpose open-domain dense retrieval systems are usually trained with a large, eclectic mix of corpora and search tasks. How should these diverse corpora and tasks be sampled for training? Conventional approaches sample them uniformly, proportional to their instance population sizes, or depend on human-level expert supervision. It is well known that the training data sampling strategy can greatly impact model performance. However, how to find the optimal strategy has not been adequately studied in the context of embedding models . We propose Inf-DDS, a novel reinforcement learning driven sampling framework that adaptively reweighs training datasets guided by influence-based reward signals and is much more lightweight with respect to GPU consumption. Our technique iteratively refines the sampling policy, prioritizing datasets that maximize model performance on a target development set. We evaluate the efficacy of our sampling strategy on a wide range of text retrieval tasks, demonstrating strong improvements in retrieval performance and better adaptation compared to existing gradient-based sampling methods, while also being 1.5x to 4x cheaper in GPU compute. Our sampling strategy achieves a 5.03 absolute NDCG@10 improvement while training a multilingual bge-m3 model and an absolute NDCG@10 improvement of 0.94 while training all-MiniLM-L6-v2 , even when starting from expert-assigned weights on a large pool of training datasets.",
    "summary_en": "An reinforcement learning-based sampling framework adaptively reweights training datasets to improve embedding model performance while reducing GPU costs.",
    "summary_zh": "基于强化学习的采样框架通过自适应重加权训练数据集，在提升嵌入模型性能的同时降低GPU成本。",
    "upvotes": 1
  },
  {
    "id": "2601.16513",
    "date": "2026-02-03",
    "title": "Competing Visions of Ethical AI: A Case Study of OpenAI",
    "authors": "Melissa Wilfley Mengting Ai Madelyn Rose Sanfilippo",
    "abstract": "",
    "summary_en": "",
    "summary_zh": "",
    "upvotes": 1
  },
  {
    "id": "2602.01897",
    "date": "2026-02-03",
    "title": "Internal Flow Signatures for Self-Checking and Refinement in LLMs",
    "authors": "Sungheon Jeong Sanggeon Yun Ryozo Masukawa Wenjun Haung Hanning Chen Mohsen Imani",
    "abstract": "Internal flow signatures analyze depthwise dynamics in large language models to enable self-checking and targeted refinement without modifying the base model. Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce internal flow signatures that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring , then summarizes trajectories in compact moving readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport , yielding depth-comparable transported step lengths , turning angles , and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement : the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. Code is available at github.com/EavnJeong/Internal-Flow-Signatures-for- Self-Checking -and-Refinement-in-LLMs.",
    "summary_en": "Internal flow signatures analyze depthwise dynamics in large language models to enable self-checking and targeted refinement without modifying the base model.",
    "summary_zh": "内部流特征分析大语言模型的深度动态，以在不修改基础模型的情况下实现自我检查与针对性优化。",
    "upvotes": 0
  },
  {
    "id": "2602.01418",
    "date": "2026-02-03",
    "title": "Where to Attend: A Principled Vision-Centric Position Encoding with Parabolas",
    "authors": "Christoffer Koo Øhrstrøm Rafael I. Cabral Muchacho Yifei Dong Filippos Moumtzidellis Ronja Güldenring Florian T. Pokorny Lazaros Nalpantidis",
    "abstract": "Parabolic Position Encoding (PaPE) is a novel position encoding method for vision modalities that improves upon existing approaches by incorporating translation invariance, rotation invariance, distance decay, directionality, and context awareness principles. We propose Parabolic Position Encoding (PaPE), a parabola-based position encoding for vision modalities in attention-based architectures . Given a set of vision tokens -such as images, point clouds, videos, or event camera streams-our objective is to encode their positions while accounting for the characteristics of vision modalities . Prior works have largely extended position encoding s from 1D-sequences in language to nD-structures in vision, but only with partial account of vision characteristics. We address this gap by designing PaPE from principles distilled from prior work: translation invariance , rotation invariance (PaPE-RI), distance decay , directionality , and context awareness . We evaluate PaPE on 8 datasets that span 4 modalities. We find that either PaPE or PaPE-RI achieves the top performance on 7 out of 8 datasets. Extrapolation experiments on ImageNet-1K show that PaPE extrapolates remarkably well, improving in absolute terms by up to 10.5% over the next-best position encoding . Code is available at https://github.com/DTU-PAS/parabolic-position-encoding.",
    "summary_en": "Parabolic Position Encoding (PaPE) is a novel position encoding method for vision modalities that improves upon existing approaches by incorporating translation invariance, rotation invariance, distance decay, directionality, and context awareness principles.",
    "summary_zh": "抛物线位置编码（PaPE）是一种面向视觉模态的新型位置编码方法，通过融合平移不变性、旋转不变性、距离衰减、方向性和上下文感知原则，改进了现有方法。",
    "upvotes": 0
  },
  {
    "id": "2602.00521",
    "date": "2026-02-03",
    "title": "Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory",
    "authors": "Junhyuk Choi Sohhyung Park Chanhee Cho Hyeonchu Park Bugeun Kim",
    "abstract": "A two-phase diagnostic framework based on Item Response Theory and Graded Response Model is introduced to assess the reliability of LLM-as-a-Judge by examining intrinsic consistency and human alignment. While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge , grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency , defined as the stability of measurement behavior under prompt variations, and (2) human alignment , capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of un reliability .",
    "summary_en": "A two-phase diagnostic framework based on Item Response Theory and Graded Response Model is introduced to assess the reliability of LLM-as-a-Judge by examining intrinsic consistency and human alignment.",
    "summary_zh": "提出了一种基于项目反应理论和等级反应模型的两阶段诊断框架，通过检验内在一致性和人类对齐来评估 LLM-as-a-Judge 的可靠性。",
    "upvotes": 0
  },
  {
    "id": "2601.14691",
    "date": "2026-02-03",
    "title": "Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation",
    "authors": "Muhammad Khalifa Lajanugen Logeswaran Jaekyeom Kim Sungryull Sohn Yunxiang Zhang Moontae Lee Hao Peng Lu Wang Honglak Lee",
    "abstract": "Large language models used as judges for agent performance evaluation are vulnerable to manipulation of reasoning traces, with content-based fabrications being more effective than style-based alterations. Large language models (LLMs) are increasingly used as judges to evaluate agent performance , particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute , which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence.",
    "summary_en": "Large language models used as judges for agent performance evaluation are vulnerable to manipulation of reasoning traces, with content-based fabrications being more effective than style-based alterations.",
    "summary_zh": "用作智能体性能评估评判器的大语言模型易受推理轨迹操纵，且基于内容的伪造比基于风格的修改更有效。",
    "upvotes": 0
  },
  {
    "id": "2601.23265",
    "date": "2026-02-02",
    "title": "PaperBanana: Automating Academic Illustration for AI Scientists",
    "authors": "Dawei Zhu Rui Meng Yale Song Xiyu Wei Sujian Li Tomas Pfister Jinsung Yoon",
    "abstract": "_paperbanana is an agentic framework that automates the creation of publication-ready academic illustrations using advanced vision-language models and image generation techniques. Despite rapid advances in autonomous AI scientists powered by language models, generating publication-ready illustrations remains a labor-intensive bottleneck in the research workflow. To lift this burden, we introduce PaperBanana, an agentic framework for automated generation of publication-ready academic illustrations. Powered by state-of-the-art VLMs and image generation models , PaperBanana orchestrates specialized agents to retrieve references, plan content and style, render images, and iteratively refine via self-critique . To rigorously evaluate our framework, we introduce PaperBananaBench , comprising 292 test cases for methodology diagrams curated from NeurIPS 2025 publications, covering diverse research domains and illustration styles. Comprehensive experiments demonstrate that PaperBanana consistently outperforms leading baselines in faithfulness, conciseness, readability, and aesthetics. We further show that our method effectively extends to the generation of high-quality statistical plots . Collectively, PaperBanana paves the way for the automated generation of publication-ready illustrations .",
    "summary_en": "_paperbanana is an agentic framework that automates the creation of publication-ready academic illustrations using advanced vision-language models and image generation techniques.",
    "summary_zh": "_paperbanana 是一个智能体框架，利用先进的视觉语言模型和图像生成技术，自动化创建出版级学术插图。",
    "upvotes": 188
  },
  {
    "id": "2601.22975",
    "date": "2026-02-02",
    "title": "Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text",
    "authors": "Ximing Lu David Acuna Jaehun Jung Jian Hu Di Zhang Shizhe Diao Yunheng Zou Shaokun Zhang Brandon Cui Mingjie Liu Hyunwoo Kim Prithviraj Ammanabrolu Jan Kautz Yi Dong Yejin Choi",
    "abstract": "Golden Goose synthesizes unlimited RLVR tasks from unverifiable internet text by creating multiple-choice question-answering versions of fill-in-the-middle tasks, enabling large-scale training and achieving state-of-the-art results in cybersecurity and other domains. Reinforcement Learning with Verifiable Rewards (RLVR) has become a cornerstone for unlocking complex reasoning in Large Language Models (LLMs). Yet, scaling up RL is bottlenecked by limited existing verifiable data, where improvements increasingly saturate over prolonged training. To overcome this, we propose Golden Goose, a simple trick to synthesize unlimited RLVR tasks from unverifiable internet text by constructing a multiple-choice question-answering version of the fill-in-the-middle task . Given a source text, we prompt an LLM to identify and mask key reasoning steps, then generate a set of diverse, plausible distractors. This enables us to leverage reasoning-rich unverifiable corpora typically excluded from prior RLVR data construction (e.g., science textbooks) to synthesize GooseReason-0.7M , a large-scale RLVR dataset with over 0.7 million tasks spanning mathematics, programming, and general scientific domains. Empirically, GooseReason effectively revives models saturated on existing RLVR data, yielding robust, sustained gains under continuous RL and achieving new state-of-the-art results for 1.5B and 4B-Instruct models across 15 diverse benchmarks. Finally, we deploy Golden Goose in a real-world setting, synthesizing RLVR tasks from raw FineWeb scrapes for the cybersecurity domain, where no prior RLVR data exists. Training Qwen3-4B-Instruct on the resulting data GooseReason-Cyber sets a new state-of-the-art in cybersecurity, surpassing a 7B domain-specialized model with extensive domain-specific pre-training and post-training. This highlights the potential of automatically scaling up RLVR data by exploiting abundant, reasoning-rich, unverifiable internet text.",
    "summary_en": "Golden Goose synthesizes unlimited RLVR tasks from unverifiable internet text by creating multiple-choice question-answering versions of fill-in-the-middle tasks, enabling large-scale training and achieving state-of-the-art results in cybersecurity and other domains.",
    "summary_zh": "Golden Goose通过将fill-in-the-middle任务转换为多项选择问答形式，基于不可验证的互联网文本合成无限的RLVR任务，实现大规模训练，并在网络安全及其他领域达到SOTA水平。",
    "upvotes": 100
  },
  {
    "id": "2601.21558",
    "date": "2026-02-02",
    "title": "ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas",
    "authors": "Xiaoyu Tian Haotian Wang Shuaiting Chen Hao Zhou Kaichi Yu Yudian Zhang Jade Ouyang Junxi Yin Jiong Chen Baoyan Guo Lei Zhang Junjie Tao Yuansheng Song Ming Cui Chengwei Liu",
    "abstract": "ASTRA is an automated framework that trains tool-augmented language models using synthetic data and verifiable reinforcement learning to improve multi-step decision-making capabilities. Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making , yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning . ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule- verifiable environments , enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.",
    "summary_en": "ASTRA is an automated framework that trains tool-augmented language models using synthetic data and verifiable reinforcement learning to improve multi-step decision-making capabilities.",
    "summary_zh": "ASTRA是一种自动化框架，使用合成数据和可验证的强化学习训练工具增强的语言模型，以提升多步决策能力。",
    "upvotes": 58
  },
  {
    "id": "2601.22813",
    "date": "2026-02-02",
    "title": "Quartet II: Accurate LLM Pre-Training in NVFP4 by Improved Unbiased Gradient Estimation",
    "authors": "Andrei Panferov Erik Schultheis Soroush Tabesh Dan Alistarh",
    "abstract": "Quantized training method Quartet II improves NVFP4 format utilization for large language model pre-training through enhanced gradient estimation and faster GPU execution. The NVFP4 lower-precision format, supported in hardware by NVIDIA Blackwell GPUs , promises to allow, for the first time, end-to-end fully-quantized pre-training of massive models such as LLMs. Yet, existing quantized training methods still sacrifice some of the representation capacity of this format in favor of more accurate unbiased quantized gradient estimation by stochastic rounding (SR), losing noticeable accuracy relative to standard FP16 and FP8 training. In this paper, improve the state of the art for quantized training in NVFP4 via a novel unbiased quantization routine for micro-scaled formats , called MS-EDEN , that has more than 2x lower quantization error than SR. We integrate it into a novel fully- NVFP4 quantization scheme for linear layers , called Quartet II . We show analytically that Quartet II achieves consistently better gradient estimation across all major matrix multiplications , both on the forward and on the backward passes. In addition, our proposal synergizes well with recent training improvements aimed specifically at NVFP4 . We further validate Quartet II on end-to-end LLM training with up to 1.9B parameters on 38B tokens. We provide kernels for execution on NVIDIA Blackwell GPUs with up to 4.2x speedup over BF16. Our code is available at https://github.com/IST-DASLab/Quartet-II .",
    "summary_en": "Quantized training method Quartet II improves NVFP4 format utilization for large language model pre-training through enhanced gradient estimation and faster GPU execution.",
    "summary_zh": "量化训练方法 Quartet II 通过增强梯度估计和加速 GPU 执行，提升了 NVFP4 格式在大语言模型预训练中的利用率。",
    "upvotes": 56
  },
  {
    "id": "2601.23143",
    "date": "2026-02-02",
    "title": "THINKSAFE: Self-Generated Safety Alignment for Reasoning Models",
    "authors": "Seanie Lee Sangwoo Park Yumin Choi Gyeongman Kim Minki Kang Jihun Yun Dongmin Park Jongho Park Sung Ju Hwang",
    "abstract": "ThinkSafe is a self-aligned framework that enhances safety in large reasoning models through lightweight refusal steering and fine-tuning on self-generated responses, maintaining reasoning performance while reducing computational costs. Large reasoning models (LRMs) achieve remarkable performance by leveraging reinforcement learning (RL) on reasoning tasks to generate long chain-of-thought (CoT) reasoning. However, this over-optimization often prioritizes compliance, making models vulnerable to harmful prompts. To mitigate this safety degradation, recent approaches rely on external teacher distillation , yet this introduces a distributional discrepancy that degrades native reasoning. We propose ThinkSafe, a self-generated alignment framework that restores safety alignment without external teachers. Our key insight is that while compliance suppresses safety mechanisms, models often retain latent knowledge to identify harm. ThinkSafe unlocks this via lightweight refusal steering , guiding the model to generate in-distribution safety reasoning traces. Fine-tuning on these self-generated responses effectively realigns the model while minimizing distribution shift. Experiments on DeepSeek-R1-Distill and Qwen3 show ThinkSafe significantly improves safety while preserving reasoning proficiency . Notably, it achieves superior safety and comparable reasoning to GRPO, with significantly reduced computational cost . Code, models, and datasets are available at https://github.com/seanie12/ThinkSafe.git.",
    "summary_en": "ThinkSafe is a self-aligned framework that enhances safety in large reasoning models through lightweight refusal steering and fine-tuning on self-generated responses, maintaining reasoning performance while reducing computational costs.",
    "summary_zh": "ThinkSafe是一种自对齐框架，通过轻量级拒绝引导和对自生成回复的微调来增强大型推理模型的安全性，在保持推理性能的同时降低计算成本。",
    "upvotes": 38
  },
  {
    "id": "2601.23184",
    "date": "2026-02-02",
    "title": "ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought",
    "authors": "Fanmeng Wang Haotian Liu Guojiang Zhao Hongteng Xu Zhifeng Gao",
    "abstract": "ReGuLaR introduces a variational auto-encoding framework that compresses reasoning processes into latent space while maintaining performance through image-rendered explicit reasoning chains for guidance. While Chain-of-Thought (CoT) significantly enhances the performance of Large Language Models (LLMs), explicit reasoning chains introduce substantial computational redundancy. Recent latent reasoning methods attempt to mitigate this by compressing reasoning processes into latent space, but often suffer from severe performance degradation due to the lack of appropriate compression guidance. In this study, we propose Rendered CoT-Guided variational Latent Reasoning (ReGuLaR), a simple yet novel latent learning paradigm resolving this issue. Fundamentally, we formulate latent reasoning within the Variational Auto-Encoding (VAE) framework, sampling the current latent reasoning state from the posterior distribution conditioned on previous ones. Specifically, when learning this variational latent reasoning model, we render explicit reasoning chains as images, from which we extract dense visual-semantic representations to regularize the posterior distribution , thereby achieving efficient compression with minimal information loss. Extensive experiments demonstrate that ReGuLaR significantly outperforms existing latent reasoning methods across both computational efficiency and reasoning effectiveness, and even surpasses CoT through multi-modal reasoning , providing a new and insightful solution to latent reasoning . Code: https://github.com/FanmengWang/ReGuLaR.",
    "summary_en": "ReGuLaR introduces a variational auto-encoding framework that compresses reasoning processes into latent space while maintaining performance through image-rendered explicit reasoning chains for guidance.",
    "summary_zh": "ReGuLaR提出了一种变分自编码框架，将推理过程压缩至隐空间，同时通过图像渲染的显式推理链进行引导以维持性能。",
    "upvotes": 36
  },
  {
    "id": "2601.22628",
    "date": "2026-02-02",
    "title": "TTCS: Test-Time Curriculum Synthesis for Self-Evolving",
    "authors": "Chengyi Yang Zhishang Xiang Yunbo Tang Zongpei Teng Chengsong Huang Fei Long Yuhan Liu Jinsong Su",
    "abstract": "TTCS is a co-evolving test-time training framework that enhances LLM reasoning abilities by iteratively generating challenging question variants and updating a reasoning solver through self-consistency rewards. Test-Time Training offers a promising way to improve the reasoning ability of large language models (LLMs) by adapting the model using only the test questions. However, existing methods struggle with difficult reasoning problems for two reasons: raw test questions are often too difficult to yield high-quality pseudo-labels , and the limited size of test sets makes continuous online updates prone to instability. To address these limitations, we propose TTCS, a co-evolving test-time training framework. Specifically, TTCS initializes two policies from the same pretrained model: a question synthesizer and a reasoning solver . These policies evolve through iterative optimization : the synthesizer generates progressively challenging question variants conditioned on the test questions, creating a structured curriculum tailored to the solver's current capability, while the solver updates itself using self-consistency rewards computed from multiple sampled responses on both original test and synthetic questions. Crucially, the solver's feedback guides the synthesizer to generate questions aligned with the model's current capability, and the generated question variants in turn stabilize the solver's test-time training . Experiments show that TTCS consistently strengthens the reasoning ability on challenging mathematical benchmarks and transfers to general-domain tasks across different LLM backbones, highlighting a scalable path towards dynamically constructing test-time curricula for self-evolving. Our code and implementation details are available at https://github.com/XMUDeepLIT/TTCS.",
    "summary_en": "TTCS is a co-evolving test-time training framework that enhances LLM reasoning abilities by iteratively generating challenging question variants and updating a reasoning solver through self-consistency rewards.",
    "summary_zh": "TTCS是一种协同演化的测试时训练框架，通过迭代生成具有挑战性的问题变体，并利用自一致性奖励更新推理求解器，从而增强LLM的推理能力。",
    "upvotes": 35
  },
  {
    "id": "2601.21998",
    "date": "2026-02-02",
    "title": "Causal World Modeling for Robot Control",
    "authors": "Lin Li Qihang Zhang Yiming Luo Shuai Yang Ruilin Wang Fei Han Mingrui Yu Zelin Gao Nan Xue Xing Zhu Yujun Shen Yinghao Xu",
    "abstract": "Video world modeling enables robot learning through a unified framework that predicts frames and executes policies simultaneously using a shared latent space and closed-loop feedback mechanisms. This work highlights that video world modeling , alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space , integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism , allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline , parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation , data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.",
    "summary_en": "Video world modeling enables robot learning through a unified framework that predicts frames and executes policies simultaneously using a shared latent space and closed-loop feedback mechanisms.",
    "summary_zh": "视频世界建模通过统一框架实现机器人学习，该框架利用共享潜空间和闭环反馈机制同时预测帧并执行策略。",
    "upvotes": 30
  },
  {
    "id": "2601.21192",
    "date": "2026-02-02",
    "title": "Do Reasoning Models Enhance Embedding Models?",
    "authors": "Wun Yu Chan Shaojin Chen Huihao Jing Kwun Hang Lau Elton Chun-Chai Li Zihao Wang Haoran Li Yangqiu Song",
    "abstract": "Embedding models initialized from RLVR-tuned reasoning models show no performance advantage over base models, with HRSA revealing preserved global geometry and linear readout despite local geometric reorganization. State-of-the-art embedding models are increasingly derived from decoder-only Large Language Model (LLM) backbones adapted via contrastive learning . Given the emergence of reasoning models trained via Reinforcement Learning with Verifiable Rewards (RLVR), a natural question arises: do enhanced reasoning translate to superior semantic representations when these models serve as embedding initializations? Contrary to expectation, our evaluation on MTEB and BRIGHT reveals a **null effect**: embedding models initialized from RLVR-tuned backbones yield no consistent performance advantage over their base counterparts when subjected to identical training recipes. To unpack this paradox, we introduce **H**ierarchical **R**epresentation **S**imilarity **A**nalysis (HRSA), a framework that decomposes similarity across representation, geometry, and function levels. HRSA reveals that while RLVR induces irreversible latent manifold 's local geometry reorganization and reversible coordinate basis drift , it preserves the global manifold geometry and linear readout. Consequently, subsequent contrastive learning drives strong alignment between base- and reasoning-initialized models, a phenomenon we term ** Manifold Realignment **. Empirically, our findings suggest that unlike Supervised Fine-Tuning (SFT), RLVR optimizes trajectories within an existing semantic landscape rather than fundamentally restructuring the landscape itself.",
    "summary_en": "Embedding models initialized from RLVR-tuned reasoning models show no performance advantage over base models, with HRSA revealing preserved global geometry and linear readout despite local geometric reorganization.",
    "summary_zh": "以RLVR调优推理模型初始化的嵌入模型相较基础模型未展现性能优势，HRSA揭示尽管局部几何重组，全局几何与线性读出仍保持。",
    "upvotes": 25
  },
  {
    "id": "2601.21468",
    "date": "2026-02-02",
    "title": "MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning",
    "authors": "Yaorui Shi Shugui Liu Yu Yang Wenyu Mao Yuxin Chen Qi GU Hui Su Xunliang Cai Xiang Wang An Zhang",
    "abstract": "MemOCR is a multimodal memory agent that enhances long-horizon reasoning by adaptively compressing interaction histories into visual layouts, enabling efficient context utilization under tight budget constraints. Long-horizon agentic reasoning necessitates effectively compressing growing interaction histories into a limited context window . Most existing memory systems serialize history as text, where token-level cost is uniform and scales linearly with length, often spending scarce budget on low-value details. To this end, we introduce MemOCR, a multimodal memory agent that improves long-horizon reasoning under tight context budgets by allocating memory space with adaptive information density through visual layout . Concretely, MemOCR maintains a structured rich-text memory (e.g., headings, highlights) and renders it into an image that the agent consults for memory access, visually prioritizing crucial evidence while aggressively compressing auxiliary details. To ensure robustness across varying memory budgets, we train MemOCR with reinforcement learning under budget-aware objectives that expose the agent to diverse compression levels. Across long-context multi-hop and single-hop question-answering benchmarks, MemOCR outperforms strong text-based baselines and achieves more effective context utilization under extreme budgets.",
    "summary_en": "MemOCR is a multimodal memory agent that enhances long-horizon reasoning by adaptively compressing interaction histories into visual layouts, enabling efficient context utilization under tight budget constraints.",
    "summary_zh": "MemOCR是一种多模态记忆智能体，通过将交互历史自适应压缩为视觉布局来增强长程推理，从而在严格的预算约束下实现高效的上下文利用。",
    "upvotes": 22
  },
  {
    "id": "2601.22636",
    "date": "2026-02-02",
    "title": "Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling",
    "authors": "Mingqian Feng Xiaodong Liu Weiwei Yang Chenliang Xu Christopher White Jianfeng Gao",
    "abstract": "A scaling-aware risk estimation method called SABER is introduced for predicting large-scale adversarial vulnerability in language models through Best-of-N sampling, enabling accurate assessment with reduced computational costs. Large Language Models (LLMs) are typically evaluated for safety under single-shot or low-budget adversarial prompting , which underestimates real-world risk. In practice, attackers can exploit large-scale parallel sampling to repeatedly probe a model until a harmful response is produced. While recent work shows that attack success increases with repeated sampling, principled methods for predicting large-scale adversarial risk remain limited. We propose a scaling-aware Best-of-N estimation of risk, SABER, for modeling jailbreak vulnerability under Best-of-N sampling . We model sample-level success probabilities using a Beta distribution , the conjugate prior of the Bernoulli distribution, and derive an analytic scaling law that enables reliable extrapolation of large-N attack success rate s from small-budget measurements. Using only n=100 samples, our anchored estimator predicts ASR@1000 with a mean absolute error of 1.66, compared to 12.04 for the baseline, which is an 86.2% reduction in estimation error. Our results reveal heterogeneous risk scaling profiles and show that models appearing robust under standard evaluation can experience rapid nonlinear risk amplification under parallel adversarial pressure. This work provides a low-cost, scalable methodology for realistic LLM safety assessment. We will release our code and evaluation scripts upon publication to future research.",
    "summary_en": "A scaling-aware risk estimation method called SABER is introduced for predicting large-scale adversarial vulnerability in language models through Best-of-N sampling, enabling accurate assessment with reduced computational costs.",
    "summary_zh": "提出了一种名为SABER的规模感知风险估计方法，通过Best-of-N采样预测语言模型的大规模对抗性脆弱性，从而在降低计算成本的同时实现准确评估。",
    "upvotes": 21
  },
  {
    "id": "2601.23182",
    "date": "2026-02-02",
    "title": "FourierSampler: Unlocking Non-Autoregressive Potential in Diffusion Language Models via Frequency-Guided Generation",
    "authors": "Siyang He Qiqi Wang Xiaoran Liu Hongnan Ma Yiwei Shi Yuerong Song Ying Zhu Tianyi Liang Zengfeng Huang Ziwei He Xipeng Qiu",
    "abstract": "Frequency-domain analysis of diffusion language models reveals that low-frequency components encode global structure while high-frequency components capture local details, enabling improved generation through FourierSampler's dynamic frequency-domain sliding window mechanism.",
    "summary_en": "Frequency-domain analysis of diffusion language models reveals that low-frequency components encode global structure while high-frequency components capture local details, enabling improved generation through FourierSampler's dynamic frequency-domain sliding window mechanism.",
    "summary_zh": "扩散语言模型的频域分析表明，低频成分编码全局结构，高频成分捕捉局部细节，通过FourierSampler的动态频域滑动窗口机制可提升生成质量。",
    "upvotes": 20
  },
  {
    "id": "2601.21957",
    "date": "2026-02-02",
    "title": "PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing",
    "authors": "Cheng Cui Ting Sun Suyin Liang Tingquan Gao Zelun Zhang Jiaxuan Liu Xueqing Wang Changda Zhou Hongen Liu Manhui Lin Yue Zhang Yubo Zhang Yi Liu Dianhai Yu Yanjun Ma",
    "abstract": "A compact vision-language model achieves state-of-the-art accuracy on document understanding tasks while maintaining efficiency through specialized benchmarking and extended functionality. We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR",
    "summary_en": "A compact vision-language model achieves state-of-the-art accuracy on document understanding tasks while maintaining efficiency through specialized benchmarking and extended functionality.",
    "summary_zh": "一种紧凑型视觉语言模型通过专门的基准测试和扩展功能，在文档理解任务上实现了最先进的准确率，同时保持效率。",
    "upvotes": 19
  },
  {
    "id": "2601.22904",
    "date": "2026-02-02",
    "title": "DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation",
    "authors": "Hun Chang Byunghee Cha Jong Chul Ye",
    "abstract": "A novel vision autoencoder framework combines semantic representation with pixel-level reconstruction using spherical latent space and Riemannian flow matching for improved fidelity and efficiency. Recent studies have explored using pretrained Vision Foundation Models (VFMs) such as DINO for generative autoencoders , showing strong generative performance. Unfortunately, existing approaches often suffer from limited reconstruction fidelity due to the loss of high-frequency details. In this work, we present the DINO Spherical Autoencoder ( DINO -SAE), a framework that bridges semantic representation and pixel-level reconstruction. Our key insight is that semantic information in contrastive representations is primarily encoded in the direction of feature vectors , while forcing strict magnitude matching can hinder the encoder from preserving fine-grained details. To address this, we introduce Hierarchical Convolutional Patch Embedding module that enhances local structure and texture preservation, and Cosine Similarity Alignment objective that enforces semantic consistency while allowing flexible feature magnitudes for detail retention. Furthermore, leveraging the observation that SSL-based foundation model representations intrinsically lie on a hypersphere , we employ Riemannian Flow Matching to train a Diffusion Transformer (DiT) directly on this spherical latent manifold . Experiments on ImageNet-1K demonstrate that our approach achieves state-of-the-art reconstruction quality , reaching 0.37 rFID and 26.2 dB PSNR , while maintaining strong semantic alignment to the pretrained VFM. Notably, our Riemannian Flow Matching -based DiT exhibits efficient convergence, achieving a gFID of 3.47 at 80 epochs.",
    "summary_en": "A novel vision autoencoder framework combines semantic representation with pixel-level reconstruction using spherical latent space and Riemannian flow matching for improved fidelity and efficiency.",
    "summary_zh": "一种新颖的视觉自编码器框架利用球面潜在空间和黎曼流匹配，将语义表示与像素级重建相结合，从而提升保真度和效率。",
    "upvotes": 15
  },
  {
    "id": "2601.20218",
    "date": "2026-02-02",
    "title": "DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment",
    "authors": "Haoyou Deng Keyu Yan Chaojie Mao Xiang Wang Yu Liu Changxin Gao Nong Sang",
    "abstract": "DenseGRPO addresses sparse reward problems in flow matching models by introducing dense rewards for intermediate denoising steps and adaptive exploration calibration. Recent GRPO-based approaches built on flow matching models have shown remarkable improvements in human preference alignment for text-to-image generation. Nevertheless, they still suffer from the sparse reward problem : the terminal reward of the entire denoising trajectory is applied to all intermediate steps, resulting in a mismatch between the global feedback signals and the exact fine-grained contributions at intermediate denoising steps. To address this issue, we introduce DenseGRPO, a novel framework that aligns human preference with dense rewards , which evaluates the fine-grained contribution of each denoising step. Specifically, our approach includes two key components: (1) we propose to predict the step-wise reward gain as dense reward of each denoising step, which applies a reward model on the intermediate clean images via an ODE-based approach . This manner ensures an alignment between feedback signals and the contributions of individual steps, facilitating effective training; and (2) based on the estimated dense rewards , a mismatch drawback between the uniform exploration setting and the time-varying noise intensity in existing GRPO-based methods is revealed, leading to an inappropriate exploration space . Thus, we propose a reward-aware scheme to calibrate the exploration space by adaptively adjusting a timestep-specific stochasticity injection in the SDE sampler , ensuring a suitable exploration space at all timesteps. Extensive experiments on multiple standard benchmarks demonstrate the effectiveness of the proposed DenseGRPO and highlight the critical role of the valid dense rewards in flow matching model alignment.",
    "summary_en": "DenseGRPO addresses sparse reward problems in flow matching models by introducing dense rewards for intermediate denoising steps and adaptive exploration calibration.",
    "summary_zh": "DenseGRPO通过引入中间去噪步骤的密集奖励和自适应探索校准，解决了flow matching模型中的稀疏奖励问题。",
    "upvotes": 15
  },
  {
    "id": "2601.22664",
    "date": "2026-02-02",
    "title": "Real-Time Aligned Reward Model beyond Semantics",
    "authors": "Zixuan Huang Xin Xia Yuxi Ren Jianbin Zheng Xuefeng Xiao Hongyan Xie Li Huaqiu Songshi Liang Zhongxiang Dai Fuzhen Zhuang Jianxin Li Yikun Ban Deqing Wang",
    "abstract": "RLHF suffers from reward overoptimization due to misalignment between reward models and policy models, which R2M addresses by incorporating real-time policy feedback to dynamically adapt reward modeling during training. Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for aligning large language models (LLMs) with human preferences, yet it is susceptible to reward overoptimization , in which policy models overfit to the reward model, exploit spurious reward patterns instead of faithfully capturing human intent. Prior mitigations primarily relies on surface semantic information and fails to efficiently address the misalignment between the reward model (RM) and the policy model caused by continuous policy distribution shifts . This inevitably leads to an increasing reward discrepancy, exacerbating reward overoptimization . To address these limitations, we introduce R2M (Real-Time Aligned Reward Model), a novel lightweight RLHF framework. R2M goes beyond vanilla reward models that solely depend on the semantic representations of a pretrained LLM. Instead, it leverages the evolving hidden states of the policy (namely policy feedback ) to align with the real-time distribution shift of the policy during the RL process. This work points to a promising new direction for improving the performance of reward models through real-time utilization of feedback from policy models .",
    "summary_en": "RLHF suffers from reward overoptimization due to misalignment between reward models and policy models, which R2M addresses by incorporating real-time policy feedback to dynamically adapt reward modeling during training.",
    "summary_zh": "RLHF因奖励模型与策略模型未对齐而存在奖励过度优化问题，R2M通过引入实时策略反馈，在训练过程中动态调整奖励建模以解决该问题。",
    "upvotes": 13
  },
  {
    "id": "2601.21716",
    "date": "2026-02-02",
    "title": "DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning",
    "authors": "Mingshuang Luo Shuang Liang Zhengkun Rong Yuxuan Luo Tianshu Hu Ruibing Hou Hong Chang Yong Li Yuan Zhang Mingyuan Gao",
    "abstract": "DreamActor-M2 presents a universal character animation framework that addresses motion injection trade-offs and pose prior limitations through in-context learning and self-bootstrapped data synthesis for improved generalization across diverse characters. Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a \"see-saw\", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space , enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs , facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation . This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization . Project Page: https://grisoon.github.io/DreamActor-M2/",
    "summary_en": "DreamActor-M2 presents a universal character animation framework that addresses motion injection trade-offs and pose prior limitations through in-context learning and self-bootstrapped data synthesis for improved generalization across diverse characters.",
    "summary_zh": "DreamActor-M2 提出了一种通用角色动画框架，通过上下文学习和自举数据合成解决运动注入的权衡问题与姿态先验的局限性，从而提升对多样化角色的泛化能力。",
    "upvotes": 13
  },
  {
    "id": "2601.22491",
    "date": "2026-02-02",
    "title": "SSL: Sweet Spot Learning for Differentiated Guidance in Agentic Optimization",
    "authors": "Jinyang Wu Changpeng Yang Yuhao Shen Fangzhi Xu Bolin Ni Chonghua Liao Yuchen Liu Hongzhen Wang Shuai Nie Shuai Zhang Haoran Luo Jiaming Xu",
    "abstract": "Sweet Spot Learning (SSL) introduces a novel reinforcement learning framework that uses tiered rewards to guide agent optimization toward optimal regions of the solution space, improving sample efficiency and cross-task transferability. Reinforcement learning with verifiable rewards has emerged as a powerful paradigm for training intelligent agents. However, existing methods typically employ binary rewards that fail to capture quality differences among trajectories achieving identical outcomes, thereby overlooking potential diversity within the solution space. Inspired by the ``sweet spot'' concept in tennis-the racket's core region that produces optimal hitting effects, we introduce Sweet Spot Learning (SSL), a novel framework that provides differentiated guidance for agent optimization. SSL follows a simple yet effective principle: progressively amplified, tiered rewards guide policies toward the sweet-spot region of the solution space. This principle naturally adapts across diverse tasks: visual perception tasks leverage distance-tiered modeling to reward proximity, while complex reasoning tasks reward incremental progress toward promising solutions. We theoretically demonstrate that SSL preserves optimal solution ordering and enhances the gradient signal-to-noise ratio , thereby fostering more directed optimization. Extensive experiments across GUI perception, short/long-term planning, and complex reasoning tasks show consistent improvements over strong baselines on 12 benchmarks, achieving up to 2.5X sample efficiency gains and effective cross-task transferability . Our work establishes SSL as a general principle for training capable and robust agents.",
    "summary_en": "Sweet Spot Learning (SSL) introduces a novel reinforcement learning framework that uses tiered rewards to guide agent optimization toward optimal regions of the solution space, improving sample efficiency and cross-task transferability.",
    "summary_zh": "Sweet Spot Learning（SSL）提出了一种新颖的强化学习框架，通过分层奖励引导智能体优化至解空间的最优区域，从而提高样本效率与跨任务可迁移性。",
    "upvotes": 12
  },
  {
    "id": "2601.23161",
    "date": "2026-02-02",
    "title": "DIFFA-2: A Practical Diffusion Large Language Model for General Audio Understanding",
    "authors": "Jiaming Zhou Xuxin Cheng Shiwan Zhao Yuhang Jia Cao Liu Ke Zeng Xunliang Cai Yong Qin",
    "abstract": "DIFFA-2, a diffusion-based large audio language model, achieves competitive audio understanding performance with improved efficiency over autoregressive counterparts through enhanced encoding, dual adapters, and staged training. Autoregressive (AR) large audio language models (LALMs) such as Qwen-2.5-Omni have achieved strong performance on audio understanding and interaction, but scaling them remains costly in data and computation, and strictly sequential decoding limits inference efficiency. Diffusion large language models (dLLMs) have recently been shown to make effective use of limited training data, and prior work on DIFFA indicates that replacing an AR backbone with a diffusion counterpart can substantially improve audio understanding under matched settings, albeit at a proof-of-concept scale without large-scale instruction tuning, preference alignment, or practical decoding schemes. We introduce DIFFA-2, a practical diffusion-based LALM for general audio understanding. DIFFA-2 upgrades the speech encoder , employs dual semantic and acoustic adapters , and is trained with a four-stage curriculum that combines semantic and acoustic alignment , large-scale supervised fine-tuning , and variance-reduced preference optimization , using only fully open-source corpora. Experiments on MMSU, MMAU, and MMAR show that DIFFA-2 consistently improves over DIFFA and is competitive to strong AR LALMs under practical training budgets, supporting diffusion-based modeling is a viable backbone for large-scale audio understanding. Our code is available at https://github.com/NKU-HLT/DIFFA.git.",
    "summary_en": "DIFFA-2, a diffusion-based large audio language model, achieves competitive audio understanding performance with improved efficiency over autoregressive counterparts through enhanced encoding, dual adapters, and staged training.",
    "summary_zh": "DIFFA-2是一种基于扩散的大型音频语言模型，通过增强编码、双适配器和分阶段训练，在音频理解性能上具备竞争力，且效率优于自回归模型。",
    "upvotes": 10
  },
  {
    "id": "2601.22837",
    "date": "2026-02-02",
    "title": "NativeTok: Native Visual Tokenization for Improved Image Generation",
    "authors": "Bin Wu Mengqi Huang Weinan Jia Zhendong Mao",
    "abstract": "NativeTok introduces a novel visual tokenization approach that enforces causal dependencies during image encoding, using a Meta Image Transformer and Mixture of Causal Expert Transformer for efficient and coherent image generation. VQ-based image generation typically follows a two-stage pipeline: a tokenizer encodes images into discrete tokens, and a generative model learns their dependencies for reconstruction. However, improved tokenization in the first stage does not necessarily enhance the second-stage generation, as existing methods fail to constrain token dependencies. This mismatch forces the generative model to learn from unordered distributions, leading to bias and weak coherence. To address this, we propose native visual tokenization , which enforces causal dependencies during tokenization . Building on this idea, we introduce NativeTok, a framework that achieves efficient reconstruction while embedding relational constraints within token sequences. NativeTok consists of: (1) a Meta Image Transformer (MIT) for latent image modeling , and (2) a Mixture of Causal Expert Transformer (MoCET), where each lightweight expert block generates a single token conditioned on prior tokens and latent features. We further design a Hierarchical Native Training strategy that updates only new expert blocks, ensuring training efficiency. Extensive experiments demonstrate the effectiveness of NativeTok.",
    "summary_en": "NativeTok introduces a novel visual tokenization approach that enforces causal dependencies during image encoding, using a Meta Image Transformer and Mixture of Causal Expert Transformer for efficient and coherent image generation.",
    "summary_zh": "NativeTok提出了一种新颖的视觉分词方法，在图像编码时强制建立因果依赖关系，利用Meta Image Transformer和Mixture of Causal Expert Transformer实现高效且连贯的图像生成。",
    "upvotes": 9
  },
  {
    "id": "2601.22642",
    "date": "2026-02-02",
    "title": "Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification",
    "authors": "Chuxue Cao Jinluan Yang Haoran Li Kunhao Pan Zijian Zhao Zhengyu Chen Yuchen Tian Lijun Wu Conghui He Sirui Han Yike Guo",
    "abstract": "A formal logic verification-guided framework dynamically interleaves symbolic verification with natural language generation to improve reasoning accuracy and reduce errors in large language models. Large Language Models (LLMs) show remarkable capabilities, yet their stochastic next-token prediction creates logical inconsistencies and reward hacking that formal symbolic systems avoid. To bridge this gap, we introduce a formal logic verification -guided framework that dynamically interleaves formal symbolic verification with the natural language generation process, providing real-time feedback to detect and rectify errors as they occur. Distinguished from previous neuro-symbolic methods limited by passive post-hoc validation, our approach actively penalizes intermediate fallacies during the reasoning chain . We operationalize this framework via a novel two-stage training pipeline that synergizes formal logic verification -guided supervised fine-tuning and policy optimization . Extensive evaluation on six benchmarks spanning mathematical, logical, and general reasoning demonstrates that our 7B and 14B models outperform state-of-the-art baselines by average margins of 10.4% and 14.2%, respectively. These results validate that formal verification can serve as a scalable mechanism to significantly push the performance boundaries of advanced LLM reasoning.",
    "summary_en": "A formal logic verification-guided framework dynamically interleaves symbolic verification with natural language generation to improve reasoning accuracy and reduce errors in large language models.",
    "summary_zh": "一种形式逻辑验证引导的框架动态交错符号验证与自然语言生成，以提高大语言模型的推理准确性并减少错误。",
    "upvotes": 9
  },
  {
    "id": "2601.18241",
    "date": "2026-02-02",
    "title": "TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance",
    "authors": "Elena Bruches Vadim Alperovich Dari Baturova Roman Derunets Daniil Grebenkin Georgy Mkrtchyan Oleg Sedukhin Mikhail Klementev Ivan Bondarenko Nikolay Bushkov Stanislav Moiseev",
    "abstract": "TAM-Eval is a framework and benchmark for evaluating large language models on comprehensive test suite maintenance tasks including creation, repair, and updating across multiple programming languages. While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction , neglecting the broader challenge of test suite maintenance . We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows , using a reference-free protocol based on test suite pass rate , code coverage , and mutation testing . Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.",
    "summary_en": "TAM-Eval is a framework and benchmark for evaluating large language models on comprehensive test suite maintenance tasks including creation, repair, and updating across multiple programming languages.",
    "summary_zh": "TAM-Eval是一个用于评估大语言模型在跨多种编程语言的全面测试套件维护任务（包括创建、修复和更新）上的框架和基准。",
    "upvotes": 8
  },
  {
    "id": "2601.15625",
    "date": "2026-02-02",
    "title": "Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors",
    "authors": "Zhiwei Zhang Fei Zhao Rui Wang Zezhong Wang Bin Liang Jiakang Wang Yao Hu Shaosheng Cao Kam-Fai Wong",
    "abstract": "A framework called Fission-GRPO is introduced to improve multi-turn tool execution in large language models by converting execution errors into corrective supervision during reinforcement learning training. Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution : following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO , a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator , then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.",
    "summary_en": "A framework called Fission-GRPO is introduced to improve multi-turn tool execution in large language models by converting execution errors into corrective supervision during reinforcement learning training.",
    "summary_zh": "提出了一种名为 Fission-GRPO 的框架，通过在强化学习训练中将执行错误转化为纠正性监督，以提升大语言模型的多轮工具执行能力。",
    "upvotes": 8
  },
  {
    "id": "2601.13097",
    "date": "2026-02-02",
    "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation",
    "authors": "Elena Bruches Daniil Grebenkin Mikhail Klementev Vadim Alperovich Roman Derunets Dari Baturova Georgy Mkrtchyan Oleg Sedukhin Ivan Bondarenko Nikolay Bushkov Stanislav Moiseev",
    "abstract": "RM-RF is a lightweight reward model that predicts execution outcomes from source code alone, offering faster and more cost-effective evaluation than traditional compile-and-run methods. We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests . Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals : (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage , and (3) whether the generated test cases improve the mutation kill rate . To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files , test files , and candidate test additions labeled by an execution-based pipeline , and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes ( zero-shot , full fine-tuning , and PEFT via LoRA ), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.",
    "summary_en": "RM-RF is a lightweight reward model that predicts execution outcomes from source code alone, offering faster and more cost-effective evaluation than traditional compile-and-run methods.",
    "summary_zh": "RM-RF是一种轻量级奖励模型，仅凭源代码即可预测执行结果，相比传统编译运行方法评估更快且成本更低。",
    "upvotes": 8
  },
  {
    "id": "2602.00158",
    "date": "2026-02-02",
    "title": "RAPTOR: Ridge-Adaptive Logistic Probes",
    "authors": "Ziqi Gao Yaotian Zhu Qingcheng Zeng Xu Zhao Ziqing Wang Feng Ruan Kaize Ding",
    "abstract": "RACTOR, a ridge-adaptive logistic probe, achieves accurate and stable concept vector estimation for activation steering in frozen LLMs with reduced training costs, supported by theoretical analysis of ridge logistic regression in high-dimensional settings. Probing studies what information is encoded in a frozen LLM 's layer representations by training a lightweight predictor on top of them. Beyond analysis, probes are often used operationally in probe-then-steer pipelines: a learned concept vector is extracted from a probe and injected via additive activation steering by adding it to a layer representation during the forward pass. The effectiveness of this pipeline hinges on estimating concept vectors that are accurate, directionally stable under ablation, and inexpensive to obtain. Motivated by these desiderata, we propose RAPTOR (Ridge-Adaptive Logistic Probe), a simple L2-regularized logistic probe whose validation-tuned ridge strength yields concept vectors from normalized weights. Across extensive experiments on instruction-tuned LLM s and human-written concept datasets, RAPTOR matches or exceeds strong baselines in accuracy while achieving competitive directional stability and substantially lower training cost; these quantitative results are supported by qualitative downstream steering demonstrations. Finally, using the Convex Gaussian Min-max Theorem ( CGMT ), we provide a mechanistic characterization of ridge logistic regression in an idealized Gaussian teacher-student model in the high-dimensional few-shot regime, explaining how penalty strength mediates probe accuracy and concept-vector stability and yielding structural predictions that qualitatively align with trends observed on real LLM embeddings.",
    "summary_en": "RACTOR, a ridge-adaptive logistic probe, achieves accurate and stable concept vector estimation for activation steering in frozen LLMs with reduced training costs, supported by theoretical analysis of ridge logistic regression in high-dimensional settings.",
    "summary_zh": "RACTOR是一种岭自适应逻辑探针，可在冻结LLM中以较低训练成本实现准确稳定的概念向量估计用于激活引导，并有高维场景下岭逻辑回归的理论分析作为支撑。",
    "upvotes": 7
  },
  {
    "id": "2601.23228",
    "date": "2026-02-02",
    "title": "Scaling Multiagent Systems with Process Rewards",
    "authors": "Ed Li Junyu Ren Cat Yan",
    "abstract": "Multiagent systems are improved through per-action process rewards from AI feedback (MAPPA), enhancing credit assignment and sample efficiency for complex tasks. While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigning credit to individual agent actions rather than only at task completion, MAPPA enables fine-grained supervision without ground truth labels while extracting maximal training signal from each rollout. We demonstrate our approach on competition math problems and tool-augmented data analysis tasks. On unseen math problems, MAPPA achieves +5.0--17.5pp on AIME and +7.8--17.2pp on AMC. For data analysis tasks, our method improves success rate by +12.5pp while quality metrics improve by up to 30%, validating that per-action supervision can lead to improvements across different multiagent system on various domains. By addressing these challenges, our work takes a first step toward scaling multiagent systems for complex, long-horizon tasks with minimal human supervision.",
    "summary_en": "Multiagent systems are improved through per-action process rewards from AI feedback (MAPPA), enhancing credit assignment and sample efficiency for complex tasks.",
    "summary_zh": "通过AI反馈的逐动作过程奖励(MAPPA)改进多智能体系统，增强复杂任务的信用分配与样本效率。",
    "upvotes": 7
  },
  {
    "id": "2601.23188",
    "date": "2026-02-02",
    "title": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience",
    "authors": "Zhongxiang Sun Qipeng Wang Weijie Yu Jingxuan Yang Haolang Lu Jun Xu",
    "abstract": "Deep search agents with hierarchical metacognitive monitoring enhance reasoning and retrieval performance through fast consistency checks and experience-driven corrective interventions. Deep search agents powered by large language models have demonstrated strong capabilities in multi-step retrieval , reasoning , and long-horizon task execution . However, their practical failures often stem from the lack of mechanisms to monitor and regulate reasoning and retrieval states as tasks evolve under uncertainty. Insights from cognitive neuroscience suggest that human metacognition is hierarchically organized, integrating fast anomaly detection with selectively triggered, experience-driven reflection . In this work, we propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), a deep search framework augmented with an explicit hierarchical metacognitive monitoring mechanism. DS-MCM integrates a Fast Consistency Monitor , which performs lightweight checks on the alignment between external evidence and internal reasoning confidence, and a Slow Experience-Driven Monitor , which is selectively activated to guide corrective intervention based on experience memory from historical agent trajectories . By embedding monitoring directly into the reasoning -retrieval loop, DS-MCM determines both when intervention is warranted and how corrective actions should be informed by prior experience. Experiments across multiple deep search benchmarks and backbone models demonstrate that DS-MCM consistently improves performance and robustness.",
    "summary_en": "Deep search agents with hierarchical metacognitive monitoring enhance reasoning and retrieval performance through fast consistency checks and experience-driven corrective interventions.",
    "summary_zh": "具备层级元认知监控的深度搜索智能体通过快速一致性检查与经验驱动的纠正干预，增强推理与检索性能。",
    "upvotes": 7
  },
  {
    "id": "2601.21358",
    "date": "2026-02-02",
    "title": "Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization",
    "authors": "Jiecong Wang Hao Peng Chunyang Liu",
    "abstract": "PLaT introduces a latent reasoning framework that decouples reasoning from verbalization, enabling dynamic termination and improved scalability over traditional approaches. Chain-of-Thought (CoT) empowers Large Language Models (LLMs) to tackle complex problems, but remains constrained by the computational cost and reasoning path collapse when grounded in discrete token spaces . Recent latent reasoning approaches attempt to optimize efficiency by performing reasoning within continuous hidden states . However, these methods typically operate as opaque end-to-end mappings from explicit reasoning steps to latent states, and often require a pre-defined number of latent steps during inference. In this work, we introduce PLaT (Planning with Latent Thoughts), a framework that reformulates latent reasoning as planning by fundamentally decouple reasoning from verbalization. We model reasoning as a deterministic trajectory of latent planning states , while a separate Decoder grounds these thoughts into text when necessary. This decoupling allows the model to dynamically determine when to terminate reasoning rather than relying on fixed hyperparameters. Empirical results on mathematical benchmarks reveal a distinct trade-off: while PLaT achieves lower greedy accuracy than baselines, it demonstrates superior scalability in terms of reasoning diversity. This indicates that PLaT learns a robust, broader solution space, offering a transparent and scalable foundation for inference-time search .",
    "summary_en": "PLaT introduces a latent reasoning framework that decouples reasoning from verbalization, enabling dynamic termination and improved scalability over traditional approaches.",
    "summary_zh": "PLaT 提出了一种潜在推理框架，将推理与言语化解耦，支持动态终止并提升了相较于传统方法的可扩展性。",
    "upvotes": 7
  },
  {
    "id": "2601.21525",
    "date": "2026-02-02",
    "title": "LMK > CLS: Landmark Pooling for Dense Embeddings",
    "authors": "Meet Doshi Aashka Trivedi Vishwajeet Kumar Parul Awasthy Yulong Li Jaydeep Sen Radu Florian Sachindra Joshi",
    "abstract": "Landmark pooling improves long-context representation learning by partitioning sequences into chunks and using landmark tokens to preserve both global and local information more effectively than traditional pooling methods. Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator , most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance . To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.",
    "summary_en": "Landmark pooling improves long-context representation learning by partitioning sequences into chunks and using landmark tokens to preserve both global and local information more effectively than traditional pooling methods.",
    "summary_zh": "Landmark池化通过将序列分块并使用landmark标记来保留全局和局部信息，比传统池化方法更有效地改进了长上下文表示学习。",
    "upvotes": 4
  },
  {
    "id": "2601.21419",
    "date": "2026-02-02",
    "title": "Revisiting Diffusion Model Predictions Through Dimensionality",
    "authors": "Qing Jin Chaoyang Wang",
    "abstract": "Diffusion models using direct data prediction outperform traditional noise or velocity prediction in high-dimensional settings, with a proposed framework automatically learning optimal prediction parameters from data. Recent advances in diffusion and flow matching models have highlighted a shift in the preferred prediction target -- moving from noise (varepsilon) and velocity (v) to direct data (x) prediction -- particularly in high-dimensional settings. However, a formal explanation of why the optimal target depends on the specific properties of the data remains elusive. In this work, we provide a theoretical framework based on a generalized prediction formulation that accommodates arbitrary output targets, of which varepsilon-, v-, and x-prediction are special cases. We derive the analytical relationship between data's geometry and the optimal prediction target, offering a rigorous justification for why x-prediction becomes superior when the ambient dimension significantly exceeds the data's intrinsic dimension . Furthermore, while our theory identifies dimensionality as the governing factor for the optimal prediction target, the intrinsic dimension of manifold-bound data is typically intractable to estimate in practice. To bridge this gap, we propose k-Diff , a framework that employs a data-driven approach to learn the optimal prediction parameter k directly from data, bypassing the need for explicit dimension estimation. Extensive experiments in both latent-space and pixel-space image generation demonstrate that k-Diff consistently outperforms fixed-target baselines across varying architectures and data scales, providing a principled and automated approach to enhancing generative performance .",
    "summary_en": "Diffusion models using direct data prediction outperform traditional noise or velocity prediction in high-dimensional settings, with a proposed framework automatically learning optimal prediction parameters from data.",
    "summary_zh": "在高维设置下，使用直接数据预测的扩散模型优于传统的噪声或速度预测，所提出的框架可自动从数据中学习最优预测参数。",
    "upvotes": 4
  },
  {
    "id": "2601.20732",
    "date": "2026-02-02",
    "title": "Continual GUI Agents",
    "authors": "Ziwei Liu Borui Kang Hangjie Yuan Zixiang Zhao Wei Li Yifan Zhu Tao Feng",
    "abstract": "Continual GUI Agents framework addresses performance degradation in dynamic digital environments through reinforcement fine-tuning with novel anchoring rewards that stabilize learning across shifting UI domains and resolutions. As digital environments (data distribution) are in flux, with new GUI data arriving over time-introducing new domains or resolutions-agents trained on static environments deteriorate in performance. In this work, we introduce Continual GUI Agents , a new task that requires GUI agents to perform continual learning under shifted domains and resolutions. We find existing methods fail to maintain stable grounding as GUI distributions shift over time, due to the diversity of UI interaction points and regions in fluxing scenarios. To address this, we introduce GUI-Anchoring in Flux (GUI-AiF), a new reinforcement fine-tuning framework that stabilizes continual learning through two novel rewards: Anchoring Point Reward in Flux ( APR-iF ) and Anchoring Region Reward in Flux ( ARR-iF ). These rewards guide the agents to align with shifting interaction points and regions, mitigating the tendency of existing reward strategies to over-adapt to static grounding cues (e.g., fixed coordinates or element scales). Extensive experiments show GUI-AiF surpasses state-of-the-art baselines. Our work establishes the first continual learning framework for GUI agents , revealing the untapped potential of reinforcement fine-tuning for continual GUI Agents .",
    "summary_en": "Continual GUI Agents framework addresses performance degradation in dynamic digital environments through reinforcement fine-tuning with novel anchoring rewards that stabilize learning across shifting UI domains and resolutions.",
    "summary_zh": "Continual GUI Agents 框架通过强化微调及新颖的锚定奖励解决动态数字环境中的性能退化问题，稳定跨变化 UI 域和分辨率的学习。",
    "upvotes": 4
  },
  {
    "id": "2601.22666",
    "date": "2026-02-02",
    "title": "ExpAlign: Expectation-Guided Vision-Language Alignment for Open-Vocabulary Grounding",
    "authors": "Junyi Hu Tian Bai Fengyi Wu Wenyan Li Zhenming Peng Yi Zhang",
    "abstract": "ExpAlign presents a vision-language alignment framework using multiple instance learning and attention-based pooling to improve open-vocabulary detection and zero-shot instance segmentation without additional annotations. Open-vocabulary grounding requires accurate vision-language alignment under weak supervision, yet existing methods either rely on global sentence embeddings that lack fine-grained expressiveness or introduce token-level alignment with explicit supervision or heavy cross-attention designs. We propose ExpAlign, a theoretically grounded vision-language alignment framework built on a principled multiple instance learning formulation. ExpAlign introduces an Expectation Alignment Head that performs attention-based soft MIL pooling over token-region similarities , enabling implicit token and instance selection without additional annotations. To further stabilize alignment learning, we develop an energy-based multi-scale consistency regularization scheme, including a Top-K multi-positive contrastive objective and a Geometry-Aware Consistency Objective derived from a Lagrangian-constrained free-energy minimization . Extensive experiments show that ExpAlign consistently improves open-vocabulary detection and zero-shot instance segmentation , particularly on long-tail categories. Most notably, it achieves 36.2 AP_r on the LVIS minival split , outperforming other state-of-the-art methods at comparable model scale, while remaining lightweight and inference-efficient.",
    "summary_en": "ExpAlign presents a vision-language alignment framework using multiple instance learning and attention-based pooling to improve open-vocabulary detection and zero-shot instance segmentation without additional annotations.",
    "summary_zh": "ExpAlign 提出了一种视觉-语言对齐框架，利用多示例学习与注意力池化，在无需额外标注的情况下提升开放词汇检测与零样本实例分割性能。",
    "upvotes": 3
  },
  {
    "id": "2601.22032",
    "date": "2026-02-02",
    "title": "Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving",
    "authors": "Linhan Wang Zichong Yang Chen Bai Guoxiang Zhang Xiaotong Liu Xiaoyin Zheng Xiao-Xiao Long Chang-Tien Lu Cheng Lu",
    "abstract": "Drive-JEPA combines V-JEPA video pretraining with multimodal trajectory distillation to achieve state-of-the-art performance in end-to-end autonomous driving. End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors . In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture ( V-JEPA ) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM , the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.",
    "summary_en": "Drive-JEPA combines V-JEPA video pretraining with multimodal trajectory distillation to achieve state-of-the-art performance in end-to-end autonomous driving.",
    "summary_zh": "Drive-JEPA 结合 V-JEPA 视频预训练与多模态轨迹蒸馏，在端到端自动驾驶中实现了最先进的性能。",
    "upvotes": 3
  },
  {
    "id": "2601.15394",
    "date": "2026-02-02",
    "title": "Memorization Dynamics in Knowledge Distillation for Language Models",
    "authors": "Jaydeep Borkar Karan Chadha Niloofar Mireshghallah Yuchen Zhang Irina-Elena Veliche Archi Mitra David A. Smith Zheng Xu Diego Garcia-Olano",
    "abstract": "Knowledge distillation reduces training data memorization compared to standard fine-tuning while maintaining performance, with distinct memorization patterns and predictability based on input characteristics. Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy , KL divergence , and perplexity ; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits 2.7times more teacher-specific examples than soft distillation . Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.",
    "summary_en": "Knowledge distillation reduces training data memorization compared to standard fine-tuning while maintaining performance, with distinct memorization patterns and predictability based on input characteristics.",
    "summary_zh": "与标准微调相比，知识蒸馏在保持性能的同时减少了训练数据记忆，并具有独特的记忆模式与基于输入特征的可预测性。",
    "upvotes": 3
  },
  {
    "id": "2601.22680",
    "date": "2026-02-02",
    "title": "Visual Personalization Turing Test",
    "authors": "Rameen Abdal James Burgess Sergey Tulyakov Kuan-Chieh Jackson Wang",
    "abstract": "A new evaluation framework called VPTT assesses contextual visual personalization through perceptual indistinguishability from human-created content, utilizing a benchmark, retrieval-augmented generator, and calibrated text-based metric.",
    "summary_en": "A new evaluation framework called VPTT assesses contextual visual personalization through perceptual indistinguishability from human-created content, utilizing a benchmark, retrieval-augmented generator, and calibrated text-based metric.",
    "summary_zh": "一个名为VPTT的新型评估框架利用基准测试、检索增强生成器和经过校准的基于文本的指标，通过与人类创作内容的感知不可区分性来评估上下文视觉个性化。",
    "upvotes": 2
  },
  {
    "id": "2601.22141",
    "date": "2026-02-02",
    "title": "Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data",
    "authors": "Grzegorz Stefanski Alberto Presta Michal Byra",
    "abstract": "Routing the Lottery framework discovers multiple specialized subnetworks tailored to different data conditions, outperforming traditional pruning methods while using fewer parameters and identifying subnetwork collapse issues. In pruning, the Lottery Ticket Hypothesis posits that large networks contain sparse subnetworks, or winning tickets , that can be trained in isolation to match the performance of their dense counterparts. However, most existing approaches assume a single universal winning ticket shared across all inputs, ignoring the inherent heterogeneity of real-world data. In this work, we propose Routing the Lottery (RTL), an adaptive pruning framework that discovers multiple specialized subnetworks, called adaptive tickets , each tailored to a class, semantic cluster, or environmental condition. Across diverse datasets and tasks, RTL consistently outperforms single- and multi-model baselines in balanced accuracy and recall, while using up to 10 times fewer parameters than independent models and exhibiting semantically aligned. Furthermore, we identify subnetwork collapse , a performance drop under aggressive pruning, and introduce a subnetwork similarity score that enables label-free diagnosis of oversparsification. Overall, our results recast pruning as a mechanism for aligning model structure with data heterogeneity, paving the way toward more modular and context-aware deep learning.",
    "summary_en": "Routing the Lottery framework discovers multiple specialized subnetworks tailored to different data conditions, outperforming traditional pruning methods while using fewer parameters and identifying subnetwork collapse issues.",
    "summary_zh": "Routing the Lottery 框架发现多个针对不同数据条件定制的专用子网络，在使用更少参数的同时性能优于传统剪枝方法，并识别出子网络崩溃问题。",
    "upvotes": 2
  },
  {
    "id": "2601.21709",
    "date": "2026-02-02",
    "title": "Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis",
    "authors": "Qingyue Yang Jie Wang Xing Li Yinqi Bai Xialiang Tong Huiling Zhen Jianye Hao Mingxuan Yuan Bin Li",
    "abstract": "Temporal Attention Pattern Predictability Analysis (TAPPA) provides a unified framework for understanding attention patterns in large language models by analyzing their mathematical formulations from a temporal perspective, distinguishing predictable from unpredictable patterns based on query self-similarity. Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce Temporal Attention Pattern Predictability Analysis ( TAPPA ), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings ( RoPE ). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM- TAPPA .",
    "summary_en": "Temporal Attention Pattern Predictability Analysis (TAPPA) provides a unified framework for understanding attention patterns in large language models by analyzing their mathematical formulations from a temporal perspective, distinguishing predictable from unpredictable patterns based on query self-similarity.",
    "summary_zh": "时序注意力模式可预测性分析（TAPPA）通过从时间视角分析大语言模型的数学公式，基于查询自相似性区分可预测与不可预测的模式，为理解注意力模式提供了统一框架。",
    "upvotes": 2
  },
  {
    "id": "2601.21666",
    "date": "2026-02-02",
    "title": "SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding",
    "authors": "Ahmed Y. Radwan Christos Emmanouilidis Hina Tabassum Deval Pandya Shaina Raza",
    "abstract": "A comprehensive benchmark for evaluating multimodal large language models on sequential audio-video data across real-world conversational domains with human-verified annotations and demographic metadata. Multimodal Large Language Models (MLLMs) are a major focus of recent AI research. However, most prior work focuses on static image understanding, while their ability to process sequential audio-video data remains underexplored. This gap highlights the need for a high-quality benchmark to systematically evaluate MLLM performance in a real-world setting. We introduce SONIC-O1, a comprehensive, fully human-verified benchmark spanning 13 real-world conversational domains with 4,958 annotations and demographic metadata. SONIC-O1 evaluates MLLMs on key tasks, including open-ended summarization, multiple-choice question (MCQ) answering, and temporal localization with supporting rationales (reasoning). Experiments on closed- and open-source models reveal limitations. While the performance gap in MCQ accuracy between two model families is relatively small, we observe a substantial 22.6% performance difference in temporal localization between the best performing closed-source and open-source models. Performance further degrades across demographic groups, indicating persistent disparities in model behavior. Overall, SONIC-O1 provides an open evaluation suite for temporally grounded and socially robust multimodal understanding . We release SONIC-O1 for reproducibility and research: Project page: https://vectorinstitute.github.io/sonic-o1/ Dataset: https://huggingface.co/datasets/vector-institute/sonic-o1 Github: https://github.com/vectorinstitute/sonic-o1 Leaderboard: https://huggingface.co/spaces/vector-institute/sonic-o1-leaderboard",
    "summary_en": "A comprehensive benchmark for evaluating multimodal large language models on sequential audio-video data across real-world conversational domains with human-verified annotations and demographic metadata.",
    "summary_zh": "一项综合基准，用于评估多模态大语言模型在真实世界对话领域中对时序音视频数据的理解能力，包含人工验证的标注与人口统计学元数据。",
    "upvotes": 2
  },
  {
    "id": "2601.21526",
    "date": "2026-02-02",
    "title": "KAPSO: A Knowledge-grounded framework for Autonomous Program Synthesis and Optimization",
    "authors": "Alireza Nadaf Alireza Mohammadshahi Majid Yazdani",
    "abstract": "KAPSO is a modular framework for autonomous program synthesis that uses iterative optimization loops with experimentation tracking, knowledge integration, and cognitive memory to improve code generation over extended tasks.",
    "summary_en": "KAPSO is a modular framework for autonomous program synthesis that uses iterative optimization loops with experimentation tracking, knowledge integration, and cognitive memory to improve code generation over extended tasks.",
    "summary_zh": "KAPSO 是一个用于自主程序合成的模块化框架，采用包含实验追踪、知识整合和认知记忆的迭代优化循环，以改进扩展任务中的代码生成。",
    "upvotes": 2
  },
  {
    "id": "2601.23134",
    "date": "2026-02-02",
    "title": "Machine Learning for Energy-Performance-aware Scheduling",
    "authors": "Zheyuan Hu Yifei Shi",
    "abstract": "A Bayesian Optimization approach using Gaussian Processes automates scheduling configuration optimization on heterogeneous multi-core systems while approximating the Pareto Frontier for energy-time trade-offs. In the post-Dennard era, optimizing embedded systems requires navigating complex trade-offs between energy efficiency and latency. Traditional heuristic tuning is often inefficient in such high-dimensional, non-smooth landscapes. In this work, we propose a Bayesian Optimization framework using Gaussian Processes to automate the search for optimal scheduling configurations on heterogeneous multi-core architectures. We explicitly address the multi-objective nature of the problem by approximating the Pareto Frontier between energy and time. Furthermore, by incorporating Sensitivity Analysis ( fANOVA ) and comparing different covariance kernels (e.g., Matérn vs. RBF ), we provide physical interpretability to the black-box model, revealing the dominant hardware parameters driving system performance.",
    "summary_en": "A Bayesian Optimization approach using Gaussian Processes automates scheduling configuration optimization on heterogeneous multi-core systems while approximating the Pareto Frontier for energy-time trade-offs.",
    "summary_zh": "利用高斯过程的贝叶斯优化方法可在异构多核系统上自动优化调度配置，并逼近能耗-时间权衡的帕累托前沿。",
    "upvotes": 1
  },
  {
    "id": "2601.22108",
    "date": "2026-02-02",
    "title": "Value-Based Pre-Training with Downstream Feedback",
    "authors": "Shuqi Ke Giulia Fanti",
    "abstract": "V-Pretraining uses downstream task gradients to reshape pretraining objectives, improving model capabilities with minimal labeled data and reduced computational costs. Can a small amount of verified goal information steer the expensive self-supervised pretraining of foundation models? Standard pretraining optimizes a fixed proxy objective (e.g., next-token prediction ), which can misallocate compute away from downstream capabilities of interest. We introduce V- Pretraining : a value-based, modality-agnostic method for controlled continued pretraining in which a lightweight task designer reshapes the pretraining task to maximize the value of each gradient step. For example, consider self-supervised learning (SSL) with sample augmentation . The V- Pretraining task designer selects pretraining tasks (e.g., augmentations) for which the pretraining loss gradient is aligned with a gradient computed over a downstream task (e.g., image segmentation). This helps steer pretraining towards relevant downstream capabilities. Notably, the pretrained model is never updated on downstream task labels; they are used only to shape the pretraining task. Under matched learner update budgets, V- Pretraining of 0.5B--7B language models improves reasoning ( GSM8K test Pass@1) by up to 18% relative over standard next-token prediction using only 12% of GSM8K training examples as feedback. In vision SSL, we improve the state-of-the-art results on ADE20K by up to 1.07 mIoU and reduce NYUv2 RMSE while improving ImageNet linear accuracy, and we provide pilot evidence of improved token efficiency in continued pretraining .",
    "summary_en": "V-Pretraining uses downstream task gradients to reshape pretraining objectives, improving model capabilities with minimal labeled data and reduced computational costs.",
    "summary_zh": "V-Pretraining利用下游任务梯度重塑预训练目标，仅需少量标注数据并降低计算成本即可提升模型能力。",
    "upvotes": 1
  }
]